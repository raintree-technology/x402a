<SYSTEM>This is the full developer documentation for Aptos Documentation</SYSTEM>

# Build the Future of Web3 on Aptos


> Everything you need to build a best-in-class Web3 experience.

import { Card, CardGrid, Tabs, TabItem } from '@astrojs/starlight/components';
import ListCard from '~/components/ListCard.astro';

<CardGrid>
  <ListCard title="Features" iconName="lightning">
    - [Keyless](/build/guides/aptos-keyless)
    - [Passkeys](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-66.md)
    - [On-chain Randomness](/build/smart-contracts/randomness)
    - [Gas and Storage Fees](/network/blockchain/gas-txn-fee)
    - [Parallel Execution](/network/blockchain/execution)
    - [Fee Payer](/build/sdks/ts-sdk/building-transactions/sponsoring-transactions)
  </ListCard>

  <ListCard title="Tooling" iconName="terminal">
    - [Aptos CLI](/build/cli)
    - [VSCode Extension](/build/smart-contracts/move-vscode-extension)
    - [Indexer API](/build/indexer/indexer-api)
    - [Official SDKs](/build/sdks)
    - [Testnet Faucet](/network/faucet)
    - [Faucet API](/build/apis/faucet-api)
  </ListCard>

  <ListCard title="Resources" iconName="file-text">
    - [Apply for a Grant](https://aptosnetwork.com/grants)
    - [Aptos Learn](https://learn.aptoslabs.com)
    - [Ecosystem Projects](https://aptosnetwork.com/ecosystem/directory)
  </ListCard>

  <ListCard title="Connect" iconName="globe-simple">
    - [Developer Discussions](https://github.com/aptos-labs/aptos-developer-discussions/discussions)
    - [Discussion Forum](https://forum.aptosfoundation.org)
    - [Discord](https://discord.gg/aptosnetwork)
    - [Telegram](https://t.me/aptos)
  </ListCard>
</CardGrid>

# Aptos Model Context Protocol (MCP)

> Learn how to use the Aptos MCP server to build applications with AI tools like Cursor and Claude Code

import { CardGrid, LinkCard } from '@astrojs/starlight/components';

The Aptos Model Context Protocol (MCP) is a server that provides a set of tools, prompts, and resources to help
developers build applications on the Aptos blockchain. It is designed to be used with AI tools like Cursor, Claude Code,
and others that support the Model Context Protocol.

## Getting Started

### Prerequisites

- [node and npm](https://nodejs.org/en)
- Build Bot Api Key

### Generate a Build Bot Api Key

To be able to make Geomi actions like managing API keys, etc., follow these instructions to generate a new Bot API Key to use with the MCP.

- Go to [https://geomi.dev/](https://geomi.dev/)
- Click on your name in the bottom left corner
- Click on "Bot Keys"
- Click on the "Create Bot Key" button
- Copy the Bot Key and paste it into the MCP configuration file as an env arg: `APTOS_BOT_KEY=<your-bot-key>`

### Supported Interfaces

We've provided guides for Cursor and Claude Code to help you integrate the Aptos MCP into your development environment.
If you're using a different AI tool, follow the steps for your favorite AI tool, and refer to the documentation for
Cursor or Claude Code for examples.

<CardGrid>
  <LinkCard href="/build/ai/aptos-mcp/claude" title="Claude Code" description="Set up for Claude Code" />

  <LinkCard href="/build/ai/aptos-mcp/cursor" title="Cursor" description="Set up for Cursor" />
</CardGrid>

# Setting up Aptos MCP with Claude Code

> Step-by-step guide to configure and use Aptos MCP with Claude Code for blockchain development

1. Install the `claude-code` package

```bash
npm install -g @anthropic-ai/claude-code
```

2. Locate where Claude Code stores its configuration, usually on Mac it is at `~/.claude.json`
3. Edit the `mcpServers` object in the `json` file with

```json
{
  "mcpServers": {
    "aptos-mcp": {
      "command": "npx",
      "args": ["-y", "@aptos-labs/aptos-mcp"],
      "type": "stdio",
      "env": {
        "APTOS_BOT_KEY": "<bot_api_key>"
      }
    }
  }
}
```

4. Obtain your `APTOS_BOT_KEY`:

- Visit [Geomi](https://geomi.dev/) and log in with your account.
- Navigate to the API Keys section and create a new key.
- Copy the generated key for use in the next step.

5. Make sure to update the `APTOS_BOT_KEY` with the key you generated in the previous step.

6. Navigate to your project

```bash
cd your-awesome-project
```

7. In a new terminal window type:

```bash
claude
```

8. You can now use Claude Code to interact with the Aptos MCP. Prompt the agent with `what aptos mcp version are you using?` to verify the connection. The agent should reply with something like:

```text
I'm using Aptos MCP version 0.0.2.
```

# Setting up Aptos MCP with Cursor

> Complete guide to integrate Aptos MCP with Cursor IDE for enhanced blockchain development workflows

1. Open the Cursor IDE
2. On the project root folder, create a `.cursor` folder
3. In the `.cursor` folder, create a `mcp.json` file
4. Paste this content

```json
{
  "mcpServers": {
    "aptos-mcp": {
      "command": "npx",
      "args": ["-y", "@aptos-labs/aptos-mcp"],
      "env": {
        "APTOS_BOT_KEY": "<bot_api_key>"
      }
    }
  }
}
```

5. Obtain your `APTOS_BOT_KEY`:
   - Visit [Geomi](https://geomi.dev/) and log in with your account.
   - Navigate to the API Keys section and generate a new key.
   - Copy the generated key for use in the next step.

6. Make sure to update the `APTOS_BOT_KEY` in the `mcp.json` file with the key you just generated.

### Verify Cursor runs your MCP

1. Open Cursor Settings: `cursor -> settings -> cursor settings`
2. Head to the `MCP` or `Tools & Integrations` section
3. Make sure it is enabled and showing a green color indicator

![Make sure it is enabled and showing a green color indicator](~/images/cursor/verify-cursor_step-3.png)

4. Click the ‚Äúrefresh‚Äù icon to update the MCP.

5. Make sure the Cursor AI window dropdown is set to `Agent`

![Make sure the Cursor AI window dropdown is set to Agent](~/images/cursor/verify-cursor_step-5.png)

6. Prompt the agent with `what aptos mcp version are you using?` to verify the connection. The agent should reply with something like:

![Prompt the agent with what aptos mcp version are you using? to verify the connection.](~/images/cursor/verify-cursor_step-6.png)

# Aptos Improvement Proposals (AIPs)

> Learn about Aptos Improvement Proposals - how the community proposes changes and improvements to the Aptos protocol

Aptos Improvement Proposals (AIPs) are a way for the Aptos community to propose
changes, improvements, and new features to the Aptos protocol. AIPs are designed
to be a collaborative process that allows anyone in the community to contribute
ideas and feedback.

AIPs are documented in the [AIPs repository](https://github.com/aptos-foundation/AIPs)
and are administered by the Aptos Foundation. Each AIP is assigned a unique
number and goes through a rigorous review process before it is accepted or rejected.

## What do AIPs cover?

AIPs can cover a wide range of topics, including:

- Node protocol changes - Mempool changes, consensus changes, etc.
- Framework (smart contract) changes - New modules, new functions, etc.
- Governance changes - Changes to the way the Aptos Foundation operates, changes
  to the way AIPs are processed, etc.

## What is this section of the docs mostly about?

This section of the docs is mostly about AIPs that are relevant to developers
and providing FAQs and quick information about them.

# AIP-115: Stateless Accounts

> Learn about AIP-115 which introduces stateless accounts that operate without explicitly created Account resources

[AIP-115](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-115.md) covers
stateless accounts.

## General FAQ

### What is a Stateless Account?

A Stateless Account is a new behavior for Aptos accounts that allows them to
operate without requiring an explicitly created `0x1::account::Account` resource.
Instead, these accounts use default behaviors until an action necessitates the
creation of the resource. This change simplifies account management and reduces
unnecessary resource creation, making it easier for developers and users to
interact with the Aptos blockchain.

### How is it different from a regular account?

Technically, there is no separate account type. All accounts are the same under
the hood. The difference is that accounts without a resource behave in a
"stateless" manner using default values. The account resource is only created
on-demand when needed.

### How does it work?

When an account signs its first transaction sequence number transaction, it
will not have the `0x1::account::Account` resource created. Instead, it will
create the `0x1::account::Account` resource only when an action that requires to
increment the sequence number.

For an orderless transaction, the account resource is not needed at all, and the
account resource will not be created.

## Technical Details FAQ

### What is the default auth\_key for Stateless Accounts?

If the `0x1::account::Account` resource does not exist, the auth\_key defaults to
the account address itself. This allows the account to sign and submit
transactions without needing a resource.

### What is the sequence number of a Stateless Account?

It defaults to `0` if the account resource does not exist. In the future, with
Orderless Transactions, the sequence number may be eliminated entirely.

### When is the account resource automatically created?

The resource is created when an action that requires on-chain state, such as:

- Rotating the authentication key
- Using capabilities or features that rely on the account resource such as sequence number
- Explicitly calling functions that access fields in the account resource

### Does creating the account resource incur extra gas cost?

Yes. The creation of the resource is deferred, and the corresponding gas and
storage fees are only charged at the moment of actual creation, not beforehand.

### Any behavior change to account module at the Move level?

`0x1::account::exists_at` always returns true, as all on-chain account addresses
are considered valid and treated as existing by default. There is no move
function in the module to check whether the underlying account resource really
exists since the goal is to make it transparent to users. As a result, any logic
that first checks whether an account exists before attempting to create it is
now obsolete.

### Can users force-create the account resource upfront?

Yes. Users can explicitly call functions like
`0x1::account::create_account_if_does_not_exist` to create the resource
manually, if desired.

### Any behavior change to API?

If you rely on the following API behavior, please adjust correspondingly.
`GET /accounts/{address}` will never return ‚Äú404 not found‚Äù but the default
authentication key and sequence number mentioned above for stateless accounts.
Therefore, if it is desired to check whether the account resource exists or not,
try `GET /accounts/{address}/resource/0x1::account::Account`

### Do existing accounts get affected?

No. Existing accounts with resources already created will continue to work
exactly as they do now. Stateless Account behavior only applies to accounts that
have not yet created a resource.

### Do dApps / CEX need to change anything?

Maybe. Previously, checking whether an account existed often relied on calling
APIs that return a 404 error if the account resource was not found. Applications
would then use this as a signal to warn users (e.g., "This account does not
exist"). Under the new model, all addresses are considered valid, and such
404-based existence checks are no longer reliable or meaningful. However, we are
not banning this pattern‚Äîdevelopers may still choose to warn users that an
account may not have performed any on-chain activity and thus might not have a
resource created yet.

If you still want to detect whether an account has an associated resource, you
can refer to the method described in Q9 or check whether the sequence\_number is
0\. But be aware that with the introduction of orderless transactions, some
accounts may only submit transactions that never create a resource, which could
result in false negatives.

We recommend designing your application to be robust regardless of whether the
account resource exists, and to avoid assuming resource presence as a proxy for
account existence.

Examples:

- A wallet might check for an account to see if it‚Äôs a new account, and provide
  a user a warning.  With this change, instead a mitigation like Q9 will be needed.
- A custodial wallet may send funds to initialize an account with gas.  With
  this change, it will need to check the account‚Äôs balance instead of just the
  account existing.

### Is this compatible with Orderless Transactions?

Yes. Orderless Transactions and Stateless Accounts are complementary. Once
Orderless Transactions are enabled, sequence numbers will no longer be needed,
enabling truly stateless usage.

## Will all accounts become Stateless in the future?

No. Stateless Accounts are not a new account type. It simply allows accounts to
behave with default logic until the account resource is needed. This lazy
resource creation, does not transform existing account state. All accounts can
behave in a stateless way by default, but they will still create the standard
resource if and when advanced features are used.

# AIP-88: Block Epilogue Transactions

> Understanding AIP-88 which introduces block epilogue transactions to provide information about executed blocks

[AIP-88](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-88.md) covers
block epilogue transactions, which are a new type of transaction that give
information about the block after it has been executed. These transactions can
only be created by the consensus and are not user-initiated.  They contain
information about gas usage in the block and will contain more information in
the future.

It replaces the previous `StateCheckpoint` transaction type, which was used to
"sometimes" signal the end of a block.  The new `BlockEpilogue` transaction is
now sometimes created at the end of a block instead, and it is guaranteed to be
the last transaction in the block.  The only case this does not apply is the
last block of an epoch, which will have no `BlockEpilogue` transaction.

## General FAQ

### What is in the Block Epilogue Transaction?

The block epilogue transaction contains a `BlockEndInfo` enum.  It is purposely
designed to be an enum so that it can be extended in the future without breaking
existing code.  The current version is `V0` and contains the following fields:

```move
module 0x1::epilogue {
  enum BlockEndInfo {
    V0 {
      /// Whether block gas limit was reached
      block_gas_limit_reached: bool,
      /// Whether block output limit was reached
      block_output_limit_reached: bool,
      /// Total gas_units block consumed
      block_effective_block_gas_units: u64,
      /// Total output size block produced
      block_approx_output_size: u64,
    },
  }
}
```

These mainly contain information about the gas usage in the block for debugging
purposes.

The JSON output will look like this:

```json
{
    "version":"1912",
    "hash":"0x54a8efc93fc94f5b545dadb63da3d4dc192125c717b336dc446d55a5b553913f",
    "state_change_hash":"0xafb6e14fe47d850fd0a7395bcfb997ffacf4715e0f895cc162c218e4a7564bc6",
    "event_root_hash":"0x414343554d554c41544f525f504c414345484f4c4445525f4841534800000000",
    "state_checkpoint_hash":"0x841a43956ca09a02b1c1cdadc65f24c390170aa666015a2e8f7ec5c9d6a3875f",
    "gas_used":"0",
    "success":true,
    "vm_status":"Executed successfully",
    "accumulator_root_hash":"0x6561976b4560ff25239dffc6cada70e7008dd42fc4d3df2eca6a86b6d2ec384d",
    "changes":[],
    "timestamp":"1719263322836578",
    "block_end_info": {
        "block_gas_limit_reached":false,
        "block_output_limit_reached":false,
        "block_effective_block_gas_units":0,
        "block_approx_output_size":1163
    },
    "type":"block_epilogue_transaction"
}
```

## Compatibility FAQ

### What does this mean for my dApp?

If you process transactions in your dApp, and expect the last transaction in a
block to be a `StateCheckpoint`, you will need to update your code to handle the
`BlockEpilogue` transaction instead.

Note that, the `BlockEpilogue` transaction is guaranteed to be the last
transaction of a block except for the last block of an epoch, which will not
have a `BlockEpilogue` transaction.

### What apps are likely to be affected?

Apps that index all transactions such as block explorers and centralized
exchange indexer processors may be affected.  However, most of these are
informational and do not affect the core functionality of the dApp.

### What can I do to process the new transaction type?

If you're using the Aptos Go SDK or the Aptos TypeScript SDK, you can update to
the latest version, which will automatically handle the new transaction type.

# Aptos APIs

> Access the Aptos blockchain through various APIs including REST API, GraphQL, and specialized endpoints for different use cases

import { CardGrid, LinkCard } from '@astrojs/starlight/components';

The Aptos Blockchain network can be accessed by several APIs, depending on your use-case.

## Aptos Fullnode

This API - embedded into Fullnodes - provides a simple, low latency, yet low-level way of _reading_ state and
_submitting_ transactions to the Aptos Blockchain. It also supports transaction simulation.

<CardGrid>
  <LinkCard href="/build/apis/fullnode-rest-api?network=mainnet" title="Aptos Fullnode REST API (Mainnet)" description="Mainnet API playground for Aptos Fullnode REST API" />

  <LinkCard href="/build/apis/fullnode-rest-api?network=testnet" title="Aptos Fullnode REST API (Testnet)" description="Testnet API playground for Aptos Fullnode REST API" />

  <LinkCard href="/build/apis/fullnode-rest-api?network=devnet" title="Aptos Fullnode REST API (Devnet)" description="Devnet API playground for Aptos Fullnode REST API" />
</CardGrid>

## Indexer

<CardGrid>
  <LinkCard
    href="/build/indexer"
    title="Indexer GraphQL API"
    description="This GraphQL API offers a high-level, opinionated GraphQL interface to read state from the Aptos Blockchain.
It's ideal for interacting with NFTs, Aptos Objects, or custom Move contracts.
Learn more about the Indexer-powered GraphQL API here."
  />

  <LinkCard
    href="/build/indexer/txn-stream"
    title="Transaction Stream API"
    description="This GRPC API streams historical and real-time transaction data to an indexing processor.
It's used by Aptos Core Indexing and can also support custom app-specific indexing processors
for real-time blockchain data processing. Learn more here."
  />
</CardGrid>

## Faucet (Only Testnet/Devnet)

<CardGrid>
  <LinkCard
    href="/build/apis/faucet-api"
    title="Faucet API"
    description="This API provides the ability to receive test tokens on devnet. Its primary purpose is the development
and testing of applications and Move contracts before deploying them to mainnet. On testnet you can mint at the mint page."
  />
</CardGrid>

The code of each of the above-mentioned APIs is open-sourced on [GitHub](https://github.com/aptos-labs/aptos-core). As
such anyone can operate these APIs and many independent operators and builders worldwide choose to do so.

### Aptos Labs operated API Deployments

[Aptos Labs](https://aptoslabs.com) operates a deployment of these APIs on behalf of [Aptos Foundation](https://aptosnetwork.com/foundation)
for each [Aptos Network](/network/nodes/networks) and makes them available for public consumption.

These APIs allow for limited access on a per-IP basis without an API key (anonymous access). To get much higher rate limits you can sign up for an [Geomi](https://geomi.dev/) account.

# Aptos Labs Geomi

> Access Aptos Labs APIs, gas station services, and no-code indexing through the Geomi developer portal

[Geomi](https://geomi.dev) is your gateway to access Aptos Labs provided APIs in a quick and easy fashion to power your dapp. Beyond API access it offers gas station and no code indexing services.

Learn more about Geomi at the dedicated [Geomi docs site](https://geomi.dev/docs).

# Data Providers

> Access Aptos blockchain data through SQL interfaces and analytics dashboards for aggregated data analysis

# Data Providers

In addition to the API run by Aptos full nodes, we also provide a few different ways to get Aptos blockchain data.

## Overview of aptos data endpoints

[REST API](/build/apis/fullnode-rest-api) allows you to query the full node directly and will have the latest data (historical data will be missing unless it's an archival full node).

[GRPC transaction stream](/build/indexer/txn-stream/aptos-hosted-txn-stream) is a stream layer we built that serves typed version of above data

[GraphQL](/build/indexer) is an endpoint where we provide product tables (such as transfers and balances) that can be queried

Product tables are parsed out from transaction and logic is [public](https://github.com/aptos-labs/aptos-indexer-processors-v2),
some vendors have implemented similar parsing logic to create a subset of tables and made them available to query.

## SQL Tables

Indexer (the stack that powers our GraphQL endpoint) defines several processors that create different product tables in Postgres.

This type of data is often used for analytics since it allows for aggregations.

### Core tables

These contain raw data very similar to what is found in REST API. Note that (transaction) version is often used instead of transaction hash.

- Blocks - version, block height, epoch, timestamp
- Transactions - version, type, sender, entry function, gas
- Signatures - signature types, signer, fee payer address
- Events - type and data for events

On chain data is stored as: [table items](/build/smart-contracts/table), [resources](/network/blockchain/resources) or [modules](/build/smart-contracts/modules-on-aptos) (executable)

- (write set) changes - change index, change type (write or delete on what type of data), resource address
- Table items - table key, table handle, decoded key (content and type), value (content and type)
- (move) resources - resource address, resource type, data
- (move) modules - bytecode for deployed modules, friends and exposed functions

## Vendors for core tables and metrics:

We have a few options that will let you access this data using SQL or UIs for building dashboards.

### Google bigquery public dataset

Provides data through [google public data](https://console.cloud.google.com/marketplace/product/bigquery-public-data/crypto-aptos-mainnet-us)

![bq\_sql](~/images/screenshots/bq_sql.png)

We also have sample analytics queries [using the above resources](https://github.com/aptos-labs/explorer/tree/main/analytics)

### Dune

We have a dashboard here: [https://dune.com/aptos/aptos-chain-metrics-overview](https://dune.com/aptos/aptos-chain-metrics-overview)

### Allium

Data source for many downstream vendors such as defillama and rwa.xyz. Raw data is available: [https://docs.allium.so/historical-data/supported-blockchains/move-ecosystem/aptos](https://docs.allium.so/historical-data/supported-blockchains/move-ecosystem/aptos)
They also have transfers for stablecoins [https://docs.allium.so/historical-data/stablecoins#stablecoin-metrics](https://docs.allium.so/historical-data/stablecoins#stablecoin-metrics)

### Artemis

Provides [topline metrics](https://app.artemis.xyz/asset/aptos) as well as chart builder

### Nansen

Provides [topline metrics](https://app.nansen.ai/macro/blockchains?chain=aptos) with additional functionality with account.

### Sentio

They have a [guide](https://docs.sentio.xyz/docs/aptos) and
data is found in data source -> external project  -> sentio/aptos-overview
They also provide [stack tracing](https://app.sentio.xyz/explorer) of transactions

### RWA.xyz

High level metrics for RWAs in [dashboard](https://app.rwa.xyz/networks/aptos).
You'll need to make an account to access stablecoin details.

### Pangea

Provides [raw data](https://docs.pangea.foundation/api-reference/aptosvm/reference),
coin/fa transfers, and some dex parsing.

### Other vendors

We also have some partners who target more enterprise use cases

- [Token Terminal](https://tokenterminal.com/resources/articles/aptos-data-partnership)
- [The Tie](https://www.thetie.io/insights/news/introducing-aptos-ecosystem-dashboard-and-on-chain-data/)
- [Elliptic](https://www.elliptic.co/media-center/elliptic-partners-with-aptos-foundation-as-a-data-integration-provider-to-offer-compliance-screening-and-risk-services-for-aptos-network)

## Vendors for real-time data

- [Geomi](https://geomi.dev/) (prev. Aptos Build)
  - Provides [API key](https://geomi.dev/docs/start) for higher rate limits on REST API and GRPC transaction stream.
  - Provides [no code indexing](https://geomi.dev/docs/no-code-indexing) to parse and turn events into tables that can be queried.
- [NODEREAL](https://nodereal.io/aptos) for REST API endpoint
- [SHINAMI](https://docs.shinami.com/reference/api-references-overview) for REST API and GraphQL endpoints
- [QuickNode](https://www.quicknode.com/chains/apt) for REST API endpoint

Additional RPC vendors can be found [here](https://aptosnetwork.com/ecosystem/directory/category/rpc)

## Tips for analyzing data

- Aptos [data overview](https://medium.com/aptoslabs/data-analyst-guide-to-aptos-pt-1-816367edc1c5) (pt.1)
- Parsing [Defi Swaps](https://medium.com/aptoslabs/data-analyst-guide-to-aptos-defi-swaps-pt2-e343ac6be84e) (pt.2)
- Calculating [supply and volume](https://medium.com/aptoslabs/data-analyst-guide-to-aptos-supply-and-volume-pt-3-535e312946ad) (pt.3)
- [Aptos Explorer analytics queries](https://github.com/aptos-labs/explorer/tree/main/analytics)
- [Aptos Spellbook on Dune](https://github.com/duneanalytics/spellbook/tree/main/dbt_subprojects/daily_spellbook/models/aptos)
- Module bytecode can be decompiled with [Revela](https://revela.verichains.io/) or aptos cli with `aptos move decompile --decompiler-version v2`

# Faucet API

> Get free APT tokens on devnet and testnet for development and testing purposes using the faucet API

The faucet allows users to get `APT` on devnet. On testnet you can only mint at the [mint page](/network/faucet). It is not available on Mainnet.

The endpoints for each faucet are:

- Devnet: [https://faucet.devnet.aptoslabs.com](https://faucet.devnet.aptoslabs.com)

## Using the faucet

Each SDK has integration for devnet to use the faucet. Below are a few examples, but you can
see more information on each individual [SDK's documentation](/build/sdks).

### Using the faucet in a wallet

Most wallets, such as [Petra](https://aptosnetwork.com/ecosystem/directory/petra) or [Pontem](https://aptosnetwork.com/ecosystem/directory/pontem-wallet)
will have a faucet button for devnet. See full list of [Aptos Wallets](https://aptosnetwork.com/ecosystem/projects/wallets).

### Using the faucet in the Aptos CLI

Once you've [set up your CLI](/build/cli/setup-cli), you can simply call fund-with-faucet.  The amount used is in Octas (1 APT = 100,000,000 Octas).

```shellscript filename="Terminal"
aptos account fund-with-faucet --account 0xd0f523c9e73e6f3d68c16ae883a9febc616e484c4998a72d8899a1009e5a89d6 --amount 100000000
```

### Using the faucet in the TypeScript SDK

Here is an example funding the account `0xd0f523c9e73e6f3d68c16ae883a9febc616e484c4998a72d8899a1009e5a89d6` with 1 APT in Devnet. The amount used is in Octas (1 APT = 100,000,000 Octas).

```typescript filename="index.ts"
import { Aptos, AptosConfig, Network } from "@aptos-labs/ts-sdk";

const aptos = new Aptos(new AptosConfig({network: Network.Devnet}));
aptos.fundAccount({accountAddress: "0xd0f523c9e73e6f3d68c16ae883a9febc616e484c4998a72d8899a1009e5a89d6", amount: 100000000});
```

### Using the faucet in the Go SDK

Here is an example funding the account `0xd0f523c9e73e6f3d68c16ae883a9febc616e484c4998a72d8899a1009e5a89d6` with 1 APT in Devnet. The amount used is in Octas (1 APT = 100,000,000 Octas).

```go filename="index.go"
import "github.com/aptos-labs/aptos-go-sdk"

func main() {
	client, err := aptos.NewClient(aptos.LocalnetConfig)
	if err != nil {
		panic(err)
	}

  client.Fund("0xd0f523c9e73e6f3d68c16ae883a9febc616e484c4998a72d8899a1009e5a89d6", 100000000)
}
```

### Calling the faucet: Other languages not supported by SDKs

If you are trying to call the faucet in other languages, you have two options:

1. Generate a client from
   the [OpenAPI spec](https://github.com/aptos-labs/aptos-core/blob/main/crates/aptos-faucet/doc/spec.yaml).
2. Call the faucet on your own.

For the latter, you will want to build a query similar to this:

```shellscript filename="Terminal"
curl -X POST
'https://faucet.devnet.aptoslabs.com/mint?amount=10000&address=0xd0f523c9e73e6f3d68c16ae883a9febc616e484c4998a72d8899a1009e5a89d6'
```

This means mint 10000 [octas](/network/glossary#Octa) to
address `0xd0f523c9e73e6f3d68c16ae883a9febc616e484c4998a72d8899a1009e5a89d6`.

# Fullnode REST API

> Low-level REST API for reading state, submitting transactions, and simulating operations on the Aptos blockchain

import { Aside, CardGrid, LinkCard } from '@astrojs/starlight/components';

This API - embedded into Fullnodes - provides a simple, low latency, yet low-level way of reading state and submitting transactions to the Aptos Blockchain. It also supports transaction simulation.
For more advanced queries, we recommend using the [Indexer GraphQL API](/build/indexer).

## Fullnode REST API Explorer

<CardGrid>
  <LinkCard href="https://fullnode.mainnet.aptoslabs.com/v1/spec#/" title="Mainnet Fullnode REST API" description="REST API Explorer for Mainnet" target="_blank" />

  <LinkCard href="https://fullnode.testnet.aptoslabs.com/v1/spec#/" title="Testnet Fullnode REST API" description="REST API Explorer for Testnet" target="_blank" />

  <LinkCard href="https://fullnode.devnet.aptoslabs.com/v1/spec#/" title="Devnet Fullnode REST API" description="REST API Explorer for Devnet" target="_blank" />
</CardGrid>

## Understanding rate limits

As with the [Aptos Indexer](/build/indexer/indexer-api), the Aptos REST API has rate limits based on compute units. You can learn more about how the ratelimiting works by reading the [Geomi docs](https://geomi.dev/docs/admin/billing).

## Viewing current and historical state

Most integrations into the Aptos blockchain benefit from a holistic and comprehensive overview of the current and
historical state of the blockchain. Aptos provides historical transactions, state, and events, all the result of
transaction execution.

- Historical transactions specify the execution status, output, and tie to related events. Each transaction has a unique
  version number associated with it that dictates its global sequential ordering in the history of the blockchain ledger.
- The state is the representation of all transaction outputs up to a specific version. In other words, a state version
  is the accumulation of all transactions inclusive of that transaction version.
- As transactions execute, they may emit events. [Events](/network/blockchain/events) are hints about changes in on-chain
  data.

<Aside type="note">
  Ensure the [fullnode](/network/nodes/networks) you are communicating with is up-to-date. The fullnode must reach the
  version containing your transaction to retrieve relevant data from it. There can be latency from the fullnodes
  retrieving state from [validator fullnodes](/network/blockchain/fullnodes), which in turn rely upon
  [validator nodes](/network/blockchain/validator-nodes) as the source of truth.
</Aside>

The storage service on a node employs two forms of pruning that erase data from nodes:

- state
- events, transactions, and everything else

While either of these may be disabled, storing the state versions is not particularly sustainable.

Events and transactions pruning can be disabled via setting the [`enable_ledger_pruner`](https://github.com/aptos-labs/aptos-core/blob/cf0bc2e4031a843cdc0c04e70b3f7cd92666afcf/config/src/config/storage_config.rs#L141)
to `false` in `storage_config.rs`. This is default behavior in Mainnet. In the near future, Aptos will provide indexers
that mitigate the need to directly query from a node.

The REST API offers querying transactions and events in these ways:

- [Transactions for an account](https://api.devnet.aptoslabs.com/v1/spec#/operations/get_account_transactions)
- [Transactions by version](https://api.devnet.aptoslabs.com/v1/spec#/operations/get_transaction_by_version)
- [Events by event handle](https://api.devnet.aptoslabs.com/v1/spec#/operations/get_events_by_event_handle)

## Reading state with the View function

View functions do not modify blockchain state when called from the API. A [View function](https://github.com/aptos-labs/aptos-core/blob/main/api/src/view_function.rs)
and its [input](https://github.com/aptos-labs/aptos-core/blob/main/api/types/src/view.rs) can be used to read
potentially complex on-chain state using Move. For example, you can evaluate who has the highest bid in an auction
contract. Here are related files:

- [`view_function.rs`](https://github.com/aptos-labs/aptos-core/blob/main/api/src/tests/view_function.rs) for an example
- related [Move](https://github.com/aptos-labs/aptos-core/blob/90c33dc7a18662839cd50f3b70baece0e2dbfc71/aptos-move/framework/aptos-framework/sources/coin.move#L226) code
- [specification](https://github.com/aptos-labs/aptos-core/blob/90c33dc7a18662839cd50f3b70baece0e2dbfc71/api/doc/spec.yaml#L8513).

The view function operates like the Aptos simulation API,
though with no side effects and an accessible output path. View functions can be called via the `/view` endpoint. Calls
to view functions require the module and function names along with input type parameters and values.

A function does not have to be immutable to be tagged as `#[view]`, but if the function is mutable it will not result in
state mutation when called from the API. If you want to tag a mutable function as `#[view]`, consider making it private
so that it cannot be maliciously called during runtime.

In order to use the View functions, you need to [publish the module](/build/cli/working-with-move-contracts)
through the [Aptos CLI](/build/cli).

In the Aptos CLI, a view function request would look like this:

```shellscript filename="Terminal"
aptos move view --function-id devnet::message::get_message --profile devnet --args address:devnet
{
  "Result": [
    "View functions rock!"
  ]
}
```

In the TypeScript SDK, a view function request would look like this:

```typescript filename="index.ts"
import { Aptos } from "@aptos-labs/ts-sdk";

const aptos = new Aptos();
const [balance] = aptos.view<[string]>({
  function: "0x1::coin::balance",
  typeArguments: ["0x1::aptos_coin::AptosCoin"],
  functionArguments: [alice.accountAddress]
});

expect(balance).toBe("100000000");
```

The view function returns a list of values as a vector. By default, the results are returned in JSON format; however,
they can be optionally returned in Binary Canonical Serialization (BCS) encoded format.

# Fullnode API Reference

> Complete API reference documentation for the Aptos Fullnode REST API endpoints and methods

{/* <DynamicApiReference /> */}

# Aptos CLI ‚Äì Install, Setup, and Use the Command-Line Interface

> Learn how to install, configure, and use the Aptos CLI to compile Move contracts, interact with the blockchain, run a local network, and manage nodes.

import { CardGrid, LinkCard } from '@astrojs/starlight/components';

The Aptos command line interface (CLI) is a tool to help you compile and test Move contracts. It can also help you quickly play with Aptos features on-chain.

For more advanced users, the CLI can also be used to run a private Aptos network (to help test code locally) and can be helpful managing a network node.

## üì• Install the Aptos CLI

<CardGrid>
  <LinkCard href="/build/cli/install-cli/install-cli-mac" title="Mac" description="Install Aptos CLI via homebrew" />

  <LinkCard href="/build/cli/install-cli/install-cli-windows" title="Windows" description="Install Aptos CLI on Windows via powershell script or pre-compiled binary" />

  <LinkCard href="/build/cli/install-cli/install-cli-linux" title="Linux" description="Install Aptos CLI on Linux via shell script or pre-compiled binary" />

  <LinkCard href="/build/cli/install-cli/install-cli-specific-version" title="Advanced (Install Specific Versions)" description="Build a specific version of the Aptos CLI from source" />
</CardGrid>

## ‚öôÔ∏è Setup the Aptos CLI

<CardGrid>
  <LinkCard href="/build/cli/setup-cli" title="Setup the CLI" description="Setup and configure the Aptos CLI " />

  <LinkCard href="/build/cli/setup-cli/install-move-prover" title="Advanced (Move Prover)" description="Setup and install the Move Prover" />
</CardGrid>

## üõ†Ô∏è Using the Aptos CLI

<CardGrid>
  <LinkCard href="/build/cli/working-with-move-contracts" title="Move Contracts" description="Compile, Publish, Simulate, and Benchmark Move Contracts " />

  <LinkCard href="/build/cli/trying-things-on-chain" title="Trying things On-chain" description="Interact with Aptos, create accounts, query accounts, use a hardware device like Ledger" />

  <LinkCard href="/build/cli/running-a-local-network" title="Running a Local Network" description="Run a local node / network" />
</CardGrid>

# Formatting Move Contracts

> Learn how to format and beautify Move smart contract code using the movefmt tool integrated into the Aptos CLI with configuration options.

`movefmt` is a formatter tool that makes Move code much easier to write, read, and maintain ‚Äî greatly improving the development experience on Aptos.

## Installation

`movefmt` is integrated into the Aptos CLI. To begin using it, first install it using the CLI update command.

```shellscript filename="Terminal"
# Install movefmt for first time usage
aptos update movefmt
```

To install a specific version of `movefmt`:

```shellscript filename="Terminal"
# Install movefmt with the target <VERSION>
aptos update movefmt --target-version <VERSION>
```

The latest release of `movefmt` can be found [here](https://github.com/movebit/movefmt/releases).

## Format your code

Similar to compilation and testing, you can use the following command to format the Move package:

```shellscript filename="Terminal"
# Format the Move package
aptos move fmt
```

Different ways of emitting the formatting result is supported:

```shellscript filename="Terminal"
# Format and overwrite all the target move files in the package.
# This is the default behavior if `--emit-mode` is not explicitly specified
aptos move fmt --emit-mode=overwrite

# Print the formatting result to terminal
aptos move fmt --emit-mode=std-out

# Print the formatting result to new files with the suffix `.fmt.out` in the same directory
aptos move fmt --emit-mode=new-file

# Print the difference between before and after formatting
aptos move fmt --emit-mode=diff
```

`movefmt` also provides different options to configure how the code will be formatted.
Here is the default configuration:

```
max_width = 90 # each line can have at most 90 characters
indent_size = 4 # the indent is 4 spaces
tab_spaces = 4 # each tab is identical to 4 spaces
hard_tabs = false # when a tab is inserted, it will be automatically replaced by 4 spaces
```

To override the default option, users can either specify a configuration file `movefmt.toml`
and put it in Move package directory or manually specify it in the command line:

```shellscript filename="Terminal"
# When formatting the code, set `max_width` to 80 and `indent_size` to 2
aptos move fmt --config max_width=80,indent_size=2
```

## Feedback

Aptos Labs remains committed to improving the developer experience for builders using Move on Aptos.
If you‚Äôre interested in shaping the style guidelines for Move, we would love to hear your comments and feedback
[here](https://github.com/movebit/movefmt/issues).

# Install Aptos CLI with ASDF or Mise

> Install the Aptos CLI or specific versions with the ASDF or Mise package managers.

import { Steps } from '@astrojs/starlight/components';

If you're already using the ASDF or Mise package managers, you can install the Aptos CLI with the following steps.

## Install with ASDF

<Steps>
  1. Check that you have [ASDF](https://asdf-vm.com/) installed.

  2. Install the Aptos CLI plugin.

     ```sh
     asdf plugin add aptos https://github.com/gregnazario/asdf-aptos.git
     ```

  3. Install the Aptos CLI

     ```sh
     asdf install aptos latest
     ```

  4. (Optional) Install a specific version.

     ```sh
     # Locally
     asdf install aptos 7.9.0

     # Globally
     asdf global aptos 7.9.0
     ```

  5. Verify the installation worked.

     ```sh
     aptos help
     ```

     These help instructions also serve as a useful detailed guide for specific commands.
</Steps>

## Install with Mise

<Steps>
  1. Check that you have [Mise](https://mise.jds.dev/) installed.

  2. Install the Aptos CLI plugin.

     ```sh
     mise plugin add aptos https://github.com/gregnazario/asdf-aptos.git
     ```

  3. Install the Aptos CLI.

     ```sh
     mise install aptos
     ```

  4. (Optional) Install a specific version.

     ```sh
     mise install aptos@7.9.0
     ```

  5. Add the tool to your local configuration.

     ```sh
     mise use aptos
     ```

  6. Verify the installation worked.

     ```sh
     aptos help
     ```

     These help instructions also serve as a useful detailed guide for specific commands.
</Steps>

# Install the Aptos CLI on Linux

> Step-by-step instructions to install the Aptos CLI on Linux using shell scripts, package managers, or pre-compiled binaries with troubleshooting guidance.

import { Aside, Steps } from '@astrojs/starlight/components';

For Linux, the easiest way to install the Aptos CLI tool is via shell script, although if that does not work, you can also install manually via downloading pre-compiled binaries. The pre-compiled binaries approach is not generally recommended as updating is very manual.

# Install via Script

<Steps>
  1. In the terminal, use one of the following commands:

     ```shellscript filename="Terminal"
     curl -fsSL "https://aptos.dev/scripts/install_cli.sh" | sh
     ```

     Or use the equivalent `wget` command:

     ```shellscript filename="Terminal"
     wget -qO- "https://aptos.dev/scripts/install_cli.sh" | sh
     ```

     <Aside type="caution">
       If you are getting `Illegal instruction` errors when running the CLI, it may be due to your CPU not supporting SIMD instructions.
       Specifically for older non-SIMD processors or Ubuntu x86\_64 docker containers on ARM Macs, you may need to run the following command instead to skip SIMD instructions:

       ```shellscript filename="Terminal"
         curl -fsSL "https://aptos.dev/scripts/install_cli.sh" | sh -s -- --generic-linux
       ```
     </Aside>

  2. (Optional) It can be helpful to add the Aptos CLI to a folder in your PATH, or to add it to your PATH directly.

     - The steps to add a folder to your PATH are shell dependent.
     - You can run `echo $SHELL` to print the default shell for your machine, then google specific steps to add a folder to your PATH for that shell.

  3. Verify the script is installed by opening a new terminal and running aptos help

     - You should see a list of commands you can run using the CLI.
     - In the future, this is a helpful resource to learn exactly how each command works.
</Steps>

<Aside type="note" emoji="‚ÑπÔ∏è">
  If you would like to update the Aptos CLI to the latest version, you can run `aptos update`.
</Aside>

# Install via Package Manager (Optional)

<Aside type="note">
  When installing Aptos via a package manager, please update it through the same package manager in the future.
</Aside>

### Arch Linux

#### Install via AUR (Arch User Repository)

```shellscript filename="Terminal"
git clone https://aur.archlinux.org/aptos-bin.git
cd aptos-bin
makepkg -si
```

or use an AUR helper like `yay`:

```shellscript filename="Terminal"
yay -S aptos-bin
```

# Install via Pre-Compiled Binaries (Backup Method)

<Steps>
  1. Go to the .

  2. Click the "Assets" expandable menu for the latest release to see the pre-compiled binaries.

  3. Download the zip file for Linux.

     1. It‚Äôll have a name like: `aptos-cli-<version>-Linux-x86_64.zip` or `aptos-cli-<version>-Linux-aarch64.zip`.
     2. Make sure you choose the right zip file for your computer architecture (x86\_64 for Intel / AMD or aarch64 for ARM).
     3. You will likely have to dismiss warnings that this is a suspicious file when downloading.

  4. Unzip the downloaded file.

  5. Move the extracted Aptos binary file into your preferred folder.

  6. Open a terminal and navigate to your preferred folder.

  7. Make ~/aptos an executable by running chmod +x ~/aptos.

  8. Verify that this installed version works by running ~/aptos help.

     You should see instructions for how to use all CLI commands. These can be helpful in the future when you are trying to understand how to use specific commands.

  9. (Optional) It can be helpful to add the Aptos CLI to a folder in your PATH, or to add it to your PATH directly.

     - The steps to add a folder to your PATH are shell dependent.
     - You can run `echo $SHELL` to print the default shell for your machine, then google specific steps to add a folder to your PATH for that shell.
</Steps>

<Aside type="note" emoji="‚ÑπÔ∏è">
  When using the pre-compiled binaries method, you can update the Aptos CLI by deleting your existing installation, then following the installation steps again.
</Aside>

# Install the Aptos CLI on Mac

> Complete installation guide for the Aptos CLI on macOS using Homebrew, shell scripts, or pre-compiled binaries with upgrade instructions.

import { Aside, Steps } from '@astrojs/starlight/components';

For Mac, the easiest way to install the Aptos CLI is with the package manager `brew`.

# Installation

<Steps>
  1. Ensure you have brew installed [https://brew.sh/](https://brew.sh/).

  2. Open a new terminal and enter the following commands.

     ```shellscript filename="Terminal"
     brew update
     brew install aptos
     ```

  3. Open another terminal and run aptos help to verify the CLI is installed.

     ```shellscript filename="Terminal"
     aptos help
     ```
</Steps>

<Aside type="caution">
  If `brew` does not work for you, you can try the steps here: [Install via Script](#install-via-script) or [Install via Pre-Compiled Binaries](#install-via-pre-compiled-binaries-backup-method).)
</Aside>

# Upgrading the CLI

Upgrading the CLI with brew just takes 2 commands:

```shellscript filename="Terminal"
brew update
brew upgrade aptos
```

# Install via Script

<Steps>
  1. In the terminal, use one of the following commands:

     ```shellscript filename="Terminal"
     curl -fsSL "https://aptos.dev/scripts/install_cli.sh" | sh
     ```

     Or use the equivalent `wget` command:

     ```shellscript filename="Terminal"
     wget -qO- "https://aptos.dev/scripts/install_cli.sh" | sh
     ```

  2. (Optional) It can be helpful to add the Aptos CLI to a folder in your PATH, or to add it to your PATH directly.

     - The steps to add a folder to your PATH are shell dependent.
     - You can run `echo $SHELL` to print the default shell for your machine, then google specific steps to add a folder to your PATH for that shell.

  3. Verify the script is installed by opening a new terminal and running aptos help

     - You should see a list of commands you can run using the CLI.
     - In the future, this is a helpful resource to learn exactly how each command works.
</Steps>

<Aside type="note" emoji="‚ÑπÔ∏è">
  If you would like to update the Aptos CLI to the latest version, you can run `aptos update`.
</Aside>

# Install via Pre-Compiled Binaries (Backup Method)

<Steps>
  1. Go to the .

  2. Click the "Assets" expandable menu for the latest release to see the pre-compiled binaries.

  3. Download the zip file for macOS.

     1. It‚Äôll have a name like: `aptos-cli-<version>-macOS-x86_64.zip` or `aptos-cli-<version>-macOS-arm64.zip`.
     2. Make sure you choose the right zip file for your computer architecture (x86\_64 for Intel / AMD or arm64 for ARM).
     3. You will likely have to dismiss warnings that this is a suspicious file when downloading.

  4. Unzip the downloaded file.

  5. Move the extracted Aptos binary file into your preferred folder.

  6. Open a terminal and navigate to your preferred folder.

  7. Make ~/aptos an executable by running chmod +x ~/aptos.

  8. Verify that this installed version works by running ~/aptos help.

     You should see instructions for how to use all CLI commands. These can be helpful in the future when you are trying to understand how to use specific commands.

  9. (Optional) It can be helpful to add the Aptos CLI to a folder in your PATH, or to add it to your PATH directly.

     - The steps to add a folder to your PATH are shell dependent.
     - You can run `echo $SHELL` to print the default shell for your machine, then google specific steps to add a folder to your PATH for that shell.
</Steps>

<Aside type="note" emoji="‚ÑπÔ∏è">
  When using the pre-compiled binaries method, you can update the Aptos CLI by deleting your existing installation, then following the installation steps again.
</Aside>

# Install Specific Aptos CLI Versions (Advanced)

> Advanced guide to build and install specific versions of the Aptos CLI from source code for specialized development needs and custom architectures.

import {Aside, Steps} from '@astrojs/starlight/components';

# Using existing releases

## Using the Aptos CLI script

If you are already using the installation script for Mac and Linux, you can install a specific version of the Aptos CLI using the following command:

```sh
curl -fsSL "https://aptos.dev/scripts/install_cli.sh" | sh -s -- --cli-version 7.9.0
```

## Using asdf

If you are already using [asdf](https://asdf-vm.com/), you can install a specific version of the Aptos CLI using the following command:

```sh
asdf install aptos 7.9.0
```

## Using mise

If you are already using [mise](https://mise.jdx.dev), you can install a specific version of the Aptos CLI using the following command:

```sh
mise install aptos@7.9.0
```

# Installation from source code

<Aside title="Note">
  This guide is for advanced users who need to build and install a specific version of the Aptos CLI.

  If you are looking to install a specific version of the Aptos CLI, we suggest you use ASDF or Mise to handle it for
  you.
{/*You can see the installation guide [here](/build/install-cli/install-cli-asdf)*/}
</Aside>

If you need a specific version of the Aptos CLI, you can build it directly from the Aptos source code. This installation
method is primarily used to interact with specific features on Devnet which may not have made it to Testnet / Mainnet
yet. You may also want to follow these steps if you are running an architecture which does not play well with the
existing releases / pre-compiled binaries.

If you do not need this advanced method, you can find the normal install steps [here](/build/cli).

## Install on macOS / Linux

<Steps>
  1. Checkout the Aptos source code.

     ```sh
     git clone https://github.com/aptos-labs/aptos-core.git
     ```

  2. Ensure you have [cargo](https://doc.rust-lang.org/cargo/) installed.

  3. Build the Aptos CLI:

     ```sh
     cargo build --package aptos --profile cli
     ```

     The binary will be available at `target/cli/aptos`.

  4. (Optional) Move this executable to a place in your PATH.

  5. Verify the installation worked.

     ```sh
     target/cli/aptos help
     ```

     These help instructions also serve as a useful detailed guide for specific commands.
</Steps>

## Install on Windows

<Steps>
  1. Checkout the Aptos source code.

     ```powershell
     git clone https://github.com/aptos-labs/aptos-core.git
     ```

  2. Ensure you have [cargo](https://doc.rust-lang.org/cargo/) installed.

  3. Build the Aptos CLI.

     ```powershell
     cargo build --package aptos --profile cli
     ```

     The binary will be available at `target\cli\aptos.exe`.

  4. (Optional) Move this executable to a place in your PATH.

  5. Verify the installation worked.

     ```powershell
     target\cli\aptos.exe help
     ```

     These help instructions also serve as a useful detailed guide for specific commands.
</Steps>

# Install the Aptos CLI on Windows

> Complete guide to install the Aptos CLI on Windows using PowerShell scripts, package managers, or pre-compiled binaries with troubleshooting tips.

import { Aside, Steps } from '@astrojs/starlight/components';

For Windows, the easiest way to install the Aptos CLI tool is via PowerShell script. If that does not work, you can also install manually via pre-compiled binaries. The pre-compiled binaries approach is not generally recommended as updating is very manual.

# Install via PowerShell Script

<Steps>
  1. In PowerShell, run the install script:

     ```powershell filename="Terminal"
     Set-ExecutionPolicy RemoteSigned -Scope CurrentUser; iwr https://aptos.dev/scripts/install_cli.ps1 | iex
     ```

  2. Verify the script is installed by opening a new terminal and running aptos help.

     - You should see a list of commands you can run using the CLI.
     - In the future, this is a helpful resource to learn exactly how each command works.
</Steps>

<Aside type="note" emoji="‚ÑπÔ∏è">
  If you would like to update the Aptos CLI to the latest version via script, you can run `aptos update`.
</Aside>

# Install via Package Manager (Optional)

<Aside type="note">
  When installing Aptos via a package manager, please update it through the same package manager in the future.
</Aside>

### If you have [Scoop](https://scoop.sh/) installed, you can run the following command to install the Aptos CLI:

```powershell filename="Terminal"
scoop install https://aptos.dev/scoop/aptos.json
```

### If you have [Chocolatey](https://chocolatey.org/) installed, you can run the following command to install the Aptos CLI:

```powershell filename="Terminal"
choco install aptos
```

### If you have [winget](https://winget.run/) installed, you can run the following command to install the Aptos CLI:

```powershell filename="Terminal"
winget install aptos
```

# Install via Pre-Compiled Binaries (Backup Method)

<Steps>
  1. Go to the .

  2. Expand "Assets" to see the pre-compiled binaries.

  3. Download the zip file for Windows.

     - It will have a name like: `aptos-cli-<version>-Windows-x86_64.zip`
     - You will likely have to dismiss warnings that this is a suspicious file when downloading.

  4. Unzip the downloaded file.

     - Move the file to whichever folder you would like to call `aptos` from in the future.

  5. Right click, then copy the path to the executable.

     Ex. `C:\Users\<username>\Downloads\aptos-cli-3.1.0-Windows-x86_64\aptos.exe`.

     <Aside type="note" emoji="‚ÑπÔ∏è">
       You may want to add this path to your PATH environment variable to simplify calling the Aptos CLI going forward.
     </Aside>

  6. Open PowerShell via the Start Menu.

  7. Verify the installation by running the help command.

     Use the path you copied earlier to call the Aptos CLI.
     Ex. `C:\Users\<username>\Downloads\aptos-cli-3.1.0-Windows-x86_64\aptos.exe help`.
</Steps>

<Aside type="note" emoji="‚ÑπÔ∏è">
  When installing with pre-compiled binaries, you can update the Aptos CLI by deleting your existing installation, then following the installation steps again.
</Aside>

<Aside type="caution">
  If neither of the above methods work, you will have to build the CLI from source by following these steps: [Install Specific Aptos CLI Versions (Advanced)](/build/cli/install-cli/install-cli-specific-version)
</Aside>

# Managing a Network Node via Aptos CLI

> Learn how to manage validator nodes and validator full nodes using the Aptos CLI for staking pool operations and governance voting.

If you are running a [validator node or validator full node (VFN)](/network/nodes/validator-node), you can use the CLI to interact with your node.

Specifically, you can use the CLI to:

1. [Manage staking pools you own](/network/nodes/validator-node/connect-nodes/staking-pool-operations).
2. [Vote on proposals](/network/nodes/validator-node/connect-nodes/staking-pool-voter).

Beyond that, you can run this help command to see more specialized commands the CLI can do relating to operating your node:

```shellscript filename="Terminal"
aptos node --help
```

# Running a Public Network (Advanced)

> Advanced guide to bootstrap and run a public Aptos network using genesis ceremonies, validator configurations, and blockchain initialization.

import { Aside } from '@astrojs/starlight/components';

<Aside type="caution">
  If you just want to run your own local network for testing, you can learn how to do that [here](/build/cli/running-a-local-network).
</Aside>

## Genesis ceremonies

The `aptos` tool supports bootstrapping new blockchains through what is known as a genesis ceremony. The output of the genesis ceremony is the output of move instructions that prepares a blockchain for online operation. The input consists of:

- A set of validators and their configuration
- The initial set of Move modules, known as a framework
- A unique `ChainId` (u8) that distinguishes this from other networks
- For test chains, there also exists an account that manages the minting of AptosCoin

## Generating genesis

- The genesis organizer constructs a `Layout` and distributes it.
- The genesis organizer prepares the Aptos framework's bytecode and distributes it.
- Each participant generates their `ValidatorConfiguration` and distributes it.
- Each participant generates a `genesis.blob` from the resulting contributions.
- The genesis organizer executes the `genesis.blob` to derive the initial waypoint and distributes it.
- Each participant begins their `aptos-node`. The `aptos-node` verifies upon startup that the `genesis.blob` with the waypoint provided by the genesis organizer.
- The blockchain will begin consensus after a quorum of stake is available.

### Prepare aptos-core

The following sections rely on tools from the Aptos source. See [Building Aptos From Source](/network/nodes/building-from-source) for setup.

### The `layout` file

The layout file contains:

- `root_key`: an Ed25519 public key for AptosCoin management.
- `users`: the set of participants
- `chain_id`: the `ChainId` or a unique integer that distinguishes this deployment from other Aptos networks

An example:

```yaml
root_key: "0xca3579457555c80fc7bb39964eb298c414fd60f81a2f8eedb0244ec07a26e575"
users:
  - alice
  - bob
chain_id: 8
```

### Building the Aptos Framework

From your Aptos-core repository, build the framework and package it:

```shellscript filename="Terminal"
cargo run --package framework
mkdir aptos-framework-release
cp aptos-framework/releases/artifacts/current/build/**/bytecode_modules/* aptos-framework-release
```

The framework will be stored within the `aptos-framework-release` directory.

### The `ValidatorConfiguration` file

The `ValidatorConfiguration` file contains:

- `account_address`: The account that manages this validator. This must be derived from the `account_key` provided within the `ValidatorConfiguration` file.
- `consensus_key`: The public key for authenticating consensus messages from the validator
- `account_key`: The public key for the account that manages this validator. This is used to derive the `account_address`.
- `network_key`: The public key for both validator and fullnode network authentication and encryption.
- `validator_host`: The network address where the validator resides. This contains a `host` and `port` field. The `host` should either be a DNS name or an IP address. Currently only IPv4 is supported.
- `full_node_host`: An optional network address where the fullnode resides. This contains a `host` and `port` field. The `host` should either be a DNS name or an IP address. Currently only IPv4 is supported.
- `stake_amount`: The number of coins being staked by this node. This is expected to be `1`, if it is different the configuration will be considered invalid.

An example:

```yaml
account_address: ccd49f3ea764365ac21e99f029ca63a9b0fbfab1c8d8d5482900e4fa32c5448a
consensus_key: "0xa05b8f41057ac72f9ca99f5e3b1b787930f03ba5e448661f2a1fac98371775ee"
account_key: "0x3d15ab64c8b14c9aab95287fd0eb894aad0b4bd929a5581bcc8225b5688f053b"
network_key: "0x43ce1a4ac031b98bb1ee4a5cd72a4cca0fd72933d64b22cef4f1a61895c2e544"
validator_host:
  host: bobs_host
  port: 6180
full_node_host:
  host: bobs_host
  port: 6182
stake_amount: 1
```

To generate this using the `aptos` CLI:

1. Generate your validator's keys:

```shellscript filename="Terminal"
cargo run --package aptos -- genesis generate-keys --output-dir bobs
```

2. Generate your `ValidatorConfiguration`:

```shellscript filename="Terminal"
cargo run --package aptos -- \\
    genesis set-validator-configuration \\
    --keys-dir bobs \\
    --username bob \\
    --validator-host bobs_host:6180 \\
    --full-node-host bobs_host:6180 \\
    --local-repository-dir .
```

3. The last command will produce a `bob.yaml` file that should be distributed to other participants for `genesis.blob` generation.

### Generating a genesis and waypoint

`genesis.blob` and the waypoint can be generated after obtaining the `layout` file, each of the individual `ValidatorConfiguration` files, and the framework release. It is important to validate that the `ValidatorConfiguration` provided in the earlier stage is the same as in the distribution for generating the `genesis.blob`. If there is a mismatch, inform all participants.

To generate the `genesis.blob` and waypoint:

- Place the `layout` file in a directory, e.g., `genesis`.
- Place all the `ValidatorConfiguration` files into the `genesis` directory.
- Ensure that the `ValidatorConfiguration` files are listed under the set of `users` within the `layout` file.
- Make a `framework` directory within the `genesis` directory and place the framework release `.mv` files into the `framework` directory.
- Use the `aptos` CLI to generate genesis and waypoint:

```shellscript filename="Terminal"
cargo run --package aptos -- genesis generate-genesis --local-repository-dir genesis
```

### Starting an `aptos-node`

Upon generating the `genesis.blob` and waypoint, place them into your validator and fullnode's configuration directory and begin your validator and fullnode.

# Replaying Past Transactions

> Learn how to replay historical blockchain transactions locally for debugging, benchmarking, and gas profiling using the Aptos CLI.

import { Aside, FileTree } from '@astrojs/starlight/components';

## Basics

You can replay past transactions locally using the `aptos move replay` command.
The command is fairly straightforward but it requires you to specify two pieces of required information:

- `--network`
  - This is the network you want to replay on
  - Possible values: `mainnet`, `testnet`, `devnet` or `<URL TO CUSTOM REST ENDPOINT>`
- `--txn-id`
  - This is the id of the transaction you want to replay
  - This is also sometimes being referred to as `version` on explorers
  - Specifically it is NOT the hexadecimal transaction hash

Let's use mainnet transaction [581400718](https://explorer.aptoslabs.com/txn/581400718?network=mainnet) (a simple coin transfer transaction) as an example.

```shellscript filename="Terminal"
aptos move replay --network mainnet --txn-id 581400718
```

<details>
  <summary>Output</summary>

  ```shellscript
  Got 1/1 txns from RestApi.
  Replaying transaction...
  {
    "Result": {
      "transaction_hash": "0x1ba73d03a0442a845735a17c7be46f3b51e2acb0e5cf68749305c5a17539ac63",
      "gas_used": 7,
      "gas_unit_price": 100,
      "sender": "c94e16736910cc160347d01de345407fe2d350fce5635ac1150319b0fbf5630e",
      "sequence_number": 14637,
      "success": true,
      "version": 581400718,
      "vm_status": "status EXECUTED of type Execution"
    }
  }
  ```
</details>

Alternatively, if you want to simulate a new transaction, check out [Local Simulation, Benchmarking and Gas Profiling](/build/cli/working-with-move-contracts/local-simulation-benchmarking-and-gas-profiling).

## Alternate Modes

Similar to local simulations, the replay command can be enhanced with one of the following options:

- `--benchmark`: Benchmark the transaction and report the running time(s).
- `--profile-gas` Profile the transaction for detailed gas usage.

### Benchmarking

```shellscript filename="Terminal"
aptos move replay --network mainnet --txn-id 581400718 --benchmark
```

<details>
  <summary>Output</summary>

  ```shellscript
  Got 1/1 txns from RestApi.
  Benchmarking transaction...
  Running time (cold code cache): 914.821¬µs
  Running time (warm code cache): 820.189¬µs
  {
    "Result": {
      "transaction_hash": "0x1ba73d03a0442a845735a17c7be46f3b51e2acb0e5cf68749305c5a17539ac63",
      "gas_used": 7,
      "gas_unit_price": 100,
      "sender": "c94e16736910cc160347d01de345407fe2d350fce5635ac1150319b0fbf5630e",
      "sequence_number": 14637,
      "success": true,
      "version": 581400718,
      "vm_status": "status EXECUTED of type Execution"
    }
  }
  ```
</details>

It's worth noting that these running times serve only as informational references, as they are contingent upon the specifications of your local machine and may be influenced by noise or other random factors.

**If you are aiming to optimize your contract, you should base your decisions on the gas profiling results.**

<Aside type="note" emoji="‚ÑπÔ∏è">
  To minimize measurement errors, the benchmark harness executes the same transaction multiple times. For this reason, it may take a while for the benchmark task to complete.
</Aside>

### Gas Profiling

The Aptos Gas Profiler is a powerful tool that can help you understand the gas usage of Aptos transactions. Once activated, it will simulate transactions using an instrumented VM, and generate a web-based report.

The gas profiler can also double as a debugger since the report also includes a full execution trace.

```shellscript filename="Terminal"
aptos move replay --network mainnet --txn-id 581400718 --profile-gas
```

<details>
  <summary>Output</summary>

  ```shellscript
  Got 1/1 txns from RestApi.
  Profiling transaction...
  Gas report saved to gas-profiling/txn-1ba73d03-0x1-aptos_account-transfer.
  {
    "Result": {
      "transaction_hash": "0x1ba73d03a0442a845735a17c7be46f3b51e2acb0e5cf68749305c5a17539ac63",
      "gas_used": 7,
      "gas_unit_price": 100,
      "sender": "c94e16736910cc160347d01de345407fe2d350fce5635ac1150319b0fbf5630e",
      "sequence_number": 14637,
      "success": true,
      "version": 581400718,
      "vm_status": "status EXECUTED of type Execution"
    }
  }
  ```
</details>

You can then find the [generated gas report](/gas-profiling/sample-report-2/index.html) in the directory gas-profiling:

<FileTree>
  - gas-profiling/
    - txn-1ba73d03-0x1-aptos\_account-transfer/
      - assets/
      - index.html
</FileTree>

To understand the gas report, please refer to [this section](/build/cli/working-with-move-contracts/local-simulation-benchmarking-and-gas-profiling#understanding-the-gas-report) of the local simulation tutorial.

# Running a Localnet via Aptos CLI

> Set up and run a local Aptos network for testing and development with Docker, including Node API, Indexer API, and faucet services.

import { Aside, Steps } from '@astrojs/starlight/components';

Local networks can be helpful when testing your code. They are not connected to any production Aptos networks like mainnet, but they are useful for three main reasons:

1. **No rate limits:** You can interact with hosted services like the Node API, Indexer API, and faucet with no rate-limits to speed up testing.
2. **Reproducibility:** You can set up specific on-chain scenarios and restart the network from scratch at any point to return to a clean slate.
3. **High availability**: The Aptos devnet and testnet networks are periodically upgraded, during which time they can be unavailable. Local development networks are also always available even if you have no internet access.

<br />

# Starting A Local Network

<Steps>
  1. Ensure you have the  installed.

  2. Ensure you have  installed.

     1. This is exclusively needed for making a production-like environment by running the Indexer API. Many downstream tools such as the Aptos SDK depend on the Indexer API.
     2. Docker recommends that you install via [Docker Desktop](https://www.docker.com/products/docker-desktop/) to get automatic updates.

  3. Start Docker.

  4. Run the following command in a new terminal to start the private network:

     ```shellscript filename="Terminal"
     aptos node run-local-testnet --with-indexer-api
     ```

     <Aside type="caution">
       Note: Despite the name (`local-testnet`), this has nothing to do with the Aptos testnet, it will run a network entirely local to your machine.
     </Aside>

     You should expect to see an output similar to this:

     ```shellscript filename="Terminal"
     Readiness endpoint: http://0.0.0.0:8070/

     Indexer API is starting, please wait...
     Node API is starting, please wait...
     Transaction stream is starting, please wait...
     Postgres is starting, please wait...
     Faucet is starting, please wait...

     Completed generating configuration:
             Log file: "/Users/dport/.aptos/testnet/validator.log"
             Test dir: "/Users/dport/.aptos/testnet"
             Aptos root key path: "/Users/dport/.aptos/testnet/mint.key"
             Waypoint: 0:397412c0f96b10fa3daa24bfda962671c3c3ae484e2d67ed60534750e2311f3d
             ChainId: 4
             REST API endpoint: http://0.0.0.0:8080
             Metrics endpoint: http://0.0.0.0:9101/metrics
             Aptosnet fullnode network endpoint: /ip4/0.0.0.0/tcp/6181
             Indexer gRPC node stream endpoint: 0.0.0.0:50051

     Aptos is running, press ctrl-c to exit

     Node API is ready. Endpoint: http://0.0.0.0:8080/
     Postgres is ready. Endpoint: postgres://postgres@127.0.0.1:5433/local_testnet
     Transaction stream is ready. Endpoint: http://0.0.0.0:50051/
     Indexer API is ready. Endpoint: http://127.0.0.1:8090
     Faucet is ready. Endpoint: http://127.0.0.1:8081/

     Applying post startup steps...

     Setup is complete, you can now use the local testnet!
     ```

  5. Wait for the network to start

     Once the terminal says `Setup is complete, you can now use the local testnet!` the local network will be running.

     <Aside type="caution">
       If you ran into an error, look at the common errors below to debug.
     </Aside>

     <details>
       <summary>Common Errors On Network Startup</summary>

       ### Address Already In Use

       ```shellscript filename="Terminal"
       panicked at 'error binding to 0.0.0.0:8080: error creating server listener: Address already in use (os error 48)'
       ```

       This means one of the ports needed by the local network is already in use by another process.

       To fix this on Unix systems, you can:

       1. Identify the name and PID of the process by running `lsof -i :8080`.
       2. Run `kill <pid>` once you know the PID to free up that port.

       ### Too many open files error

       ```shellscript filename="Terminal"
       panicked at crates/aptos/src/node/local_testnet/logging.rs:64:10:
       called \`Result::unwrap()\` on an \`Err\` value: Os { code: 24, kind: Uncategorized, message: \"Too many open files\" }
       ```

       This means there were too many open files on your system. On many Unix systems you can increase the maximum number of open files by adding something like this to your `.zshrc`:

       ```shellscript filename="Terminal"
       ulimit -n 1048576
       ```

       ### Docker is not available

       ```shellscript filename="Terminal"
       Unexpected error: Failed to apply pre-run steps for Postgres: Docker is not available, confirm it is installed and running. On Linux you may need to use sudo
       ```

       To debug this, try the below fixes:

       1. Make sure you have docker installed by running `docker --version`.
       2. Ensure the Docker daemon is running by running `docker info` (if this errors saying `Cannot connect to the Docker daemon` Docker is NOT running).
       3. Make sure the socket for connecting to Docker is present on your machine in the default location. For example, on Unix systems `/var/run/docker.sock` should exist.
          1. If that file does not exist, open Docker Desktop and enable `Settings -> Advanced -> Allow the default Docker socket to be used`.
          2. Or, you can find where the Docker socket is by running `docker context inspect | grep Host`, then symlink that location to the default location by running `sudo ln -s /Users/dport/.docker/run/docker.sock /var/run/docker.sock`
     </details>

     As you can see from the example output in step 4, once the local network is running, you have access to the following services:

     - [Node API](/build/apis/fullnode-rest-api): This is a REST API that runs directly on the node. It enables core write functionality such as transaction submission and a limited set of read functionality, such as reading account resources or Move module information.
     - [Indexer API](/build/indexer/indexer-api): This is a [GraphQL](https://graphql.org/) API that provides rich read access to indexed blockchain data. If you click on the URL for the Indexer API above, by default [http://127.0.0.1:8090](http://127.0.0.1:8090), it will open the Hasura Console, a web UI that will help you query the Indexer GraphQL API.
     - [Transaction Stream Service](/build/indexer/txn-stream): This is a gRPC stream of transactions used by the Indexer API and SDK. This is only relevant to you if you are developing a [Indexer SDK](/build/indexer/indexer-sdk) custom processor.
     - [Postgres](https://www.postgresql.org/): This is the database that the Indexer processors write to. The Indexer API reads from this database.
     - [Faucet](/build/apis/faucet-api): You can use this to fund accounts on your local network.

     If you do not want to run any of these sub-components of a network, there are flags to disable them.

     If you are writing a script and would like to wait for the local network to come up with all services, you can make a GET request to `http://127.0.0.1:8070`. At first this will return http code [503](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/503). When it returns [200](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/200) it means all the services are ready.

     For more information on different flags you can pass when starting your local network, or configuration settings such as changing which port certain services run on, run the help command:

     ```shellscript filename="Terminal"
     aptos node run-local-testnet --help
     ```
</Steps>

## Using The Local Network

Now that the network is running, you can use it like you would any other network.

So, you can create a local profile like this:

```shellscript filename="Terminal"
aptos init --profile <your-profile-name> --network local
```

You can then use that profile for any commands you want to use going forward. For example, if you wanted to publish a Move module like the [`hello_blockchain`](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/move-examples/hello_blockchain) package to your local network you could run:

```shellscript filename="Terminal"
aptos move publish --profile <your-profile-name> --package-dir /opt/git/aptos-core/aptos-move/move-examples/hello_blockchain --named-addresses HelloBlockchain=local
```

### Configuring the TypeScript SDK

If you want to use the local network with the TypeScript SDK, you can use local network URLs when initializing the client object (`Aptos`):

```tsx
import { Aptos, AptosConfig, Network } from "@aptos-labs/ts-sdk";

const network = Network.LOCAL;
const config = new AptosConfig({ network });
const client = new Aptos(config);
```

### Resetting the local network

Sometimes while developing it is helpful to reset the local network back to its initial state, for example:

- You made backwards incompatible changes to a Move module, and you'd like to redeploy it without renaming it or using a new account.
- You are building an [Indexer SDK](/build/indexer/indexer-sdk) custom processor and would like to index using a fresh network.
- You want to clear all on chain state, e.g., accounts, objects, etc.

To start with a brand new local network, use the `--force-restart` flag:

```shellscript filename="Terminal"
aptos node run-local-testnet --force-restart
```

It will then prompt you if you really want to restart the chain, to ensure that you do not delete your work by accident.

```shellscript filename="Terminal"
Are you sure you want to delete the existing chain? [yes/no]
> yes
```

If you do not want to be prompted, include `--assume-yes` as well:

```shellscript filename="Terminal"
aptos node run-local-testnet --force-restart --assume-yes
```

# Setup CLI Initial Configuration

> Learn how to configure the Aptos CLI with network settings, profiles, and credentials for secure and efficient blockchain interactions.

import { Aside } from '@astrojs/starlight/components';

If you are using the CLI to try things out on-chain, you will need to configure the network, faucet, and credentials you want the CLI to use.

This makes using the CLI easier and more secure as you will not be forced to repeatedly copy addresses or private keys.

<Aside type="caution">
  If you still need to install the CLI, follow [these steps](/build/cli/install-cli/install-cli-specific-version).
</Aside>

1. Run `aptos init` and follow the instructions in the command line.

<Aside type="note" emoji="‚ÑπÔ∏è">
  To use default settings, you can provide no input and just press "Enter". For example:
</Aside>

```shellscript filename="Terminal"
aptos init
```

```shellscript filename="Output"
Configuring for profile default
Enter your rest endpoint [Current: None | No input: https://api.devnet.aptoslabs.com]

No rest url given, using https://api.devnet.aptoslabs.com...
Enter your faucet endpoint [Current: None | No input: https://faucet.devnet.aptoslabs.com]

No faucet url given, using https://faucet.devnet.aptoslabs.com...
Enter your private key as a hex literal (0x...) [Current: None | No input: Generate new key (or keep one if present)]

No key given, generating key...
Account 00f1f20ddd0b0dd2291b6e42c97274668c479bca70f07c6b6a80b99720779696 doesn't exist, creating it and funding it with 10000 coins
Aptos is now set up for account 00f1f20ddd0b0dd2291b6e42c97274668c479bca70f07c6b6a80b99720779696!  Run `aptos help` for more information about commands

{
  "Result": "Success"
}
```

2. Later, if you want to update these settings, you can do so by running `aptos init` again.
3. The rest of these configuration steps are optional / quality of life. To continue to use the CLI for your specific use case, follow the [usage guide here](/build/cli#%EF%B8%8F-using-the-aptos-cli).

## (Optional) Creating Named Configurations (Profiles)

For testing more complicated scenarios, you will often want multiple accounts on-chain. One way to do this is to create a named configuration which we call a profile.

To create a profile, run `aptos init --profile <name_of_profile>`. The configuration you generate will be usable when calling CLI commands as replacements for arguments.

For example:

```shellscript filename="Terminal"
aptos init --profile bob
```

```shellscript filename="Terminal"
aptos account fund-with-faucet --profile bob
```

```shellscript filename="Output"
{
  "Result": "Added 100000000 Octas to account 0x63169727b08fc137b8720e451f7a90584ccce04c301e151daeadc7b8191fdfad"
}
```

## (Optional) Setting Up Shell Completion

One quality of life feature you can enable is shell auto-completions.

1. Determine which shell you are using (you can run `echo $SHELL` if you are unsure).
2. Look up where configuration files for shell completions go for that shell (it varies from shell to shell). The supported shells are `[bash, zsh, fish, PowerShell, elvish]`.
3. Run the following command with your specific shell and the output file for completions using your shell:

```shellscript filename="Terminal"
aptos config generate-shell-completions --shell <YOUR_SHELL_HERE> --output-file <OUTPUT_DESTINATION_FOR_YOUR_SHELL>
```

Example command for [`oh my zsh`](https://ohmyz.sh/):

```shellscript filename="Terminal"
aptos config generate-shell-completions --shell zsh --output-file ~/.oh-my-zsh/completions/_aptos
```

## (Optional) Global Config

By default, the CLI will look for a configuration in `.aptos/config.yaml` in each workspace directory. If you would like to use a shared configuration for all workspaces, you can follow these steps:

1. Create a folder in your home directory called `.aptos` (so it has the path `~/.aptos`).
2. Create a yaml file inside `.aptos` called `global_config.yaml`.
3. Run the command:

```shellscript filename="Terminal"
aptos config set-global-config --config-type global
```

You should see:

```json
{
  "Result": {
    "config_type": "Global"
  }
}
```

# Install the Move Prover

> Step-by-step guide to install and set up the Move Prover dependencies for formal verification of Move smart contracts using the Aptos CLI.

import { Aside } from '@astrojs/starlight/components';

If you want to use the [Move Prover](/build/smart-contracts/prover), install the Move Prover dependencies after [installing the CLI binary](/build/cli/setup-cli).
There are two ways to install Prover dependencies.

## Installation through Aptos CLI (Recommended)

1. [Install the latest Aptos CLI binary](/build/cli/install-cli/install-cli-mac).

2. Execute the command `aptos update prover-dependencies`.

<Aside type="note">
  Environment variables `BOOGIE_EXE` and `Z3_EXE` will be set automatically after installation. Please make sure
  they are in effect in the current environment.
</Aside>

## Installation through `aptos-core` (Not Recommended)

1. See [Building Aptos From Source](/network/nodes/building-from-source)

2. Then, in the checked out aptos-core directory, install additional Move tools:

   <details>
     <summary>Linux / macOS</summary>

     1. Open a Terminal session.
     2. Run the dev setup script to prepare your environment: `./scripts/dev_setup.sh -yp`
     3. Update your current shell environment: `source ~/.profile`

     <Aside type="note" emoji="‚ÑπÔ∏è">
       `dev_setup.sh -p` updates your `~./profile` with environment variables to support the installed Move Prover tools. You may need to set `.bash_profile` or `.zprofile` or other setup files for your shell.
     </Aside>
   </details>

   <details>
     <summary>Windows</summary>

     1. Open a PowerShell terminal as an administrator.
     2. Run the dev setup script to prepare your environment: `PowerShell -ExecutionPolicy Bypass -File ./scripts/windows_dev_setup.ps1 -y`
   </details>

After installation, you can run the Move Prover to prove an [example](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/move-examples/hello_prover):

```shellscript filename="Terminal"
aptos move prove --package-dir aptos-move/move-examples/hello_prover/
```

## Troubleshooting

If you encounter errors like the one below when running the command, double-check your Aptos CLI version or verify that you're using the correct `aptos` tool, especially if you have multiple versions installed.

```shellscript filename="Terminal
error: unexpected token
    ‚îå‚îÄ ~/.move/https___github_com_aptos-labs_aptos-core_git_main/aptos-move/framework/aptos-framework/sources/randomness.move:515:16
    ‚îÇ
515 ‚îÇ         for (i in 0..n) {
    ‚îÇ             -  ^ Expected ')'
    ‚îÇ             ‚îÇ
    ‚îÇ             To match this '('

{
  "Error": "Move Prover failed: exiting with model building errors"
}
```

# Start a Move package from a template

> Quickly bootstrap new Move projects using built-in templates with the Aptos CLI, including the hello-blockchain template and customization options.

import { CardGrid, LinkCard, Steps } from '@astrojs/starlight/components';

import { RemoteCodeblock } from '~/components/RemoteCodeblock';

Follow the steps below to quickly get started.

<Steps>
  1. Initialize

     Run the following to initialize a package using the `hello-blockchain` template:

     ```shellscript filename="Terminal"
     aptos move init --name hello_blockchain --template hello-blockchain
     ```

  2. Start building

     The template creates a `hello_blockchain.move` file under `sources` to help get you started.

     <RemoteCodeblock permalink="https://github.com/aptos-labs/aptos-core/blob/afd3706c17bcccfb39a9d6059aecbfa648ed295d/aptos-move/move-examples/hello_blockchain/sources/hello_blockchain.move#L1-L64" />

  3. See all templates

     Run the following command to see all templates (and for general help initializing a package):

     ```shellscript
     aptos move init --help
     ```
</Steps>

### Learn More

<CardGrid>
  <LinkCard href="/build/smart-contracts" title="Smart Contracts" description="Learn how to build in Move" />

  <LinkCard href="/build/smart-contracts/create-package" title="Create Package" description="Get started by learning how to create a Move package" />
</CardGrid>

# Trying Things On-Chain With Aptos CLI

> Learn how to interact with the Aptos blockchain using CLI profiles, including account management, transaction sending, and hardware wallet integration.

The CLI can be a convenient tool for quickly looking up on-chain data and sending transactions from your accounts.

The most common way to specify what accounts you want to interact with is through profiles. You can create a new profile on the cli by running the following command:

```shellscript filename="Terminal"
aptos init --profile <your-profile-name>
```

If any command takes an account, you can pass in the name of a profile instead. If a command implicitly uses the default profile, it will usually have an optional parameter to use a specified profile instead which you can find by running `aptos <your-command> --help`.

With that, the three main things you can use the CLI to do on-chain include:

1. [Looking Up On-Chain Account Info](/build/cli/trying-things-on-chain/looking-up-account-info)
2. [Creating test accounts and sending transactions](/build/cli/trying-things-on-chain/create-test-accounts)
3. [Securely interacting on-chain via a Hardware Ledger](/build/cli/trying-things-on-chain/ledger)

# Create Test Accounts and Send Transactions From Aptos CLI

> Learn how to create test accounts, fund them with faucet tokens, and send transactions between accounts using the Aptos CLI for testing and development.

import { Aside } from '@astrojs/starlight/components';

<Aside type="note" emoji="‚ÑπÔ∏è">
  You can install the Aptos CLI by following [these steps](/build/cli) if you have not done so already.
</Aside>

In general, to make a new account on-chain, you will need to generate keys and then fund the account. On devnet, you can fund a new account by asking a "faucet" account with test Aptos tokens to send them to your account. On testnet you can mint at the [mint page](/network/faucet).

Using the CLI, you can generate and fund a test account using:

```shellscript filename="Terminal"
aptos init --profile <your-profile-name>
```

Once you have a funded account you can send coins between accounts with the `transfer` command like this:

```shellscript filename="Terminal"
aptos account transfer --account superuser --amount 100
```

You should see a result like:

```json filename="Output"
{
  "Result": {
    "gas_used": 73,
    "balance_changes": {
      "742854f7dca56ea6309b51e8cebb830b12623f9c9d76c72c3242e4cad353dedc": {
        "coin": {
          "value": "10100"
        },
        "deposit_events": {
          "counter": "2",
          "guid": {
            "id": {
              "addr": "0x742854f7dca56ea6309b51e8cebb830b12623f9c9d76c72c3242e4cad353dedc",
              "creation_num": "1"
            }
          }
        },
        "withdraw_events": {
          "counter": "0",
          "guid": {
            "id": {
              "addr": "0x742854f7dca56ea6309b51e8cebb830b12623f9c9d76c72c3242e4cad353dedc",
              "creation_num": "2"
            }
          }
        }
      },
      "b9bd2cfa58ca29bce1d7add25fce5c62220604cd0236fe3f90d9de91ed9fb8cb": {
        "coin": {
          "value": "9827"
        },
        "deposit_events": {
          "counter": "1",
          "guid": {
            "id": {
              "addr": "0xb9bd2cfa58ca29bce1d7add25fce5c62220604cd0236fe3f90d9de91ed9fb8cb",
              "creation_num": "1"
            }
          }
        },
        "withdraw_events": {
          "counter": "1",
          "guid": {
            "id": {
              "addr": "0xb9bd2cfa58ca29bce1d7add25fce5c62220604cd0236fe3f90d9de91ed9fb8cb",
              "creation_num": "2"
            }
          }
        }
      }
    },
    "sender": "b9bd2cfa58ca29bce1d7add25fce5c62220604cd0236fe3f90d9de91ed9fb8cb",
    "success": true,
    "version": 1139,
    "vm_status": "Executed successfully"
  }
}
```

This can be useful for manual testing of Move contracts or just to try seeing how the chain works in practice.

<Aside type="note" emoji="‚ÑπÔ∏è">
  To have more control over what your generated credentials look like, instead of `aptos init`, you can use:

  1. `aptos key generate --vanity-prefix 0x<your-prefix>`
  2. `aptos account fund-with-faucet --account <your-newly-generated-account-address>`

  Note however that addresses are different than keys.
</Aside>

# Use Hardware Ledger via the Aptos CLI

> Learn how to securely interact with the Aptos blockchain using hardware Ledger devices, including setup, key rotation, and transaction signing.

import { Aside, Steps } from '@astrojs/starlight/components';

Using a hardware wallet like Ledger is the most secure way to sign transactions on `mainnet` as your private key never leaves your device.

<Aside type="caution">
  The `Ledger Nano S` has limited memory and may not be able to sign many transactions on Aptos. If you are trying to sign a transaction that is too big for your device to handle, you will get the error `Wrong raw transaction length`.
</Aside>

## Initial Setup

You will need to do a few steps of configuration for the Aptos CLI and your Ledger device to sign transactions.

<Steps>
  1. Ensure you have the Aptos CLI installed.

     You can install the Aptos CLI by following [these steps](/build/cli) if you have not done so already.

  2. Ensure you have done the basic setup for your Ledger device.

     You can find those steps on [Ledger‚Äôs website](https://www.ledger.com/). For example, here are the set up instructions for the [Ledger Nano X](https://support.ledger.com/article/360018784134-zd).

  3. Plug your Ledger device into your computer.

  4. Install the Aptos App on your Ledger device by following .

  5. Unlock your Ledger device and open the Aptos app.

     <Aside type="note" emoji="‚ÑπÔ∏è">
       Whenever you want to sign using your Ledger you will need to plug it in, unlock it, and open the Aptos app before running any CLI commands.
     </Aside>

  6. Create a new Ledger profile in the Aptos CLI

     ```shellscript filename="Terminal"
     aptos init --profile <your-profile> --ledger
     ```

     Then follow the terminal prompts like so:

     ```text filename="Terminal"
     Configuring for profile <your-profile>
     Choose network from [devnet, testnet, mainnet, local, custom | defaults to devnet]

     No network given, using devnet...
     Please choose an index from the following 5 ledger accounts, or choose an arbitrary index that you want to use:
     [0] Derivation path: m/44'/637'/0'/0'/0' (Address: 59836ba1dd0c845713bdab34346688d6f1dba290dbf677929f2fc20593ba0cfb)
     [1] Derivation path: m/44'/637'/1'/0'/0' (Address: 21563230cf6d69ee72a51d21920430d844ee48235e708edbafbc69708075a86e)
     [2] Derivation path: m/44'/637'/2'/0'/0' (Address: 667446181b3b980ef29f5145a7a2cc34d433fc3ee8c97fc044fd978435f2cb8d)
     [3] Derivation path: m/44'/637'/3'/0'/0' (Address: 2dcf037a9f31d93e202c074229a1b69ea8ee4d2f2d63323476001c65b0ec4f31)
     [4] Derivation path: m/44'/637'/4'/0'/0' (Address: 23c579a9bdde1a59f1c9d36d8d379aeefe7a5997b5b58bd5a5b0c12a4f170431)

     0
     Account 59836ba1dd0c845713bdab34346688d6f1dba290dbf677929f2fc20593ba0cfb has been already found on-chain

     ---
     Aptos CLI is now set up for account 59836ba1dd0c845713bdab34346688d6f1dba290dbf677929f2fc20593ba0cfb as profile <your-profile>!  Run `aptos --help` for more information about commands
     {
       "Result": "Success"
     }
     ```

     In the example, they chose to use the first ledger account by entering `0` after the `aptos init` command. You may choose whichever account you want.

     **Common errors:**

     1. If you see the error `Device Not Found`, make sure to unlock your Ledger then try this step again.
     2. If you see the error `Aptos ledger app is not opened`, make sure to open the Aptos app on your Ledger, then try this step again.

  7. Finally, you will need to enable blind signing on your Ledger device by following .

     1. Blind signing allows you to confirm a smart contract interaction you cannot verify through a human-readable language.
     2. This is needed to execute transactions without limitation as some payloads are too big to display.
</Steps>

## Signing Using Ledger

After doing the initial setup, you can sign transactions by following these steps:

1. Plug in your ledger.
2. Unlock it.
3. Open the Aptos app.
4. Run the Aptos CLI command which requires a signature.

<Aside type="note" emoji="‚ÑπÔ∏è">
  This process works for any command that requires a signature, whether that‚Äôs to transfer coins, publish a Move contract, interact with a contract, etc.
</Aside>

For example, if you wanted to publish a Move package like the [`hello_blockchain`](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/move-examples/hello_blockchain) demo contract you could follow the above steps then run:

```shellscript filename="Terminal"
aptos move publish --profile <your-ledger-profile-name> --named-addresses hello_blockchain=<your-ledger-profile-name>
```

You should see a response like:

```shellscript filename="Terminal"
Compiling, may take a little while to download git dependencies...
INCLUDING DEPENDENCY AptosFramework
INCLUDING DEPENDENCY AptosStdlib
INCLUDING DEPENDENCY MoveStdlib
BUILDING Examples
package size 1755 bytes
Do you want to submit a transaction for a range of [139600 - 209400] Octas at a gas unit price of 100 Octas? [yes/no] >

yes

{
  "Result": {
    "transaction_hash": "0xd5a12594f85284cfd5518d547d084030b178ee926fa3d8cbf699cc0596eff538",
    "gas_used": 1396,
    "gas_unit_price": 100,
    "sender": "59836ba1dd0c845713bdab34346688d6f1dba290dbf677929f2fc20593ba0cfb",
    "sequence_number": 0,
    "success": true,
    "timestamp_us": 1689887104333038,
    "version": 126445,
    "vm_status": "Executed successfully"
  }
}

```

After you have approved publishing this package you will be prompted to sign the transaction on your Ledger device. Once signed, the package will be published to the network!

One error you might run into is `Error: Wrong raw transaction length`. This means that the transaction or package size was too big for your device to sign. Currently the Aptos Ledger app can only support transactions that are smaller than 20kb. The `Ledger Nano S` device has less memory than that, which is why it is more likely to produce this error.

## Authentication key rotation

If you have an active account that is not secured using a hardware wallet, then
you may wish to rotate the account's authentication key so that it corresponds
to a [BIP44 account index] private key held on your Ledger.

Alternatively, if you have an account linked with a Ledger hardware wallet that
you wish to publish a large package from, you might want to temporarily rotate
the account's authentication key to a hot key to avoid memory issues.

This tutorial will walk you through both scenarios.

<Aside type="caution" emoji="‚ùó">
  Before you start this tutorial make sure you have completed the
  [key rotation guide](/build/guides/key-rotation).
</Aside>

<Steps>
  1. Complete the key rotation guide

     Confirm that you have completed the
     [key rotation guide](/build/guides/key-rotation).

  2. Verify your Ledger is ready

     1. Connect and unlock your Ledger.
     2. Check what version of the Aptos app you have: `Aptos > About > Version`.
     3. If you do not have version `0.6.9` or higher, update it using Ledger Live.
     4. Enable blind signing: `Aptos > Settings > Enable Blind Signing`.

  3. Start a localnet

     Start a localnet:

     ```shellscript filename="Terminal"
     aptos node run-localnet
     ```

     The localnet is ready when it prints out:

     ```shellscript filename="Terminal"
     Applying post startup steps...

     Setup is complete, you can now use the localnet!
     ```

     <Aside type="note" emoji="üß†">
       If you are a power user on MacOS or Linux, the following command can be used
       to start a fresh localnet as a background process:

       ```shellscript filename="Terminal"
       mkdir -p localnet-data
       aptos node run-localnet \
           --assume-yes \
           --test-dir localnet-data \
           --force-restart &
       export LOCALNET_PID=$!
       ```

       You can then stop the localnet at any point with the following command:

       ```shellscript filename="Terminal"
       kill $LOCALNET_PID
       ```
     </Aside>

  4. Set up localnet hot wallet profile

     Create a private key corresponding to an authentication key, and thus initial
     account address, that starts with the vanity prefix `0xaaa`:

     ```shellscript filename="Terminal"
     aptos key generate \
         --assume-yes \
         --output-file private-key-a \
         --vanity-prefix 0xaaa
     ```

     <details>
       <summary>Example output</summary>

       ```shellscript filename="Terminal"
       {
         "Result": {
           "PublicKey Path": "private-key-a.pub",
           "PrivateKey Path": "private-key-a",
           "Account Address:": "0xaaac71af5f2a4af4ec2639a15799bf9b945afb061c8bee102b636531c1b00eb5"
         }
       }
       ```
     </details>

     Use the private key to initialize a `hot-wallet-1` profile on the localnet:

     ```shellscript filename="Terminal"
     aptos init \
         --assume-yes \
         --network local \
         --private-key-file private-key-a \
         --profile hot-wallet-1
     ```

     <details>
       <summary>Example output</summary>

       ```shellscript filename="Terminal"
       Configuring for profile hot-wallet-1
       Configuring for network Local
       Using command line argument for private key
       Account 0xaaac71af5f2a4af4ec2639a15799bf9b945afb061c8bee102b636531c1b00eb5 doesn\'t exist, creating it and funding it with 100000000 Octas
       Account 0xaaac71af5f2a4af4ec2639a15799bf9b945afb061c8bee102b636531c1b00eb5 funded successfully

       ---
       Aptos CLI is now set up for account 0xaaac71af5f2a4af4ec2639a15799bf9b945afb061c8bee102b636531c1b00eb5 as profile hot-wallet-1!  Run `aptos --help` for more information about commands
       {
         "Result": "Success"
       }
       ```
     </details>

  5. Rotate the hot wallet key

     Rotate the authentication key of the hot wallet to use [BIP44 account index]
     1000 on your Ledger:

     ```shellscript filename="Terminal"
     aptos account rotate-key \
         --assume-yes \
         --new-derivation-index 1000 \
         --profile hot-wallet-1 \
         --save-to-profile ledger-wallet-1000
     ```

     <Aside type="note" emoji="üß†">
       As a best practice, this command uses a [BIP44 account index] that starts at a
       large number (1000) to indicate that the account is secured by a rotated
       authentication key on a Ledger, to ensure it does not conflict with any other
       existing accounts.

       This practice aids in profile recovery, as shown below.
     </Aside>

     Follow the instructions from the CLI prompt:

     ```shellscript filename="Terminal"
     Approve rotation proof challenge signature on your Ledger device
     ```

     <details>
       <summary>Example output</summary>

       ```shellscript filename="Terminal"
       {
         "Result": {
           "message": "Saved new profile ledger-wallet-1000",
           "transaction": {
             "transaction_hash": "0x1a6df99651ac170bda10cfb9898fa196321d80a928033791b9d2231f77738bb2",
             "gas_used": 448,
             "gas_unit_price": 100,
             "sender": "aaac71af5f2a4af4ec2639a15799bf9b945afb061c8bee102b636531c1b00eb5",
             "sequence_number": 0,
             "success": true,
             "timestamp_us": 1717986382369736,
             "version": 186,
             "vm_status": "Executed successfully"
           }
         }
       }
       ```
     </details>

     Compare the `hot-wallet-1` and `ledger-wallet-1000` profiles, noting that they
     have the same `account` address but different `public_key` values:

     ```shellscript filename="Terminal"
     aptos config show-profiles --profile hot-wallet-1
     aptos config show-profiles --profile ledger-wallet-1000
     ```

     <details>
       <summary>Example output</summary>

       ```shellscript filename="Terminal"
       {
         "Result": {
           "hot-wallet-1": {
             "has_private_key": true,
             "public_key": "0xffb1240fd1267207cc3ed2e1b5386e090a9ca2c844d7f9e0077b3d7dd5d5e430",
             "account": "aaa271bca468fb8518f73a732a484b29a1bc296ebcb23f15639d4865a5cebe87",
             "rest_url": "http://localhost:8080",
             "faucet_url": "http://localhost:8081"
           }
         }
       }
       {
         "Result": {
           "ledger-wallet-1000": {
             "has_private_key": false,
             "public_key": "0x20ba83f9b9fdab73b0ace8fda26ce24c98cf55060b72b69cfbd25add6a25d09b",
             "account": "aaa271bca468fb8518f73a732a484b29a1bc296ebcb23f15639d4865a5cebe87",
             "rest_url": "http://localhost:8080",
             "faucet_url": "http://localhost:8081"
           }
         }
       }
       ```
     </details>

     Since the account is no longer secured by the hot private key, delete the
     private and public key files.

     <Aside type="note" emoji="üß†">
       If you are using a UNIX-like machine:

       ```shell filename="Terminal"
       rm private-key-a
       rm private-key-b
       rm private-key-a.pub
       rm private-key-b.pub
       ```
     </Aside>

     Now that you have successfully rotated the authentication key of the hot wallet,
     you can delete the profiles too:

     ```shellscript filename="Terminal"
     aptos config delete-profile --profile hot-wallet-1
     aptos config delete-profile --profile ledger-wallet-1000
     ```

     <details>
       <summary>Example output</summary>

       ```shellscript filename="Terminal"
       {
         "Result": "Deleted profile hot-wallet-1"
       }
       {
         "Result": "Deleted profile ledger-wallet-1000"
       }
       ```
     </details>

  6. Recover profile

     Since you know that you rotated the authentication key of the hot wallet to the
     Ledger, and since you used the best practice of a [BIP44 account index] offset
     of 1000, you can easily recover the profile using the [BIP44 account index]
     alone:

     ```shellscript filename="Terminal"
     aptos init \
         --assume-yes \
         --derivation-index 1000 \
         --network local \
         --profile ledger-wallet-1000-recovered
     ```

     <details>
       <summary>Example output</summary>

       ```shellscript filename="Terminal"
       Configuring for profile ledger-wallet-1000-recovered
       Configuring for network Local
       Account 0xaaac71af5f2a4af4ec2639a15799bf9b945afb061c8bee102b636531c1b00eb5 has been already found onchain

       ---
       Aptos CLI is now set up for account 0xaaac71af5f2a4af4ec2639a15799bf9b945afb061c8bee102b636531c1b00eb5 as profile ledger-wallet-1000-recovered!  Run `aptos --help` for more information about commands
       {
         "Result": "Success"
       }
       ```
     </details>

     Note that this profile corresponds to the specified `0xaaa...` vanity account
     address:

     ```shellscript filename="Terminal"
     aptos config show-profiles --profile ledger-wallet-1000-recovered
     ```

     <details>
       <summary>Example output</summary>

       ```shellscript filename="Terminal"
       {
         "Result": {
           "ledger-wallet-1000-recovered": {
             "has_private_key": false,
             "public_key": "0x20ba83f9b9fdab73b0ace8fda26ce24c98cf55060b72b69cfbd25add6a25d09b",
             "account": "aaac71af5f2a4af4ec2639a15799bf9b945afb061c8bee102b636531c1b00eb5",
             "rest_url": "http://localhost:8080",
             "faucet_url": "http://localhost:8081"
           }
         }
       }
       ```
     </details>

     <Aside type="note" emoji="üß†">
       The `aptos init` command first checks the [`account::OriginatingAddress`] table
       for determining the account address associated with a public key, so as long as
       you follow best practices from the
       [key rotation guide](/build/guides/key-rotation) and only
       authenticate one account at a time with a private key, you'll easily be able to
       recover your profile based on the [BIP44 account index] alone.
     </Aside>

  7. Rotate to new hot private key

     If you have an account linked with a Ledger hardware wallet that you wish to use
     for publication of a large package, you'll be unable to sign the package
     publication transaction due to the Ledger's memory limitations. In this case,
     you'll want to temporarily rotate to a hot wallet.

     Start by generating a new private key:

     ```shellscript filename="Terminal"
     aptos key generate \
         --assume-yes \
         --output-file private-key-b \
         --vanity-prefix 0xbbb
     ```

     <details>
       <summary>Example output</summary>

       ```shellscript filename="Terminal"
       {
         "Result": {
           "PublicKey Path": "private-key-b.pub",
           "PrivateKey Path": "private-key-b",
           "Account Address:": "0xbbbede2b4f1d49eff0b156ab0756889a6f2bb68f215399d5015da9ac45921b47"
         }
       }
       ```
     </details>

     Rotate the authentication key of the account linked with the Ledger to the new
     private key:

     ```shellscript filename="Terminal"
     aptos account rotate-key \
         --assume-yes \
         --new-private-key-file private-key-b \
         --profile ledger-wallet-1000-recovered \
         --save-to-profile temporary-hot-wallet
     ```

     Follow the instructions from the CLI prompt:

     ```shellscript filename="Terminal"
     Approve rotation proof challenge signature on your Ledger device
     ```

     ```shellscript filename="Terminal"
     Approve transaction on your Ledger device
     ```

     <details>
       <summary>Example output</summary>

       ```shellscript filename="Terminal"
       {
         "Result": {
           "message": "Saved new profile temporary-hot-wallet",
           "transaction": {
             "transaction_hash": "0xe49782e92d8fd824fd6dce8f6ed42a11cf8ee84c201f3aa639c435e737c80eaa",
             "gas_used": 449,
             "gas_unit_price": 100,
             "sender": "aaac71af5f2a4af4ec2639a15799bf9b945afb061c8bee102b636531c1b00eb5",
             "sequence_number": 1,
             "success": true,
             "timestamp_us": 1717986617911082,
             "version": 631,
             "vm_status": "Executed successfully"
           }
         }
       ```
     </details>

     Since the CLI profile `ledger-wallet-1000-recovered` is now stale, rename it
     in case you get interrupted and forget that the private key has been rotated:

     ```shellscript filename="Terminal"
     aptos config rename-profile \
         --profile ledger-wallet-1000-recovered \
         --new-profile-name ledger-wallet-1000-stale
     ```

     <details>
       <summary>Example output</summary>

       ```shellscript filename="Terminal"
       {
         "Result": "Renamed profile ledger-wallet-1000-recovered to ledger-wallet-1000-stale"
       }
       ```
     </details>

  8. Rotate back to Ledger

     Once you've signed the large package publication transaction with the hot key,
     you can then rotate the authentication key back to the corresponding to the
     private key on the Ledger at index 1000:

     ```shellscript filename="Terminal"
     aptos account rotate-key \
         --assume-yes \
         --new-derivation-index 1000 \
         --profile temporary-hot-wallet \
         --save-to-profile ledger-wallet-1000
     ```

     Follow the instructions from the CLI prompt:

     ```shellscript filename="Terminal"
     Approve rotation proof challenge signature on your Ledger device
     ```

     <details>
       <summary>Example output</summary>

       ```shellscript filename="Terminal"
       {
         "Result": {
           "message": "Saved new profile ledger-wallet-1000",
           "transaction": {
             "transaction_hash": "0x9503819d4ea13bcd9eafed25984807d86d22e8a9837565a7495b54d13890d103",
             "gas_used": 449,
             "gas_unit_price": 100,
             "sender": "aaac71af5f2a4af4ec2639a15799bf9b945afb061c8bee102b636531c1b00eb5",
             "sequence_number": 2,
             "success": true,
             "timestamp_us": 1717986672963544,
             "version": 742,
             "vm_status": "Executed successfully"
           }
         }
       }
       ```
     </details>

     Verify that the `ledger-wallet-1000-stale` and `ledger-wallet-1000` profiles
     have the same `account` address and `public_key`:

     ```shellscript filename="Terminal"
     aptos config show-profiles --profile ledger-wallet-1000-stale
     aptos config show-profiles --profile ledger-wallet-1000
     ```

     Delete the `temporary-hot-wallet` and `ledger-wallet-1000-stale` profiles,
     which you no longer need.

     ```shellscript filename="Terminal"
     aptos config delete-profile --profile temporary-hot-wallet
     aptos config delete-profile --profile ledger-wallet-1000-stale
     ```

     <details>
       <summary>Example output</summary>

       ```shellscript filename="Terminal"
       {
         "Result": "Deleted profile temporary-hot-wallet"
       }
       {
         "Result": "Deleted profile ledger-wallet-1000-stale"
       }
       ```
     </details>

     Since you no longer need the temporary private key, delete it too.

     <Aside type="note" emoji="üß†">
       If you are using a UNIX-like machine:

       ```shell filename="Terminal"
       rm private-key-*
       ```
     </Aside>

  9. Clean up

     Delete the remaining test profile:

     ```shell filename="Terminal"
     aptos config delete-profile --profile ledger-wallet-1000
     ```

     Then stop the localnet.

     <Aside type="note" emoji="üß†">
       If you are using a UNIX-like machine:

       ```shell filename="Terminal"
       aptos config delete-profile --profile ledger-wallet-1000
       kill $LOCALNET_PID
       rm -fr localnet-data
       ```
     </Aside>
</Steps>

[`account::OriginatingAddress`]: https://github.com/aptos-labs/aptos-core/blob/acb6c891cd42a63b3af96561a1aca164b800c7ee/aptos-move/framework/aptos-framework/sources/account.move#L70

[BIP44 account index]: https://github.com/bitcoin/bips/blob/master/bip-0044.mediawiki

# Look Up On-Chain Account Info Using Aptos CLI

> Learn how to query on-chain account information including balances, resources, and Move modules using the Aptos CLI with detailed examples and output explanations.

import { Aside } from '@astrojs/starlight/components';

<Aside type="note" emoji="‚ÑπÔ∏è">
  You can install the Aptos CLI by following [these steps](/build/cli) if you have not done so already.
</Aside>

You can look up resources and data an account has on-chain by running the following command:

```shellscript filename="Terminal"
aptos account list --account <your-profile-name-or-account-address>
```

This will show all resources that an account has. For example, below shows the balance as `coin:value`, and the associated coin for the native gas token APT would be `0x1::aptos_coin::AptosCoin`.
This is represented in subdivisions, so in this case it's `10^-8` or 8 zeros of decimal points.

```json filename="Output"
{
  "Result": [
    {
      "coin": {
        "value": "110000"
      },
      "deposit_events": {
        "counter": "3",
        "guid": {
          "id": {
            "addr": "0xf1f20ddd0b0dd2291b6e42c97274668c479bca70f07c6b6a80b99720779696",
            "creation_num": "2"
          }
        }
      },
      "frozen": false,
      "withdraw_events": {
        "counter": "0",
        "guid": {
          "id": {
            "addr": "0xf1f20ddd0b0dd2291b6e42c97274668c479bca70f07c6b6a80b99720779696",
            "creation_num": "3"
          }
        }
      }
    }
  ]
}
```

If you‚Äôre interested in a specific type of account data, you can specify that with the `--query` parameter. The supported queries are:

- `balance` - to see the current balance and a list of deposit and withdrawal events.
- `modules` - see the Move contracts that are published on this account.
- `resources` - this is what the default command does with no query specified.

Here‚Äôs an example of what calling with the `--query modules` parameter looks like:

```shellscript filename="Terminal"
aptos account list --query modules
```

This will show all modules that an account has. For example:

```json filename="Output"
{
  "Result": [
    {
      "bytecode": "0xa11ceb0b050000000b01000a020a12031c2504410405452d0772da0108cc0240068c030a0a9603150cab03650d90040400000101010201030104000506000006080004070700020e0401060100080001000009020300010f0404000410060100031107000002120709010602130a030106050806080105010802020c0a02000103040508020802070801010a0201060c010800010b0301090002070b030109000900074d657373616765056572726f72056576656e74067369676e657206737472696e67124d6573736167654368616e67654576656e740d4d657373616765486f6c64657206537472696e670b6765745f6d6573736167650b7365745f6d6573736167650c66726f6d5f6d6573736167650a746f5f6d657373616765076d657373616765156d6573736167655f6368616e67655f6576656e74730b4576656e7448616e646c65096e6f745f666f756e6404757466380a616464726573735f6f66106e65775f6576656e745f68616e646c650a656d69745f6576656e74b9bd2cfa58ca29bce1d7add25fce5c62220604cd0236fe3f90d9de91ed9fb8cb0000000000000000000000000000000000000000000000000000000000000001030800000000000000000002020a08020b08020102020c08020d0b030108000001000101030b0a002901030607001102270b002b0110001402010104010105240b0111030c040e0011040c020a02290120030b05120e000b040e00380012012d0105230b022a010c050a051000140c030a050f010b030a04120038010b040b050f0015020100010100",
      "abi": {
        "address": "0xb9bd2cfa58ca29bce1d7add25fce5c62220604cd0236fe3f90d9de91ed9fb8cb",
        "name": "Message",
        "friends": [],
        "exposed_functions": [
          {
            "name": "get_message",
            "visibility": "public",
            "is_entry": false,
            "generic_type_params": [],
            "params": [
              "address"
            ],
            "return": [
              "0x1::string::String"
            ]
          },
          {
            "name": "set_message",
            "visibility": "public",
            "is_entry": true,
            "generic_type_params": [],
            "params": [
              "signer",
              "vector<u8>"
            ],
            "return": []
          }
        ],
        "structs": [
          {
            "name": "MessageChangeEvent",
            "is_native": false,
            "abilities": [
              "drop",
              "store"
            ],
            "generic_type_params": [],
            "fields": [
              {
                "name": "from_message",
                "type": "0x1::string::String"
              },
              {
                "name": "to_message",
                "type": "0x1::string::String"
              }
            ]
          },
          {
            "name": "MessageHolder",
            "is_native": false,
            "abilities": [
              "key"
            ],
            "generic_type_params": [],
            "fields": [
              {
                "name": "message",
                "type": "0x1::string::String"
              },
              {
                "name": "message_change_events",
                "type": "0x1::event::EventHandle<0xb9bd2cfa58ca29bce1d7add25fce5c62220604cd0236fe3f90d9de91ed9fb8cb::Message::MessageChangeEvent>"
              }
            ]
          }
        ]
      }
    }
  ]
}
```

# Working With Move Contracts

> Comprehensive guide to compile, test, publish, and run Move smart contracts using the Aptos CLI with examples and best practices.

import { Aside } from '@astrojs/starlight/components';

The Aptos CLI is mostly used to compile, test, and formally verify Move contracts. If you have not installed the Aptos CLI yet, you can do so by following the steps here [Install the Aptos CLI](/build/cli#-install-the-aptos-cli).

You can jump to specific sections by using the table of contents on the right.

To see how to chain together Move contracts on-chain using the CLI, you can follow this ["CLI Arguments" tutorial](/build/cli/working-with-move-contracts/arguments-in-json-tutorial).

<Aside type="note" emoji="‚ÑπÔ∏è">
  Throughout this document there are parts of commands you will have to modify to fit your situation. Those variables will be wrapped in triangle brackets `<like this>`.
</Aside>

## 1. Compiling Move

You can compile a Move package by running:

```shellscript filename="Terminal"
aptos move compile --package-dir <your-package-directory>
```

<Aside type="note" emoji="‚ÑπÔ∏è">
  The package directory is the folder which contains the `Move.toml` file.
</Aside>

Based on the settings in your `Move.toml` file, you may need to pass in additional information to that compile command.

For example, if you look at the [hello\_blockchain example Move contract](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/move-examples/hello_blockchain), in the `Move.toml` file it specifies a variable named address called `hello_blockchain`.

```toml filename="Move.toml"
[addresses]
hello_blockchain = "_"
```

So, to compile this, you will need to pass in the value for `hello_blockchain` with the `--named-addresses` parameter.
You can use either a full address e.g. `0x123456...7890` or a name of a profile in the CLI e.g. `default` or `superuser`.

Below we will use `default` in our example:

```shellscript filename="Terminal"
aptos move compile --package-dir aptos-move/move-examples/hello_blockchain/ --named-addresses hello_blockchain=default
```

You can learn more about optional parameters when compiling Move contracts by running `aptos move compile --help`.

## 2. Unit Testing Move Contracts

The Aptos CLI can also be used to compile and run unit tests locally by running:

```shellscript filename="Terminal"
aptos move test --package-dir <your-package-directory>
```

This command both compiles and runs tests, so it needs all the same optional parameters you use when compiling.

You can learn more about the optional parameters for testing move contracts by running `aptos move test --help`.

### Printing Debugging Information

When writing tests, it can be helpful to print out debug information or stack traces. You can do that by using `debug::print` and `debug::print_stack_trace` to print information when you use `aptos move test`. See an example of how they are used in [DebugDemo.move](https://github.com/aptos-labs/aptos-core/blob/main/crates/aptos/debug-move-example/sources/DebugDemo.move).

To see the output of testing [DebugDemo.move](https://github.com/aptos-labs/aptos-core/blob/main/crates/aptos/debug-move-example/sources/DebugDemo.move)‚Äôs package:

1. Clone `[aptos-core](https://github.com/aptos-labs/aptos-core)`.
2. Navigate to the [debug-move-example](https://github.com/aptos-labs/aptos-core/tree/main/crates/aptos/debug-move-example) by running `cd crates/aptos/debug-move-example`.
3. Run `aptos move test`.

You should see:

```shellscript filename="Terminal"
Running Move unit tests
[debug] 0000000000000000000000000000000000000000000000000000000000000001
Call Stack:
    [0] 0000000000000000000000000000000000000000000000000000000000000001::Message::sender_can_set_message

        Code:
            [4] CallGeneric(0)
            [5] MoveLoc(0)
            [6] LdConst(0)
          > [7] Call(1)
            [8] Ret

        Locals:
            [0] -
            [1] 0000000000000000000000000000000000000000000000000000000000000001

Operand Stack:
```

For more on how to write unit tests with Move, follow this [Move tutorial](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/move-examples/move-tutorial) (step 2 focuses on unit tests).

## 3. Generating Test Coverage Reports

The Aptos CLI can be used to analyze and improve the testing of your Move modules. To use this feature:

To see the code coverage of your tests run the following command from your Move package‚Äôs directory:

```shellscript filename="Terminal"
aptos move test --coverage
```

If you would like to focus your coverage down to specific packages, you can do so with the `--filter` option. To narrow even further to specific Move modules, use the `--module` parameter.

For more detailed / advanced coverage information (such as your test coverage in the compiled bytecode) you can run `aptos move coverage` . With that command, the CLI will prompt you for more details on what specifically you would like more coverage information about.

You can learn more about optional parameters for test coverage by running `aptos move test --help` and `aptos move coverage --help`.

## 4. Publishing Move Contracts

To publish a Move contract, you will need to run:

```shellscript filename="Terminal"
aptos move publish --package-dir <your-package-directory>
```

Note that when you are publishing on the main network, the credentials you pass into optional parameters like `--named-addresses` will need to reflect accounts on that network instead of test credentials.

The package will be published to your default profile in the CLI. You can override that to specify which account to publish to using `--profile` in the command. To generate a new profile for a specific account, use `aptos init --profile <name_of_profile>` and follow the prompts.

Please also note that when publishing Move modules, if multiple modules are in one package, then all modules in that package must use the same account. If they use different accounts, then the publishing will fail at the transaction level.

<Aside type="note" emoji="‚ÑπÔ∏è">
By default, the CLI sends transactions to the remote fullnode for simulation. 

To simulate locally, append the `--local` option to your command. You can also profile gas usage with the `--profile-gas` option.

 See [Local Simulation, Benchmarking & Gas Profiling](/build/cli/working-with-move-contracts/local-simulation-benchmarking-and-gas-profiling) for details.
</Aside>

<Aside type="caution">
  By default Move contracts publish their source code. To avoid publishing with source code, publish with the `--included-artifacts none` argument.

  Since the Aptos blockchain is inherently open by design, note that even without source access it is possible to regenerate Move source from published Move bytecode.
</Aside>

## 5. Running Published Contracts

Now that you have published your Move package, you can run it directly from the CLI.

You will first need to construct your `function-id` by combining:

```jsx
<the-address-you-published-to>::<module_name>::<function_name>
```

You can then pass in args by using the `--args` parameter.

As an example, if you were to have published the [hello\_blockchain example package](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/move-examples/hello_blockchain) to an account with an address `b9bd2cfa58ca29bce1d7add25fce5c62220604cd0236fe3f90d9de91ed9fb8cb` you could run its `set_message` function via the following command:

```shellscript filename="Terminal"
aptos move run --function-id 0xb9bd2cfa58ca29bce1d7add25fce5c62220604cd0236fe3f90d9de91ed9fb8cb::message::set_message --args string:hello!
```

Which should result in:

```json
{
  "Result": {
    "changes": [
      {
        "address": "b9bd2cfa58ca29bce1d7add25fce5c62220604cd0236fe3f90d9de91ed9fb8cb",
        "data": {
          "authentication_key": "0xb9bd2cfa58ca29bce1d7add25fce5c62220604cd0236fe3f90d9de91ed9fb8cb",
          "self_address": "0xb9bd2cfa58ca29bce1d7add25fce5c62220604cd0236fe3f90d9de91ed9fb8cb",
          "sequence_number": "3"
        },
        "event": "write_resource",
        "resource": "0x1::account::Account"
      },
      {
        "address": "b9bd2cfa58ca29bce1d7add25fce5c62220604cd0236fe3f90d9de91ed9fb8cb",
        "data": {
          "coin": {
            "value": "9777"
          },
          "deposit_events": {
            "counter": "1",
            "guid": {
              "id": {
                "addr": "0xb9bd2cfa58ca29bce1d7add25fce5c62220604cd0236fe3f90d9de91ed9fb8cb",
                "creation_num": "1"
              }
            }
          },
          "withdraw_events": {
            "counter": "1",
            "guid": {
              "id": {
                "addr": "0xb9bd2cfa58ca29bce1d7add25fce5c62220604cd0236fe3f90d9de91ed9fb8cb",
                "creation_num": "2"
              }
            }
          }
        },
        "event": "write_resource",
        "resource": "0x1::coin::CoinStore<0x1::aptos_coin::AptosCoin>"
      },
      {
        "address": "b9bd2cfa58ca29bce1d7add25fce5c62220604cd0236fe3f90d9de91ed9fb8cb",
        "data": {
          "counter": "4"
        },
        "event": "write_resource",
        "resource": "0x1::guid::Generator"
      },
      {
        "address": "b9bd2cfa58ca29bce1d7add25fce5c62220604cd0236fe3f90d9de91ed9fb8cb",
        "data": {
          "message": "hello!",
          "message_change_events": {
            "counter": "0",
            "guid": {
              "id": {
                "addr": "0xb9bd2cfa58ca29bce1d7add25fce5c62220604cd0236fe3f90d9de91ed9fb8cb",
                "creation_num": "3"
              }
            }
          }
        },
        "event": "write_resource",
        "resource": "0xb9bd2cfa58ca29bce1d7add25fce5c62220604cd0236fe3f90d9de91ed9fb8cb::Message::MessageHolder"
      }
    ],
    "gas_used": 41,
    "success": true,
    "version": 3488,
    "vm_status": "Executed successfully"
  }
}
```

## 6. (Optional) Formally Verifying Move Scripts

For cases where you want to guarantee that your code works as expected beyond unit testing, you can use the [Move Prover](/build/smart-contracts/prover) to formally verify your Move contract code.

You can install the Move Prover by following [these steps](/build/cli/setup-cli/install-move-prover).

Once you have installed the Move Prover, you can use it from the Aptos CLI by running:

```shellscript filename="Terminal"
aptos move prove --package-dir <your-package-directory>
```

To learn how to formally verify your code, please follow the in-depth Move tutorial [here](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/move-examples/move-tutorial) (step 7 and 8 cover how to use the Move Prover and write formal specifications in the example code).

# Arguments in JSON Tutorial

> Learn how to pass complex arguments to Move functions using JSON format in the Aptos CLI, including vectors, entry functions, view functions, and script functions.

import { Aside } from '@astrojs/starlight/components';

## Package info

This section references the [`CliArgs` example package](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/move-examples/cli_args), which contains the following manifest:

```toml filename="move.toml"
[package]
name = "CliArgs"
version = "0.1.0"
upgrade_policy = "compatible"

[addresses]
test_account = "_"

[dependencies]
AptosFramework = { git = "https://github.com/aptos-labs/aptos-framework.git", rev = "mainnet", subdir = "aptos-framework" }
```

Here, the package is deployed under the named address `test_account`.

<Aside type="note" emoji="‚ÑπÔ∏è">
  Set your working directory to [`aptos-move/move-examples/cli_args`](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/move-examples/cli_args) to follow along:

  ```shellscript filename="Terminal"
  cd <aptos-core-parent-directory>/aptos-core/aptos-move/move-examples/cli_args
  ```
</Aside>

## Deploying the package

Start by mining a vanity address for Ace, who will deploy the package:

```shellscript filename="Terminal"
aptos key generate \
    --vanity-prefix 0xace \
    --output-file ace.key
```

<details>
  <summary>Output</summary>

  ```shellscript filename="Terminal"
  {
    "Result": {
      "Account Address:": "0xacef1b9b7d4ab208b99fed60746d18dcd74865edb7eb3c3f1428233988e4ba46",
      "PublicKey Path": "ace.key.pub",
      "PrivateKey Path": "ace.key"
    }
  }
  ```

  <Aside type="note" emoji="‚ÑπÔ∏è">
    The exact account address should vary for each run, though the vanity prefix should not.
  </Aside>
</details>

Store Ace's address in a shell variable, so you can call it inline later on:

```shellscript filename="Terminal"
# Your exact address will vary
ace_addr=0xacef1b9b7d4ab208b99fed60746d18dcd74865edb7eb3c3f1428233988e4ba46
```

Fund Ace's account with the faucet (only works on devnet):

```shellscript filename="Terminal"
aptos account fund-with-faucet --account $ace_addr
```

<details>
  <summary>Output</summary>

  ```shellscript filename="Terminal"
  {
    "Result": "Added 100000000 Octas to account acef1b9b7d4ab208b99fed60746d18dcd74865edb7eb3c3f1428233988e4ba46"
  }
  ```
</details>

Now publish the package under Ace's account:

```shellscript filename="Terminal"
aptos move publish \
    --named-addresses test_account=$ace_addr \
    --private-key-file ace.key \
    --assume-yes
```

<details>
  <summary>Output</summary>

  ```json filename="Terminal"
  {
    "Result": {
      "transaction_hash": "0x1d7b074dd95724c5459a1c30fe4cb3875e7b0478cc90c87c8e3f21381625bec1",
      "gas_used": 1294,
      "gas_unit_price": 100,
      "sender": "acef1b9b7d4ab208b99fed60746d18dcd74865edb7eb3c3f1428233988e4ba46",
      "sequence_number": 0,
      "success": true,
      "timestamp_us": 1685077849297587,
      "version": 528422121,
      "vm_status": "Executed successfully"
    }
  }
  ```
</details>

## Entry functions

The only module in the package, `cli_args.move`, defines a simple `Holder` resource with fields of various data types:

```move filename="Holder in cli_args.move"
module test_account::cli_args {
  use std::signer;
  use aptos_std::type_info::{Self, TypeInfo};
  use std::string::String;

  struct Holder has key, drop {
      u8_solo: u8,
      bytes: vector<u8>,
      utf8_string: String,
      bool_vec: vector<bool>,
      address_vec_vec: vector<vector<address>>,
      type_info_1: TypeInfo,
      type_info_2: TypeInfo,
  }
```

A public entry function with multi-nested vectors can be used to set the fields:

```move filename="Setter function in cli_args.move"
/// Set values in a `Holder` under `account`.
public entry fun set_vals<T1, T2>(
    account: signer,
    u8_solo: u8,
    bytes: vector<u8>,
    utf8_string: String,
    bool_vec: vector<bool>,
    address_vec_vec: vector<vector<address>>,
) acquires Holder {
    let account_addr = signer::address_of(&account);
    if (exists<Holder>(account_addr)) {
        move_from<Holder>(account_addr);
    };
    move_to(&account, Holder {
        u8_solo,
        bytes,
        utf8_string,
        bool_vec,
        address_vec_vec,
        type_info_1: type_info::type_of<T1>(),
        type_info_2: type_info::type_of<T2>(),
    });
}
```

After the package has been published, `aptos move run` can be used to call `set_vals()`:

<Aside type="note" emoji="‚ÑπÔ∏è">
  To pass vectors (including nested vectors) as arguments from the command line, use JSON syntax escaped with quotes!
</Aside>

```shellscript filename="Running function with nested vector arguments from CLI"
aptos move run \
    --function-id $ace_addr::cli_args::set_vals \
    --type-args \
        0x1::account::Account \
        0x1::chain_id::ChainId \
    --args \
        u8:123 \
        "hex:0x1234" \
        "string:hello, world\! ‚ô•" \
        "bool:[false, true, false, false]" \
        'address:[["0xace", "0xbee"], ["0xcad"], []]' \
    --private-key-file ace.key \
    --assume-yes
```

<details>
  <summary>Output</summary>

  ```json filename="Terminal"
  {
    "Result": {
      "transaction_hash": "0x5e141dc6c28e86fa9f5594de93d07a014264ebadfb99be6db922a929eb1da24f",
      "gas_used": 504,
      "gas_unit_price": 100,
      "sender": "acef1b9b7d4ab208b99fed60746d18dcd74865edb7eb3c3f1428233988e4ba46",
      "sequence_number": 1,
      "success": true,
      "timestamp_us": 1685077888820037,
      "version": 528422422,
      "vm_status": "Executed successfully"
    }
  }
  ```
</details>

The function ID, type arguments, and arguments can alternatively be specified in a JSON file:

```json filename="entry_function_arguments.json"
{
    "function_id": "<test_account>::cli_args::set_vals",
    "type_args": [
        "0x1::account::Account",
        "0x1::chain_id::ChainId"
    ],
    "args": [
        {
            "type": "u8",
            "value": 123
        },
        {
            "type": "hex",
            "value": "0x1234"
        },
        {
            "type": "string",
            "value": "hello, world! ‚ô•"
        },
        {
            "type": "bool",
            "value": [
                false,
                true,
                false,
                false
            ]
        },
        {
            "type": "address",
            "value": [
                [
                    "0xace",
                    "0xbee"
                ],
                [
                    "0xcad"
                ],
                []
            ]
        }
    ]
}
```

Here, the call to `aptos move run` looks like:

```shellscript filename="Running function with JSON input file"
aptos move run \
    --json-file entry_function_arguments.json \
    --private-key-file ace.key \
    --assume-yes
```

<details>
  <summary>Output</summary>

  ```json filename="Terminal"
  {
    "Result": {
      "transaction_hash": "0x60a32315bb48bf6d31629332f6b1a3471dd0cb016fdee8d0bb7dcd0be9833e60",
      "gas_used": 3,
      "gas_unit_price": 100,
      "sender": "acef1b9b7d4ab208b99fed60746d18dcd74865edb7eb3c3f1428233988e4ba46",
      "sequence_number": 2,
      "success": true,
      "timestamp_us": 1685077961499641,
      "version": 528422965,
      "vm_status": "Executed successfully"
    }
  }
  ```
</details>

<Aside type="note" emoji="‚ÑπÔ∏è">
  If you are trying to run the example yourself don't forget to substitute Ace's actual address for `<test_account>` in `entry_function_arguments.json`!
</Aside>

## View functions

Once the values in a `Holder` have been set, the `reveal()` view function can be used to check the first three fields, and to compare type arguments against the last two fields:

```move filename="View function"
struct RevealResult has drop {
    u8_solo: u8,
    bytes: vector<u8>,
    utf8_string: String,
    bool_vec: vector<bool>,
    address_vec_vec: vector<vector<address>>,
    type_info_1_match: bool,
    type_info_2_match: bool
}

#[view]
/// Pack into a `RevealResult` the first three fields in host's
/// `Holder`, as well as two `bool` flags denoting if `T1` & `T2`
/// respectively match `Holder.type_info_1` & `Holder.type_info_2`,
/// then return the `RevealResult`.
public fun reveal<T1, T2>(host: address): RevealResult acquires Holder {
    let holder_ref = borrow_global<Holder>(host);
    RevealResult {
        u8_solo: holder_ref.u8_solo,
        bytes: holder_ref.bytes,
        utf8_string: holder_ref.utf8_string,
        bool_vec: holder_ref.bool_vec,
        address_vec_vec: holder_ref.address_vec_vec,
        type_info_1_match:
            type_info::type_of<T1>() == holder_ref.type_info_1,
        type_info_2_match:
            type_info::type_of<T2>() == holder_ref.type_info_2
    }
}
```

This view function can be called with arguments specified either from the CLI or from a JSON file:

```shellscript filename="Arguments via CLI"
aptos move view \
    --function-id $ace_addr::cli_args::reveal \
    --type-args \
        0x1::account::Account \
        0x1::account::Account \
    --args address:$ace_addr
```

```shellscript filename="Arguments via JSON file"
aptos move view --json-file view_function_arguments.json
```

<Aside type="note" emoji="‚ÑπÔ∏è">
  If you are trying to run the example yourself don't forget to substitute Ace's actual address for `<test_account>` in `view_function_arguments.json` (twice)!
</Aside>

```json filename="view_function_arguments.json"
{
    "function_id": "<test_account>::cli_args::reveal",
    "type_args": [
        "0x1::account::Account",
        "0x1::account::Account"
    ],
    "args": [
        {
            "type": "address",
            "value": "<test_account>"
        }
    ]
}
```

```shellscript filename="Terminal"
{
  "Result": [
    {
      "address_vec_vec": [
        [
          "0xace",
          "0xbee"
        ],
        [
          "0xcad"
        ],
        []
      ],
      "bool_vec": [
        false,
        true,
        false,
        false
      ],
      "bytes": "0x1234",
      "type_info_1_match": true,
      "type_info_2_match": false,
      "u8_solo": 123,
      "utf8_string": "hello, world! ‚ô•"
    }
  ]
}
```

## Script functions

The package also contains a script, `set_vals.move`, which is a wrapper for the setter function:

```move filename="script"
script {
    use test_account::cli_args;
    use std::vector;
    use std::string::String;

    /// Get a `bool` vector where each element indicates `true` if the
    /// corresponding element in `u8_vec` is greater than `u8_solo`.
    /// Then pack `address_solo` in a `vector<vector<<address>>` and
    /// pass resulting argument set to public entry function.
    fun set_vals<T1, T2>(
        account: signer,
        u8_solo: u8,
        bytes: vector<u8>,
        utf8_string: String,
        u8_vec: vector<u8>,
        address_solo: address,
    ) {
        let bool_vec = vector::map_ref(&u8_vec, |e_ref| *e_ref > u8_solo);
        let addr_vec_vec = vector[vector[address_solo]];
        cli_args::set_vals<T1, T2>(account, u8_solo, bytes, utf8_string, bool_vec, addr_vec_vec);
    }
}
```

First compile the package (this will compile the script):

```shellscript filename="Compilation"
aptos move compile --named-addresses test_account=$ace_addr
```

<details>
  <summary>Output</summary>

  ```json filename="Terminal"
  {
    "Result": [
      "acef1b9b7d4ab208b99fed60746d18dcd74865edb7eb3c3f1428233988e4ba46::cli_args"
    ]
  }
  ```
</details>

Next, run `aptos move run-script`:

```shellscript filename="Arguments via CLI"
aptos move run-script \
    --compiled-script-path build/CliArgs/bytecode_scripts/set_vals.mv \
    --type-args \
        0x1::account::Account \
        0x1::chain_id::ChainId \
    --args \
        u8:123 \
        "hex:0x1234" \
        "string:hello, world\! ‚ô•" \
        "u8:[122, 123, 124, 125]" \
        address:"0xace" \
    --private-key-file ace.key \
    --assume-yes
```

<details>
  <summary>Output</summary>

  ```json filename="Terminal"
  {
    "Result": {
      "transaction_hash": "0x1d644eba8187843cc43919469112339bc2c435a49a733ac813b7bc6c79770152",
      "gas_used": 3,
      "gas_unit_price": 100,
      "sender": "acef1b9b7d4ab208b99fed60746d18dcd74865edb7eb3c3f1428233988e4ba46",
      "sequence_number": 3,
      "success": true,
      "timestamp_us": 1685078415935612,
      "version": 528426413,
      "vm_status": "Executed successfully"
    }
  }
  ```
</details>

```shellscript filename="Arguments via JSON file"
aptos move run-script \
    --compiled-script-path build/CliArgs/bytecode_scripts/set_vals.mv \
    --json-file script_function_arguments.json \
    --private-key-file ace.key \
    --assume-yes
```

<details>
  <summary>Output</summary>

  ```json filename="Terminal"
  {
    "Result": {
      "transaction_hash": "0x840e2d6a5ab80d5a570effb3665f775f1755e0fd8d76e52bfa7241aaade883d7",
      "gas_used": 3,
      "gas_unit_price": 100,
      "sender": "acef1b9b7d4ab208b99fed60746d18dcd74865edb7eb3c3f1428233988e4ba46",
      "sequence_number": 4,
      "success": true,
      "timestamp_us": 1685078516832128,
      "version": 528427132,
      "vm_status": "Executed successfully"
    }
  }
  ```
</details>

```json filename="script_function_arguments.json"
{
    "type_args": [
        "0x1::account::Account",
        "0x1::chain_id::ChainId"
    ],
    "args": [
        {
            "type": "u8",
            "value": 123
        },
        {
            "type": "hex",
            "value": "0x1234"
        },
        {
            "type": "string",
            "value": "hello, world! ‚ô•"
        },
        {
            "type": "u8",
            "value": [
                122,
                123,
                124,
                125
            ]
        },
        {
            "type": "address",
            "value": "0xace"
        }
    ]
}
```

Both such script function invocations result in the following `reveal()` view function output:

```shellscript filename="View function call"
aptos move view \
    --function-id $ace_addr::cli_args::reveal \
    --type-args \
        0x1::account::Account \
        0x1::chain_id::ChainId \
    --args address:$ace_addr
```

```json filename="View function output"
{
  "Result": [
    {
      "address_vec_vec": [["0xace"]],
      "bool_vec": [false, false, true, true],
      "bytes": "0x1234",
      "type_info_1_match": true,
      "type_info_2_match": true,
      "u8_solo": 123,
      "utf8_string": "hello, world! ‚ô•"
    }
  ]
}
```

<Aside type="note" emoji="‚ÑπÔ∏è">
  As of the time of this writing, the `aptos` CLI only supports script function arguments for vectors of type `u8`, and only up to a vector depth of 1. Hence `vector<address>` and `vector<vector<u8>>` are invalid script function argument types.
</Aside>

# Local Simulation, Benchmarking & Gas Profiling

> Learn how to simulate, benchmark, and profile gas usage of Move transactions locally using the Aptos CLI for performance optimization and debugging.

import { Aside, FileTree } from '@astrojs/starlight/components';

## Overview

The previous tutorial demonstrates how you can deploy and interact with Move contracts using various CLI commands.

By default, those commands send a transaction to the remote fullnode for simulation and execution.
You can override this behavior and simulate the transaction locally, by appending one of the following command line options of your preference:

- `--local`: Simulate the transaction locally without conducting any further measurements or analysis.
- `--benchmark`: Benchmark the transaction and report the running time(s).
- `--profile-gas`: Profile the transaction for detailed gas usage.

These additional options can be used in combination with the following CLI commands:

- `aptos move run`
- `aptos move run-script`
- `aptos move publish`

Alternatively, if you are interested in replaying a past transaction, check out [this tutorial](/build/cli/replay-past-transactions).

<Aside type="note" emoji="‚ÑπÔ∏è">
  Local simulations do not result in any to the on-chain state.
</Aside>

## Deploying the Example Contract

For demonstration purposes, we will continue to use the [`hello_blockchain`](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/move-examples/hello_blockchain) package as an example.

First, publish the package to devnet or testnet (if you haven't done so already).

Change into the package directory.

```shellscript filename="Terminal"
cd aptos-move/move-examples/hello_blockchain
```

Then publish the package using the following command.

```shellscript filename="Terminal"
aptos move publish --named-addresses hello_blockchain=default --assume-yes
```

<details>
  <summary>Output</summary>

  ```shellscript
  {
    "Result": {
      "transaction_hash": "0xe4ae0ec4ea3474b2123838885b04d7f4b046c174d14d7dc1c56916f2eb553bcf",
      "gas_used": 1118,
      "gas_unit_price": 100,
      "sender": "dbcbe741d003a7369d87ec8717afb5df425977106497052f96f4e236372f7dd5",
      "sequence_number": 5,
      "success": true,
      "timestamp_us": 1713914742422749,
      "version": 1033819503,
      "vm_status": "Executed successfully"
    }
  }
  ```
</details>

Notice that you do need to have your CLI profile set up properly and bind the named addresses correctly. Please refer to [CLI Configuration](/build/cli/setup-cli) for more details.

<Aside type="note" emoji="‚ÑπÔ∏è">
  Note: publishing the package to devnet/testnet is just one way to set up the stage for local simulation and is not the only one possible.
  Alternatively you can use a local node, or simulate transactions that do not need to have code published first, such as scripts and even the package publishing transaction itself.
</Aside>

## Local Simulation

Next, execute the entry function message::set\_message with local simulation enabled using the additional command line option `--local`. This will execute the transaction locally without conducting any further measurements or analysis.

```shellscript filename="Terminal"
aptos move run --function-id 'default::message::set_message' --args 'string:abc' --local
```

<details>
  <summary>Output</summary>

  ```shellscript
  Simulating transaction locally...
  {
    "Result": {
      "transaction_hash": "0x5aab20980688185eed2c9a27bab624c84b8b8117241cd4a367ba2a012069f57b",
      "gas_used": 441,
      "gas_unit_price": 100,
      "sender": "dbcbe741d003a7369d87ec8717afb5df425977106497052f96f4e236372f7dd5",
      "success": true,
      "version": 1033887414,
      "vm_status": "status EXECUTED of type Execution"
    }
  }
  ```
</details>

<Aside type="note" emoji="‚ÑπÔ∏è">
  Local and remote simulation shall produce identical results.
</Aside>

## Benchmarking

To measure the running time(s) of your transaction, use the `--benchmark` option.

```shellscript filename="Terminal"
aptos move run --function-id 'default::message::set_message' --args 'string:abc' --benchmark
```

<details>
  <summary>Output</summary>

  ```shellscript
  Benchmarking transaction locally...
  Running time (cold code cache): 985.141¬µs
  Running time (warm code cache): 848.159¬µs
  {
    "Result": {
      "transaction_hash": "0xa2fe548d37f12ee79df13e70fdd8212e37074c1b080b89b7d92e82550684ecdb",
      "gas_used": 441,
      "gas_unit_price": 100,
      "sender": "dbcbe741d003a7369d87ec8717afb5df425977106497052f96f4e236372f7dd5",
      "success": true,
      "version": 1033936831,
      "vm_status": "status EXECUTED of type Execution"
    }
  }
  ```
</details>

It's worth noting that these running times serve only as informational references, as they are contingent upon the specifications of your local machine and may be influenced by noise or other random factors.

**If you are aiming to optimize your contract, you should base your decisions on the gas profiling results.**

<Aside type="note" emoji="‚ÑπÔ∏è">
  To minimize measurement errors, the benchmark harness executes the same transaction multiple times. For this reason, it may take a while for the benchmark task to complete.
</Aside>

## Gas Profiling

The Aptos Gas Profiler is a powerful tool that can help you understand the gas usage of Aptos transactions. Once activated, it will simulate transactions using an instrumented VM, and generate a web-based report.

The gas profiler can also double as a debugger since the report also includes a full execution trace.

### Using the Gas Profiler

The gas profiler can be invoked by appending the `--profile-gas` option.

```shellscript filename="Terminal"
aptos move run --function-id 'default::message::set_message' --args 'string:abc' --profile-gas
```

<details>
  <summary>Output</summary>

  ```shellscript
  Simulating transaction locally using the gas profiler...
  Gas report saved to gas-profiling/txn-d0bc3422-0xdbcb-message-set_message.
  {
    "Result": {
      "transaction_hash": "0xd0bc342232f14a6a7d2d45251719aee45373bdb53f68403cfc6dc6062c74fa9e",
      "gas_used": 441,
      "gas_unit_price": 100,
      "sender": "dbcbe741d003a7369d87ec8717afb5df425977106497052f96f4e236372f7dd5",
      "success": true,
      "version": 1034003962,
      "vm_status": "status EXECUTED of type Execution"
    }
  }
  ```
</details>

You can then find the generated gas report in the directory `gas-profiling`:

<FileTree>
  - hello\_blockchain/
    - Move.toml
    - sources/
    - gas-profiling/
      - txn-XXXXXXXX-0xXXXX-message-set\_message/
        - assets/
        - index.html
</FileTree>

`index.html` is the main page of the report, which can view using your web browser.
[Sample report](/gas-profiling/sample-report-2/index.html)

### Understanding the Gas Report

The gas report consists of three sections that help you to understand the gas usage through different lenses.

#### Flamegraphs

The first section consists of visualization of the gas usage in the form of two flamegraphs: one for execution & IO, the other for storage.
The reason why we need two graphs is that these are measured in different units: one in gas units, and the other in APT.

It is possible to interact with various elements in the graph. If you hover your cursor over an item, it will show you the precise cost and percentage.
![gas-profiling-flamegraph-0.png](~/images/gas-profiling-flamegraph-0.png)

If you click on an item, you can zoom into it and see the child items more clearly.
You can reset the view by clicking the "Reset Zoom" button in the top-left corner.
![gas-profiling-flamegraph-1.png](~/images/gas-profiling-flamegraph-1.png)

There is also "Search" button in the top-right corner that allows to match certain items and highlight them.
![gas-profiling-flamegraph-2.png](~/images/gas-profiling-flamegraph-2.png)

#### Cost Break-down

The second section is a detailed break-down of all gas costs. Data presented in this section is categorized, aggregated and sorted.
This can be especially helpful if you know what numbers to look at.

For example, the following tables show the execution costs of all Move bytecode instructions/operations.
The percentage here is relative to the total cost of the belonging category (Exec + IO in this case).

![gas-profiling-cost-break-down-table.png](~/images/gas-profiling-cost-break-down-table.png)

#### Full Execution Trace

The final section of the gas report is the full execution trace of the transaction that looks like this:

```text filename="Example execution trace"
    intrinsic                                                     2.76        85.12%
    dependencies                                                  0.0607      1.87%
        0xdbcb..::message                                         0.0607      1.87%
    0xdbcb..::message::set_message                                0.32416     10.00%
        create_ty                                                 0.0004      0.01%
        create_ty                                                 0.0004      0.01%
        create_ty                                                 0.0004      0.01%
        create_ty                                                 0.0004      0.01%
        create_ty                                                 0.0008      0.02%
        imm_borrow_loc                                            0.00022     0.01%
        call                                                      0.00441     0.14%
        0x1::signer::address_of                                   0.007534    0.23%
            create_ty                                             0.0008      0.02%
            move_loc                                              0.000441    0.01%
            call                                                  0.004043    0.12%
            0x1::signer::borrow_address                           0.000735    0.02%
            read_ref                                              0.001295    0.04%
            ret                                                   0.00022     0.01%
        st_loc                                                    0.000441    0.01%
        copy_loc                                                  0.000854    0.03%
        load<0xdbcb..::0xdbcb..::message::MessageHolder>          0.302385    9.33%
        exists_generic                                            0.000919    0.03%
        not                                                       0.000588    0.02%
        br_false                                                  0.000441    0.01%
        imm_borrow_loc                                            0.00022     0.01%
        move_loc                                                  0.000441    0.01%
        pack                                                      0.000955    0.03%
        move_to_generic                                           0.001838    0.06%
        branch                                                    0.000294    0.01%
        @28
        ret                                                       0.00022     0.01%
    ledger writes                                                 0.097756    3.01%
        transaction
        events
        state write ops                                           0.097756    3.01%
            create<0xdbcb..::0xdbcb..::message::MessageHolder>    0.097756    3.01%
```

The left column lists all Move instructions and operations being executed, with each level of indentation indicating a function call.

The middle column represents the gas costs associated with the operations.

There is also a special notation `@number` that represents a jump to a particular location in the byte code. (`@28` in the snippet above)
This is purely informational and to help understand the control flow.

# Multisig Governance Tutorial

> Learn how to create and use multisig accounts for governance operations using the Aptos CLI with hands-on examples for transaction proposals and execution.

import { Aside } from '@astrojs/starlight/components';

## Background

This section builds upon the [Arguments in JSON tutorial](/build/cli/working-with-move-contracts/arguments-in-json-tutorial). If you have not done that, please complete that tutorial first.

This tutorial likewise references the [`CliArgs` example package](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/move-examples/cli_args).

<Aside type="note" emoji="‚ÑπÔ∏è">
  If you would like to follow along, start by completing the [Arguments in JSON](/build/cli/working-with-move-contracts/arguments-in-json-tutorial) tutorial steps!
</Aside>

For this example, Ace and Bee will conduct governance operations from a 2-of-2 "multisig v2" account (an on-chain multisig account per [`multisig_account.move`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/multisig_account.move))

## Account creation

Since Ace's account was created during the [Arguments in JSON](/build/cli/working-with-move-contracts/arguments-in-json-tutorial) tutorial, start by mining a vanity address account for Bee too:

```shellscript filename="Terminal"
aptos key generate \
    --vanity-prefix 0xbee \
    --output-file bee.key
```

<details>
  <summary>Output</summary>

  ```shellscript filename="Terminal"
  {
    "Result": {
      "PublicKey Path": "bee.key.pub",
      "PrivateKey Path": "bee.key",
      "Account Address:": "0xbeec980219d246581cef5166dc6ba5fb1e090c7a7786a5176d111a9029b16ddc"
    }
  }
  ```
</details>

<Aside type="note" emoji="‚ÑπÔ∏è">
  The exact account address should vary for each run, though the vanity prefix should not.
</Aside>

Store Bee's address in a shell variable, so you can call it inline later on:

```shellscript filename="Terminal"
# Your exact address should vary
bee_addr=0xbeec980219d246581cef5166dc6ba5fb1e090c7a7786a5176d111a9029b16ddc
```

Fund Bee's account using the faucet:

```shellscript filename="Terminal"
aptos account fund-with-faucet --account $bee_addr
```

<details>
  <summary>Output</summary>

  ```shellscript filename="Terminal"
  {
    "Result": "Added 100000000 Octas to account beec980219d246581cef5166dc6ba5fb1e090c7a7786a5176d111a9029b16ddc"
  }
  ```
</details>

Ace can now create a multisig account:

```shellscript filename="Terminal"
aptos multisig create \
    --additional-owners $bee_addr \
    --num-signatures-required 2 \
    --private-key-file ace.key \
    --assume-yes
```

<details>
  <summary>Output</summary>

  ```shellscript filename="Terminal"
  {
    "Result": {
      "multisig_address": "57478da34604655c68b1dcb89e4f4a9124b6c0ecc1c59a0931d58cc4e60ac5c5",
      "transaction_hash": "0x849cc756de2d3b57210f5d32ae4b5e7d1f80e5d376233885944b6f3cc2124a05",
      "gas_used": 1524,
      "gas_unit_price": 100,
      "sender": "acef1b9b7d4ab208b99fed60746d18dcd74865edb7eb3c3f1428233988e4ba46",
      "sequence_number": 5,
      "success": true,
      "timestamp_us": 1685078644186194,
      "version": 528428043,
      "vm_status": "Executed successfully"
    }
  }
  ```
</details>

Store the multisig address in a shell variable:

```shellscript filename="Terminal"
# Your address should vary
multisig_addr=0x57478da34604655c68b1dcb89e4f4a9124b6c0ecc1c59a0931d58cc4e60ac5c5
```

## Inspect the multisig

Use the assorted [`multisig_account.move` view functions](https://github.com/aptos-labs/aptos-core/blob/9fa0102c3e474d99ea35a0a85c6893604be41611/aptos-move/framework/aptos-framework/sources/multisig_account.move#L237) to inspect the multisig:

```shellscript filename="Number of signatures required"
aptos move view \
    --function-id 0x1::multisig_account::num_signatures_required \
    --args \
        address:"$multisig_addr"
```

<details>
  <summary>Output</summary>

  ```shellscript filename="Terminal"
  {
    "Result": [
      "2"
    ]
  }
  ```
</details>

```shellscript filename="Owners"
aptos move view \
    --function-id 0x1::multisig_account::owners \
    --args \
        address:"$multisig_addr"
```

<details>
  <summary>Output</summary>

  ```shellscript filename="Terminal"
  {
    "Result": [
      [
        "0xbeec980219d246581cef5166dc6ba5fb1e090c7a7786a5176d111a9029b16ddc",
        "0xacef1b9b7d4ab208b99fed60746d18dcd74865edb7eb3c3f1428233988e4ba46"
      ]
    ]
  }
  ```
</details>

```shellscript filename="Last resolved sequence number"
aptos move view \
    --function-id 0x1::multisig_account::last_resolved_sequence_number \
    --args \
        address:"$multisig_addr"
```

<details>
  <summary>Output</summary>

  ```shellscript filename="Terminal"
  {
    "Result": [
      "0"
    ]
  }
  ```
</details>

```shellscript filename="Next sequence number"
aptos move view \
    --function-id 0x1::multisig_account::next_sequence_number \
    --args \
        address:"$multisig_addr"
```

<details>
  <summary>Output</summary>

  ```shellscript filename="Terminal"
  {
    "Result": [
      "1"
    ]
  }
  ```
</details>

## Enqueue a publication transaction

The first multisig transaction enqueued will be a transaction for publication of the [`CliArgs` example package](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/move-examples/cli_args).
First, generate a publication payload entry function JSON file:

```shellscript filename="Command"
aptos move build-publish-payload \
    --named-addresses test_account=$multisig_addr \
    --json-output-file publication.json \
    --assume-yes
```

<details>
  <summary>Output</summary>

  ```shellscript filename="Terminal"
  {
    "Result": "Publication payload entry function JSON file saved to publication.json"
  }
  ```
</details>

Now have Ace propose publication of the package from the multisig account, storing only the payload hash on-chain:

```shellscript filename="Command"
aptos multisig create-transaction \
    --multisig-address $multisig_addr \
    --json-file publication.json \
    --store-hash-only \
    --private-key-file ace.key \
    --assume-yes
```

<details>
  <summary>Output</summary>

  ```shellscript filename="Terminal"
  {
    "Result": {
      "transaction_hash": "0x70c75903f8e1b1c0069f1e84ef9583ad8000f24124b33a746c88d2b031f7fe2c",
      "gas_used": 510,
      "gas_unit_price": 100,
      "sender": "acef1b9b7d4ab208b99fed60746d18dcd74865edb7eb3c3f1428233988e4ba46",
      "sequence_number": 6,
      "success": true,
      "timestamp_us": 1685078836492390,
      "version": 528429447,
      "vm_status": "Executed successfully"
    }
  }
  ```
</details>

Note that the last resolved sequence number is still 0 because no transactions have been resolved:

```shellscript filename="Last resolved sequence number"
aptos move view \
    --function-id 0x1::multisig_account::last_resolved_sequence_number \
    --args \
        address:"$multisig_addr"
```

<details>
  <summary>Output</summary>

  ```shellscript filename="Terminal"
  {
    "Result": [
      "0"
    ]
  }
  ```
</details>

However, the next sequence number has been incremented because a transaction has been enqueued:

```shellscript filename="Next sequence number"
aptos move view \
    --function-id 0x1::multisig_account::next_sequence_number \
    --args \
        address:"$multisig_addr"
```

<details>
  <summary>Output</summary>

  ```shellscript filename="Terminal"
  {
    "Result": [
      "2"
    ]
  }
  ```
</details>

The multisig transaction enqueued on-chain can now be inspected:

```shellscript filename="Get transaction"
aptos move view \
    --function-id 0x1::multisig_account::get_transaction \
    --args \
        address:"$multisig_addr" \
        u64:1
```

<details>
  <summary>Output</summary>

  ```shellscript filename="Terminal"
  {
    "Result": [
      {
        "creation_time_secs": "1685078836",
        "creator": "0xacef1b9b7d4ab208b99fed60746d18dcd74865edb7eb3c3f1428233988e4ba46",
        "payload": {
          "vec": []
        },
        "payload_hash": {
          "vec": [
            "0x62b91159c1428c1ef488c7290771de458464bd665691d9653d195bc28e0d2080"
          ]
        },
        "votes": {
          "data": [
            {
              "key": "0xacef1b9b7d4ab208b99fed60746d18dcd74865edb7eb3c3f1428233988e4ba46",
              "value": true
            }
          ]
        }
      }
    ]
  }
  ```
</details>

Note from the above result that no payload is stored on-chain, and that Ace implicitly approved the transaction (voted `true`) upon the submission of the proposal.

## Enqueue a governance parameter transaction

Now have Bee enqueue a governance parameter setter transaction, storing the entire transaction payload on-chain:

```shellscript filename="Command"
aptos multisig create-transaction \
    --multisig-address $multisig_addr \
    --function-id $multisig_addr::cli_args::set_vals \
    --type-args \
        0x1::account::Account \
        0x1::chain_id::ChainId \
    --args \
        u8:123 \
        "bool:[false, true, false, false]" \
        'address:[["0xace", "0xbee"], ["0xcad"], []]' \
    --private-key-file bee.key \
    --assume-yes
```

<details>
  <summary>Output</summary>

  ```shellscript filename="Terminal"
  {
    "Result": {
      "transaction_hash": "0xd0a348072d5bfc5a2e5d444f92f0ecc10b978dad720b174303bc6d91342f27ec",
      "gas_used": 511,
      "gas_unit_price": 100,
      "sender": "beec980219d246581cef5166dc6ba5fb1e090c7a7786a5176d111a9029b16ddc",
      "sequence_number": 0,
      "success": true,
      "timestamp_us": 1685078954841650,
      "version": 528430315,
      "vm_status": "Executed successfully"
    }
  }
  ```
</details>

Note the next sequence number has been incremented again:

```shellscript filename="Next sequence number"
aptos move view \
    --function-id 0x1::multisig_account::next_sequence_number \
    --args \
        address:"$multisig_addr"
```

<details>
  <summary>Output</summary>

  ```shellscript filename="Terminal"
  {
    "Result": [
      "3"
    ]
  }
  ```
</details>

Now both the publication and parameter transactions are pending:

```shellscript filename="Get pending transactions"
aptos move view \
    --function-id 0x1::multisig_account::get_pending_transactions \
    --args \
        address:"$multisig_addr"
```

<details>
  <summary>Output</summary>

  ```shellscript filename="Terminal"
  {
    "Result": [
      [
        {
          "creation_time_secs": "1685078836",
          "creator": "0xacef1b9b7d4ab208b99fed60746d18dcd74865edb7eb3c3f1428233988e4ba46",
          "payload": {
            "vec": []
          },
          "payload_hash": {
            "vec": [
              "0x62b91159c1428c1ef488c7290771de458464bd665691d9653d195bc28e0d2080"
            ]
          },
          "votes": {
            "data": [
              {
                "key": "0xacef1b9b7d4ab208b99fed60746d18dcd74865edb7eb3c3f1428233988e4ba46",
                "value": true
              }
            ]
          }
        },
        {
          "creation_time_secs": "1685078954",
          "creator": "0xbeec980219d246581cef5166dc6ba5fb1e090c7a7786a5176d111a9029b16ddc",
          "payload": {
            "vec": [
              "0x0057478da34604655c68b1dcb89e4f4a9124b6c0ecc1c59a0931d58cc4e60ac5c508636c695f61726773087365745f76616c7302070000000000000000000000000000000000000000000000000000000000000001076163636f756e74074163636f756e740007000000000000000000000000000000000000000000000000000000000000000108636861696e5f696407436861696e49640003017b0504000100006403020000000000000000000000000000000000000000000000000000000000000ace0000000000000000000000000000000000000000000000000000000000000bee010000000000000000000000000000000000000000000000000000000000000cad00"
            ]
          },
          "payload_hash": {
            "vec": []
          },
          "votes": {
            "data": [
              {
                "key": "0xbeec980219d246581cef5166dc6ba5fb1e090c7a7786a5176d111a9029b16ddc",
                "value": true
              }
            ]
          }
        }
      ]
    ]
  }
  ```
</details>

## Execute the publication transaction

Since only Ace has voted on the publication transaction (which he implicitly approved upon proposing) the transaction can't be executed yet:

```shellscript filename="Can be executed"
aptos move view \
    --function-id 0x1::multisig_account::can_be_executed \
    --args \
        address:"$multisig_addr" \
        u64:1
```

<details>
  <summary>Output</summary>

  ```shellscript filename="Terminal"
  {
    "Result": [
      false
    ]
  }
  ```
</details>

Before Bee votes, however, she verifies that the payload hash stored on-chain matches the publication entry function JSON file:

```shellscript filename="Verifying transaction proposal"
aptos multisig verify-proposal \
    --multisig-address $multisig_addr \
    --json-file publication.json \
    --sequence-number 1
```

<details>
  <summary>Output</summary>

  ```shellscript filename="Terminal"
  {
    "Result": {
      "Status": "Transaction match",
      "Multisig transaction": {
        "creation_time_secs": "1685078836",
        "creator": "0xacef1b9b7d4ab208b99fed60746d18dcd74865edb7eb3c3f1428233988e4ba46",
        "payload": {
          "vec": []
        },
        "payload_hash": {
          "vec": [
            "0x62b91159c1428c1ef488c7290771de458464bd665691d9653d195bc28e0d2080"
          ]
        },
        "votes": {
          "data": [
            {
              "key": "0xacef1b9b7d4ab208b99fed60746d18dcd74865edb7eb3c3f1428233988e4ba46",
              "value": true
            }
          ]
        }
      }
    }
  }
  ```
</details>

Since Bee has verified that the on-chain payload hash checks out against her locally-compiled package publication JSON file, she votes yes:

```shellscript filename="Approving transaction"
aptos multisig approve \
    --multisig-address $multisig_addr \
    --sequence-number 1 \
    --private-key-file bee.key \
    --assume-yes
```

<details>
  <summary>Output</summary>

  ```shellscript filename="Terminal"
  {
    "Result": {
      "transaction_hash": "0xa5fb49f1077de6aa6d976e6bcc05e4c50c6cd061f1c87e8f1ea74e7a04a06bd1",
      "gas_used": 6,
      "gas_unit_price": 100,
      "sender": "beec980219d246581cef5166dc6ba5fb1e090c7a7786a5176d111a9029b16ddc",
      "sequence_number": 1,
      "success": true,
      "timestamp_us": 1685079892130861,
      "version": 528437204,
      "vm_status": "Executed successfully"
    }
  }
  ```
</details>

Now the transaction can be executed:

```shellscript filename="Can be executed"
aptos move view \
    --function-id 0x1::multisig_account::can_be_executed \
    --args \
        address:"$multisig_addr" \
        u64:1
```

<details>
  <summary>Output</summary>

  ```shellscript filename="Terminal"
  {
    "Result": [
      true
    ]
  }
  ```
</details>

Now either Ace or Bee can invoke the publication transaction from the multisig account, passing the full transaction payload since only the hash was stored on-chain:

```shellscript filename="Publication"
aptos multisig execute-with-payload \
    --multisig-address $multisig_addr \
    --json-file publication.json \
    --private-key-file bee.key \
    --max-gas 10000 \
    --assume-yes
```

<Aside type="note" emoji="‚ÑπÔ∏è">
  Pending the resolution of [#8304](https://github.com/aptos-labs/aptos-core/issues/8304), the transaction simulator (which is used to estimate gas costs) is broken for multisig transactions, so you will have to manually specify a max gas amount.
</Aside>

<details>
  <summary>Output</summary>

  Also pending the resolution of [#8304](https://github.com/aptos-labs/aptos-core/issues/8304), the CLI output for a successful multisig publication transaction execution results in an API error if only the payload hash has been stored on-chain, but the transaction can be manually verified using an explorer.
</details>

## Execute the governance parameter transaction

Since only Bee has voted on the governance parameter transaction (which she implicitly approved upon proposing), the transaction can't be executed yet:

```shellscript filename="Can be executed"
aptos move view \
    --function-id 0x1::multisig_account::can_be_executed \
    --args \
        address:"$multisig_addr" \
        u64:2
```

<details>
  <summary>Output</summary>

  ```shellscript filename="Terminal"
  {
    "Result": [
      false
    ]
  }
  ```
</details>

Before Ace votes, however, he verifies that the payload stored on-chain matches the function arguments he expects:

```shellscript filename="Verifying transaction proposal"
aptos multisig verify-proposal \
    --multisig-address $multisig_addr \
    --function-id $multisig_addr::cli_args::set_vals \
    --type-args \
        0x1::account::Account \
        0x1::chain_id::ChainId \
    --args \
        u8:123 \
        "bool:[false, true, false, false]" \
        'address:[["0xace", "0xbee"], ["0xcad"], []]' \
    --sequence-number 2
```

<details>
  <summary>Output</summary>

  ```shellscript filename="Terminal"
  {
    "Result": {
      "Status": "Transaction match",
      "Multisig transaction": {
        "creation_time_secs": "1685078954",
        "creator": "0xbeec980219d246581cef5166dc6ba5fb1e090c7a7786a5176d111a9029b16ddc",
        "payload": {
          "vec": [
            "0x0057478da34604655c68b1dcb89e4f4a9124b6c0ecc1c59a0931d58cc4e60ac5c508636c695f61726773087365745f76616c7302070000000000000000000000000000000000000000000000000000000000000001076163636f756e74074163636f756e740007000000000000000000000000000000000000000000000000000000000000000108636861696e5f696407436861696e49640003017b0504000100006403020000000000000000000000000000000000000000000000000000000000000ace0000000000000000000000000000000000000000000000000000000000000bee010000000000000000000000000000000000000000000000000000000000000cad00"
          ]
        },
        "payload_hash": {
          "vec": []
        },
        "votes": {
          "data": [
            {
              "key": "0xbeec980219d246581cef5166dc6ba5fb1e090c7a7786a5176d111a9029b16ddc",
              "value": true
            }
          ]
        }
      }
    }
  }
  ```
</details>

Note that the verification fails if he modifies even a single argument:

```shellscript filename="Failed transaction verification with modified u8"
aptos multisig verify-proposal \
    --multisig-address $multisig_addr \
    --function-id $multisig_addr::cli_args::set_vals \
    --type-args \
        0x1::account::Account \
        0x1::chain_id::ChainId \
    --args \
        u8:200 \
        "bool:[false, true, false, false]" \
        'address:[["0xace", "0xbee"], ["0xcad"], []]' \
    --sequence-number 2
```

<details>
  <summary>Output</summary>

  ```shellscript filename="Terminal"
  {
    "Error": "Unexpected error: Transaction mismatch: The transaction you provided has a payload hash of 0xe494b0072d6f940317344967cf0e818c80082375833708c773b0275f3ad07e51, but the on-chain transaction proposal you specified has a payload hash of 0x070ed7c3f812f25f585461305d507b96a4e756f784e01c8c59901871267a1580. For more info, see https://aptos.dev/move/move-on-aptos/cli#multisig-governance"
  }
  ```
</details>

Ace approves the transaction:

```shellscript filename="Approving transaction"
aptos multisig approve \
    --multisig-address $multisig_addr \
    --sequence-number 2 \
    --private-key-file ace.key \
    --assume-yes
```

<details>
  <summary>Output</summary>

  ```shellscript filename="Terminal"
  {
    "Result": {
      "transaction_hash": "0x233427d95832234fa13dddad5e0b225d40168b4c2c6b84f5255eecc3e68401bf",
      "gas_used": 6,
      "gas_unit_price": 100,
      "sender": "acef1b9b7d4ab208b99fed60746d18dcd74865edb7eb3c3f1428233988e4ba46",
      "sequence_number": 7,
      "success": true,
      "timestamp_us": 1685080266378400,
      "version": 528439883,
      "vm_status": "Executed successfully"
    }
  }
  ```
</details>

Since the payload was stored on-chain, it is not required to execute the pending transaction:

```shellscript filename="Execution"
aptos multisig execute \
    --multisig-address $multisig_addr \
    --private-key-file ace.key \
    --max-gas 10000 \
    --assume-yes
```

<details>
  <summary>Output</summary>

  ```shellscript filename="Terminal"
  {
    "Result": {
      "transaction_hash": "0xbc99f929708a1058b223aa880d04607a78ebe503367ec4dab23af4a3bdb541b2",
      "gas_used": 505,
      "gas_unit_price": 100,
      "sender": "acef1b9b7d4ab208b99fed60746d18dcd74865edb7eb3c3f1428233988e4ba46",
      "sequence_number": 8,
      "success": true,
      "timestamp_us": 1685080344045461,
      "version": 528440423,
      "vm_status": "Executed successfully"

  ```
</details>

# Transaction Simulation Sessions

> Guide on performing complex local simulations using Transaction Simulation Sessions.

import { Aside, FileTree } from '@astrojs/starlight/components';

In the previous tutorials, we demonstrated how you can [simulate a transaction locally](/build/cli/working-with-move-contracts/local-simulation-benchmarking-and-gas-profiling),
or [replay a past transaction](/build/cli/replay-past-transactions). However, these methods only work for a single transaction.

To simulate multiple transactions in sequence, you'll need to use **Transaction Simulation Sessions** -- an advanced CLI feature that
allows you to create a persistent local environment that saves and restores states between runs, with the added benefit of being able
to inspect transaction outputs with ease.

This makes it possible to test complex workflows ‚Äî such as contract deployment, resource updates, or multi-step interactions.

<Aside type="note" emoji="‚ÑπÔ∏è">
Before you get started, make sure you have updated your Aptos CLI to the latest version.

Older versions of the Aptos CLI may not support Transaction Simulation Sessions as it's a relatively new feature.
</Aside>

## Initializing a Session
You can initialize a session either from:
- **A clean local genesis**, for a completely local, isolated environment, or
- **A forked network state** (Devnet, Testnet, or Mainnet), allowing you to test your changes against real-world data.

Regardless of which mode you choose, the interface, commands, and how session data is saved are exactly the same.
Just specify your preferred mode when you initialize the session.

### From a Forked Network State
With network forking, you can test your Move code using **live network data** ‚Äî balances, resources, and published modules.

To start with a forked network state, run:
```shellscript filename="Terminal"
aptos move sim init --path <SESSION_PATH> --network <NETWORK> --api-key <YOUR_API_KEY>
```
Here `<NETWORK>` can be one of the following: `devnet`, `testnet`, `mainnet`, or a custom fullnode URL.
The session will store all its data in the specified `<SESSION_PATH>` directory.

<Aside type="note" emoji="‚ÑπÔ∏è">
You'll need a free Aptos developer account and an API key to use network forking mode.
Without an API key, you are given a very low rate limit and may run into rate limit errors almost certainly.

You can follow the official instructions here: [Setup an API Key](/build/guides/build-e2e-dapp#setup-api-key).
</Aside>

### From a Clean Local Genesis
For day-to-day development, sometimes you just need a clean slate ‚Äî no real network data needed.
This is perfect for ad-hoc simulation,synthetic testing, or continuous integration.

To start with a clean local genesis, run:
```shellscript filename="Terminal"
aptos move sim init --path <SESSION_PATH>
```
Everything else works the same ‚Äî except that the simulation won't touch the network at all, as all data is local.

## Running simulations
Once initialized, you can run transactions against your session using the standard `aptos move` commands,
adding the `--session` argument to indicate which local session to use.

Supported commands include:
- `run`
- `run-script`
- `publish`
- `view`
- `create-object-and-publish-package`
- `upgrade-object-package`
- `deploy-object`
- `upgrade-object`
- `create-resource-account-and-publish-package`

There are also additional utilities under `aptos move sim` for managing and inspecting sessions.
- `fund`: fund an account with a given amount of APT
- `view-resource`: view a Move resource
- `view-resource-group`: view a resource group

For more detailed help, run `aptos move sim --help`.

### Example Workflow
```shellscript filename="Terminal"
# 1. Fund your default account with 1 APT (for demo)
aptos move sim fund --session sess --account default --amount 100000000

# 2. Execute a transfer transaction
aptos move run --session sess \
  --function-id 0x1::aptos_account::transfer \
  --args address:default u64:100

# 3. Query your account's sequence number
aptos move view --session sess \
  --function-id 0x1::account::get_sequence_number \
  --args address:default

# 4. View your on-chain Account resource
aptos move sim view-resource --session sess \
  --account default \
  --resource 0x1::account::Account

# 5. View a resource group (e.g. your fungible store)
aptos move sim view-resource-group --session sess \
  --account default \
  --resource-group 0x1::object::ObjectGroup \
  --derived-object-address 0xA
```
Again, all state changes are local and are stored under your session directory.

## Inspecting Session Data
Each Transaction Simulation Session organizes its data in a structured directory tree, making it easy to inspect every step of your simulation.

Here's how the layout looks like for the sample session:
<FileTree>
  - sess/
    - [0] fund (fungible)/
      - summary.json
    - [1] execute 0x1::aptos_account::transfer/
      - events.json
      - summary.json
      - write_set.json
    - [2] view 0x1::account::get_sequence_number/
      - summary.json
    - [3] view resource 0xdbcb...::0x1::account::Account/
      - summary.json
    - [4] view resource group 0x20ce...::0x1::object::ObjectGroup/
      - summary.json
    - config.json
    - delta.json
</FileTree>

### Sample Outputs
`[1] execute 0x1::aptos_account::transfer/summary.json`
```json
{
  "execute_transaction": {
    "status": {
      "Keep": "Success"
    },
    "gas_used": 498,
    "fee_statement": {
      "total_charge_gas_units": 498,
      "execution_gas_units": 4,
      "io_gas_units": 3,
      "storage_fee_octas": 49160,
      "storage_fee_refund_octas": 0
    }
  }
}
```
`[1] execute 0x1::aptos_account::transfer/events.json`
```json
[
  {
    "V2": {
      "type_tag": "0x1::fungible_asset::Withdraw",
      "event_data": {
        "store": "20ce9f242351eae77cae7eb27e7e55f798e6c3b3528fcbb325bccea103e53ff9",
        "amount": 100
      }
    }
  },
  {
    "V2": {
      "type_tag": "0x1::fungible_asset::Deposit",
      "event_data": {
        "store": "20ce9f242351eae77cae7eb27e7e55f798e6c3b3528fcbb325bccea103e53ff9",
        "amount": 100
      }
    }
  },
  {
    "V2": {
      "type_tag": "0x1::transaction_fee::FeeStatement",
      "event_data": {
        "total_charge_gas_units": 498,
        "execution_gas_units": 4,
        "io_gas_units": 3,
        "storage_fee_octas": 49160,
        "storage_fee_refund_octas": 0
      }
    }
  }
]
```

## Future Plans
We are working on adding more features to Transaction Simulation Sessions, such as:
- Gas Profiler integration
- Better performance
- Snapshot and rollback support

# create-aptos-dapp - A templating tool for Aptos dapps

> Build template projects for dapp developers to easily create front-end and smart contracts on the Aptos network

import { Steps, TabItem, Tabs } from '@astrojs/starlight/components';

`create-aptos-dapp` builds a template project for dapp developers to easily create a front-end and a smart contract on the Aptos network.

## Why use create-aptos-dapp?

- **Templated Setup**: `create-aptos-dapp` generates predefined end-to-end dapp templates and configuration files for you. It saves manual setup of the project structure, which can be time-consuming and error-prone.
- **Contract Directory:** `create-aptos-dapp` generates a `contract` directory that includes the basic structure for Move smart contract modules.
- **Best Practices**: `create-aptos-dapp` incorporates best practices and structure recommendations to develop for the Aptos network.
- **Built-in Move Commands**: `create-aptos-dapp` includes built-in commands for common tasks, such as initializing the Move compiler, compiling, and publishing smart contracts on-chain.

## Prerequisites

- [node and npm](https://nodejs.org/en) (npm ‚â• 5.2.0)
- [Python 3.6+](https://www.python.org/)

## Using `create-aptos-dapp`

<Steps>
  1. Navigate to the directory you want to work in.

     ```shellscript filename="Terminal"
     cd your/workspace
     ```

  2. Install create-aptos-dapp.

     <Tabs>
       <TabItem label="npx">
         ```shellscript filename="Terminal"
         npx create-aptos-dapp@latest
         ```
       </TabItem>

       <TabItem label="pnpx">
         ```shellscript filename="Terminal"
         pnpx create-aptos-dapp@latest
         ```
       </TabItem>

       <TabItem label="yarn">
         ```shellscript filename="Terminal"
         yarn create aptos-dapp
         ```
       </TabItem>

       <TabItem label="pnpm">
         ```shellscript filename="Terminal"
         pnpm create create-aptos-dapp@latest
         ```
       </TabItem>
     </Tabs>

  3. Follow the CLI prompts.

     After installing, you will need to answer several questions about your project including:

     1. The project's name
     2. Which template to use ([see below](#current-templates))
     3. Whether to use Mainnet or Devnet for testing

     ![cad](~/images/cad-video.gif)
</Steps>

## Templates

`create-aptos-dapp` provides you with premade end-to-end dapp templates, i.e. a ready dapp with configurations and a beautiful UI to get you started with creating a dapp on Aptos.

The goals of the templates are to:

1. Familiarize users with different Aptos Standards by having an end-to-end dapp template examples.
2. Educate users on how to build a dapp on Aptos from the front-end layer to the smart contract layer and how everything in-between.
3. Provide users with pre-made templates to quickly deploy simple dapps

### Current Templates

All current templates are available on [Aptos Learn](https://learn.aptoslabs.com/en/dapp-templates). Read more about specific templates below:

- [Boilerplate Template](https://learn.aptoslabs.com/en/dapp-templates/boilerplate-template)
- [NFT minting dapp Template](https://learn.aptoslabs.com/en/dapp-templates/nft-minting-template)
- [Token minting dapp Template](https://learn.aptoslabs.com/en/dapp-templates/token-minting-template)
- [Token staking dapp Template](https://learn.aptoslabs.com/en/dapp-templates/token-staking-template)
- [Custom indexer template](https://learn.aptoslabs.com/en/dapp-templates/custom-indexer-template)

## Tools `create-aptos-dapp` utilizes

- React framework
- Vite development tool
- shadcn/ui + tailwind for styling
- Aptos TS SDK
- Aptos Wallet Adapter
- Node based Move commands

# Create Aptos Dapp FAQ

> Frequently asked questions about using create-aptos-dapp tool and its templates

## Why do we use `import.meta.env`?

The template is built in a way that there are pages meant to be accessed only on DEV mode and pages that are meant to be accessed also on PROD mode. For example, ‚Äúcreate collection‚Äù and ‚Äúmy collections‚Äù pages are only meant for local development and can only be accessed on DEV mode while the ‚Äúpublic mint‚Äù page can be accessed on PROD mode. `import.meta.env` is the `Vite` way to know what is the environment the dapp is running on - DEV or PROD.

## I tried to publish my dapp to a live server but getting `404 error`

Might need to update the root route, if you deployed your site to `user-name.github.io/my-repo` then root route should be updated to `my-repo`

## What is Tailwind CSS?

Tailwind is a utility-first CSS framework that scans your components for class names and generates a static CSS file containing the corresponding styles at build-time.

This framework makes it easy to quickly author styles that are co-located with your component markup without incurring any runtime performance costs. It also helps you to maintain a consistent theme throughout your app that is responsive to light and dark mode.

To learn more about Tailwind CSS, please refer to their official [documentation](https://tailwindcss.com/docs/utility-first).

## What is `shadcn/ui`?

Shadcn is a collection of accessible components that you can copy and paste into your app through their CLI tool. Since the source files live in your app's codebase, you can customize them as much as you need to.

These components are built on top of [Radix UI Primitives](https://www.radix-ui.com/primitives) and are styled with [Tailwind CSS](https://tailwindcss.com/). To learn more about `shadcn/ui`, please refer to their official [documentation](https://ui.shadcn.com/docs).

## How to modify the theme?

The theme for this template is split across `tailwind.config.js` and `frontend/index.css`. The Tailwind config declares all of the theme colors, text styles, animation keyframes, border radii, etc. The root CSS file (`index.css`) declares the actual color values for light and dark mode as CSS custom properties (CSS variables), the base radius value, and applies any global CSS required.

For example, if you want to make all of the buttons and cards more round in your app, you can increase the base radius value (`--radius`) in `index.css`.

If you want to add a new text style, you can define it in the `addTextStyles` function towards the end of `tailwind.config.js`.

And if you want to modify the primary color of the app, you can update the HSL color values defined in `index.css`.

## How to add components?

Additional components can be added through the `shadcn-ui` CLI. For example, if you wish to add a `Switch` component, you can run the following command:

```shellscript filename="Terminal"
npx shadcn-ui@latest add switch
```

This command will create a `switch.tsx` file in your `frontend/components/ui` directory that contains a styled switch component. For a full list of available shadcn components, please refer to the [shadcn component documentation](https://ui.shadcn.com/docs/components).

If you need to add a component that's not included in the `shadcn/ui` collection, you're welcome to add your own components under `frontend/components` or within the `frontend/pages` directory if they're specific to the page that you're working on.

## How to add colors?

If you're creating your own custom components or adding to the UI in some way, you may need to add some new colors. To add a new color, you must first define the light and dark HSL color values in `frontend/index.css` and then add the new theme color token to the theme defined in `tailwind.config.js`.

For more detailed instructions, please refer to the [shadcn documentation on theming](https://ui.shadcn.com/docs/theming).

## How to add dark mode?

In an effort to maintain simplicity in the dapp template, only light mode is set up. However, color values are defined for both light and dark mode in the theme. If you wish to add dark mode to your app, you simply have to add the shadcn `ThemeProvider` and `ModeToggle` to your app. Once added, the UI will be fully responsive to both light and dark mode. For detailed instructions on how to achieve this, please refer to the [shadcn dark mode documentation](https://ui.shadcn.com/docs/dark-mode/vite).

# Get Started Building on Aptos

> Learn how to build on Aptos with smart contracts, indexer queries, SDKs, APIs, and comprehensive developer resources

import { CardGrid, LinkCard } from '@astrojs/starlight/components';

import { GraphQLEditor } from '~/components/react/GraphQLEditor';

## What would you like to learn?

<CardGrid>
  <LinkCard href="/build/smart-contracts" title="Smart Contracts" description="Learn how to write smart contracts on Aptos with the Move programming language." />

  <LinkCard href="/build/indexer" title="Query Data" description="Use the Aptos Indexer to query for on-chain data efficiently." />

  <LinkCard href="/network/blockchain/blockchain-deep-dive" title="Blockchain Infrastructure" description="Learn the different components of the Aptos blockchain's infrastructure." />
</CardGrid>

## What developer tools should I use?

<CardGrid>
  <LinkCard href="/build/sdks" title="SDKs" description="Use our TypeScript, Python, Rust, and other SDKs to submit transactions and read on-chain data." />

  <LinkCard href="/build/indexer" title="Indexer" description="Query for on-chain data like account balances, historical transactions, NFTs by account, and more." />

  <LinkCard href="/build/cli" title="CLI" description="Compile and profile Move smart contracts, run a local network, and more with the Aptos CLI." />
</CardGrid>

Here's an interactive example of our [Indexer](/build/indexer) and how you can query for the Current Fungible Asset Balances of an account. More usage examples can be found in [example queries](/build/indexer/indexer-api/fungible-asset-balances).

<GraphQLEditor
  query={`query GetFungibleAssetBalances($address: String, $offset: Int) {
  current_fungible_asset_balances(
    where: { owner_address: { _eq: $address } }
    offset: $offset
    limit: 100
    order_by: { amount: desc }
  ) {
    asset_type
    amount
    __typename
  }
}`}
  variables={`{
  "address": "0x0000000000000000000000000000000000000000000000000000000000000001",
  "offset": 0
}`}
/>

## Coming from another ecosystem?

Quickly ramp up on some of the differences and similarities between Aptos and other ecosystems.

<CardGrid>
  <LinkCard href="/build/get-started/ethereum-cheatsheet" title="Ethereum / EVM to Aptos Cheatsheet" />

  <LinkCard href="/build/get-started/solana-cheatsheet" title="Solana / SVM to Aptos Cheatsheet" />

  <LinkCard href="/network/blockchain/move#comparison-to-other-vms" title="VM Comparison" />
</CardGrid>

## Do you have any examples?

We've got all kinds of examples and guides, catered to what you're looking for.

### End-to-end guides

<CardGrid>
  <LinkCard href="/build/guides/first-transaction" title="Your First Transaction" description="This tutorial describes how to generate and submit transactions to the Aptos blockchain, and verify these submitted transactions." />

  <LinkCard href="/build/guides/your-first-nft" title="Your First NFT" description="This tutorial describes how to create and transfer non-fungible assets on the Aptos blockchain." />

  <LinkCard href="/build/guides/first-fungible-asset" title="Your First Fungible Asset" description="This tutorial introduces how you can compile, deploy, and mint your own fungible asset (FA), named FACoin." />
</CardGrid>

### Smart Contract guides

See the [Smart Contract](/build/smart-contracts) section for more info

<CardGrid>
  <LinkCard href="/build/guides/build-e2e-dapp/1-create-smart-contract" title="Create a Smart Contract" description="This is the first chapter of the tutorial on building an end-to-end dapp on Aptos." />

  <LinkCard href="https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/move-examples" title="Aptos Move Examples" description="30+ examples on how to develop Move on Aptos" target="_blank" />

  <LinkCard href="https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/move-examples/move-tutorial" title="Move Tutorial" description="Covers the basics of programming with Move" target="_blank" />
</CardGrid>

### Interactive guides

<CardGrid>
  <LinkCard href="https://learn.aptoslabs.com/en/workshops" title="Aptos Learn" description="Basic and advanced guides" target="_blank" />

  <LinkCard href="https://movespiders.com" title="Move Spiders" description="Learn about Move with a friendly spider mascot by Move Spiders" target="_blank" />

  <LinkCard href="https://www.aptosshores.com" title="Aptos Shores" description="Learn about Move with Aptos Shores" target="_blank" />
</CardGrid>

## How do I setup a full node or validator?

<CardGrid>
  <LinkCard href="/network/nodes/full-node" title="Setup a full node" />

  <LinkCard href="/network/nodes/validator-node" title="Setup a validator" />
</CardGrid>

# Developer Environment Setup

> Set up your development environment for frontend, smart contracts, and full-stack Aptos applications with step-by-step guides

import { CardGrid, LinkCard, Steps, TabItem, Tabs } from '@astrojs/starlight/components';

Here is an easy way to setup your environment depending on the type of development.

<Tabs>
  {/* Frontend */}

  <TabItem label="Frontend">
    <Steps>
      1. Initialize Frontend Project

         Here are some examples of popular choices:

         <Tabs>
           <TabItem label="Next.js">
             ```shellscript filename="Terminal"
             pnpx create-next-app@latest
             ```
           </TabItem>

           <TabItem label="Vite (TS)">
             ```shellscript filename="Terminal"
             pnpx create vite my-aptos-app --template react-ts
             ```
           </TabItem>
         </Tabs>

      2. Install @aptos-labs/ts-sdk

         ```shellscript npm2yarn
         npm i @aptos-labs/ts-sdk
         ```

      3. Setup TS SDK

         <CardGrid>
           <LinkCard
             href="/build/sdks/ts-sdk/quickstart"
             title="TS SDK Quickstart"
             description="See how to setup your account, network, use the
         faucet, send / simulate transactions, and more"
           />
         </CardGrid>

      4. Build your app!

         The developer setup for using Aptos in your frontend is now complete.
         Checkout our other tools that streamline the development process

         <CardGrid>
           <LinkCard
             href="/build/indexer"
             title="Indexer"
             description="Efficiently query for on-chain state like balances,
         transaction activity, token data, and more"
           />

           <LinkCard
             href="https://github.com/aptos-labs/aptos-ts-sdk/tree/main/examples/typescript"
             title="TS SDK Examples"
             description="20+ Examples of how to use the TS
         SDK"
             target="_blank"
           />

           <LinkCard href="https://geomi.dev/" title="Geomi" description="Hitting rate limits for Fullnode API / Indexers? Get an API Key here" target="_blank" />
         </CardGrid>
    </Steps>
  </TabItem>

  {/* Smart Contract */}

  <TabItem label="Smart Contract">
    <Steps>
      1. Install CLI

         <CardGrid>
           <LinkCard href="/build/cli" title="Aptos CLI" description="Instructions for how to install Aptos CLI" />
         </CardGrid>

      2. Setup Editor or IDE

         Add the following extensions to your editor of choice to make Move
         Development easier

         <Tabs>
           <TabItem label="JetBrains IDEs">
             <CardGrid>
               <LinkCard
                 href="https://plugins.jetbrains.com/plugin/14721-move-language"
                 title="Move on Aptos"
                 description="Language server and syntax highlighter for
         JetBrains IDEs like CLion, Rust Rover, WebStorm,
         IntelliJ"
                 target="_blank"
               />
             </CardGrid>
           </TabItem>

           <TabItem label="VSCode">
             <CardGrid>
               <LinkCard href="https://marketplace.visualstudio.com/items?itemName=AptosLabs.move-on-aptos" title="Move on Aptos extension" description="Full-featured Aptos Move IDE for VSCode" target="_blank" />
             </CardGrid>
           </TabItem>

           <TabItem label="Cursor, Kiro, etc.">
             <CardGrid>
               <LinkCard href="https://open-vsx.org/extension/aptoslabs/move-on-aptos" title="Move on Aptos extension" description="Full-featured Aptos Move IDE for OpenVSX-powered platforms" target="_blank" />
             </CardGrid>
           </TabItem>
         </Tabs>

      3. Create Smart Contract

         Navigate to your application folder and initialize a new smart contract by
         doing:

         ```shellscript filename="Terminal"
         aptos move init --name my_todo_list
         ```

      4. Build, Compile, and Deploy Smart Contract!

         The developer setup for using Aptos for smart contracts is now complete.
         For more info see the link to the Dapp tutorial below

         <CardGrid>
           <LinkCard
             href="/build/guides/build-e2e-dapp/1-create-smart-contract#what-is-a-movetoml-file"
             title="Create Smart Contract Guide"
             description="An easy todo list guide for how to setup a smart
         contract with Move"
           />
         </CardGrid>
    </Steps>
  </TabItem>

  {/* create-aptos-dapp */}

  <TabItem label="Create Aptos Dapp">
    <Steps>
      1. Install create-aptos-dapp

         Run the below command to install a dApp from a template in seconds:

         <Tabs>
           { /* npx */ }

           <TabItem label="npx">
             ```shellscript filename="Terminal"
             npx create-aptos-dapp@latest
             ```
           </TabItem>

           { /* pnpx */ }

           <TabItem label="pnpx">
             ```shellscript filename="Terminal"
             pnpx create-aptos-dapp@latest
             ```
           </TabItem>
         </Tabs>

      2. Follow the prompts

         Follow the CLI prompts to select a name, [template](/build/create-aptos-dapp#templates), and network for your new dApp.

         ![cad](~/images/cad-video.gif)

      3. Start building and customizing your new dApp!

         Navigate to your new project and open in your favorite IDE to continue building!

         Follow the generated `README.md` file for next steps.

      4. Continue reading

         <CardGrid>
           <LinkCard href="/build/create-aptos-dapp" title="Create Aptos Dapp" description="Get more information about the tool" />

           <LinkCard href="/build/create-aptos-dapp#templates" title="Templates" description="Browse premade templates" />

           <LinkCard href="/build/create-aptos-dapp/faq" title="FAQ" description="Get help for common issues and questions" />
         </CardGrid>
    </Steps>
  </TabItem>
</Tabs>

# Ethereum to Aptos Migration Guide

> Comprehensive comparison and migration guide for Ethereum developers transitioning to Aptos blockchain development

To learn more about the differences and similarities see [Aptos Learn](https://learn.aptoslabs.com/en/tutorials/ethereum-to-aptos-guide/cheat-sheet?workshop=eth-to-aptos)

### High Level Overview

| Feature                    | Ethereum                                                                                                                       | Aptos                                                                                                                                 |
| -------------------------- | ------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------- |
| **Smart Contracts**        | Solidity, EVM                                                                                                                  | Move, MoveVM                                                                                                                          |
| **Benefits**               | Mature, wide adoption                                                                                                          | Scalability, low latency, predictable fees                                                                                            |
| **Transaction Fees**       | Variable, can be high                                                                                                          | Lower and more predictable                                                                                                            |
| **Account Addresses**      | 160-bit                                                                                                                        | 256-bit                                                                                                                               |
| **Account Structure**      | Balance in a single field, uses nonce                                                                                          | Modules and resources, uses sequence number                                                                                           |
| **Data Storage**           | Patricia Merkle Trees                                                                                                          | Global storage with resources and modules                                                                                             |
| **Storage Mindset**        | Contract-based storage                                                                                                         | Account centric mindset for code and data                                                                                             |
| **Example Code**           | [ERC-20](https://github.com/OpenZeppelin/openzeppelin-contracts/tree/master/contracts/token/ERC20)                             | [Fungible Asset](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/fungible_asset.move) |
| **Caller ID**              | `msg.sender`                                                                                                                   | `&signer` reference                                                                                                                   |
| **Upgradeability**         | Proxy patterns                                                                                                                 | Direct module upgrades                                                                                                                |
| **Safety & Security**      | Vulnerable to attacks like reentrancy                                                                                          | Mitigates common vulnerabilities                                                                                                      |
| **Dispatch Type**          | Dynamic dispatch                                                                                                               | Static dispatch                                                                                                                       |
| **FT Standard**            | [ERC-20](https://docs.openzeppelin.com/contracts/4.x/erc20)                                                                    | [Coin](/build/smart-contracts/aptos-coin) (legacy) and [Fungible Asset](/build/smart-contracts/fungible-asset)                        |
| **NFT Standards**          | [ERC-721](https://docs.openzeppelin.com/contracts/4.x/erc721), [ERC-1155](https://docs.openzeppelin.com/contracts/4.x/erc1155) | [Digital Asset](/build/smart-contracts/digital-asset)                                                                                 |
| **Blockchain Interaction** | [Ethers.js library](https://docs.ethers.org/v6/)                                                                               | [Aptos Typescript SDK](/build/sdks/ts-sdk)                                                                                            |

<br />

### Comparing Token Standards in Detail

|                        | Solidity                                                          | Move (Aptos)                                                                                                                                                    |
| ---------------------- | ----------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Token Structure**    | Each token is its own contract.                                   | Every token is a typed `Coin` or `FungibleAsset` using a single, reusable contract.                                                                             |
| **Token Standard**     | Must conform to standards like ERC20; implementations can vary.   | Uniform interface and implementation for all tokens.                                                                                                            |
| **Balance Storage**    | Balances stored in contract using a mapping structure.            | **Resource-Oriented Balance**: Balances stored as a resource in the user's account. Resources cannot be arbitrarily created, ensuring integrity of token value. |
| **Transfer Mechanism** | Tokens can be transferred without receiver's explicit permission. | Except for specific cases (like AptosCoin), Tokens generally require receiver's `signer` authority for transfer.                                                |

<br />

### Comparing EVM and Move VM in Detail

- **EVM**: Known for its flexibility and dynamic dispatch, which allows a wide range of smart contract behaviors. This flexibility, however, can lead to complexities in parallel execution and network operations.
- **Move VM**: Focuses on safety and efficiency with a more integrated approach between the VM and the programming language. Its data storage model allows for better parallelization, and its static dispatch method enhances security and predictability.

<br />

|                                 | EVM (Ethereum Virtual Machine)                                         | Move VM (Move Virtual Machine)                                                                                     |
| ------------------------------- | ---------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------ |
| **Data Storage**                | Data is stored in the smart contract's storage space.                  | Data is stored across smart contracts, user accounts, and objects.                                                 |
| **Parallelization**             | Parallel execution is limited due to shared storage space.             | More parallel execution enabled due to flexible split storage design.                                              |
| **VM and Language Integration** | Separate layers for EVM and smart contract languages (e.g., Solidity). | Seamless integration between VM layer and Move language, with native functions written in Rust executable in Move. |
| **Critical Network Operations** | Implementation of network operations can be complex and less direct.   | Critical operations like validator set management natively implemented in Move, allowing for direct execution.     |
| **Function Calling**            | Dynamic dispatch allows for arbitrary smart contract calls.            | Static dispatch aligns with a focus on security and predictable behavior.                                          |
| **Type Safety**                 | Contract types provide a level of type safety.                         | Module structs and generics in Move offer robust type safety.                                                      |
| **Transaction Safety**          | Uses nonces for transaction ordering and safety.                       | Uses sequence numbers for transaction ordering and safety.                                                         |
| **Authenticated Storage**       | Yes, with smart contract storage.                                      | Yes, leveraging Move‚Äôs resource model.                                                                             |
| **Object Accessibility**        | Objects are not globally accessible; bound to smart contract scope.    | Guaranteed global accessibility of objects.                                                                        |

# Solana to Aptos Migration Guide

> Detailed comparison and transition guide for Solana developers moving to Aptos blockchain development

To learn more about the differences and similarities see [Aptos Learn](https://learn.aptoslabs.com/en/tutorials/solana-to-aptos-guide/cheat-sheet?workshop=solana-to-aptos)

|                              | Solana                                                                                                             | Aptos                                                                                                                                     |
| ---------------------------- | ------------------------------------------------------------------------------------------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------- |
| **Smart Contracts**          | Rust, SVM                                                                                                          | Move, MoveVM                                                                                                                              |
| **Transaction Fees**         | Low                                                                                                                | Low                                                                                                                                       |
| **Parallelization**          | Pessimistic parallelism, need to declare all write accounts                                                        | Optimistic parallelism, chain infers write accounts for you                                                                               |
| **Contract Account Support** | PDA Account                                                                                                        | [Object](/build/smart-contracts/objects) or [resource account](/build/smart-contracts/resource-accounts)(encourage to use object instead) |
| **Data Storage**             | Data stored in account owned by programs                                                                           | Data stored as resource under user account or object                                                                                      |
| **Storage Level**            | Program level                                                                                                      | Global when stored under object                                                                                                           |
| **Storage Mindset**          | User data stored distributedly under account                                                                       | User data stored distributedly under object                                                                                               |
| **Example Code**             | [Todo list contract on Solana](https://github.com/aptos-labs/move-by-examples/tree/main/advanced-todo-list/solana) | [Todo list contract on Aptos](https://github.com/aptos-labs/move-by-examples/tree/main/advanced-todo-list/aptos)                          |
| **Caller ID**                | `signer`                                                                                                           | `signer`                                                                                                                                  |
| **Upgradability**            | Program is upgradable                                                                                              | Module is upgradable                                                                                                                      |
| **Dispatch Type**            | Static dispatch                                                                                                    | Static dispatch                                                                                                                           |
| **FT Standards**             | Token program                                                                                                      | [Coin](/build/smart-contracts/aptos-coin) (legacy) and [Fungible Asset Standard](/build/smart-contracts/fungible-asset)                   |
| **NFT Standards**            | Token program                                                                                                      | [Digital Asset Standard](/build/smart-contracts/digital-asset)                                                                            |
| **Blockchain Interaction**   | Solana web3.js library                                                                                             | [Aptos Typescript SDK](/build/sdks/ts-sdk)                                                                                                |

# Learn from Guides

> Comprehensive step-by-step tutorials to help you build on Aptos blockchain, from beginner basics to advanced development patterns

import { CardGrid, LinkCard } from '@astrojs/starlight/components';

Welcome to Aptos guides! Whether you're just getting started or building advanced applications, these step-by-step tutorials will help you accomplish specific tasks on the Aptos blockchain.

## Beginner Guides

Start your journey with these foundational tutorials:

<CardGrid>
  <LinkCard href="/build/guides/first-transaction" title="Your First Transaction" description="Learn how to create, submit and verify a basic transaction on the Aptos blockchain." />

  <LinkCard href="/build/guides/your-first-nft" title="Your First NFT" description="Create, mint, and transfer digital assets (NFTs) using the Aptos TypeScript SDK." />

  <LinkCard href="/build/guides/first-fungible-asset" title="Your First Fungible Asset" description="Create and manage a fungible asset that can be transferred between accounts." />

  <LinkCard href="/build/guides/first-coin" title="Your First Coin" description="Build your own custom coin with minting and transfer capabilities on Aptos." />

  <LinkCard href="/build/guides/first-move-module" title="Your First Move Module" description="Create a simple Move module and deploy it to the Aptos blockchain." />

  <LinkCard href="/build/guides/build-e2e-dapp" title="Your First Dapp" description="Build a complete todo list dapp (decentralized application) with smart contracts and a React frontend." />

  <LinkCard href="/build/guides/first-multisig" title="Your First Multisig" description="Set up a multi-signature account requiring approval from multiple key holders." />
</CardGrid>

## Advanced Guides

Ready for more complex scenarios? Explore these advanced topics:

<CardGrid>
  <LinkCard href="/build/guides/multisig-managed-fungible-asset" title="Multisig Managed Assets" description="Create a secure fungible asset controlled by a multisig account requiring multiple approvals for minting, freezing, and burning operations." />

  <LinkCard href="/build/guides/aptos-keyless" title="Aptos Keyless" description="Enable users to create blockchain accounts using their existing Google or Apple logins, eliminating the need for seed phrases or private keys." />

  <LinkCard href="/build/guides/sponsored-transactions" title="Sponsored Transactions" description="Implement fee sponsorship to let your decentralized application cover transaction gas fees for users, removing the need for them to hold APT tokens." />

  <LinkCard href="/build/guides/transaction-management" title="Transaction Management" description="Master advanced transaction orchestration techniques including sequence number management, failure recovery, and parallel processing with worker accounts for high-volume applications." />

  <LinkCard href="/build/guides/key-rotation" title="Key Rotation" description="Use Aptos' secure key rotation capability to update an account's private authentication credentials without changing account addresses or disrupting existing integrations." />

  <LinkCard href="/build/guides/exchanges" title="Exchange Integration" description="A comprehensive guide for integrating Aptos and Aptos assets into an exchange, covering infrastructure setup, address standards, asset management, balance tracking, and transaction processing." />

  <LinkCard href="/build/guides/oracles" title="Oracles" description="Implement price feeds in your Aptos smart contracts using Pyth Network oracles, with configuration steps and examples for accessing real-time market data." />
</CardGrid>

# Aptos Keyless

> Integrate Keyless accounts for seamless user onboarding using social logins instead of traditional private key management.

## Integrate with Aptos Keyless accounts

- [Introduction](/build/guides/aptos-keyless/introduction)
- [OIDC Support and Configuration](/build/guides/aptos-keyless/oidc-support)
- [Integration Guide](/build/guides/aptos-keyless/integration-guide)
- [Simple Example](/build/guides/aptos-keyless/simple-example)
- [How Aptos Keyless works](/build/guides/aptos-keyless/how-keyless-works)
- [Terminology and FAQ](/build/guides/aptos-keyless/other)

## Using an IAM Provider? Integrate with Aptos Federated Keyless

- [Federated Keyless](/build/guides/aptos-keyless/federated-keyless)

## Example

Visit this page to learn more [Simple Example](/build/guides/aptos-keyless/simple-example)

<br />

<iframe
  src="https://stackblitz.com/edit/vitejs-vite-3fuvtu?embed=1&file=README.md"
  style={{
width: "100%",
height: "800px",
border: "0",
borderRadius: "4px",
overflow: "hidden",
}}
  title="aptos-keyless-example"
  allow="accelerometer; ambient-light-sensor; camera; encrypted-media; geolocation; gyroscope; hid; microphone; midi; payment; usb; vr; xr-spatial-tracking"
  sandbox="allow-forms allow-modals allow-popups allow-presentation allow-same-origin allow-scripts"
/>

# Federated Keyless

> Extended Keyless support for additional OIDC providers through IAM systems like Auth0 and AWS Cognito.

## Federated Keyless

[AIP-96](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-96.md): Federated Keyless is an extension of Aptos Keyless to support more OpenID Connect (OIDC) providers, beyond the ones that are allow-listed in `0x1::jwks` via JWK consensus, while maintaining its decentralization. Federated keyless adds support for authenticating users via identity & access management (IAM) providers (e.g. Auth0, AWS Cognito) as long as your project uses a supported IAM provider for user authentication.

To elaborate further, Federated Keyless enables:

1. Extension of authentication methods
   a. All authentication methods supported by the IAM are available to the dApp including email/SMS OTP and their marketplace of social login integrations like Discord, Naver, X and more. Auth0 marketplace linked [here](https://marketplace.auth0.com/) as an example.

2. Compatibility with existing account systems
   a. Since IAMs also support custom authentication, it allows an application to bring its own username/password (Cognito [docs](https://docs.aws.amazon.com/cognito/latest/developerguide/amazon-cognito-user-pools-authentication-flow.html), Auth0 [docs](https://auth0.com/blog/Custom-Authentication-With-Auth0/)). An application can start using an existing account system already set up with an IAM or they can migrate their existing account system to an IAM to generate Keyless-compatible JWTs.

- [Federated Keyless Key Considerations](/build/guides/aptos-keyless/federated-keyless/key-considerations)
- [Federated Keyless Integration Guide](/build/guides/aptos-keyless/federated-keyless/integration-guide)
- [Federated Keyless FAQs](/build/guides/aptos-keyless/federated-keyless/other)

# Federated Keyless Integration Guide

> Step-by-step guide for integrating Federated Keyless with IAM providers like Auth0 and AWS Cognito.

import { Aside, Steps } from '@astrojs/starlight/components';

<Steps>
  1. Step 1. Setup your IAM provider

     Set up your project with your IAM to match the account structure you are looking for.

     - [Getting Started with AWS Cognito](https://aws.amazon.com/cognito/getting-started/)
     - [Getting Started with Auth0](https://auth0.com/docs/get-started)

  2. Step 2. Register the JSON Web Key Set (JWKS) on-chain

     Federated Keyless accounts require the JWKS to be registered on-chain.

     To register the JWKS - call the `0x1::jwks::update_federated_jwk_set` entry function with an Aptos account that will store the JWKs that will be used to validate transactions signed by federated keyless accounts.

     <Aside type="caution">
       **Losing access to the JWK owner account compromises the Federated Keyless accounts created with it**

       The JWK owner account is the only account that can update the JWKS.  If you lose access to the JWK owner account, you will not be able to update the JWKS and the Federated Keyless accounts created with it will stop working in the case of a key rotation.  Users will be unable to validate their JWT tokens as they will be signed with the new key whos public key is not registered on the Aptos blockchain.
     </Aside>

     The JWK set can be found as follows -

     AWS Cognito - `https://cognito-idp.<region>.amazonaws.com/<userPoolId>/.well-known/jwks.json`
     Auth0 - `https://<yourDomain>/.well-known/jwks.json`

     The typescript SDK contains functionality to simplify the process given the issuer for your IAM provider setup (the `iss` claim value on your user‚Äôs JWT tokens) and an account to use to make the update.

     ```tsx
     import {Aptos} from '@aptos-labs/ts-sdk'; // Requires version v1.29.1 or later

     const aptos = new Aptos(new AptosConfig({ network: Network.DEVNET })); // Configure your network here
     const alice = // Derive your Aptos account here
     const jwkTxn = await aptos.updateFederatedKeylessJwkSetTransaction({ sender: alice, iss });
     await aptos.signAndSubmitTransaction({ signer: alice, transaction: jwkTxn });
     ```

     You can use the interactive example provided by the SDK to easily register the JWKS for your IAM provider in devnet or testnet.  This will setup the JWK owner account with a Google Keyless account.

     ```shellscript
     git clone https://github.com/aptos-labs/aptos-ts-sdk
     cd aptos-ts-sdk
     pnpm install && pnpm build
     cd examples/typescript
     pnpm install
     pnpm jwk_update
     ```

     To setup the JWK owner account in mainnet, you will need create an account and use it to register the JWKS.

     Save the address of the account you used to register the JWKS as you will need it for the next step.

     To learn more about the `0x1::jwks::update_federated_jwk_set` entry function, see the [reference documentation](/move-reference/mainnet/aptos-framework/jwks#jwks_update_federated_jwk_set).

     <Aside type="caution">
       **Handling key rotations**

       Whenever there is a key rotation of the JWKS, it is important to update the JWKS registered on chain promptly to avoid any loss of access to Federated Keyless accounts.  See [here](/build/guides/aptos-keyless/federated-keyless/key-considerations) for more info.
     </Aside>

  3. Step 3. Follow the Aptos Keyless integration guide

     Now that you have registered the JWKS, you can follow the Aptos Keyless integration guide starting from step 2.  Be sure to set the `jwkAddress` to the address of the account you used to register the JWKS when deriving the `KeylessAccount`.

     [Aptos Keyless Integration Guide - Step 2](/build/guides/aptos-keyless/integration-guide#step-2-install-the-aptos-typescript-sdk)
</Steps>

# Federated Keyless Key Considerations

> Important considerations and supported IAM providers for implementing Federated Keyless accounts in production.

## Federated Keyless Key Considerations

**Supported IAMs**

Currently, the supported IAMs are Amazon Cognito and Auth0 across devnet, testnet, and mainnet. See a table of the full set of supported IAM providers [here](/build/guides/aptos-keyless/oidc-support).

**Federated Keyless flow**

The flow for Federated Keyless transactions is the same as described [here](/build/guides/aptos-keyless/how-keyless-works). However, the difference is that in Federated Keyless, instead of the OIDC provider (e.g., Google, Apple) acting as the issuer of the JWT, the IAM provider (e.g., Auth0, Cognito) acts as the issuer. The user authenticates with the application, the IAM receives the user‚Äôs credentials, and then the IAM issues the Keyless-compatible JWT.

**Available authentication methods**

All authentication methods that are supported by the IAM providers are available for use - this includes SMS OTP, email link, and the traditional username + password.

**Configuration limitations**

A Keyless account address varies according to the `aud` (AKA application ID or client ID), and `iss` (AKA issuer). The setup of your user data within the IAM must reflect the interoperability you seek to provide to your users. JWT tokens issued for a user in the same user pool but for different applications will result in a different address derivation if the `aud` value is different.

**JSON Web Key Set management**

If you or the IAM platform rotates the key pairs used to signed the JWT tokens, the JWK set must be updated on chain using the same account used to instantiate your app's Federated Keyless accounts.  As such it is vital to -

1. Maintain access to your JWKS owner account
2. Update the JWK set on chain whenever a key rotation occurs

When a keypair is rotated existing keyless account instantiations will continue to work so long as the old JWK has not been removed.  Any new JWTs issued by the new keypair will not be accepted until the JWK set on chain is updated to contain its public key.

**The trust and security model for Federated Keyless**

Compared to the existing Keyless implementation, dApp developers utilizing Federated Keyless alongside certain authentication methods like email/SMS, OTP and email/password may have more access to user credentials when leveraging IAM providers than with the existing direct OIDC provider integrations.

We recommend each dApp developer perform their own research and consult with their legal counsel before integrating an authentication method.  Developers should also understand to what extent they may have access to user credentials and what controls they have in place.

# Federated Keyless FAQ

> Frequently asked questions about Federated Keyless implementation, IAM provider changes, and account migration.

## Federated Keyless FAQs

**What if I stop using my IAM for my application? What if I switch IAM providers?**

- An account address depends on values of several variables that are specific to an IAM service, including `aud` (client ID) and `iss` (issuer).  If these values are changed, then a different address will be derived.
- If you want to switch IAM providers, you will need to develop an account migration flow, resulting in a key rotation from the account derived from the prior IAM provider to the account derived from the new IAM provider.
- We recommend allowing your users to add a secondary authentication method to their accounts (e.g., back-up private key) so that they can maintain access should the authentication path into their account via Federated Keyless be disrupted via a service provider change. In order to implement this, you need to do a key rotation to a multikey account. For relevant documentation see [key rotation](/build/guides/key-rotation) and [multikey SDK](https://aptos-labs.github.io/aptos-ts-sdk/@aptos-labs/ts-sdk-1.35.0/classes/MultiKeyAccount.html).

**Does using an IAM cost money?**

- Yes, IAMs usually cost money, but they can help provide useful functionality within your application such as role-based access control (authorization), user management, user authentication, security + compliance, and analytics + monitoring.

**In the case the dApp or IAM provider goes offline, how do I make sure my users can continue accessing their accounts?**

- We recommend allowing your users to add a secondary authentication method to their accounts (e.g., back-up private key) so that they can maintain access should the authentication path into their account via Federated Keyless is disrupted via service provider change or other outage.

**I use an open source IAM like Keycloak. Can I use Federated Keyless?**

- Not today. Due to the trust placed in the IAM to have sufficient uptime and security standards, we have limited the accepted IAM set to the currently supported issuers. If you believe your provider should be included for consideration, please consider raising an AIP or contact us in the Keyless developers [telegram](https://t.me/+h5CN-W35yUFiYzkx).

# Federated Keyless Simple Example

> Working example of Federated Keyless implementation using Auth0 as the IAM provider with complete code samples.

The Federated Keyless Example shows how to set up a Federated Keyless account using Auth0 as the IAM provider.

Explore the code in [aptos-keyless-example repository](https://github.com/aptos-labs/aptos-keyless-example/tree/main/examples/federated-keyless-example/).

The Keyless Simple Example is currently undergoing maintenance. Please check back later.

# How Keyless Works

> Technical deep dive into how Aptos Keyless derives and accesses blockchain accounts using OIDC provider authentication.

import { YouTube } from 'astro-embed';

Aptos Keyless enables a dApp to **derive** and **access** a blockchain account for a user who successfully signed in to the dApp via an OIDC provider (e.g., Google). Importantly, this blockchain account is **scoped to the dApp**. This means other dApps, who can similarly sign-in the same user, via the same OIDC provider, are not able to access this account and instead get their own account.

_But how does this work?_

This article will explain the full keyless flow depicted below, from the user first signing into a dapp, to obtaining her zero-knowledge proof and to, finally, transacting on-chain.

![Keyless overview](~/images/aptos-keyless/keyless-overview.png "Keyless overview")

## Overview

At a very high level, a successful sign-in into the dApp via the OIDC provider will result in the dApp receiving a **JSON Web Token (JWT)** signed by the OIDC provider. The JWT will contain, among other things, three important pieces of information:

1. The user‚Äôs identity (contained in the JWT‚Äôs `sub` field)
2. The dApp‚Äôs identity (contained in the JWT‚Äôs `aud` field)
3. Application-specific data; specifically, an **ephemeral public key (EPK)** (contained in the JWT‚Äôs `nonce` field), whose associated **ephemeral secret key (ESK)** only the user knows.

Now, assume that the user‚Äôs blockchain account address is (more or less) a hash of the user‚Äôs identity in `sub` and the dApp‚Äôs identity in `aud` from above.

Then, the **key observation** is that the signed JWT effectively acts as a **digital certificate**, **temporarily** binding this blockchain address to the EPK, and allowing the EPK to sign TXNs for it. In other words, it securely delegates TXN signing rights for this blockchain account to the EPK (Note: The EPK contains an expiration date and is thus short-lived).

Importantly, if the user loses their ESK, the user can obtain a new signed JWT over a new EPK via the application by simply signing in again via the OIDC provider (Or, in some cases, by requesting a new signed JWT using an OAuth refresh token).

With this system, the **challenge** is maintaining privacy, since revealing the JWT on-chain would leak the user‚Äôs identity. Furthermore, revealing the EPK to the OIDC provider would allow it to track the user‚Äôs TXNs on-chain.

We explain below how Keyless accounts work and how they address these challenges.

## Flow: Deriving a keyless account for a user in a dApp

First, let us look at how a dApp can sign-in a user via (say) Google, derive that user‚Äôs keyless blockchain address and, for example, send that user an asset.

![Keyless account diagram](~/images/aptos-keyless/keyless-account.png "Keyless account diagram")

**Step 1**: The user generates an ephemeral key pair: an EPK with an expiration date, and its associated ESK. The dApp keeps the EPK and safely stores the ESK on the user-side (e.g., in the browser‚Äôs local storage, or in a trusted enclave if the ESK is a WebAuthn passkey).

**Step 2**: The dApp commits to the EPK as $H(\mathsf{epk}, \rho)$, where $\rho$ is a blinding factor. When the user clicks on the ‚ÄúSign in with Google‚Äù button, the dApp redirects the user to Google‚Äôs sign in page and, importantly, sets the `nonce` parameter in the URL to this EPK commitment. This hides the EPK from Google, maintaining privacy of the user‚Äôs TXN activity.

**Step 3**: Typically, the user has an HTTP cookie from having previously-signed-in to their Google account, so Google merely checks this cookie. If the user has multiple Google accounts, Google asks the user to select which one they want to sign-in into the dApp (The less common path is for the user to have to type in their Google username and password).

**Step 4**: Once the user has signed in, Google sends the dApp a signed JWT, which includes the user's `sub` identifier (e.g., `uid-123`), the application‚Äôs `aud` identifier (e.g., `"dapp-xyz"`) and the `nonce` with the EPK commitment (This assumes that the dApp has previously registered with Google and received this `"dapp-xyz"` identifier).

**Step 5**: The dApp now has almost everything it needs to derive a keyless account for the user: the user‚Äôs identifier (`sub`) and the dApp‚Äôs identifier (`aud`). But, to preserve the privacy of the user, the dApp will use a third piece of information: a blinding factor $r$ called a **pepper**. The dApp will contact a so-called **guardian** who will deterministically derive a random $r$ from the given (`sub`, `aud`). Importantly, the guardian will only reveal $r$ to the dApp upon seeing a validly-signed JWT for the queried (`sub`, `aud`).

**Step 6**: The dApp derives the address of the account as $\mathsf{addr} = H(\texttt{"uid-123"}, \texttt{"dapp-xyz"}, r)$, where $H$ is a cryptographic hash function.

Note that the pepper $r$ is used to hide the user and app identity inside the address since, as we described above, only an authorized user with a valid JWT will be able to obtain this pepper.

Also, note that the address is independent of the EPK. This is why the ESK need not be long-lived and can be lost.

Finally, the dApp can, for example, send an NFT to the user at their address $\mathsf{addr}$.

But how can the dApp authorize TXN from this account at $\mathsf{addr}$? We discuss that next.

## Flow: Obtaining a zero-knowledge proof before transacting

In the previous flow, we showed how a dApp can sign in a Google user and derive their privacy-preserving keyless address, with the help of a guardian.

Next, we show how this dApp can obtain a zero-knowledge proof (ZKP), which will allow it to authorize transactions from this address for the user. Importantly, the transaction will hide the user‚Äôs identifying information (e.g., the `sub` field).

![Keyless proof diagram](~/images/aptos-keyless/keyless-proof.png "Keyless proof diagram")

**Step 1**: The dApp sends all the necessary public information (i.e., $\mathsf{epk}$, $\mathsf{GPK}$) and private information (i.e., JWT, signature $\sigma\_G$ from Google, EPK blinding factor $\rho$, and pepper $r$) to the **prover service**.

**Step 2**: The prover derives the user‚Äôs address $\mathsf{addr}$ and computes a zero-knowledge proof (ZKP) $\pi$ for the keyless relation $\mathcal{R}\_\mathsf{keyless}$ (described below). This proof acts as a **privacy-preserving** digital certificate, and binds the user's address $\mathsf{addr}$ to the ephemeral public key $\mathsf{epk}$. The prover then sends $\pi$ to the dApp.

In order to bind the $\mathsf{epk}$ with the user's address $\mathsf{addr}$, the ZKP will be used to convince the validators that the user is in possession of (1) a JWT signed by Google, (2) which commits to the $\mathsf{epk}$ in its `nonce` field, and (3) contains the same information as in the address, without leaking anything about the JWT, its signature $\sigma\_G$, $\rho$, or $r$.

More formally, the ZKP $\pi$ convinces a verifier (i.e., the blockchain), who has public inputs $(\mathsf{addr}, \mathsf{epk}, \mathsf{GPK})$, that the prover knows secret inputs $(\mathsf{jwt}, \sigma\_G, \rho, r)$ such that the relation $\mathcal{R}\_\mathsf{keyless}$ depicted below holds:

![Keyless relation diagram](~/images/aptos-keyless/keyless_relation.png "Keyless relation diagram")

Recall from before that the signed JWT itself binds the blockchain address $\mathsf{addr}$ to $\mathsf{epk}$, so that $\mathsf{epk}$ can sign transactions for $\mathsf{addr}$. However, the JWT would leak the user‚Äôs identity, so the ZKP serves to hide the JWT (and other private information) while arguing that the proper checks hold (i.e., the checks in $\mathcal{R}\_\mathsf{keyless}$).

Next, we show how the dApp can now authorize TXNs from $\mathsf{addr}$.

## Flow: Sending a TXN from a keyless account

The previous flow explained how a dApp can obtain a ZKP from the prover service. Next, we describe how the dApp leverages this ZKP to transact for the account.

![Keyless signing diagram](~/images/aptos-keyless/keyless-signing.png "Keyless signing diagram")

**Step 1**: The dApp obtains an ephemeral signature $\sigma\_\mathsf{eph}$ over the TXN from the user. This could be done behind the user‚Äôs back, by the dApp itself who might manage the ESK. Or, it could be an actual signing request sent to the user, such as when the ESK is a WebAuthn passkey, which is stored on the user‚Äôs trusted hardware.

**Step 2**: The dApp sends the TXN, the ZKP $\pi$, the ephemeral public key $\mathsf{epk}$, and the ephemeral signature $\sigma\_\mathsf{eph}$ to the blockchain validators.

**Step 3**: To check the TXN is validly-signed, the validators perform several steps: (1) check that $\mathsf{epk}$ has not expired, (2) fetch the user‚Äôs address $\mathsf{addr}$ from the TXN, (3) verify the ZKP against $(\mathsf{addr}, \mathsf{epk}, \mathsf{GPK})$, and (4) verify the ephemeral signature $\sigma\_\mathsf{eph}$ on the TXN against the $\mathsf{epk}$. If all these checks pass, they can safely execute the TXN.

## Want more?

The key ideas behind keyless accounts are also explained in this 20 minute presentation below.<br />

<YouTube title="Keyless Presentation" id="sKqeGR4BoI0" />

# Keyless Integration Guide

> Step-by-step guide to integrate domain-scoped Keyless accounts directly into your dApp with practical examples.

import { Aside, Steps } from '@astrojs/starlight/components';

<Aside type="note">
  **Keyless Account Scoping**

  Use of the \*\*_Aptos Keyless Integration Guide_\*\* will allow for the integration of keyless accounts directly into your application. This means that blockchain accounts are scoped to your application's domain (logging in with your Google account on dApp A and logging in with your Google account on dApp B will create separate accounts). Stay tuned for more to come on Aptos‚Äô plan to allow Keyless accounts to be used portably across applications.

  To provide feedback, get support, or be a design partner as we enhance Aptos Keyless, join us here: [https://t.me/+h5CN-W35yUFiYzkx](https://t.me/+h5CN-W35yUFiYzkx)
</Aside>

At a high level, there are three steps to follow in order to integrate Keyless Accounts.

1. **Configure your OpenID integration with your IdP.** In this step, the dApp will register with the IdP of choice (e.g. Google) and receive a `client_id`
2. **Install the Aptos TypeScript SDK.**
3. **Integrate Keyless Account support in your application client**
   1. Set up the `"Sign In with [Idp]"` flow for your user.
   2. Instantiate the user‚Äôs `KeylessAccount`
   3. Sign and submit transactions via the `KeylessAccount`.

## Example Implementation

You can find an example app demonstrating basic Keyless integration with Google in the [aptos-keyless-example repository](https://github.com/aptos-labs/aptos-keyless-example/). Follow the directions in the README to start with the example. For more detailed instructions on keyless, please read the rest of this integration guide.

<Steps>
  1. Step 1. Configure your OpenID integration with your IdP

     The first step is to setup the configuration with your IdP(s).

     [Follow the instructions here](/build/guides/aptos-keyless/oidc-support)

  2. Step 2. Install the Aptos TypeScript SDK

     ```shellscript
     # Keyless is supported in version 1.18.1 and above
     pnpm install @aptos-labs/ts-sdk
     ```

  3. Step 3. Client Integration Steps

     Below are the default steps for a client to integrate Keyless Accounts

     #### 1. Present the user with a "Sign In with \[IdP]" button on the UI

     1. In the background, we create an ephemeral key pair. Store this in local storage.

        ```typescript
        import {EphemeralKeyPair} from '@aptos-labs/ts-sdk';

        const ephemeralKeyPair = EphemeralKeyPair.generate();
        ```

     2. Save the `EphemeralKeyPair` in local storage, keyed by its `nonce`.

        ```typescript
        // This saves the EphemeralKeyPair in local storage
        storeEphemeralKeyPair(ephemeralKeyPair);
        ```

     <details>
       <summary>Example implementation for `storeEphemeralKeyPair`</summary>

       <Aside type="note">
         This implementation is an example of how to store the `EphemeralKeyPair` in local storage. Different implementations may be used according to your application's needs.
       </Aside>

       ```typescript filename="ephemeral.ts"

       /**
        * Store the ephemeral key pair in localStorage.
        */
       export const storeEphemeralKeyPair = (ekp: EphemeralKeyPair): void =>
         localStorage.setItem("@aptos/ekp", encodeEphemeralKeyPair(ekp));

       /**
        * Retrieve the ephemeral key pair from localStorage if it exists.
        */
       export const getLocalEphemeralKeyPair = (): EphemeralKeyPair | undefined => {
         try {
           const encodedEkp = localStorage.getItem("@aptos/ekp");
           return encodedEkp ? decodeEphemeralKeyPair(encodedEkp) : undefined;
         } catch (error) {
           console.warn(
             "Failed to decode ephemeral key pair from localStorage",
             error
           );
           return undefined;
         }
       };

       /**
        * Stringify the ephemeral key pairs to be stored in localStorage
        */
       export const encodeEphemeralKeyPair = (ekp: EphemeralKeyPair): string =>
         JSON.stringify(ekp, (_, e) => {
           if (typeof e === "bigint") return { __type: "bigint", value: e.toString() };
           if (e instanceof Uint8Array)
             return { __type: "Uint8Array", value: Array.from(e) };
           if (e instanceof EphemeralKeyPair)
             return { __type: "EphemeralKeyPair", data: e.bcsToBytes() };
           return e;
         });

       /**
        * Parse the ephemeral key pairs from a string
        */
       export const decodeEphemeralKeyPair = (encodedEkp: string): EphemeralKeyPair =>
         JSON.parse(encodedEkp, (_, e) => {
           if (e && e.__type === "bigint") return BigInt(e.value);
           if (e && e.__type === "Uint8Array") return new Uint8Array(e.value);
           if (e && e.__type === "EphemeralKeyPair")
             return EphemeralKeyPair.fromBytes(e.data);
           return e;
         });
       ```
     </details>

     3. Prepare the URL params of the login URL. Set the `redirect_uri` and `client_id` to your configured values with the IdP. Set the `nonce` to the nonce of the `EphemeralKeyPair` from step 1.1.

        ```typescript
        const redirectUri = 'https://.../login/callback'
        const clientId = env.IDP_CLIENT_ID
        // Get the nonce associated with ephemeralKeyPair
        const nonce = ephemeralKeyPair.nonce
        ```

     4. Construct the login URL for the user to authenticate with the IdP. Make sure the `openid` scope is set. Other scopes such as `email` and `profile` can be set based on your app‚Äôs needs.

        ```typescript
        const loginUrl = `https://accounts.google.com/o/oauth2/v2/auth?response_type=id_token&scope=openid+email+profile&nonce=${nonce}&redirect_uri=${redirectUri}&client_id=${clientId}`
        ```

     5. When the user clicks the login button, redirect the user to the `loginUrl` that was created in step 1.4.

     #### 2. Handle the callback by parsing the token and create a Keyless account for the user

     1. Once the user completes the login flow, they will be redirected to the `redirect_uri` set in step 1. The JWT will be set in the URL as a search parameter in a URL fragment, keyed by `id_token`. Extract the JWT from the `window` by doing the following:

        ```typescript
        const parseJWTFromURL = (url: string): string | null => {
          const urlObject = new URL(url);
          const fragment = urlObject.hash.substring(1);
          const params = new URLSearchParams(fragment);
          return params.get('id_token');
        };

        // window.location.href = https://.../login/google/callback#id_token=...
        const jwt = parseJWTFromURL(window.location.href)
        ```

     2. Decode the JWT and get the extract the nonce value from the payload.

        ```typescript
        import { jwtDecode } from 'jwt-decode';

        const payload = jwtDecode<{ nonce: string }>(jwt);
        const jwtNonce = payload.nonce
        ```

     3. Fetch the `EphemeralKeyPair` stored in step 1.2. Make sure to validate the nonce matches the decoded nonce and that the `EphemeralKeyPair` is not expired.

        ```typescript
        const ekp = getLocalEphemeralKeyPair();

        // Validate the EphemeralKeyPair
        if (!ekp || ekp.nonce !== jwtNonce || ekp.isExpired() ) {
          throw new Error("Ephemeral key pair not found or expired");
        }
        ```

     4. Instantiate the user‚Äôs `KeylessAccount`

        Depending on the type of Keyless you are using, follow the instructions below:

        1. Normal Keyless

        ```tsx
        import {Aptos, AptosConfig, Network} from '@aptos-labs/ts-sdk';

        const aptos = new Aptos(new AptosConfig({ network: Network.DEVNET })); // Configure your network here
        const keylessAccount = await aptos.deriveKeylessAccount({
            jwt,
            ephemeralKeyPair,
        });
        ```

        2. Federated Keyless

        ```tsx
        import {Aptos, AptosConfig, Network} from '@aptos-labs/ts-sdk';

        const aptos = new Aptos(new AptosConfig({ network: Network.DEVNET })); // Configure your network here
        const keylessAccount = await aptos.deriveKeylessAccount({
            jwt,
            ephemeralKeyPair,
            jwkAddress: jwkOwner.accountAddress
        });
        ```

     #### 3. Store the KeylessAccount in local storage (Optional)

     1. After the account has been derived, store the `KeylessAccount` in local storage. This allows the user to return to the application without having to re-authenticate.

        ```typescript filename="keyless.ts"
        export const storeKeylessAccount = (account: KeylessAccount): void =>
          localStorage.setItem("@aptos/account", encodeKeylessAccount(account));

        export const encodeKeylessAccount = (account: KeylessAccount): string =>
          JSON.stringify(account, (_, e) => {
            if (typeof e === "bigint") return { __type: "bigint", value: e.toString() };
            if (e instanceof Uint8Array)
              return { __type: "Uint8Array", value: Array.from(e) };
            if (e instanceof KeylessAccount)
              return { __type: "KeylessAccount", data: e.bcsToBytes() };
            return e;
          });
        ```

     2. Whenever the user returns back to the application, retrieve the `KeylessAccount` from local storage and use it to sign transactions.

        ```typescript filename="keyless.ts"
        export const getLocalKeylessAccount = (): KeylessAccount | undefined => {
          try {
            const encodedAccount = localStorage.getItem("@aptos/account");
            return encodedAccount ? decodeKeylessAccount(encodedAccount) : undefined;
          } catch (error) {
            console.warn(
              "Failed to decode account from localStorage",
              error
            );
            return undefined;
          }
        };

        export const decodeKeylessAccount = (encodedAccount: string): KeylessAccount =>
          JSON.parse(encodedAccount, (_, e) => {
            if (e && e.__type === "bigint") return BigInt(e.value);
            if (e && e.__type === "Uint8Array") return new Uint8Array(e.value);
            if (e && e.__type === "KeylessAccount")
              return KeylessAccount.fromBytes(e.data);
            return e;
          });
        ```

     #### 4. Submit transactions to the Aptos blockchain

     1. Create the transaction you want to submit.  Below is a simple coin transfer transaction for example:

        ```tsx
        import {Account} from '@aptos-labs/ts-sdk';

        const bob = Account.generate();
        const transaction = await aptos.transferCoinTransaction({
            sender: keylessAccount.accountAddress,
            recipient: bob.accountAddress,
            amount: 100,
        });
        ```

     2. Sign and submit the transaction to the chain.

        ```tsx
        const committedTxn = await aptos.signAndSubmitTransaction({ signer: keylessAccount, transaction });
        ```

     3. Wait for the transaction to be processed on-chain

        ```tsx
        const committedTransactionResponse = await aptos.waitForTransaction({ transactionHash: committedTxn.hash });
        ```
</Steps>

# Keyless Introduction

> Revolutionary blockchain accounts using OIDC authentication - eliminate private keys for seamless user onboarding.

Keyless accounts represent a pivotal advancement within the Aptos ecosystem, revolutionizing the way users onboard and interact with decentralized applications (dApps). Aptos Keyless allows users to gain ownership of a **self-custodial** Aptos blockchain account from their existing OpenID Connect (OIDC) account(s) (e.g., Sign in with Google; Sign in with Apple), rather than from a traditional secret key or mnemonic. In a nutshell, with Aptos Keyless, a user‚Äôs blockchain account is their OIDC account. Over time, Keyless will evolve to support many IdPs who support the OIDC standard, but we will begin with support for the providers listed [here](/build/guides/aptos-keyless/oidc-support).

At the core of the keyless accounts paradigm lies a deep understanding of user experience and security challenges prevalent in traditional blockchain systems. Managing private keys, the cornerstone of user identity and asset ownership, often proves cumbersome and error-prone for users, particularly those lacking technical expertise. Keyless accounts offer an elegant solution by obviating the need for users to grapple with the intricacies of private key management. Instead, users authenticate themselves through access to common social sign in options like Google, Apple, and many more. With this new system comes some important tradeoffs to understand on behalf of your users before implementing Keyless in your application. The following pages will expand on the benefits of Keyless accounts, how to integrate, the system architecture, and FAQs. For a more verbose and technical dive into Keyless accounts, please see [AIP-61-Keyless Accounts](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-61.md).

There are two ways to interact with Keyless accounts in the Aptos ecosystem. Developers are able to either 1) integrate the Aptos Keyless SDK directly into their dApp or 2) integrate a wallet, like Aptos Connect, that supports Keyless account creation. This documentation will focus on case #1 and more details on #2 can be found [here](https://aptosconnect.app/docs/). Please note that a direct integration of the Keyless SDK will result in user accounts being domain specific to your dApp whereas the use of a wallet integration will allow your users to carry their accounts to any application that supports that wallet.

Note: the Aptos Keyless SDK and Aptos Connect are representative examples of the aforementioned product experience, but developers in our ecosystem are building alternatives, like a Keyless Unity SDK and alternative wallet products with Keyless integration.

## Aptos Keyless Benefits

Keyless accounts are revolutionary to users for the following reasons:

1. **Simplified login user experience**: "1-click" account creation via familiar Web2 logins like Sign In with Google.
2. **Enhanced dApp user experience**: Ability to transact on the Aptos blockchain without needing to navigate away from the application experience to download a wallet.
3. **Secure key management**: Requires no manual secret key management by the user. Users sign transactions with the JSON Web Token (JWT) token issued by OIDC providers. As such, blockchain account access is synonymous with access to one‚Äôs OIDC account
4. **Improved account recovery**: Web2-like recovery flows are available to regain access to one‚Äôs blockchain account in case the user ever loses access to their OIDC account.
5. **Seamless cross-device experiences**: Users log in with their OIDC account no matter what device they are on - no need to download wallet software on each device, import their keys and encrypt them with a password, which must be maintained.

With these benefits, come some important structural components of Keyless accounts for developers to be aware of. You can see more on this in our FAQs.

# Keyless OIDC Support

> Comprehensive list of supported OpenID Connect identity providers and configuration options across networks.

import { Steps } from '@astrojs/starlight/components';

Aptos Keyless supports the following IdPs and IAM providers on our network(s). Support for additional IdPs to come. Please reach out if you have need for coverage for a specific use case.

| Identity Provider | Federated Only | Devnet    | Testnet | Mainnet |
| ----------------- | -------------- | --------- | ------- | ------- |
| Google            | No             | Live      | Live    | Live    |
| Apple             | No             | Live      | Live    | Live    |
| Auth0             | Yes            | Live      | Live    | Live    |
| Cognito           | Yes            | Live      | Live    | Live    |
| Microsoft         | No             | In review | -       | -       |
| Github            | No             | In review | -       | -       |
| Facebook          | No             | In review | -       | -       |

If your identity provider is marked as "Federated Only", you will need to follow the instructions for [Federated Keyless](/build/guides/aptos-keyless/federated-keyless).

To integrate Aptos Keyless into your dApp, you must register your dApp with at least one of the available identity providers via their OIDC registration process. Each respective registration process will assign a Client ID to your application, which will serve as an identifier for your application in the Keyless architecture.

## Registering your dApp with Google

<Steps>
  1. Step 1: Sign in to Google Developer Console

     1. Navigate to the [Google Cloud Console](https://console.cloud.google.com/).
     2. Sign in with your Google account credentials.

  2. Step 2: Create a New Project

     1. If you don't have an existing project, click on the "Select a project" dropdown menu at the top of the page and choose "New Project."
     2. Enter a name for your project and click "Create." Detailed instructions can be found [here](https://cloud.google.com/resource-manager/docs/creating-managing-projects#creating_a_project).

  3. Step 3: Configure Consent Screen

     1. In the left sidebar, navigate to "APIs & Services" > "OAuth consent screen."
     2. Choose "External" user type and click "Create."
     3. Enter the required details such as the application name, user support email, and developer contact information.
     4. Optionally, add additional details like the application logo and privacy policy URL.
     5. Click "Save and continue." Detailed steps are available [here](https://developers.google.com/workspace/guides/create-credentials#configure_the_oauth_consent_screen).

  4. Step 4: Register Your Application

     1. In the left sidebar, navigate to "APIs & Services" > "Credentials."
        ![Google Credentials navigation screenshot](~/images/aptos-keyless/google-credentials-nav.png "Google Credentials navigation screenshot")

     2. Click on "Create Credentials" and select "OAuth client ID."
        ![Google create credentials screenshot](~/images/aptos-keyless/google-create-credentials.png "Google create credentials screenshot")

     3. Choose the application type (e.g., Web application, Desktop app, or Mobile app).

     4. Enter the necessary details such as the name of your application and the authorized redirect URIs. For OIDC, the redirect URIs should follow the format [https://your-app-domain.com/auth/google/callback](https://your-app-domain.com/auth/google/callback).

     5. Click "Create."

  5. Step 5: Obtain Client ID and Client Secret

     1. After creating the OAuth client ID, Google will provide you with a client ID and client secret. These credentials are essential for authenticating your application.
     2. Note down the client ID and client secret securely. Do not expose them publicly.

  6. Step 6: Configure OIDC Integration in Your Application

     1. Integrate OIDC authentication into your application using a suitable OIDC library or framework (e.g., Passport.js for Node.js, Spring Security for Java, or Auth0 for various platforms).
     2. Use the client ID and client secret obtained from Google to configure OIDC authentication in your application settings.
     3. Set up the appropriate callback URL ([https://your-app-domain.com/auth/google/callback](https://your-app-domain.com/auth/google/callback)) for handling authentication responses from Google.
</Steps>

## Registering your dApp with Apple

<Steps>
  1. Step 1: Sign in to Apple Developer Account

     1. Go to the [Apple Developer website](https://developer.apple.com/).
     2. Sign in with your Apple ID.
     3. Enroll in the Apple Developer Program if not already.
        ![Apple developer program enrollment screenshot](~/images/aptos-keyless/apple-dev-program.png "Apple developer program enrollment screenshot")

  2. Step 2: Create a New App ID

     1. Navigate to the "Certificates, Identifiers & Profiles" section.
     2. Click on "Identifiers" in the sidebar.
     3. Click the "+" button to create a new App ID.
     4. Fill in the details for your app, including the name and bundle ID.
     5. Enable "Sign in with Apple" under the "Capabilities" section.
     6. Click "Continue" and then "Register" to create the App ID.

  3. Step 3: Generate a Private Key

     1. In the "Keys" section of the "Certificates, Identifiers & Profiles" page, click the "+" button to create a new key.
     2. Enter a name for the key, enable the "Sign in with Apple" capability, and click "Continue."
     3. Download the generated private key and securely store it. This key will be used to authenticate your app with Apple's OIDC service.

  4. Step 4: Configure Redirect URIs

     1. Under the "App ID" section, locate your newly created App ID and click on it.
     2. Scroll down to the "Sign in with Apple" section and click on "Edit."
     3. Add the redirect URIs that your application will use for callback after authentication. The format should be [https://your-app-domain.com/auth/apple/callback](https://your-app-domain.com/auth/apple/callback).
     4. Click "Save" to update the settings.

  5. Step 5: Set Up Your OIDC Integration

     1. Use an OIDC library or framework compatible with Apple's OIDC service (e.g., Passport.js for Node.js, Spring Security for Java).
     2. Configure your application to use the client ID and private key obtained from Apple during the registration process.
     3. Set up the appropriate callback URL ([https://your-app-domain.com/auth/apple/callback](https://your-app-domain.com/auth/apple/callback)) for handling authentication responses from Apple.
</Steps>

# Keyless Terminology and FAQ

> Essential terminology, definitions, and frequently asked questions about Aptos Keyless accounts and OIDC integration.

## Terminology

- **OpenID Connect (OIDC)**: is the identity authentication protocol used to enable federated identity verification. This protocol is what is used when a user goes through the "Sign in with Google" flow for example.
- **Identity Provider (IdP)**: is the trusted authority who authenticates your identity via OIDC. Supported example includes: Google.
- **JSON Web Token (JWT):** is an open standard used to share security information between two parties ‚Äî a client and a server. Each JWT contains encoded JSON objects, including a set of claims. JWTs are signed using a cryptographic algorithm to ensure that the claims cannot be altered after the token is issued.
  - `iss`, an identifier for the OIDC provider (e.g., [https://accounts.google.com](https://accounts.google.com))
  - `aud`, the OAuth `client_id` of the application that the user is signing in to (e.g., [Notion.so](https://notion.so))
  - `sub`, an identifier that the OIDC provider uses to identify the user
    - This could be an identifier specific to this `client_id`
    - Or, it could be an identifier shared across different `client_id`'s (e.g., Facebook‚Äôs OIDC does this)
  - `email`, some providers might also expose the user‚Äôs email as one of the fields (e.g., Google)
    - in addition, an `email_verified` field will be exposed to indicate if the provider has verified that the user owns this email address
  - `nonce`, arbitrary data that the application wants the OIDC provider to sign over
  - `iat`, the time the JWT was issued at.
- **Ephemeral Key Pair:** a temporary public/private key pair that is used to sign transactions for an Aptos Keyless account. The public key and its expiration date are committed in the JWT token via the `nonce` field.
- **Keyless Account:** a blockchain account that is directly-derived from (1) a user‚Äôs OIDC account (e.g., `alice@gmail.com`) and (2) an associated application‚Äôs OAuth client\_id (e.g., Notion.so). Users authenticate through the OIDC flow.
- **JSON Web Key (JWK):** is the cryptographic public key of the OIDC provider. This public key is used to verify the signature on the JWTs that the OIDC provider issues to the client application. This way, the client application can verify the authenticity of the tokens and ensure that they have not been tampered with.
- **client\_id:** the OAuth identifier for your application that you will receive from the IdP after registering your application with them. This will be used in our keyless architecture in the address derivation for your users.
- **redirect\_uri:** the URI of the callback handler once the user successfully authenticates. Needs to be registered with your IdP.

## Ceremony

Aptos engaged in iterative trusted setup ceremonies to secure our Groth16 based ZK circuit. A trusted setup ceremony is a multi-party computation (MPC) that outputs the prover and verifier keys used in a zkSNARK system, common for efficient zero-knowledge proof systems. As long as a single participant in the ceremony is honest, the process is considered secure and the outputs will be valid. Our initial ceremony consisted of 140+ members of the Aptos ecosystem, which was an incredible show of the power of decentralization, security, and community - and a follow up ceremony was held following a developer feedback phase that allowed us to identify and implement an improvement to our circuit that helped us ensure Keyless is universally accessible. Our final ceremony contributions can be found in this repo \[here] and verified using the process outlined \[here].

## Frequently Asked Questions

**What is the best way to use Keyless accounts?**

- The best way to use Keyless accounts depends on your use case. If seamless account interoperability across our ecosystem is important to your dApp experience (think: mint an NFT on your platform and allow users to sell their NFT on an external NFT marketplace), you might want to consider integrating a wallet that supports Keyless. If you want to create a fully embedded account experience in your dApp, allowing users to transact without ever leaving your application, you might want to do a direct integration of the Aptos Keyless SDK.

**Does Keyless work with sponsored transactions or do my users always need to pay for their own gas?**

- Yes, Keyless works with sponsored transactions like any regular private key based account.

**If I use the Aptos Keyless SDK, can my user‚Äôs use their accounts across other dApps?**

- Keyless accounts are scoped to the domain they are created with as the address derivation includes a unique identifier for the application.

**What is Aptos Connect?**

- Account Management Infrastructure: Central to the keyless accounts paradigm is a robust account management infrastructure that facilitates the creation, deletion, and management of user accounts, alongside the storage and retrieval of associated metadata.

- While the adoption of keyless accounts heralds a paradigm shift towards enhanced usability and security, it is imperative for developers to remain cognizant of tradeoffs associated with this system vs. common alternatives like plaintext private keys.

**Are there dependency on external services?**

- Yes, Keyless accounts introduce a degree of dependency on external authentication services (pepper and prover), necessitating contingency plans and fallback mechanisms to mitigate service disruptions and ensure uninterrupted user access

**If my dApp goes down, my users cannot access their Keyless accounts. How can I help protect them in that case?**

- We encourage dApp developers to support additional backup recovery options for your users when integrating Keyless into a dApp. Specifically, we recommend that you support adding a backup private key to Keyless accounts in your dApp. Practically, this would transform the accounts into 1 of 2 multi-signature accounts where both keys are owned by the user. This would allow users to continue using OIDC login via your dApp to access their Keyless accounts but would add the ability for your users to export their backup private key to any self custodial product, where they could sign transactions from that same account with their traditional private key. Doing this will ensure that users never lose access to their digital assets, even if your dApp shuts down or the user loses access to their OIDC account.
- You should make a determination at what point in the user journey to incorporate a back-up is appropriate for your dApp.  Incorporating a backup method later in the user journey would preserve the seamless onboarding experience that Keyless offers but could result in less users receiving a recovery key. Prompting users to add a backup key during the onboarding process would likely lead to more users receiving a recovery key but could add potential friction during the onboarding process.

# Keyless Simple Example

> Interactive StackBlitz example demonstrating Keyless account integration with Google authentication and practical code samples.

Explore the code in [aptos-keyless-example repository](https://github.com/aptos-labs/aptos-keyless-example/tree/main/examples/keyless-example/).

The Keyless Simple Example is currently undergoing maintenance. Please check back later.

This is a live Keyless example on StackBlitz. Follow the instructions in the `README.md` to add your own Google `client_id`. Explore the code in [aptos-keyless-example repository](https://github.com/aptos-labs/aptos-keyless-example/tree/main/examples/keyless-example/).

<br />

<iframe
  src="https://stackblitz.com/edit/vitejs-vite-3fuvtu?embed=1&file=README.md"
  style={{
width: "100%",
height: "800px",
border: "0",
borderRadius: "4px",
overflow: "hidden",
}}
  title="aptos-keyless-example"
  allow="accelerometer; ambient-light-sensor; camera; encrypted-media; geolocation; gyroscope; hid; microphone; midi; payment; usb; vr; xr-spatial-tracking"
  sandbox="allow-forms allow-modals allow-popups allow-presentation allow-same-origin allow-scripts"
/>

# Build an End-to-End Dapp on Aptos

> Complete tutorial for building a todo list dapp from smart contract to frontend with wallet integration on Aptos.

import { Steps } from '@astrojs/starlight/components';

A common way to learn a new framework or programming language is to build a simple todo list. In this tutorial, we will learn how to build an end-to-end todo list dapp, starting from the smart contract side through the front-end side and finally use of a wallet to interact with the two.

See the completed code in the [source-code](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/move-examples/my_first_dapp).

## Prerequisites

You must have:

- [node and npm](https://nodejs.org/en/)
- [VSCode IDE](https://code.visualstudio.com/) or [Cursor](https://www.cursor.com/)

Although we will explain some React decisions, we are not going to deep dive into how React works; so we assume you have some previous experience with React.

## Setup

In this section, we will setup three things:

1. API key using [Geomi](https://geomi.dev/)
2. Project using [create-aptos-dapp](/build/create-aptos-dapp) which will hold our project files, both client-side code (React based) and the Move code (our smart contract)
3. [Move On Aptos](/build/smart-contracts/move-vscode-extension) VSCode extension

### Setup API key

First let's create an API key using [Geomi](https://geomi.dev/). The Aptos TypeScript SDK uses Geomi API by default, and without an API key, you will get very low rate limits.

<Steps>
  1. **Visit Geomi**: Go to [geomi.dev](https://geomi.dev/) in your web browser.

  2. **Sign up or Log in**: Create a new account or log in to your existing Geomi account.

  3. **Create a new project**: Click on "Create New Project" to create a new project and name it `my-first-dapp`.
     ![Geomi API key creation 1](~/images/screenshots/geomi-api-1.png)
     ![Geomi API key creation 2](~/images/screenshots/geomi-api-2.png)

  4. **Navigate to API Resource tab**: Navigate to the API Resource tab in your dashboard.
     ![Geomi API key creation 3](~/images/screenshots/geomi-api-3.png)

  5. **Create New API Resource**: Name it `my-first-dapp-api` and set the network to `Devnet`.
     ![Geomi API key creation 4](~/images/screenshots/geomi-api-4.png)

  6. **Configure API Key**: Since we will be using the API key in our web app, toggle on `Client usage`. Here you can configure allowed URLs and extension IDs that can use the API key. Set `Allowed URLs` to `http://localhost`, which is the development server we will be using. Also set `Per IP rate limit` to `100,000`.
     ![Geomi API key creation 5](~/images/screenshots/geomi-api-5.png)

  7. **Copy and Save**: Now you have your API key. Copy the key as we will be using it in the next step.
     ![Geomi API key creation 6](~/images/screenshots/geomi-api-6.png)
</Steps>

### Setup Project with create-aptos-dapp

Next, we will be using [create-aptos-dapp](/build/create-aptos-dapp) to create the project.

<Steps>
  1. **Open a terminal and navigate to the desired directory** for the project (for example, the `Desktop` directory).

  2. **Run the create-aptos-dapp command** to create the project:
     ```shellscript filename="Terminal"
     npx create-aptos-dapp@latest
     ```

  3. **Follow the instructions to create the project** with these settings:
     - Choose a name for the project, for example `my-first-dapp`
     - Choose the `Full-stack project` option
     - Choose the `Boilerplate Template` option
     - For simplicity, choose not to use Surf
     - Choose the `Vite app` framework option
     - Choose the `Devnet` network option
     - Say `Yes` for using API key and paste the Geomi API key you copied earlier
     - Say `No` for customizing default selections

  4. The tool will create the project in a directory with the same name as the project and install the required dependencies.

  5. Follow the `Next Steps` instructions.
</Steps>

### Setup Move On Aptos VSCode extension

Finally, let's install the [Move On Aptos](/build/smart-contracts/move-vscode-extension) VSCode extension.

<Steps>
  1. Open VSCode (or Cursor) and navigate to the Extensions tab.
  2. Search for `Move On Aptos` published by `aptoslabs` and install the extension.
</Steps>

## Chapters

After meeting the [prerequisites](#prerequisites) and [getting set up](#setup) as described below, you will follow this tutorial in this order:

1. [Create a smart contract](/build/guides/build-e2e-dapp/1-create-smart-contract)
2. [Set up a frontend](/build/guides/build-e2e-dapp/2-set-up-the-frontend)
3. [Fetch Data from Chain](/build/guides/build-e2e-dapp/3-fetch-data-from-chain)
4. [Submit data to chain](/build/guides/build-e2e-dapp/4-submit-data-to-chain)
5. [Handle Tasks](/build/guides/build-e2e-dapp/5-handle-tasks)

Now let's [create the Todo List smart contract](/build/guides/build-e2e-dapp/1-create-smart-contract).

# 1. Create a Smart Contract

> First step in building an end-to-end dapp: create and deploy the Move smart contract for managing todo tasks.

import { Aside, Steps } from '@astrojs/starlight/components';

This is the first chapter of the tutorial on [building an end-to-end dapp on Aptos](/build/guides/build-e2e-dapp). If you haven‚Äôt done it, review that introduction, and ensure your environment meets the [prerequisites](/build/guides/build-e2e-dapp#prerequisites) listed there.

Now that you are all set up, let's explore the `contract` directory.

![contract-directory](~/images/build-e2e-dapp-img-1-1.png)

### What is a `Move.toml` file?

A `Move.toml` file is a manifest file that contains metadata such as name, version, and dependencies for the package.

Take a look at the new `Move.toml` file. You should see your package information and an `AptosFramework` dependency. The `AptosFramework` dependency points to the `aptos-core/aptos-move/framework/aptos-framework` GitHub repo main branch.

### Why `sources` directory?

The `sources` directory holds a collection of `.move` modules files. And later when we want to compile the package using the CLI, the compiler will look for that `sources` directory and its `Move.toml` file.

### What is the `tests` directory?

The `tests` directory holds `.move` files that are used to test the files in our `sources` directory.

### Create a Move module

An account is needed to publish a Move module. When we installed the template, the tool created a new account for us and added it to the `.env` file.
If you open that file, you will see content resembling:

```shellscript filename=".env"
PROJECT_NAME=my-first-dapp
VITE_APP_NETWORK=devnet
VITE_APTOS_API_KEY=YOUR_API_KEY
VITE_MODULE_PUBLISHER_ACCOUNT_ADDRESS=0x1cecfef9e239eff12fb1a3d189a121c37f48908d86c0e9c02ec103e0a05ddebb
#This is the module publisher account's private key. Be cautious about who you share it with, and ensure it is not exposed when deploying your dApp.
VITE_MODULE_PUBLISHER_ACCOUNT_PRIVATE_KEY=0x84638fd5c42d0937503111a587307169842f355ab661b5253c01cfe389373f43
```

<Aside type="note">
  You just created a new account on the Aptos (dev) network! Yay! You can see it by going to the Aptos Explorer Devnet network view, pasting the `VITE_MODULE_PUBLISHER_ACCOUNT_ADDRESS` value from your `.env` file into the search field, and clicking on the dropdown option!
</Aside>

The Boilerplate template comes with a pre generated `message_board.move` file, a relevant test file and a `Move.toml` file. We will not be using `message_board.move` in this tutorial, so delete it.

As mentioned, our sources directory holds our `.move` module files; so let's create a new `todolist.move` file.

<Steps>
  1. **Create a new `todolist.move` file** within the `sources` directory and add the following to that file:
     ```move filename="todolist.move"
     module todolist_addr::todolist {

     }
     ```

  2. **Open the `Move.toml` file**, replace the name from `MessageBoard` to `Todolist` and the address from `message_board_addr` to `todolist_addr`, like the following code:
     ```toml filename="Move.toml"
     [package]
     name = "Todolist"
     version = "1.0.0"
     authors = []

     [addresses]
     todolist_addr = "_"

     [dependencies]
     AptosFramework = { git = "https://github.com/aptos-labs/aptos-framework.git", rev = "mainnet", subdir = "aptos-framework" }

     [dev-dependencies]
     ```
</Steps>

<Aside type="note">
  A Move module is stored under an address (so when it published anyone can access it using that address); the syntax for a Move module is

  ```move filename="todolist.move"
  module <account-address>::<module-name> {

  }
  ```

  In our module, the `account-address` is `todolist_addr` (a variable we just declared on the `Move.toml` file in the previous step that holds an `address`), and the `module-name` is `todolist` (a random name we selected).
</Aside>

### What is the `'_'` in the `Move.toml` file?

The `'_'` is a placeholder for the account address. When we run the `move` compiler, the compiler will replace it with the actual account address.

### Scripts for running `move` commands

`create-aptos-dapp` comes with premade scripts to easily run `move` commands, like `compile`, `test` and `publish`.

<Steps>
  1. Open each of the files in the `scripts/move` directory and update the `message_board_addr` variable to be `todolist_addr`.
     ```js filename="scripts/move/compile.js"
     ...
       namedAddresses: {
         todolist_addr: process.env.VITE_MODULE_PUBLISHER_ACCOUNT_ADDRESS,
       },
     ...
     ```
</Steps>

<Aside type="note">
  Later, when we will run the each of the `move` commands, it will run these scripts, and replace the `'_'` with the actual account address that assigned to the `todolist_addr` variable.
</Aside>

### Our contract logic

Before jumping into writing code, let‚Äôs first understand what we want our smart contract program to do. For ease of understanding, we will keep the logic pretty simple:

1. An account creates a new list.
2. An account creates a new task on their list.
   - Whenever someone creates a new task, emit a `TaskCreated` event.
3. Let an account mark their task as completed.

<Aside type="note">
  Creating an event is not mandatory yet useful if dapps/users want to monitor data, such as how many people create a new task, using the [Aptos Indexer](/build/indexer).
</Aside>

We can start with defining a `TodoList` struct, that holds the:

- tasks array
- a task counter that counts the number of created tasks (we can use that to differentiate between the tasks)

And also create a `Task` struct that holds:

- `task_id` - derived from the TodoList task counter.
- `creator_addr` - the account address who created that task.
- `content` - the task content.
- `completed` - a boolean that marks whether that task is completed or not.

On the `todolist.move` file, update the content in the module with:

```move filename="todolist.move"
...
/// Main resource that stores all tasks for an account
struct TodoList has key {
    tasks: Table<u64, Task>,
    task_counter: u64
}

/// Individual task structure
struct Task has store, drop, copy {
    task_id: u64,
    creator_addr: address,
    content: String,
    completed: bool,
}
...
```

**What did we just add?**

**TodoList**

A struct that has the `key` and `store` abilities:

- `Key` ability allows struct to be used as a storage identifier. In other words, `key`
  is an ability to be stored at the top-level and act as a storage. We need it here to have `TodoList` be a resource stored in our user account.

When a struct has the `key` ability, it turns this struct into a `resource`:

- `Resource` is stored under the account - therefore it _exists_ only when assigned to an account and can be _accessed_ through this account only.

**Task**

A struct that has the `store`, `drop` and `copy`abilities.

‚Ä¢ `Store` - Task needs `Store` as it‚Äôs stored inside another struct (TodoList)

‚Ä¢ `Copy` - value can be _copied_ (or cloned by value).

‚Ä¢ `Drop` - value can be _dropped_ by the end of scope.

Let‚Äôs try to compile what we have now **(Spoiler alert: it will not work)**:

<Steps>
  1. Run: `npm run move:compile`
     **Seeing errors?!** Let‚Äôs understand them.

     We have some errors on `Unbound type`- this is happening because we used some types but never imported them, and the compiler doesn't know where to get them from.

     On the top of the module, import those types by adding:

     ```move filename="todolist.move"
     ...
     use aptos_std::table::Table;
     use std::string::String; 
     ...
     ```

     That will tell the compiler where it can get those types from.

  2. Run the `npm run move:compile` command again; If all goes well, we should see a response resembling (where the resulting account address is your default profile account address):

     ```shellscript filename="Terminal"
     Compiling, may take a little while to download git dependencies...
     UPDATING GIT DEPENDENCY https://github.com/aptos-labs/aptos-core.git
     INCLUDING DEPENDENCY AptosFramework
     INCLUDING DEPENDENCY AptosStdlib
     INCLUDING DEPENDENCY MoveStdlib
     BUILDING Todolist
     {
     "Result": [
         "1cecfef9e239eff12fb1a3d189a121c37f48908d86c0e9c02ec103e0a05ddebb::todolist"
       ]
     }
     ```

     At this point, we have successfully compiled our Move module. Yay!
</Steps>

<Aside type="note">
  If you are still unable to compile your Move module, make sure you have deleted the `message_board.move` file, and replaced the `message_board_addr` to `todolist_addr` in the `Move.toml` file.
</Aside>

We also have a new `move/build` directory (created by the compiler) that holds our compiled modules, build information and `sources` directory.

### Create list function

The first thing an account can and should do with our contract is to create a new list.

Creating a list is essentially submitting a transaction, and so we need to know the `signer` who signed and submitted the transaction:

<Steps>
  1. Add a `create_list` function that accepts a `signer` inside the `Todolist` module.

     ```move filename="todolist.move"
     public entry fun create_list(account: &signer){

     }
     ```

     **Let‚Äôs understand the components of this function**

     - `entry` - an _entry_ function is a function that can be called via transactions. Simply put, whenever you want to submit a transaction to the chain, you should call an entry function.

     - `&signer` - The **signer** argument is injected by the Move VM as the address who signed that transaction.

     Our code has a `TodoList` resource. Resource is stored under the account; therefore, it _exists_ only when assigned to an account and can be _accessed_ only through this account.

     That means to create the `TodoList` resource, we need to assign it to an account that only this account can have access to.

     The `create_list` function can handle that `TodoList` resource creation.

  2. Add the following to the `create_list` function

     ```move filename="todolist.move"
     /// Initializes a new todo list for the account
     public entry fun create_list(account: &signer) {
         let tasks_holder = TodoList {
             tasks: table::new(),
             task_counter: 0
         };
         // Move the TodoList resource under the signer account
         move_to(account, tasks_holder);
     }
     ```

     This function takes in a `signer`, creates a new `TodoList` resource, and uses `move_to` to have the resource stored in the provided signer account.

  3. Let‚Äôs make sure everything is still working by running the `npm run move:compile` command again.
</Steps>

### Create task function

As mentioned before, our contract has a create task function that lets an account create a new task. Creating a task is also essentially submitting a transaction, and so we need to know the `signer` who signed and submitted the transaction. Another element we want to accept in our function is the task `content`.

<Steps>
  1. Add a `create_task` function that accepts a `signer` and task `content` and the function logic.

     ```move filename="todolist.move"
     /// Creates a new task in the todo list
     public entry fun create_task(account: &signer, content: String) acquires TodoList {
         // Get the signer address
         let signer_address = signer::address_of(account);

         // Get the TodoList resource
         let todo_list = borrow_global_mut<TodoList>(signer_address);
         
         // Increment task counter
         let counter = todo_list.task_counter + 1;
         
         // Create a new task
         let new_task = Task {
             task_id: counter,
             creator_addr: signer_address,
             content,
             completed: false
         };
         
         // Add the new task to the tasks table
         todo_list.tasks.upsert(counter, new_task);
         
         // Update the task counter
         todo_list.task_counter = counter;
         
         // Emit a task created event
         event::emit(TaskCreated {
             task_id: counter,
             creator_addr: signer_address,
             content,
             completed: false
         })
     }
     ```
  2. You will notice that we have not created the `TaskCreated` event struct yet. Create it at the top of the file  (under the use statements) with the following code:

     ```move filename="todolist.move"
     #[event]
     struct TaskCreated has drop, store {
         task_id: u64,
         creator_addr: address,
         content: String,
         completed: bool,
     }
     ```
  3. Since we now use three new modules - signer, event, and table (you can see it being used in `signer::`, `event::`, and `table::`) - we need to import these modules.
     At the top of the file, add those two use statements (replace the `table` use statement with the following code):

     ```move filename="todolist.move"
     use aptos_framework::event;
     use aptos_std::table::{Self, Table}; // This one we already have, need to modify it
     use std::signer;
     ```
  4. Let‚Äôs make sure everything is still working by running the `npm run move:compile` command again.
</Steps>

**Back to the code; what is happening here?**

- First, we want to get the signer address, so we can get this account‚Äôs `TodoList` resource.
- Then, we retrieve the `TodoList` resource with the `signer_address`; with that we have access to the `TodoList` properties.
- We can now increment the `task_counter` property, and create a new `Task` with the `signer_address`, `counter` and the provided `content`.
- We push it to the `todo_list.tasks` table that holds all of our tasks along with the new `counter` (which is the table key) and the newly created Task.
- Then we assign the global `task_counter` to be the new incremented counter.
- Finally, we emit the `TaskCreated` event that holds the new Task data. `event::emit()` is an `aptos-framework` function that emits a module event with payload `msg`. In our case, we are passing the function a `TaskCreated` event struct with the new Task data.

### Complete task function

Another function we want our contract to hold is the option to mark a task as completed.

<Steps>
  1. Add a `complete_task` function that accepts a `signer` and a `task_id`:

     ```move filename="todolist.move"
     /// Marks a task as completed
     public entry fun complete_task(account: &signer, task_id: u64) acquires TodoList {
         // Get the signer address
         let signer_address = signer::address_of(account);
         
         // Get the TodoList resource
         let todo_list = borrow_global_mut<TodoList>(signer_address);
         
         // Get the task record
         let task_record = todo_list.tasks.borrow_mut(task_id);
         
         // Mark the task as completed
         task_record.completed = true;
     }
     ```

     **Let‚Äôs understand the code.**

     - As before in our create list function, we retrieve the `TodoList` struct by the signer address, so we can have access to the tasks table that holds all the account tasks.
     - Then, we get a mutable reference for the task with the provided `task_id` on the `todo_list.tasks` table.
     - Finally, we update that task `completed` property to be true.

  2. Now compile the code by running: `npm run move:compile` to make sure everything is still working.
</Steps>

### Add validations

As this code now compiles, we want to have some validations and checks before creating a new task or updating the task as completed, so we can be sure our functions work as expected.

<Steps>
  1. Add a check to the `create_task` function to make sure the signer account has a list:

     ```move filename="todolist.move"
     public entry fun create_task(account: &signer, content: String) acquires TodoList {
       // gets the signer address
       let signer_address = signer::address_of(account);

       // assert signer has created a list
       assert!(exists<TodoList>(signer_address), 1);

       ...
     }
     ```

  2. Add a check to the `complete_task` function to make sure the:

     - signer has created a list.
     - task exists.
     - task is not completed.

     With the following code:

     ```move filename="todolist.move"
     /// Marks a task as completed
     public entry fun complete_task(account: &signer, task_id: u64) acquires TodoList {
       // Get the signer address
       let signer_address = signer::address_of(account);
       
       // Ensure the account has initialized a todo list
       assert!(exists<TodoList>(signer_address), 1);
       
       // Get the TodoList resource
       let todo_list = borrow_global_mut<TodoList>(signer_address);
       
       // Ensure the task exists
       assert!(todo_list.tasks.contains(task_id), 2);
       
       // Get the task record
       let task_record = todo_list.tasks.borrow_mut(task_id);
       
       // Ensure the task is not already completed
       assert!(task_record.completed == false, 3);
       
       // Mark the task as completed
       task_record.completed = true;
     }
     ```
</Steps>

We just added our first `assert` statements!

If you noticed, `assert` accepts two arguments: the first is what to check for, and the second is an error code. Instead of passing in an arbitrary number, a convention is to declare `errors` on the top of the module file and use these instead.

On the top of the module file (under the `use` statements), add those error declarations:

```move filename="todolist.move"
// Errors
/// Account has not initialized a todo list
const ENOT_INITIALIZED: u64 = 1;
/// Task does not exist
const ETASK_DOESNT_EXIST: u64 = 2;
/// Task is already completed
const ETASK_IS_COMPLETED: u64 = 3;
```

Now we can update our asserts with these constants:

```move filename="todolist.move"
/// Creates a new task in the todo list
public entry fun create_task(account: &signer, content: String) acquires TodoList {
    // Get the signer address
    let signer_address = signer::address_of(account);

    // Ensure the account has initialized a todo list
    assert!(exists<TodoList>(signer_address), ENOT_INITIALIZED);

  ...
}

/// Marks a task as completed
public entry fun complete_task(account: &signer, task_id: u64) acquires TodoList {
    // Get the signer address
    let signer_address = signer::address_of(account);
    
    // Ensure the account has initialized a todo list
    assert!(exists<TodoList>(signer_address), ENOT_INITIALIZED);
    
    // Get the TodoList resource
    let todo_list = borrow_global_mut<TodoList>(signer_address);
    
    // Ensure the task exists
    assert!(todo_list.tasks.contains(task_id), ETASK_DOESNT_EXIST);
    
    // Get the task record
    let task_record = todo_list.tasks.borrow_mut(task_id);
    
    // Ensure the task is not already completed
    assert!(task_record.completed == false, ETASK_IS_COMPLETED);
    
    // Mark the task as completed
    task_record.completed = true;
}
```

**WONDERFUL!!**

Let‚Äôs stop for one moment and make sure our code compiles by running the `npm run move:compile` command. If all goes well, we should output resembling:

```shellscript filename="Terminal"
Compiling, may take a little while to download git dependencies...
UPDATING GIT DEPENDENCY https://github.com/aptos-labs/aptos-core.git
INCLUDING DEPENDENCY AptosFramework
INCLUDING DEPENDENCY AptosStdlib
INCLUDING DEPENDENCY MoveStdlib
BUILDING MessageBoard
{
  "Result": [
    "1cecfef9e239eff12fb1a3d189a121c37f48908d86c0e9c02ec103e0a05ddebb::todolist"
  ]
}
```

If you encounter errors, make sure you followed the steps above correctly and try to determine the cause of the issues.

### Write tests

Now that we have our smart contract logic ready, we need to add some tests for it.

First, delete the `test_end_to_end.move` file in the `tests` directory, as we won't be using it.

<Steps>
  1. For simplicity, and because we don't have much code to test, we will have the tests in the `todolist.move` file. If you need to write a more complex test, you should create a separate test file in the `tests` directory.

     The test steps are:

     ```move filename="todolist.move"
       // create a list
       // create a task
       // update task as completed
     ```

  2. Add the following code to the bottom of the `todolist.move` file:

     ```move filename="todolist.move"
     #[test]
     public entry fun test_flow() {

     }
     ```

     Note: Test functions use the `#[test]` annotation.

     <Aside type="note">
       we need to use `entry` here because we are testing an `entry` function.
     </Aside>

  3. Update the test function to be:

     ```move filename="todolist.move"
     #[test(admin = @0x123)]
     public entry fun test_flow(admin: signer) acquires TodoList {
         // Create an admin account for testing
         account::create_account_for_test(signer::address_of(&admin));
         
         // Initialize a todo list for the admin account
         create_list(&admin);

         // Create a task and verify it was added correctly
         create_task(&admin, string::utf8(b"Create e2e guide video for aptos devs."));
         let todo_list = borrow_global<TodoList>(signer::address_of(&admin));
         assert!(todo_list.task_counter == 1, 5);
         
         // Verify task details
         let task_record = todo_list.tasks.borrow(todo_list.task_counter);
         assert!(task_record.task_id == 1, 6);
         assert!(task_record.completed == false, 7);
         assert!(task_record.content == string::utf8(b"Create e2e guide video for aptos devs."), 8);
         assert!(task_record.creator_addr == signer::address_of(&admin), 9);

         // Complete the task and verify it was marked as completed
         complete_task(&admin, 1);
         let todo_list = borrow_global<TodoList>(signer::address_of(&admin));
         let task_record = todo_list.tasks.borrow(1);
         assert!(task_record.task_id == 1, 10);
         assert!(task_record.completed == true, 11);
         assert!(task_record.content == string::utf8(b"Create e2e guide video for aptos devs."), 12);
         assert!(task_record.creator_addr == signer::address_of(&admin), 13);
     }
     ```

     Our `#[test]` annotation has changed and declares an account variable.

     Additionally, the function itself now accepts a signer argument.

     **Let‚Äôs understand our tests.**

     Since our tests run outside an account scope, we need to _create_ accounts to use in our tests. The `#[test]` annotation gives us the option to declare those accounts. We use an `admin` account and set it to a random account address (`@0x123`). The function accepts this signer (account) and creates it by using a built-in function to create an account for test.

     Then we simply go through the flow by:

     - creating a list
     - creating a task
     - updating a task as completed

     And assert the expected data/behavior at each step.

     Before running the tests again, we need to import (`use`) some new modules we are now employing in our code:

  4. At the top of the file, add these `use` statements:

     ```move filename="todolist.move"
     #[test_only]
     use aptos_framework::account;
     #[test_only]
     use std::string::{Self}; 
     ```

     Note that we are using the `#[test_only]` annotation to import the modules only for testing. This is because we don't want to use these modules in our production code.

  5. Run the `npm run move:test` command. If all goes right, we should see a success message like:

     ```move filename="todolist.move"
     Running Move unit tests
     [ PASS    ] 0x1cecfef9e239eff12fb1a3d189a121c37f48908d86c0e9c02ec103e0a05ddebb::todolist::test_flow
     Test result: OK. Total tests: 1; passed: 1; failed: 0
     {
       "Result": "Success"
     }
     ```

  6. Let‚Äôs add one more test to make sure our `complete_task` function works as expected. Add another test function with:

     ```move filename="todolist.move"
     #[test(admin = @0x123)]
     #[expected_failure(abort_code = ENOT_INITIALIZED)]
     public entry fun account_can_not_update_task(admin: signer) acquires TodoList {
         // Create an admin account for testing
         account::create_account_for_test(signer::address_of(&admin));
         
         // Attempt to complete a task without creating a list first (should fail)
         complete_task(&admin, 2);
     }
     ```

     This test confirms that an account can‚Äôt use that function if they haven‚Äôt created a list before.

     The test also uses a special annotation `#[expected_failure]` that, as the name suggests, expects to fail with an `ENOT_INITIALIZED` error code.

  7. Run the `npm run move:test` command. If all goes right, we should see a success message like:

     ```shellscript filename="Terminal"
     Running Move unit tests
     [ PASS    ] 0x1cecfef9e239eff12fb1a3d189a121c37f48908d86c0e9c02ec103e0a05ddebb::todolist::account_can_not_update_task
     [ PASS    ] 0x1cecfef9e239eff12fb1a3d189a121c37f48908d86c0e9c02ec103e0a05ddebb::todolist::test_flow
     Test result: OK. Total tests: 2; passed: 2; failed: 0
     {
       "Result": "Success"
     }
     ```
</Steps>

Now that everything works, we can compile the Move modules and publish the Move package to chain so our React app (and everyone else) can interact with our smart contract!

### Publish todolist module to chain

<Steps>
  1. Run: `npm run move:test` and `npm run move:compile` - all should work without errors.
  2. Run: `npm run move:publish`
  3. Enter `yes` to the prompt `Do you want to publish this package at object address 0x8f66343d40de3eeef5dd45cab8c1531a542f0e5f546da9f11852d4c2b30165a7 [yes/no] >`. **(Spoiler alert: it will fail)**
</Steps>

**Oh no! We got an error!**

It complains about an account mismatch with the `MODULE_ADDRESS_DOES_NOT_MATCH_SENDER` error code. Apparently we compiled the package with a different account we try to publish it.

Let's fix it.

1. Open the `scripts/move/publish.js` file.
2. Update the `addressName` variable value to be `todolist_addr`.

That will use the same account we used for compiling the package.

Let's try again:

<Steps>
  1. Run: `npm run move:publish`

  2. Enter `yes` in the prompt.

  3. Enter `yes` in the second prompt.

  4. That will compile, simulate and finally publish your module into devnet. You should see a success message:

     ```shellscript filename="Terminal"
     Transaction submitted: https://explorer.aptoslabs.com/txn/0x68dadf24b9ec29b9c32bd78836d20032de615bbef5f10db580228577f7ca945a?network=devnet
     Code was successfully deployed to object address 0x2bce4f7bb8a67641875ba5076850d2154eb9621b0c021982bdcd80731279efa6
     {
       "Result": "Success"
     }
     ```

  5. You can now head to the [Aptos Explorer](https://explorer.aptoslabs.com/?network=devnet) link and view the transaction details. You can also see the module published on chain by looking for the object address.
</Steps>

<Aside type="note">
  Check out your `.env` file and see the `VITE_MODULE_ADDRESS` variable, it is set to the object address of the published module.
</Aside>

### Full Todolist module code

Here is the full `todolist.move` file to confirm your work:

```move filename="todolist.move"
module todolist_addr::todolist {
    use aptos_framework::event;
    use aptos_std::table::{Self, Table};
    use std::signer;
    use std::string::String; 

    #[test_only]
    use aptos_framework::account;
    #[test_only]
    use std::string::{Self}; 

    // Errors
    /// Account has not initialized a todo list
    const ENOT_INITIALIZED: u64 = 1;
    /// Task does not exist
    const ETASK_DOESNT_EXIST: u64 = 2;
    /// Task is already completed
    const ETASK_IS_COMPLETED: u64 = 3;

    #[event]
    struct TaskCreated has drop, store {
        task_id: u64,
        creator_addr: address,
        content: String,
        completed: bool,
    }

    /// Main resource that stores all tasks for an account
    struct TodoList has key {
        tasks: Table<u64, Task>,
        task_counter: u64
    }

    /// Individual task structure
    struct Task has store, drop, copy {
        task_id: u64,
        creator_addr: address,
        content: String,
        completed: bool,
    }

    /// Initializes a new todo list for the account
    public entry fun create_list(account: &signer) {
        let tasks_holder = TodoList {
            tasks: table::new(),
            task_counter: 0
        };
        // Move the TodoList resource under the signer account
        move_to(account, tasks_holder);
    }

    /// Creates a new task in the todo list
    public entry fun create_task(account: &signer, content: String) acquires TodoList {
        // Get the signer address
        let signer_address = signer::address_of(account);

        // Ensure the account has initialized a todo list
        assert!(exists<TodoList>(signer_address), ENOT_INITIALIZED);

        // Get the TodoList resource
        let todo_list = borrow_global_mut<TodoList>(signer_address);
        
        // Increment task counter
        let counter = todo_list.task_counter + 1;
        
        // Create a new task
        let new_task = Task {
            task_id: counter,
            creator_addr: signer_address,
            content,
            completed: false
        };
        
        // Add the new task to the tasks table
        todo_list.tasks.upsert(counter, new_task);
        
        // Update the task counter
        todo_list.task_counter = counter;
        
        // Emit a task created event
        event::emit(TaskCreated {
            task_id: counter,
            creator_addr: signer_address,
            content,
            completed: false
        })
    }

    /// Marks a task as completed
    public entry fun complete_task(account: &signer, task_id: u64) acquires TodoList {
        // Get the signer address
        let signer_address = signer::address_of(account);
        
        // Ensure the account has initialized a todo list
        assert!(exists<TodoList>(signer_address), ENOT_INITIALIZED);
        
        // Get the TodoList resource
        let todo_list = borrow_global_mut<TodoList>(signer_address);
        
        // Ensure the task exists
        assert!(todo_list.tasks.contains(task_id), ETASK_DOESNT_EXIST);
        
        // Get the task record
        let task_record = todo_list.tasks.borrow_mut(task_id);
        
        // Ensure the task is not already completed
        assert!(task_record.completed == false, ETASK_IS_COMPLETED);
        
        // Mark the task as completed
        task_record.completed = true;
    }

    #[test(admin = @0x123)]
    public entry fun test_flow(admin: signer) acquires TodoList {
        // Create an admin account for testing
        account::create_account_for_test(signer::address_of(&admin));
        
        // Initialize a todo list for the admin account
        create_list(&admin);

        // Create a task and verify it was added correctly
        create_task(&admin, string::utf8(b"Create e2e guide video for aptos devs."));
        let todo_list = borrow_global<TodoList>(signer::address_of(&admin));
        assert!(todo_list.task_counter == 1, 5);
        
        // Verify task details
        let task_record = todo_list.tasks.borrow(todo_list.task_counter);
        assert!(task_record.task_id == 1, 6);
        assert!(task_record.completed == false, 7);
        assert!(task_record.content == string::utf8(b"Create e2e guide video for aptos devs."), 8);
        assert!(task_record.creator_addr == signer::address_of(&admin), 9);

        // Complete the task and verify it was marked as completed
        complete_task(&admin, 1);
        let todo_list = borrow_global<TodoList>(signer::address_of(&admin));
        let task_record = todo_list.tasks.borrow(1);
        assert!(task_record.task_id == 1, 10);
        assert!(task_record.completed == true, 11);
        assert!(task_record.content == string::utf8(b"Create e2e guide video for aptos devs."), 12);
        assert!(task_record.creator_addr == signer::address_of(&admin), 13);
    }

    #[test(admin = @0x123)]
    #[expected_failure(abort_code = ENOT_INITIALIZED)]
    public entry fun account_can_not_update_task(admin: signer) acquires TodoList {
        // Create an admin account for testing
        account::create_account_for_test(signer::address_of(&admin));
        
        // Attempt to complete a task without creating a list first (should fail)
        complete_task(&admin, 2);
    }
}
```

Now let's [set up the frontend](/build/guides/build-e2e-dapp/2-set-up-the-frontend) in chapter 2.

# 2. Set up the frontend

> Configure the React frontend with wallet adapter integration for interacting with your Aptos smart contract.

This is the second chapter of the tutorial on [building an end-to-end dapp on Aptos](/build/guides/build-e2e-dapp) where you have already [created a smart contract](/build/guides/build-e2e-dapp/1-create-smart-contract) and are now setting up the frontend.

## Set up the frontend

`create-aptos-dapp` has already created the frontend for us with a basic layout and Wallet implementation using the [aptos-wallet-adapter](/build/sdks/wallet-adapter#aptos-wallet-adapter) library.

1. Run: `npm run dev`

   At this point you should have your app running on [http://localhost:5173](http://localhost:5173), which displays the default template layout.

2. In the `frontend` directory, find all the frontend files. Let‚Äôs clean it up a bit.

3. Open the `App.tsx` file and update its content to be:

```typescript filename="App.tsx"
import { Header } from "@/components/Header";
import { TopBanner } from "@/components/TopBanner";

function App() {
  return (
    <>
      <TopBanner />
      <Header />
      <div className="flex items-center justify-center flex-col">
        <div>My app goes here</div>
      </div>
    </>
  );
}

export default App;

```

Once you save the changes, you should see that the app content has changed in the browser and displays `My app goes here`.

## Our dapp UI

First we will build the dapp UI layout. We have two UI states for the app:

- When an account hasn't created a list yet (on the left).
- When an account has created a list and can now add tasks to it (on the right).
  ![dapp-ui](~/images/build-e2e-dapp-img-3.png)

We now have a working client with a Wallet connect button and a wallet selector modal. Feel free to play with it and connect a wallet with it.

Then learn how to [fetch data from chain](/build/guides/build-e2e-dapp/3-fetch-data-from-chain) in chapter 3.

# 3. Fetch Data from Chain

> Learn to retrieve on-chain data by checking for TodoList resources and implementing conditional UI logic.

import { Steps } from '@astrojs/starlight/components';

In the third chapter of the tutorial on [building an end-to-end dapp on Aptos](/build/guides/build-e2e-dapp), you will be learning to fetch data from chain.

Our UI logic relies on whether the connected account has created a todo list. If the account has created a todo list, our app should display that list; if not, the app should display a button offering the option to create a new list.

For that, we first need to check if the connected account has a `TodoList` resource. In our smart contract, whenever someone creates a todo list we create and assign a `TodoList` resource to their account.

To fetch data from chain, we can use the [Aptos TypeScript SDK](/build/sdks/ts-sdk). The SDK provides classes and functions for us to easily interact and query the Aptos chain.

To get started:

<Steps>
  1. **Stop the local server** if running and go to the `App.tsx` file.

  2. **Import wallet from the wallet adapter React provider**:
     ```tsx filename="App.tsx"
     import { useWallet } from "@aptos-labs/wallet-adapter-react";
     ```

  3. **Extract the account object from the wallet adapter**:

     ```tsx filename="App.tsx"
     function App (
       const { account } = useWallet();
     )
     ```

     The `account` object is `null` if there is no account connected; when an account is connected, the `account` object holds the account information, including the account address.

  4. **Set up React hooks and state**:

     - Import `useEffect` and `useState` using:

     ```tsx filename="App.tsx"
     import { useState, useEffect } from "react";
     ```

     - Create local state to track whether the account has a todo list and add a `useEffect` hook to fetch data when the account changes:

     ```tsx filename="App.tsx"
     function App() {
       const [accountHasList, setAccountHasList] = useState<boolean>(false);
       useEffect(() => {
         fetchList();
       }, [account?.address]);
     }
     ```

  5. **Import required dependencies**:

     - Import `MODULE_ADDRESS` variable using:

     ```tsx filename="App.tsx"
     import { MODULE_ADDRESS } from "./constants";
     ```

     - Import `aptosClient` using:

     ```tsx filename="App.tsx"
     import { aptosClient } from "./utils/aptosClient";
     ```

  6. **Create the `fetchList` function**:
     ```tsx filename="App.tsx"
     const fetchList = async () => {
       if (!account) return [];
       const moduleAddress = MODULE_ADDRESS;
       try {
         const todoListResource = await aptosClient().getAccountResource(
           {
             accountAddress:account?.address,
             resourceType:`${moduleAddress}::todolist::TodoList`
           }
         );
         setAccountHasList(true);
       } catch (e: any) {
         setAccountHasList(false);
       }
     };
     ```

  7. **Update the UI based on the `accountHasList` state**:

     - Import `Button` component using:

     ```tsx filename="App.tsx"
     import { Button } from "./components/ui/button";
     ```

     - Update the UI based on the `accountHasList` state:

     ```tsx filename="App.tsx"
     return (
       <>
         <TopBanner />
         <Header />
         <div className="flex items-center justify-center flex-col">
           {!accountHasList && (
             <div className="flex items-center justify-center flex-col">
               <Button>Add new list</Button>
             </div>
           )}
         </div>
       </>
     );
     ```

     The `aptosClient().getAccountResource()` expects an _account address_ that holds the resource we are looking for and a string representation of an on-chain _Move struct type_:

     - **account address** - is the current connected account (we are getting it from the wallet account object)
     - **Move struct type string syntax**:
       - The account address who holds the move module
       - The module name the resource lives in = `todolist`
       - The resource name = `TodoList`

     If the request succeeds and there is a resource for that account, we want to set our local state to `true`; otherwise, we would set it to `false`.

     We now have an **Add new list** button that appears only if the account doesn't have a list.

  8. Start the local server with `npm run dev`. You should see the **Add new list** button.
</Steps>

Next, let‚Äôs understand how to create a new list by [submitting data to chain](/build/guides/build-e2e-dapp/4-submit-data-to-chain) in chapter 4.

# 4. Submit Data to Chain

> Implement transaction submission to create new todo lists using wallet adapter's signAndSubmitTransaction function.

In the fourth chapter of the tutorial on [building an end-to-end dapp on Aptos](/build/guides/build-e2e-dapp), you will be submitting data to the chain.

So now we have an **Add new list** button that appears if the connected account hasn‚Äôt created a list yet. We still don't have a way for an account to create a list, so let‚Äôs add that functionality.

1. First, our wallet adapter provider has a `signAndSubmitTransaction` function; let‚Äôs extract it by updating the following:

```tsx filename="App.tsx"
const { account, signAndSubmitTransaction } = useWallet();
```

2. Add an `onClick` event to the new list button:

```tsx filename="App.tsx"
<Button
  onClick={addNewList}
>
  Add new list
</Button>
```

3. Update the import statement from `@aptos-labs/wallet-adapter-react` to also import the `InputTransactionData` type and

```tsx filename="App.tsx"
import {
  useWallet,
  InputTransactionData,
} from "@aptos-labs/wallet-adapter-react";
```

4. Add the `addNewList` function:

```tsx filename="App.tsx"

const addNewList = async () => {
  if (!account) return [];

   const transaction:InputTransactionData = {
      data: {
        function:`${moduleAddress}::todolist::create_list`,
        functionArguments:[]
      }
    }
  try {
    // sign and submit transaction to chain
    const response = await signAndSubmitTransaction(transaction);
    // wait for transaction
    await aptosClient().waitForTransaction({transactionHash:response.hash});
    setAccountHasList(true);
  } catch (error: any) {
    setAccountHasList(false);
  }
};
```

5. Since our new function also uses `moduleAddress`, let‚Äôs get it out of the `fetchList` function scope to the global scope so it can be used globally.

In our `fetchList` function, find the line:

```tsx filename="App.tsx"
const moduleAddress = MODULE_ADDRESS;
```

And move it to outside of the main `App` function, so it can be globally accessed.

**Let‚Äôs go over the `addNewList` function code.**

First, we use the `account` property from our wallet provider to make sure there is an account connected to our app.

Then we build our transaction data to be submitted to chain:

```tsx filename="App.tsx"
const transaction:InputTransactionData = {
      data: {
        function:`${moduleAddress}::todolist::create_list`,
        functionArguments:[]
      }
    }
```

- `function`- is built from the module address, module name and the function name.
- `functionArguments` - the arguments the function expects, in our case it doesn‚Äôt expect any arguments.

Next, we submit the transaction payload and wait for its response. The response returned from the `signAndSubmitTransaction` function holds the transaction hash. Since it can take a bit for the transaction to be fully executed on chain and we also want to make sure it is executed successfully, we `waitForTransaction`. And only then we can set our local `accountHasList` state to `true`.

6. Before testing our app, let‚Äôs tweak our UI a bit and add a Spinner component to show up while we are waiting for the transaction.
   Add a local state to keep track whether a transaction is in progress:

```tsx filename="App.tsx"
const [transactionInProgress, setTransactionInProgress] =
  useState<boolean>(false);
```

7. Update our `addNewList` function to update the local state:

```tsx filename="App.tsx"
const addNewList = async () => {
  if (!account) return [];
  setTransactionInProgress(true);
  const transaction:InputTransactionData = {
      data: {
        function:`${moduleAddress}::todolist::create_list`,
        functionArguments:[]
      }
    }
  try {
    // sign and submit transaction to chain
    const response = await signAndSubmitTransaction(transaction);
    // wait for transaction
    await aptosClient().waitForTransaction({transactionHash:response.hash});
    setAccountHasList(true);
  } catch (error: any) {
    setAccountHasList(false);
  } finally {
    setTransactionInProgress(false);
  }
};
```

9. Update our UI with the following:

```tsx filename="App.tsx"
return (
  <>
    ...
      {!accountHasList && (
        <div className="flex items-center justify-center flex-col">
          <Button onClick={addNewList} disabled={transactionInProgress}>
            Add new list
          </Button>
        </div>
      )}
  </>
);
```

Now you can head over to our app, and add a new list!

Since you haven‚Äôt made the user interface able to handle cases where an account has created a list, you will do so next [handling tasks](/build/guides/build-e2e-dapp/5-handle-tasks) in chapter 5.

# 5. Handle Tasks

> Complete the dapp by implementing task management functionality to fetch existing tasks and add new ones.

In the fifth and final chapter of the tutorial on [building an end-to-end dapp on Aptos](/build/guides/build-e2e-dapp), you will add functionality to the app so the user interface is able to handle cases where an account has created a list.

We have covered how to [fetch data](/build/guides/build-e2e-dapp/3-fetch-data-from-chain) (an account‚Äôs todo list) from chain and how to [submit a transaction](/build/guides/build-e2e-dapp/4-submit-data-to-chain) (new todo list) to chain using Wallet.

Let‚Äôs finish building our app by implementing fetch tasks and adding a task function.

## Fetch tasks

1. Create a local state `tasks` that will hold our tasks. It will be a state of a Task type (that has the same properties we set on our smart contract):

```typescript filename="App.tsx"
type Task = {
  address: string;
  completed: boolean;
  content: string;
  task_id: string;
};

function App() {
	const [tasks, setTasks] = useState<Task[]>([]);
	...
}
```

2. Update our `fetchList` function to fetch the tasks in the account‚Äôs `TodoList` resource:

```typescript filename="App.tsx"
const fetchList = async () => {
  if (!account) return [];
  try {
    const todoListResource = await aptosClient().getAccountResource({
      accountAddress:account?.address,
      resourceType:`${moduleAddress}::todolist::TodoList`
    });
    setAccountHasList(true);
		// tasks table handle
    const tableHandle = (todoListResource as any).tasks.handle;
		// tasks table counter
    const taskCounter = (todoListResource as any).task_counter;

    let tasks = [];
    let counter = 1;
    while (counter <= taskCounter) {
      const tableItem = {
        key_type: "u64",
        value_type: `${moduleAddress}::todolist::Task`,
        key: `${counter}`,
      };
      const task = await aptosClient().getTableItem<Task>({handle:tableHandle, data:tableItem});
      tasks.push(task);
      counter++;
    }
	  // set tasks in local state
    setTasks(tasks);
  } catch (e: any) {
    setAccountHasList(false);
  }
};
```

**This part is a bit confusing, so stick with us!**

Tasks are stored in a table (this is how we built our contract). To fetch a table item (i.e a task), we need that task's table handle. We also need the `task_counter` in that resource so we can loop over and fetch the task with the `task_id` that matches the `task_counter`.

```typescript filename="App.tsx"
const tableHandle = (TodoListResource as any).data.tasks.handle;
const taskCounter = (TodoListResource as any).data.task_counter;
```

Now that we have our tasks table handle and our `task_counter` variable, lets loop over the `taskCounter` . We define a `counter` and set it to 1 as the task\_counter / task\_id is never less than 1.

We loop while the `counter` is less then the `taskCounter` and fetch the table item and push it to the tasks array:

```typescript filename="App.tsx"
let tasks = [];
let counter = 1;
while (counter <= taskCounter) {
  const tableItem = {
    key_type: "u64",
    value_type: `${moduleAddress}::todolist::Task`,
    key: `${counter}`,
  };
  const task = await aptosClient().getTableItem(tableHandle, tableItem);
  tasks.push(task);
  counter++;
}
```

We build a `tableItem` object to fetch. If we take a look at our table structure from the contract:

```typescript filename="App.tsx"
tasks: Table<u64, Task>,
```

We see that it has a `key` type `u64` and a `value` of type `Task`. And whenever we create a new task, we assign the `key` to be the incremented task counter.

```move filename="todolist.move"
// adds the new task into the tasks table
table::upsert(&mut todo_list.tasks, counter, new_task);
```

So the object we built is:

```typescript filename="App.tsx"
{
  key_type: "u64",
  value_type:`${moduleAddress}::todolist::Task`,
  key: `${taskCounter}`,
}
```

Where `key_type` is the table `key` type, `key` is the key value we are looking for, and the `value_type` is the table `value` which is a `Task` struct. The Task struct uses the same format from our previous resource query:

- The account address who holds that module = our profile account address
- The module name the resource lives in = `todolist`
- The struct name = `Task`

The last thing we want to do is display the tasks we just fetched.

3. In our `App.tsx` file, update our UI with the following code:

Import the `Input` using `import { Input } from "./components/ui/input";`

```tsx filename="App.tsx"
{!accountHasList ? (
  <Button onClick={addNewList} disabled={transactionInProgress}>
    Add new list
  </Button>
) : (
  <div className="flex flex-col gap-10">
    {tasks &&
      tasks.length > 0 &&
      tasks.map((task) => (
        <div key={task.task_id} className="flex justify-between flex-row">
          <p className="text-xl font-bold">{task.content}</p>
          <div>
            <Input type="checkbox"/>
          </div>
        </div>
      ))}
  </div>
)}
```

That will display the **Add new list** button if account doesn‚Äôt have a list or instead the tasks if the account has a list.

Go ahead and refresh your browser - see the magic!

We haven‚Äôt added any tasks yet, so we dont see anything. Let‚Äôs add the option to add some tasks!

## Add task

1. Update our UI with an _add task_ input:

```tsx filename="App.tsx"
{!accountHasList ? (
  ...
) : (
  <div className="flex flex-col gap-10">
    // Add this!
    <div className="flex flex-row gap-10">
      <Input/>
      <Button>Add new task</Button>
    </div>
    ...
  </div>
  ...
)}
```

We have added a text input to write the task and a button to add the task.

2. Create a new local state that holds the task content:

```tsx filename="App.tsx"
function App() {
  ...
  const [newTask, setNewTask] = useState<string>("");
  ...
}
```

3. Find our `<Input/>` component, add the `onChange` event to it, pass it our `onWriteTask` function and set the input value to be the `newTask` local state:

```tsx filename="App.tsx"
<Input value={newTask} onChange={(e) => setNewTask(e.target.value)} />
```

Cool! Now we have a working flow that when the user types something on the Input component, a function will get fired and set our local state with that content.

4. Let‚Äôs also add a function that submits the typed task to chain! Find the `<Button>` component and update it with the following

```tsx filename="App.tsx"
<Button
  onClick={onTaskAdded} // add this
>
  Add new task
</Button>
```

That adds an `onClickevent` that triggers an `onTaskAdded` function.

When someones adds a new task we:

- want to verify they are connected with a wallet.
- build a transaction payload that would be submitted to chain.
- submit it to chain using our wallet.
- wait for the transaction.
- update our UI with that new task (without the need to refresh the page).

5. Add an `onTaskAdded` function with:

```tsx filename="App.tsx"
  const onTaskAdded = async () => {
    // check for connected account
    if (!account) return;
    setTransactionInProgress(true);
    const transaction: InputTransactionData = {
      data: {
        function: `${moduleAddress}::todolist::create_task`,
        functionArguments: [newTask],
      },
    };

    // hold the latest task.task_id from our local state
    const latestId = tasks.length > 0 ? parseInt(tasks[tasks.length - 1].task_id) + 1 : 1;

    // build a newTaskToPush object into our local state
    const newTaskToPush: Task = {
      address: account.address.toString(),
      completed: false,
      content: newTask,
      task_id: latestId + "",
    };

    try {
      // sign and submit transaction to chain
      const response = await signAndSubmitTransaction(transaction);
      // wait for transaction
      await aptosClient().waitForTransaction({ transactionHash: response.hash });

      // Create a new array based on current state:
      let newTasks = [...tasks];

      // Add item to the tasks array
      newTasks.push(newTaskToPush);
      // Set state
      setTasks(newTasks);
      // clear input text
      setNewTask("");
    } catch (error: any) {
      console.log("error", error);
    } finally {
      setTransactionInProgress(false);
    }
  };
```

**Let‚Äôs go over on what is happening.**

First, note we use the `account` property from our wallet provider to make sure there is an account connected to our app.

Then we build our transaction data to be submitted to chain:

```tsx filename="App.tsx"
const transaction:InputTransactionData = {
      data:{
        function:`${moduleAddress}::todolist::create_task`,
        functionArguments:[newTask]
      }
    }
```

- `function`- is built from the module address, module name and the function name.
- `functionArguments` - the arguments the function expects, in our case the task content.

Then, within our try/catch block, we use a wallet provider function to submit the transaction to chain and an SDK function to wait for that transaction.
If all goes well, we want to find the current latest task ID so we can add it to our current tasks state array. We will also create a new task to push to the current tasks state array (so we can display the new task in our tasks list on the UI without the need to refresh the page).

TRY IT!

Type a new task in the text input, click **Add**, approve the transaction and see it being added to the tasks list.

## Mark task as completed

Next, we can implement the `complete_task` function. We have the checkbox in our UI so users can mark a task as completed.

1. Update the `<Checkbox/>` component with an `onCheck` property that would call an `onCheckboxChange` function once it is checked:

```tsx filename="App.tsx"
 <Input type="checkbox" onChange={(event) => onCheckboxChange(event, task.task_id)} />
```

2. Create the `onCheckboxChange` function:

```tsx filename="App.tsx"
const onCheckboxChange = async (event: React.ChangeEvent<HTMLInputElement>, taskId: string) => {
    if (!account) return;
    if (!event.target.checked) return;
    setTransactionInProgress(true);
    const transaction: InputTransactionData = {
      data: {
        function: `${moduleAddress}::todolist::complete_task`,
        functionArguments: [taskId],
      },
    };

    try {
      // sign and submit transaction to chain
      const response = await signAndSubmitTransaction(transaction);
      // wait for transaction
      await aptosClient().waitForTransaction({ transactionHash: response.hash });

      setTasks((prevState) => {
        const newState = prevState.map((obj) => {
          // if task_id equals the checked taskId, update completed property
          if (obj.task_id === taskId) {
            return { ...obj, completed: true };
          }

          // otherwise return object as is
          return obj;
        });

        return newState;
      });
    } catch (error: any) {
      console.log("error", error);
    } finally {
      setTransactionInProgress(false);
    }
  };
```

Here we basically do the same thing we did when we created a new list or a new task.

We make sure there is an account connected, set the transaction in progress state, build the transaction payload, submit the transaction, wait for it and update the task on the UI as completed.

3. Update the `Checkbox` component to be checked by default if a task has already marked as completed:

```tsx filename="App.tsx"
...
actions={[
<div>
    {task.completed ? (
    <Input type="checkbox" checked={true} disabled />
    ) : (
    <Input type="checkbox" onChange={(event) => onCheckboxChange(event, task.task_id)} />
    )}
</div>,
]}
...
```

Try it! Check a task‚Äôs checkbox, approve the transaction and see the task marked as completed.

You have now learned how to build a dapp on Aptos from end to end. Congratulations! Tell your friends. :-)

# Exchange Integration Guide

> Comprehensive guide for integrating Aptos and its assets into cryptocurrency exchanges with balance tracking and testing.

import { Aside } from '@astrojs/starlight/components';

This describes how to integrate Aptos and Aptos assets into an exchange.  It provides
generic information for tracking balances, transferring assets, and testing the integration.

## Overview

This document will guide you through the following tasks to integrate with Aptos:

- Infrastructure
- Address standards
- Asset standards
- Retrieving balances
- Tracking balance changes
- Transferring assets
- Testing the integration

## Infrastructure

It's suggested that you run your own [full node](/network/nodes/full-node) to interact with the Aptos blockchain.
This will allow you to query the blockchain for the latest state and submit transactions.
You can also use the [Indexer](/build/indexer) to query for on-chain data efficiently.

## Address Standards

### Addresses

A single address can be represented in three ways.  We recommend you show all leading zeros, and the `0x`. Here is an example of all three representations for the framework address `0x1`:

- `0x00000000000000000000000000000001` - A full representation of 32-bytes in hex with a leading `0x`.  This is preferred.
- `0x1` - The short representation of the address with a leading `0x`. This is kept around for compatibility, but preferred with all leading 0s.
- `00000000000000000000000000000001` - A full representation of 32-bytes in hex without a leading `0x`. This is kept around for compatibility, but preferred with leading 0x.

For example SDKs will handle this parsing automatically, and we suggest you use the SDKs directly to handle it for you.

```typescript filename="example.ts"
import { AccountAddress } from "@aptos-labs/ts-sdk";
const address = AccountAddress.from("0x1");
address.toStringLong(); // 0x00000000000000000000000000000001
```

There is additionally, Aptos Name Service (ANS) for friendly .apt names.  For more information about addresses
and Aptos Names, see our page on [Accounts](/network/blockchain/accounts).

## Account Standards

Accounts must exist prior to sending a transaction to the blockchain.  This is done by creating an account resource, which can
be created by simply calling `0x1::aptos_account::transfer` with a zero amount to the account you want to create.  Optionally,
`0x1::aptos_account::create_account` can be used to create an account with a zero balance.

```typescript filename="example.ts"
import { Aptos, Ed25519Account, Ed25519PrivateKey } from "@aptos-labs/ts-sdk";

const aptos = new Aptos();
const account = new Ed25519Account({privateKey: new Ed25519PrivateKey("private key")})
const transaction = await aptos.transferCoinTransaction({sender: account.accountAddress, recipient: "receiver address", amount: 100000000})
const pendingTransaction = await aptos.transaction.signAndSubmitTransaction({signer: account, transaction})
const committedTransaction = await aptos.waitForTransaction({transactionHash: pendingTransaction.hash});
```

## Asset Standards

Aptos provides two standards for fungible tokens, similar to ERC-20 tokens on Ethereum:

- An earlier [Coin standard](/build/smart-contracts/aptos-coin) used by assets on Aptos.
- A newer [Fungible Asset Standard](/build/smart-contracts/fungible-asset) which is more featured.

Additionally, there is a migratory period for assets from Coin to Fungible Asset standards.
We will call this from now on **migrated coins**. Migrated coins may have two forms, but either
can be used interchangeably with Coin standards. This is important to note when querying balances, to
use coin functions and not fungible asset functions. The FA standard can only deal with the FA form.

<Aside type="note">
  APT, the native token of Aptos, is a migrated coin.  This means it can be used
  with both the Coin and Fungible Asset standards.
</Aside>

### Coin Standard (tl;dr)

A **coin** has an associated contract that holds the on-chain struct that represents the coin.  The coin is
represented as a struct name e.g. `0x1::aptos_coin::AptosCoin` for `APT`.

All coins are stored in an account resource called `0x1::coin::CoinStore<CoinType>`.  Coins must be registered
prior to using the `CoinStore`, but if using the proper functions e.g. `0x1::aptos_account::transfer`
or `0x1::aptos_account::transfer_coins<CoinType>`, this will be done automatically.

Coins can be _migrated_ to a fungible asset.  In order to support a migrated asset,
continue calling the coin functions as will be mentioned later.

More info can be found at: [Coin Standard](/build/smart-contracts/aptos-coin)

### Fungible Asset Standard (tl;dr)

A **fungible asset** has an associated metadata address that holds the metadata for the fungible asset.  This is commonly called the
fa metadata address.  The asset is represented as an address e.g. `0xA` for `APT`.

All fungible assets are stored in an `object`, which is called a `fungible asset store`.

For exchanges, the most important store is `primary_fungible_store`, which is the default store for fungible assets.
This is directly connected to an owner. From this point on in this guide, we will
only talk about supporting `primary_fungible_store` for fungible assets.

More info can be found at: [Fungible Asset Standard](/build/smart-contracts/fungible-asset)

## Retrieving Balances

Retrieving current balances for assets are different for each standard.  Integration is considered complete when it can handle both.

Balances are always returned in their subunits.  For example, `APT` is returned in `octas` (1e-8 APT).  So, when an API
returns a balance of `100000000`, this is `1 APT`. If it returns `100`, this is `0.000001 APT`.

### Coin (and migrated coins) Balances

<Aside type="note">
  Note: This includes APT and any other coin that was migrated to a fungible
  asset.  If the asset is a migrated coin, use this over fungible asset balance.  The
  fungible asset balance will not include the coin portion of the balance.
</Aside>

To retrieve the balance of a coin, or a coin that was migrated to a fungible asset, you can use
the `0x1::coin::balance<CoinType>(account address)` view function.  This will combine the coin and coin migrated to fungible asset balances.

```typescript filename="example.ts"
import { Aptos, AptosConfig, Network } from "@aptos-labs/ts-sdk";

const config = new AptosConfig({ network: Network.DEVNET });
const aptos = new Aptos(config);

const coinType = "0x1::aptos_coin::AptosCoin";
const account = "0x00000000000000000000000000000001";
const [balanceStr] = await aptos.view<[string]>({
  payload: {
    function: "0x1::coin::balance",
    typeArguments: [coinType],
    functionArguments: [account]
  }
});
const balance = parseInt(balanceStr, 10);
```

A specific ledger version (transaction height) can be provided to get the balance at that point in time.  The below example shows for ledger version `1,000,000`.

```typescript filename="example.ts"
import { Aptos, AptosConfig, Network } from "@aptos-labs/ts-sdk";

const config = new AptosConfig({ network: Network.DEVNET });
const aptos = new Aptos(config);

const coinType = "0x1::aptos_coin::AptosCoin";
const account = "0x00000000000000000000000000000001";
const [balanceStr] = await aptos.view<[string]>({
  payload: {
    function: "0x1::coin::balance",
    typeArguments: [coinType],
    functionArguments: [account],
    options: {
      ledgerVersion: 1_000_000
    }
  }
});
const balance = parseInt(balanceStr, 10);
```

### Fungible Asset Balances

To retrieve the balance of a fungible asset, you can use
the `0x1::primary_fungible_store::balance<0x1::object::ObjectCore>(account address, fungible asset metadata address)` view function.
Note, that this will not include the balance of coins if it's a migrated coin.

```typescript filename="example.ts"
import { Aptos, AptosConfig, Network } from "@aptos-labs/ts-sdk";

const config = new AptosConfig({ network: Network.DEVNET });
const aptos = new Aptos(config);

const faMetadataAddress = "0xA";
const account = "0x00000000000000000000000000000001";
const [balanceStr] = await aptos.view<[string]>({
  payload: {
    function: "0x1::primary_fungible_store::balance",
    typeArguments: ["0x1::object::ObjectCore"],
    functionArguments: [account, faMetadataAddress]
  }
});
const balance = parseInt(balanceStr, 10);
```

A specific ledger version (transaction height) can be provided to get the balance at that point in time.  The below example shows for ledger version `1,000,000`.

```typescript filename="example.ts"
import { Aptos, AptosConfig, Network } from "@aptos-labs/ts-sdk";

const config = new AptosConfig({ network: Network.DEVNET });
const aptos = new Aptos(config);

const faMetadataAddress = "0xA";
const account = "0x00000000000000000000000000000001";
const [balanceStr] = await aptos.view<[string]>({
  payload: {
    function: "0x1::primary_fungible_store::balance",
    typeArguments: ["0x1::object::ObjectCore"],
    functionArguments: [account, faMetadataAddress]
  },
  options: {
    ledgerVersion: 1_000_000
  }
});
const balance = parseInt(balanceStr, 10);
```

Besides SDK, you can also directly use aptos node's [balance API endpoint](/build/apis/fullnode-rest-api#tag/accounts/GET/accounts/\{address}/balance/\{asset_type}) to get the balance of a migrated coin or fungible asset.

## Tracking Balance Changes

Balance changes can be queried in one of two ways:

1. By watching for events that change the balance for each transaction.
2. By querying the indexer for indexed balance change events.

In the past, it was able to use the `events` endpoint for an account to get the
transactions that changed the balance.  This is still possible, but will be deprecated
in the future, and is not recommended for new integrations.

### Coin Balance Changes

Coin balances are tracked as two items, write set changes, and events.  Write set
changes are end state of the coin balance, and events are the events that are
emitted when a coin is withdrawn or deposited.

Here is an [example of a coin transfer](https://explorer.aptoslabs.com/txn/1747361321?network=mainnet).
The coin transfer can be tracked as an individual transaction
[here](https://fullnode.mainnet.aptoslabs.com/v1/transactions/by_version/1747361321)
from the REST API.

We'll break it down into a few parts:

1. The general transaction details tell information about the transaction.  The
   most important thing here is the transaction version is `1747361321`.  This gives
   us total order of all transactions on the blockchain. Think of it like block
   height, but for transactions.

<details>
  <summary>Transaction Details</summary>

  ```json
  {
    "version": "1747361321",
    "hash": "0x7c56ad56c7d02bb11887e535b9f1b221626d5b0d4cb5a1ffbadc358c1db515ea",
    "state_change_hash": "0xc901b5e9e0965201e8205977720d7dea8a3709ee0d818fd5ec752cac13eaf18a",
    "event_root_hash": "0x0077cb7df9db9ee7194c489db177fe9a325bcf3f1309ea99ed934085e5592041",
    "state_checkpoint_hash": null,
    "gas_used": "999",
    "success": true,
    "vm_status": "Executed successfully",
    "accumulator_root_hash": "0xb531e918441ff0a37b49856e0f1b80c329146461582287cf9788964d25e31a68",
  }
  ```
</details>

2. The Write set `changes` are the end state of the transaction.  It shows all
   resources that were modified by the transaction, and what it's final state was.

In this case, we only care about coin store changes.

<details>
  <summary>Coin Store Changes</summary>

  ```json
    "changes": [
    {
      "address": "0x559d4f690c683fca7c539237aa8dc4c6ec09886b7016bf66f2cdeffef55468f0",
      "state_key_hash": "0xb2bfa7198457291a0e582b912be2bf8577feff08e352c9f16935a55ebd202dcc",
      "data": {
        "type": "0x1::coin::CoinStore<0x1::aptos_coin::AptosCoin>",
        "data": {
          "coin": {
            "value": "903837250"
          },
          "deposit_events": {
            "counter": "10",
            "guid": {
              "id": {
                "addr": "0x559d4f690c683fca7c539237aa8dc4c6ec09886b7016bf66f2cdeffef55468f0",
                "creation_num": "2"
              }
            }
          },
          "frozen": false,
          "withdraw_events": {
            "counter": "52485",
            "guid": {
              "id": {
                "addr": "0x559d4f690c683fca7c539237aa8dc4c6ec09886b7016bf66f2cdeffef55468f0",
                "creation_num": "3"
              }
            }
          }
        }
      },
      "type": "write_resource"
    },
    {
      "address": "0x5d6233bb8d7f8bd714af196339e9fb3104c9d66f38867b2a0585c4f7b9d04d28",
      "state_key_hash": "0xa45b7cfe18cc0ef1d6588f0f548a6a6a260d5e6bbab174507ed40cd21b7bd082",
      "data": {
        "type": "0x1::coin::CoinStore<0x1::aptos_coin::AptosCoin>",
        "data": {
          "coin": {
            "value": "10"
          },
          "deposit_events": {
            "counter": "1",
            "guid": {
              "id": {
                "addr": "0x5d6233bb8d7f8bd714af196339e9fb3104c9d66f38867b2a0585c4f7b9d04d28",
                "creation_num": "2"
              }
            }
          },
          "frozen": false,
          "withdraw_events": {
            "counter": "0",
            "guid": {
              "id": {
                "addr": "0x5d6233bb8d7f8bd714af196339e9fb3104c9d66f38867b2a0585c4f7b9d04d28",
                "creation_num": "3"
              }
            }
          }
        }
      },
      "type": "write_resource"
    }],
  ```
</details>

3. Events are the events that were emitted by the transaction.  In this case, we
   only care about the `0x1::coin::Withdraw` and `0x1::coin::Deposit` events.

The Coin withdraw event is emitted when coins are withdrawn from an account. The
account's balance will decrease by that amount in the field `data.amount`.  To
determine the matching asset, you must match the `guid` in the `withdraw_events`
to the `guid` in the `changes` section for a `CoinStore`. But if the `CoinStore`
is not found in the `changes`, it means it got deleted, and a `CoinStoreDeleteEvent`
must be present instead. Then you can match the `guid` with
`deleted_withdraw_event_handle_creation_number` and `event_handle_creation_address`.

<details>
  <summary>Coin Withdraw Event</summary>

  ```json
  {
    "events": [
      {
        "guid": {
          "creation_number": "3",
          "account_address": "0xf8e25f6c8ce40a15107fb4b4d288ca03dd434d057392f2ccb5fde505a300a0bf"
        },
        "sequence_number": "0",
        "type": "0x1::coin::WithdrawEvent",
        "data": {
          "amount": "100000"
        }
      },
    ]
  }
  ```
</details>

<details>
  <summary>Coin Store Deletion Event</summary>

  ```json
  {
    "events": [
      {
        "guid": {
          "creation_number": "0",
          "account_address": "0x0"
        },
        "sequence_number": "0",
        "type": "0x1::coin::CoinStoreDeletion",
        "data": {
          "coin_type": "0x1::aptos_coin::AptosCoin",
          "deleted_deposit_event_handle_creation_number": "2",
          "deleted_withdraw_event_handle_creation_number": "3",
          "event_handle_creation_address": "0xf8e25f6c8ce40a15107fb4b4d288ca03dd434d057392f2ccb5fde505a300a0bf"
        }
      }
    ]
  }
  ```
</details>

The Coin deposit event is emitted when coins are deposited into an account. The
account's balance will increase by that amount in the field `data.amoount`.  To
determine the matching asset, you must match the `guid` in the `deposit_events`
to the `guid` in the `changes` section for a `CoinStore`. Similarly, if the `CoinStore`
is not found in the `changes`, it means it got deleted, and a `CoinStoreDeleteEvent`
must be present instead. Then you can match the `guid` with
`deleted_deposit_event_handle_creation_number` and `event_handle_creation_address`.

<details>
  <summary>Coin Deposit Event</summary>

  ```json
  {
    "events": [{
      "guid": {
        "creation_number": "2",
        "account_address": "0x5d6233bb8d7f8bd714af196339e9fb3104c9d66f38867b2a0585c4f7b9d04d28"
      },
      "sequence_number": "0",
      "type": "0x1::coin::DepositEvent",
      "data": {
        "amount": "10"
      }
    }]
  }
  ```
</details>

4. Gas usage only is tracked for APT.  There is no direct event for tracking gas,
   but it can be calculated from the transaction.  Using the `gas_used` field, and
   the `gas_unit_price` field, you can calculate the total gas used.  In this case,
   the `gas_used` is `999` and the `gas_unit_price` is `100`, so the total gas deducted
   from the sender(`0x559d4f690c683fca7c539237aa8dc4c6ec09886b7016bf66f2cdeffef55468f0`)
   is `999 * 100 = 99900 subunits`  Remember that the subunits are used here. The
   value in the gas token `APT` is `0.00099900 APT`.

<details>
  <summary>Gas Information</summary>

  ```json
   {
     "gas_used": "999",
     "max_gas_amount": "100000",
     "gas_unit_price": "100",
     "sender": "0x559d4f690c683fca7c539237aa8dc4c6ec09886b7016bf66f2cdeffef55468f0",
  }
  ```
</details>

5. Overall, you need both the events and the changes to determine the amount transferred
   of the account.  The final balances will show in the changes alone.  If you watch
   all of these events, you will be able to handle all possible transactions.  Below
   is the full example of the transaction response.

<details>
  <summary>Full Response</summary>

  ```json
  {
    "version": "1747361321",
    "hash": "0x7c56ad56c7d02bb11887e535b9f1b221626d5b0d4cb5a1ffbadc358c1db515ea",
    "state_change_hash": "0xc901b5e9e0965201e8205977720d7dea8a3709ee0d818fd5ec752cac13eaf18a",
    "event_root_hash": "0x0077cb7df9db9ee7194c489db177fe9a325bcf3f1309ea99ed934085e5592041",
    "state_checkpoint_hash": null,
    "gas_used": "999",
    "success": true,
    "vm_status": "Executed successfully",
    "accumulator_root_hash": "0xb531e918441ff0a37b49856e0f1b80c329146461582287cf9788964d25e31a68",
    "changes": [
  {
    "address": "0x559d4f690c683fca7c539237aa8dc4c6ec09886b7016bf66f2cdeffef55468f0",
    "state_key_hash": "0xb2bfa7198457291a0e582b912be2bf8577feff08e352c9f16935a55ebd202dcc",
    "data": {
    "type": "0x1::coin::CoinStore<0x1::aptos_coin::AptosCoin>",
    "data": {
    "coin": {
    "value": "903837250"
  },
    "deposit_events": {
    "counter": "10",
    "guid": {
    "id": {
    "addr": "0x559d4f690c683fca7c539237aa8dc4c6ec09886b7016bf66f2cdeffef55468f0",
    "creation_num": "2"
  }
  }
  },
    "frozen": false,
    "withdraw_events": {
    "counter": "52485",
    "guid": {
    "id": {
    "addr": "0x559d4f690c683fca7c539237aa8dc4c6ec09886b7016bf66f2cdeffef55468f0",
    "creation_num": "3"
  }
  }
  }
  }
  },
    "type": "write_resource"
  },
  {
    "address": "0x559d4f690c683fca7c539237aa8dc4c6ec09886b7016bf66f2cdeffef55468f0",
    "state_key_hash": "0xa3f2635d084b3cc01ae545c96ee15901549dab594363a46bf18e3d575c83102d",
    "data": {
    "type": "0x1::account::Account",
    "data": {
    "authentication_key": "0x559d4f690c683fca7c539237aa8dc4c6ec09886b7016bf66f2cdeffef55468f0",
    "coin_register_events": {
    "counter": "1",
    "guid": {
    "id": {
    "addr": "0x559d4f690c683fca7c539237aa8dc4c6ec09886b7016bf66f2cdeffef55468f0",
    "creation_num": "0"
  }
  }
  },
    "guid_creation_num": "4",
    "key_rotation_events": {
    "counter": "0",
    "guid": {
    "id": {
    "addr": "0x559d4f690c683fca7c539237aa8dc4c6ec09886b7016bf66f2cdeffef55468f0",
    "creation_num": "1"
  }
  }
  },
    "rotation_capability_offer": {
    "for": {
    "vec": []
  }
  },
    "sequence_number": "104628",
    "signer_capability_offer": {
    "for": {
    "vec": []
  }
  }
  }
  },
    "type": "write_resource"
  },
  {
    "address": "0x5d6233bb8d7f8bd714af196339e9fb3104c9d66f38867b2a0585c4f7b9d04d28",
    "state_key_hash": "0xa45b7cfe18cc0ef1d6588f0f548a6a6a260d5e6bbab174507ed40cd21b7bd082",
    "data": {
    "type": "0x1::coin::CoinStore<0x1::aptos_coin::AptosCoin>",
    "data": {
    "coin": {
    "value": "10"
  },
    "deposit_events": {
    "counter": "1",
    "guid": {
    "id": {
    "addr": "0x5d6233bb8d7f8bd714af196339e9fb3104c9d66f38867b2a0585c4f7b9d04d28",
    "creation_num": "2"
  }
  }
  },
    "frozen": false,
    "withdraw_events": {
    "counter": "0",
    "guid": {
    "id": {
    "addr": "0x5d6233bb8d7f8bd714af196339e9fb3104c9d66f38867b2a0585c4f7b9d04d28",
    "creation_num": "3"
  }
  }
  }
  }
  },
    "type": "write_resource"
  },
  {
    "address": "0x5d6233bb8d7f8bd714af196339e9fb3104c9d66f38867b2a0585c4f7b9d04d28",
    "state_key_hash": "0xba04f5a13812778031f67322e9801be65a846224e46f1360a6008402fcd0e0e0",
    "data": {
    "type": "0x1::account::Account",
    "data": {
    "authentication_key": "0x5d6233bb8d7f8bd714af196339e9fb3104c9d66f38867b2a0585c4f7b9d04d28",
    "coin_register_events": {
    "counter": "1",
    "guid": {
    "id": {
    "addr": "0x5d6233bb8d7f8bd714af196339e9fb3104c9d66f38867b2a0585c4f7b9d04d28",
    "creation_num": "0"
  }
  }
  },
    "guid_creation_num": "4",
    "key_rotation_events": {
    "counter": "0",
    "guid": {
    "id": {
    "addr": "0x5d6233bb8d7f8bd714af196339e9fb3104c9d66f38867b2a0585c4f7b9d04d28",
    "creation_num": "1"
  }
  }
  },
    "rotation_capability_offer": {
    "for": {
    "vec": []
  }
  },
    "sequence_number": "0",
    "signer_capability_offer": {
    "for": {
    "vec": []
  }
  }
  }
  },
    "type": "write_resource"
  },
  {
    "state_key_hash": "0x6e4b28d40f98a106a65163530924c0dcb40c1349d3aa915d108b4d6cfc1ddb19",
    "handle": "0x1b854694ae746cdbd8d44186ca4929b2b337df21d1c74633be19b2710552fdca",
    "key": "0x0619dc29a0aac8fa146714058e8dd6d2d0f3bdf5f6331907bf91f3acd81e6935",
    "value": "0x9f9835f429758d010000000000000000",
    "data": null,
    "type": "write_table_item"
  }
    ],
    "sender": "0x559d4f690c683fca7c539237aa8dc4c6ec09886b7016bf66f2cdeffef55468f0",
    "sequence_number": "104627",
    "max_gas_amount": "100000",
    "gas_unit_price": "100",
    "expiration_timestamp_secs": "1727826277",
    "payload": {
    "function": "0x1::aptos_account::transfer",
    "type_arguments": [],
    "arguments": [
    "0x5d6233bb8d7f8bd714af196339e9fb3104c9d66f38867b2a0585c4f7b9d04d28",
    "10"
    ],
    "type": "entry_function_payload"
  },
    "signature": {
    "public_key": "0xfd448fada2bac29c5f3213277e001ca8851d5644578e79484b0426c41357a457",
    "signature": "0x40d8a6ee9150aa5736bee23ce1b1b851790bc0aa7e2485c0760d5808027040a2ef4170b88962867b045197576c5e89a4c640bf43586e6b3ead2b510b59acc20a",
    "type": "ed25519_signature"
  },
    "events": [
  {
    "guid": {
    "creation_number": "0",
    "account_address": "0x5d6233bb8d7f8bd714af196339e9fb3104c9d66f38867b2a0585c4f7b9d04d28"
  },
    "sequence_number": "0",
    "type": "0x1::account::CoinRegisterEvent",
    "data": {
    "type_info": {
    "account_address": "0x1",
    "module_name": "0x6170746f735f636f696e",
    "struct_name": "0x4170746f73436f696e"
  }
  }
  },
  {
    "guid": {
    "creation_number": "3",
    "account_address": "0x559d4f690c683fca7c539237aa8dc4c6ec09886b7016bf66f2cdeffef55468f0"
  },
    "sequence_number": "52484",
    "type": "0x1::coin::WithdrawEvent",
    "data": {
    "amount": "10"
  }
  },
  {
    "guid": {
    "creation_number": "2",
    "account_address": "0x5d6233bb8d7f8bd714af196339e9fb3104c9d66f38867b2a0585c4f7b9d04d28"
  },
    "sequence_number": "0",
    "type": "0x1::coin::DepositEvent",
    "data": {
    "amount": "10"
  }
  },
  {
    "guid": {
    "creation_number": "0",
    "account_address": "0x0"
  },
    "sequence_number": "0",
    "type": "0x1::transaction_fee::FeeStatement",
    "data": {
    "execution_gas_units": "6",
    "io_gas_units": "5",
    "storage_fee_octas": "98800",
    "storage_fee_refund_octas": "0",
    "total_charge_gas_units": "999"
  }
  }
    ],
    "timestamp": "1727825677775812",
    "type": "user_transaction"
  }
  ```
</details>

### Fungible Asset Balance Changes

For fungible assets, the balance changes are tracked in the `primary_fungible_store`.
The primary fungible store address is deterministic, and will always be tracked by
the owner of the store.

An example: [https://api.mainnet.aptoslabs.com/v1/transactions/by\\\_version/1750174030](https://api.mainnet.aptoslabs.com/v1/transactions/by\\_version/1750174030)

There are a few steps when tracking fungible assets:

1. There will be two types of events for fungible assets.  `0x1::fungible_asset::Deposit` and `0x1::fungible_asset::Withdraw`.

`Withdraw` events are similar to the coin events, where the balance will decrease by the amount in the `data.amount` field.
And similarly `Deposit` events will increase the balance by the amount in the `data.amount` field.

Note that, I've omitted the sequence number, and GUID fields, as they do not apply to module events.

Each event has a `store` field, which in this case is `0x8a9d57692a9d4deb1680eaf107b83c152436e10f7bb521143fa403fa95ef76a`.
This is the address of the `FungibleStore` for the asset, where the balance is stored.  Note this, for the next step.

<details>
  <summary>Fungible Asset Events</summary>

  ```json
  {
    "events": [
      {
        "type": "0x1::fungible_asset::Withdraw",
        "data": {
          "amount": "1",
          "store": "0x8a9d57692a9d4deb1680eaf107b83c152436e10f7bb521143fa403fa95ef76a"
        }
      },
      {
        "type": "0x1::fungible_asset::Deposit",
        "data": {
          "amount": "1",
          "store": "0x8a9d57692a9d4deb1680eaf107b83c152436e10f7bb521143fa403fa95ef76a"
        }
      }
    ]
  }
  ```
</details>

2. Next, we take a look at the `0x1::fungible_asset::FungibleStore` changes.  This
   will show the end state of the balance for the fungible asset.  The balance is in
   the `data.balance` field.  The `address` field will match the `store` field from
   the events.  The identifier of the fungible asset, is the `metadata` field.  It
   is the address of the `metadata` for the fungible asset.

Additionally, to figure out the actual owner of the assets, you will need to look
at the owner of the store.  In this case, you will need the `0x1::object::ObjectCore`, where
the `address` field matches the `store` field from the events.  The `owner` field
will show the asset owner's address. similar to the coin events, if the `ObjectCore`
is not found in the `changes`, it means it got deleted, and a `FungibleStoreDeletion`
event must be present instead. Then you can match the `store` fields between the
`Withdraw`/`Deposit` events and the `FungibleStoreDeletion` event.

<details>
  <summary>Fungible Asset Changes</summary>

  ```json
  {
    "changes":[
      {
        "address": "0x8a9d57692a9d4deb1680eaf107b83c152436e10f7bb521143fa403fa95ef76a",
        "state_key_hash": "0x5b587931247dd5b43874ab29c3305c0ee7d26e7571fed3aea409375530e3a62c",
        "data": {
          "type": "0x1::fungible_asset::FungibleStore",
          "data": {
            "balance": "126691270443",
            "frozen": false,
            "metadata": {
              "inner": "0x2ebb2ccac5e027a87fa0e2e5f656a3a4238d6a48d93ec9b610d570fc0aa0df12"
            }
          }
        },
        "type": "write_resource"
      },
      {
        "address": "0x8a9d57692a9d4deb1680eaf107b83c152436e10f7bb521143fa403fa95ef76a",
        "state_key_hash": "0x5b587931247dd5b43874ab29c3305c0ee7d26e7571fed3aea409375530e3a62c",
        "data": {
          "type": "0x1::object::ObjectCore",
          "data": {
            "allow_ungated_transfer": false,
            "guid_creation_num": "1125899906842628",
            "owner": "0xc67545d6f3d36ed01efc9b28cbfd0c1ae326d5d262dd077a29539bcee0edce9e",
            "transfer_events": {
              "counter": "0",
              "guid": {
                "id": {
                  "addr": "0x8a9d57692a9d4deb1680eaf107b83c152436e10f7bb521143fa403fa95ef76a",
                  "creation_num": "1125899906842624"
                }
              }
            }
          }
        },
        "type": "write_resource"
      }
    ]
  }
  ```
</details>

<details>
  <summary>FungibleStore Deletion Event</summary>

  ```json
  {
    "guid": {
      "creation_number": "0",
      "account_address": "0x0"
    },
    "sequence_number": "0",
    "type": "0x1::fungible_asset::FungibleStoreDeletion",
    "data": {
      "metadata": "0x2ebb2ccac5e027a87fa0e2e5f656a3a4238d6a48d93ec9b610d570fc0aa0df12",
      "owner": "0xcf3906e2c9bc7e489c3b09d5ed5d90d8d403a68a50fe52932116b26e5878af26",
      "store": "0xa6ab8518e5f28a5f27247a895aa8b3de4a917209c6841b16187e8d64a67de242"
    }
  }
  ```
</details>

### Coins migrated to Fungible Asset Balance Changes

For coins migrated to fungible assets, it is just simply tracking of the two above.
A coin migrated to a fungible asset will have both the coin store changes and the
primary fungible asset store changes.  The amounts would need to be aggregated
together, and otherwise, handled as a coin.

The Fungible asset metadata address is the hash of the coin type and 0xA

```
address = sha3_256(0xA | coin_type | 0xFE)
```

Here is an example of a migrated coin with APT: [https://api.mainnet.aptoslabs.com/v1/transactions/by\\\_version/1642580695](https://api.mainnet.aptoslabs.com/v1/transactions/by\\_version/1642580695)

<details>
  <summary>Full response</summary>

  ```json
  {
    "version": "1642580695",
    "hash": "0xe67ba1c4242d5c1de42eb8419558c4edf2318e185a3940a00f4150b519d06508",
    "state_change_hash": "0x07c5ec97afdf731c2778fccb37fe209369b28dcf6dcf11c3cf13b83c962f7f96",
    "event_root_hash": "0xad349cbea90bef601dfae9df822f5698af296951fc5f94359fcacc1e69e9fa3d",
    "state_checkpoint_hash": null,
    "gas_used": "545",
    "success": true,
    "vm_status": "Executed successfully",
    "accumulator_root_hash": "0x88e81bde70f32a86e46b288a917a44b2868a46973fac7fad16b5e780f48b0e67",
    "changes": [
  {
    "address": "0xa",
    "state_key_hash": "0x1db5441d8fa4229c5844f73fd66da4ad8176cb8793d8b3a7f6ca858722030043",
    "data": {
    "type": "0x1::coin::PairedCoinType",
    "data": {
    "type": {
    "account_address": "0x1",
    "module_name": "0x6170746f735f636f696e",
    "struct_name": "0x4170746f73436f696e"
  }
  }
  },
    "type": "write_resource"
  },
  {
    "address": "0xa",
    "state_key_hash": "0x1db5441d8fa4229c5844f73fd66da4ad8176cb8793d8b3a7f6ca858722030043",
    "data": {
    "type": "0x1::coin::PairedFungibleAssetRefs",
    "data": {
    "burn_ref_opt": {
    "vec": [
  {
    "metadata": {
    "inner": "0xa"
  }
  }
    ]
  },
    "mint_ref_opt": {
    "vec": [
  {
    "metadata": {
    "inner": "0xa"
  }
  }
    ]
  },
    "transfer_ref_opt": {
    "vec": [
  {
    "metadata": {
    "inner": "0xa"
  }
  }
    ]
  }
  }
  },
    "type": "write_resource"
  },
  {
    "address": "0xa",
    "state_key_hash": "0x1db5441d8fa4229c5844f73fd66da4ad8176cb8793d8b3a7f6ca858722030043",
    "data": {
    "type": "0x1::fungible_asset::ConcurrentSupply",
    "data": {
    "current": {
    "max_value": "340282366920938463463374607431768211455",
    "value": "47948384"
  }
  }
  },
    "type": "write_resource"
  },
  {
    "address": "0xa",
    "state_key_hash": "0x1db5441d8fa4229c5844f73fd66da4ad8176cb8793d8b3a7f6ca858722030043",
    "data": {
    "type": "0x1::fungible_asset::Metadata",
    "data": {
    "decimals": 8,
    "icon_uri": "",
    "name": "Aptos Coin",
    "project_uri": "",
    "symbol": "APT"
  }
  },
    "type": "write_resource"
  },
  {
    "address": "0xa",
    "state_key_hash": "0x1db5441d8fa4229c5844f73fd66da4ad8176cb8793d8b3a7f6ca858722030043",
    "data": {
    "type": "0x1::object::ObjectCore",
    "data": {
    "allow_ungated_transfer": true,
    "guid_creation_num": "1125899906842625",
    "owner": "0x1",
    "transfer_events": {
    "counter": "0",
    "guid": {
    "id": {
    "addr": "0xa",
    "creation_num": "1125899906842624"
  }
  }
  }
  }
  },
    "type": "write_resource"
  },
  {
    "address": "0xa",
    "state_key_hash": "0x1db5441d8fa4229c5844f73fd66da4ad8176cb8793d8b3a7f6ca858722030043",
    "data": {
    "type": "0x1::primary_fungible_store::DeriveRefPod",
    "data": {
    "metadata_derive_ref": {
    "self": "0xa"
  }
  }
  },
    "type": "write_resource"
  },
  {
    "address": "0x7ed92ce166e251fc133f6b4d46a6b41307962e3b6864c2231110b3808648188",
    "state_key_hash": "0x5ce89e323a23fb5570694dfb687d474d44563638c5ef774a2364d8347f5732b8",
    "data": {
    "type": "0x1::coin::MigrationFlag",
    "data": {
    "dummy_field": false
  }
  },
    "type": "write_resource"
  },
  {
    "address": "0x7ed92ce166e251fc133f6b4d46a6b41307962e3b6864c2231110b3808648188",
    "state_key_hash": "0x5ce89e323a23fb5570694dfb687d474d44563638c5ef774a2364d8347f5732b8",
    "data": {
    "type": "0x1::fungible_asset::FungibleStore",
    "data": {
    "balance": "37949184",
    "frozen": false,
    "metadata": {
    "inner": "0xa"
  }
  }
  },
    "type": "write_resource"
  },
  {
    "address": "0x7ed92ce166e251fc133f6b4d46a6b41307962e3b6864c2231110b3808648188",
    "state_key_hash": "0x5ce89e323a23fb5570694dfb687d474d44563638c5ef774a2364d8347f5732b8",
    "data": {
    "type": "0x1::object::ObjectCore",
    "data": {
    "allow_ungated_transfer": false,
    "guid_creation_num": "1125899906842625",
    "owner": "0xa746e980ae21949a4f084db7403430f00bce3c9a1da4101ffcf0bf45ebd35e7e",
    "transfer_events": {
    "counter": "0",
    "guid": {
    "id": {
    "addr": "0x7ed92ce166e251fc133f6b4d46a6b41307962e3b6864c2231110b3808648188",
    "creation_num": "1125899906842624"
  }
  }
  }
  }
  },
    "type": "write_resource"
  },
  {
    "address": "0x8a4613c356c21a45045e06dcc404bfee363aabd65a774d4d43defd71289239b2",
    "state_key_hash": "0x7c2d6e31d4ac5bbf93e19412437c0c288766b240674f71f457b9e3ef68be5003",
    "data": {
    "type": "0x1::fungible_asset::FungibleStore",
    "data": {
    "balance": "10000",
    "frozen": false,
    "metadata": {
    "inner": "0xa"
  }
  }
  },
    "type": "write_resource"
  },
  {
    "address": "0x8a4613c356c21a45045e06dcc404bfee363aabd65a774d4d43defd71289239b2",
    "state_key_hash": "0x7c2d6e31d4ac5bbf93e19412437c0c288766b240674f71f457b9e3ef68be5003",
    "data": {
    "type": "0x1::object::ObjectCore",
    "data": {
    "allow_ungated_transfer": false,
    "guid_creation_num": "1125899906842625",
    "owner": "0x5",
    "transfer_events": {
    "counter": "0",
    "guid": {
    "id": {
    "addr": "0x8a4613c356c21a45045e06dcc404bfee363aabd65a774d4d43defd71289239b2",
    "creation_num": "1125899906842624"
  }
  }
  }
  }
  },
    "type": "write_resource"
  },
  {
    "address": "0xa746e980ae21949a4f084db7403430f00bce3c9a1da4101ffcf0bf45ebd35e7e",
    "state_key_hash": "0xfb7c1f2762da89f00a222f93bd771b478edb4361475c4a518178564be8616dd6",
    "data": {
    "type": "0x1::account::Account",
    "data": {
    "authentication_key": "0xa746e980ae21949a4f084db7403430f00bce3c9a1da4101ffcf0bf45ebd35e7e",
    "coin_register_events": {
    "counter": "14",
    "guid": {
    "id": {
    "addr": "0xa746e980ae21949a4f084db7403430f00bce3c9a1da4101ffcf0bf45ebd35e7e",
    "creation_num": "0"
  }
  }
  },
    "guid_creation_num": "44",
    "key_rotation_events": {
    "counter": "0",
    "guid": {
    "id": {
    "addr": "0xa746e980ae21949a4f084db7403430f00bce3c9a1da4101ffcf0bf45ebd35e7e",
    "creation_num": "1"
  }
  }
  },
    "rotation_capability_offer": {
    "for": {
    "vec": []
  }
  },
    "sequence_number": "52",
    "signer_capability_offer": {
    "for": {
    "vec": []
  }
  }
  }
  },
    "type": "write_resource"
  }
    ],
    "sender": "0xa746e980ae21949a4f084db7403430f00bce3c9a1da4101ffcf0bf45ebd35e7e",
    "sequence_number": "51",
    "max_gas_amount": "817",
    "gas_unit_price": "100",
    "expiration_timestamp_secs": "1724196316",
    "payload": {
    "function": "0x1::primary_fungible_store::transfer",
    "type_arguments": [
    "0x1::fungible_asset::Metadata"
    ],
    "arguments": [
  {
    "inner": "0xa"
  },
    "0x5",
    "10000"
    ],
    "type": "entry_function_payload"
  },
    "signature": {
    "public_key": "0x330e75a102e37270b788caee8dd819e5badedd5fa17fe9f72017732e9bb98c60",
    "signature": "0xd4666df2887cf2d8192230e4a03d842ea75a86ffbc46a9a16a9baede6ff646c6b2bcafc524d3a4a7a66c223b5db576beb5cfefbd549620e69097c0a364c7a800",
    "type": "ed25519_signature"
  },
    "events": [
  {
    "guid": {
    "creation_number": "0",
    "account_address": "0x0"
  },
    "sequence_number": "0",
    "type": "0x1::fungible_asset::Withdraw",
    "data": {
    "amount": "10000",
    "store": "0x7ed92ce166e251fc133f6b4d46a6b41307962e3b6864c2231110b3808648188"
  }
  },
  {
    "guid": {
    "creation_number": "0",
    "account_address": "0x0"
  },
    "sequence_number": "0",
    "type": "0x1::fungible_asset::Deposit",
    "data": {
    "amount": "10000",
    "store": "0x8a4613c356c21a45045e06dcc404bfee363aabd65a774d4d43defd71289239b2"
  }
  },
  {
    "guid": {
    "creation_number": "0",
    "account_address": "0x0"
  },
    "sequence_number": "0",
    "type": "0x1::fungible_asset::Withdraw",
    "data": {
    "amount": "54500",
    "store": "0x7ed92ce166e251fc133f6b4d46a6b41307962e3b6864c2231110b3808648188"
  }
  },
  {
    "guid": {
    "creation_number": "0",
    "account_address": "0x0"
  },
    "sequence_number": "0",
    "type": "0x1::transaction_fee::FeeStatement",
    "data": {
    "execution_gas_units": "6",
    "io_gas_units": "7",
    "storage_fee_octas": "53240",
    "storage_fee_refund_octas": "0",
    "total_charge_gas_units": "545"
  }
  }
    ],
    "timestamp": "1724196287102837",
    "type": "user_transaction"
  }
  ```
</details>

## Transferring Assets

### Coin (or migrated coin) Transfers

<Aside type="note">
  APT, the native token of Aptos, is a migrated coin.  Please use the `aptos_account::transfer` functions
  to transfer APT tokens.
</Aside>

We suggest you use `0x1::aptos_account::transfer_coins<CoinType>(receiver address, amount)` for transferring coins.  It will
register the coin if it hasn't been registered yet, and create the associated account if it hasn't been created yet.
This will continue to work with any coins that were migrated to a fungible asset, including APT.

Coins can be transferred in the following ways:

- [`0x1::aptos_account::transfer_coins<CoinType>(receiver address, amount)`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/aptos_account.move#L108-L112) - Transfer a coin to another account.
- [`0x1::aptos_account::batch_transfer_coins<CoinType>(receiver addresses, amounts)`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/aptos_account.move#L93-L106) - Transfer a coin to multiple accounts.
- [`0x1::aptos_account::transfer(receiver address, amount)`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/aptos_account.move#L74-L91) - Transfer specifically APT to another account.

{/* TODO examples */}

### Fungible Asset Transfers

We suggest you use `0x1::primary_fungible_store::transfer<0x1::object::ObjectCore>(receiver address, amount)` for transferring fungible assets.
It will send the associated fungible asset, and create a primary store for the asset if it hasn't been created yet.

{/* TODO examples */}

<Aside type="caution">
  Note: This will not create an account for the user if it hasn't been created
  yet. You will need to call
  `0x1::aptos_account::create_account(account address)` to create the account
  before the user can
  submit transactions.
</Aside>

{ /* TODO Staking some other day */ }

## Testing

In order to check that everything is working correctly, we've provided these checks.

### Balance Checks

To test balance checks, you can check the balance for the account `0x5` for the asset `0x1::aptos_coin::AptosCoin`.
The balance should show `0.002 APT`, where 0.001 APT is a coin, and 0.001 APT is a migrated coin (fungible asset).

If your balance is not correct, see [Coin and Migrated Coin Balances](#coin-and-migrated-coins-balances) for more information.

### Balance Change / Transfer Checks

#### Check Coin Transfer

To test a transfer, create a transaction to transfer 0.001 APT to another account.
The transaction should be successful, and the balance should be updated, where
the balance is 0.001 APT smaller and minus the gas cost associated.

#### Check Fungible Asset Transfer

To test a transfer, you can fund an account with the fungible asset here [https://test-token-faucet.vercel.app/](https://test-token-faucet.vercel.app/)
and then transfer the fungible asset to another account.  The balance should be updated
according to the change, and you should be able to track the mint on the website.

## Stablecoin Addresses

| Token Name           | Token Symbol | Token Address                                                                                                                                                                                                        | Source of Address                                                                          |
| -------------------- | ------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------ |
| Tether USD           | USDt         | [0x357b0b74bc833e95a115ad22604854d6b0fca151cecd94111770e5d6ffc9dc2b](https://explorer.aptoslabs.com/fungible_asset/0x357b0b74bc833e95a115ad22604854d6b0fca151cecd94111770e5d6ffc9dc2b?network=mainnet)               | [Aptos Foundation](https://aptosnetwork.com/currents/global-finance-moves-faster-on-aptos) |
| USDC                 | USDC         | [0xbae207659db88bea0cbead6da0ed00aac12edcdda169e591cd41c94180b46f3b](https://explorer.aptoslabs.com/fungible_asset/0xbae207659db88bea0cbead6da0ed00aac12edcdda169e591cd41c94180b46f3b?network=mainnet)               | [Circle](https://developers.circle.com/stablecoins/usdc-on-main-networks)                  |
| Ondo US Dollar Yield | USDY         | [0xcfea864b32833f157f042618bd845145256b1bf4c0da34a7013b76e42daa53cc::usdy::USDY](https://explorer.aptoslabs.com/coin/0xcfea864b32833f157f042618bd845145256b1bf4c0da34a7013b76e42daa53cc::usdy::USDY?network=mainnet) | [Ondo Finance](https://ondo.finance/usdy)                                                  |

## FAQ

### What is the finality of a transaction?

Aptos uses a BFT consensus algorithm, so transactions are finalized immediately
after committing to the blockchain.

### What is the transaction fee on a transaction?

Transaction fees are variable, but for most cases here are fixed.  Check out
[simulating transactions](/network/blockchain/gas-txn-fee#estimating-gas-consumption-via-simulation)
to get an idea of the fee.

# Your First Coin

> Create, deploy, and mint your own cryptocurrency (MoonCoin) on Aptos using Move smart contracts and multiple SDK options.

import { Aside, TabItem, Tabs } from '@astrojs/starlight/components';

This tutorial introduces how you can compile, deploy, and mint your own coin (as defined [here](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/coin.move)), named [MoonCoin](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/move-examples/moon_coin).

## Step 1: Pick an SDK

Install your preferred SDK from the below list:

- [TypeScript SDK](/build/sdks/ts-sdk)
- [Python SDK](/build/sdks/python-sdk)

***

## Step 2: Install the CLI

[Install the precompiled binary for the Aptos CLI](/build/cli).

***

## Step 3: Run the example

<Tabs>
  <TabItem label="TypeScript">
    Clone the `aptos-ts-sdk` repo and build it:

    ```shellscript filename="Terminal"
    git clone https://github.com/aptos-labs/aptos-ts-sdk.git
    cd aptos-ts-sdk
    pnpm install
    pnpm build
    ```

    Navigate to the TypeScript examples directory:

    ```shellscript filename="Terminal"
    cd examples/typescript/
    ```

    Install the necessary dependencies:

    ```shellscript filename="Terminal"
    pnpm install
    ```

    Run the TypeScript [`your_coin`](https://github.com/aptos-labs/aptos-ts-sdk/blob/main/examples/typescript/your_coin.ts) example:

    ```shellscript filename="Terminal"
    pnpm run your_coin
    ```

    The application will complete, printing:

    ```shellscript filename="Terminal"
    Bob's initial MoonCoin balance: 0.
    Alice mints herself 100 MoonCoin.
    Alice transfers 100 MoonCoin to Bob.
    Bob's updated MoonCoin balance: 100.
    ```
  </TabItem>

  <TabItem label="Python">
    Clone the `aptos-core` repo:

    ```shellscript filename="Terminal"
    git clone https://github.com/aptos-labs/aptos-core
    ```

    Navigate to the Python SDK directory:

    ```shellscript filename="Terminal"
    cd aptos-core/ecosystem/python/sdk
    ```

    Install the necessary dependencies:

    ```shellscript filename="Terminal"
    curl -sSL https://install.python-poetry.org | python3
    poetry install
    ```

    Run the Python [`your_coin`](https://github.com/aptos-labs/aptos-python-sdk/blob/main/examples/your_coin.py) example:

    ```shellscript filename="Terminal"
    poetry run python -m examples.your_coin ~/aptos-core/aptos-move/move-examples/moon_coin
    ```

    ### Step 3.1: Build the package

    The example run will pause with the following output:

    ```shellscript filename="Terminal"
    === Addresses ===
    Alice: 0x5e603a89cf690d7134cf2f24fdb16ba90c4f5686333721c12e835fb6c76bc7ba
    Bob: 0xc8421fa4a99153f955e50f1de2a6acff2f3fd0bb33aa17ba1f5b32b699f6c825

    Update the package with Alice's address, compile, and press enter.
    ```

    At this point, open another terminal and change directories to the MoonCoin package's directory:

    ```shellscript filename="Terminal"
    cd ~/aptos-core/aptos-move/move-examples/moon_coin
    ```

    Next, build the package using the CLI:

    ```shellscript filename="Terminal"
    aptos move compile --named-addresses MoonCoin=0x5e603a89cf690d7134cf2f24fdb16ba90c4f5686333721c12e835fb6c76bc7ba --save-metadata
    ```

    The `--named-addresses` is a list of address mappings that must be translated in order for the package to be compiled to be stored in Alice's account. Notice how `MoonCoin` is set to Alice's address printed above. Also `--save-metadata` is required to publish the package.

    ***

    ### Step 3.2: Completing the example

    Returning to the previous prompt, press ENTER as the package is now ready to be published.

    The application will complete, printing:

    ```shellscript filename="Terminal"

    Publishing MoonCoin package.

    Bob registers the newly created coin so he can receive it from Alice.
    Bob's initial MoonCoin balance: 0.
    Alice mints Bob some of the new coin.
    Bob's updated MoonCoin balance: 100.
    ```
  </TabItem>
</Tabs>

***

## Step 4: MoonCoin in depth

### Step 4.1: Building and publishing the MoonCoin package

Move contracts are effectively a set of Move modules known as a package. When deploying or upgrading a new package, the compiler must be invoked with `--save-metadata` to publish the package. In the case of MoonCoin, the following output files are critical:

- `build/Examples/package-metadata.bcs`: Contains the metadata associated with the package.
- `build/Examples/bytecode_modules/moon_coin.mv`: Contains the bytecode for the `moon_coin.move` module.

These are read by the example and published to the Aptos blockchain:

<Tabs>
  <TabItem label="TypeScript">
    In the TypeScript example, we use `aptos move build-publish-payload` command to compile and build the module.
    That command builds the `build` folder that contains the `package-metadata.bcs` and the bytecode for the `moon_coin.mv` module. The command also builds a publication transaction payload and stores it in a JSON output file that we can later read from to get the `metadataBytes` and `byteCode` to publish the contract to chain with.

    Compile the package:

    ```typescript filename="example.ts"
    export function compilePackage(
      packageDir: string,
      outputFile: string,
      namedAddresses: Array<{ name: string; address: AccountAddress }>,
    ) {
      const addressArg = namedAddresses
        .map(({ name, address }) => `${name}=${address}`)
        .join(" ");
      // Assume-yes automatically overwrites the previous compiled version, only do this if you are sure you want to overwrite the previous version.
      const compileCommand = `aptos move build-publish-payload --json-output-file ${outputFile} --package-dir ${packageDir} --named-addresses ${addressArg} --assume-yes`;
      execSync(compileCommand);
    }

    compilePackage("move/moonCoin", "move/moonCoin/moonCoin.json", [
      { name: "MoonCoin", address: alice.accountAddress },
    ]);
    ```

    Publish the package to chain:

    ```typescript filename="example.ts"
    export function getPackageBytesToPublish(filePath: string) {
      // current working directory - the root folder of this repo
      const cwd = process.cwd();
      // target directory - current working directory + filePath (filePath JSON file is generated with the previous, compilePackage, CLI command)
      const modulePath = path.join(cwd, filePath);

      const jsonData = JSON.parse(fs.readFileSync(modulePath, "utf8"));

      const metadataBytes = jsonData.args[0].value;
      const byteCode = jsonData.args[1].value;

      return { metadataBytes, byteCode };
    }

    const { metadataBytes, byteCode } = getPackageBytesToPublish(
      "move/moonCoin/moonCoin.json",
    );

    // Publish MoonCoin package to chain
    const transaction = await aptos.publishPackageTransaction({
      account: alice.accountAddress,
      metadataBytes,
      moduleBytecode: byteCode,
    });

    const pendingTransaction = await aptos.signAndSubmitTransaction({
      signer: alice,
      transaction,
    });

    await aptos.waitForTransaction({ transactionHash: pendingTransaction.hash });
    ```
  </TabItem>

  <TabItem label="Python">
    ```python filename="example.py"
    module_path = os.path.join(
        moon_coin_path, "build", "Examples", "bytecode_modules", "moon_coin.mv"
    )
    with open(module_path, "rb") as f:
        module = f.read()

    metadata_path = os.path.join(
        moon_coin_path, "build", "Examples", "package-metadata.bcs"
    )
    with open(metadata_path, "rb") as f:
        metadata = f.read()

    print("\nPublishing MoonCoin package.")
    package_publisher = PackagePublisher(rest_client)
    txn_hash = await package_publisher.publish_package(alice, metadata, [module])
    await rest_client.wait_for_transaction(txn_hash)
    ```
  </TabItem>
</Tabs>

***

### Step 4.2: Understanding the MoonCoin module

The MoonCoin module defines the `MoonCoin` struct, or the distinct type of coin type. In addition, it contains a function called `init_module`. The `init_module` function is called when the module is published. In this case, MoonCoin initializes the `MoonCoin` coin type as a `ManagedCoin`, which is maintained by the owner of the account.

<Aside type="note">
  ManagedCoin framework
  [`ManagedCoin`](https://github.com/aptos-labs/aptos-core/blob/f81ccb01f00227f9c0f36856fead4879f185a9f6/aptos-move/framework/aptos-framework/sources/managed_coin.move#L1) is a simple coin management framework for coins directly managed by users. It provides convenience wrappers around `mint` and `burn`.
</Aside>

```move filename="moon_coin.mv"
module MoonCoin::moon_coin {
    struct MoonCoin {}

    fun init_module(sender: &signer) {
        aptos_framework::managed_coin::initialize<MoonCoin>(
            sender,
            b"Moon Coin",
            b"MOON",
            6,
            false,
        );
    }
}
```

***

### Step 4.3: Understanding coins

Coins have several primitives:

- **Minting**: Creating new coins.
- **Burning**: Deleting coins.
- **Freezing**: Preventing an account from storing coins in `CoinStore`.
- **Registering**: Creating a `CoinStore` resource on an account for storing coins.
- **Transferring**: Withdrawing and depositing coins into `CoinStore`.

<Aside type="note">
  The entity that creates a new coin gains the capabilities for minting, burning, and freezing.
</Aside>

***

#### Step 4.3.1: Initializing a coin

Once a coin type has been published to the Aptos blockchain, the entity that published that coin type can initialize it:

```move
module 0x1::coin {
    public fun initialize<CoinType>(
        account: &signer,
        name: string::String,
        symbol: string::String,
        decimals: u8,
        monitor_supply: bool,
    ): (BurnCapability<CoinType>, FreezeCapability<CoinType>, MintCapability<CoinType>) {
        let account_addr = signer::address_of(account);

        assert!(
            coin_address<CoinType>() == account_addr,
            error::invalid_argument(ECOIN_INFO_ADDRESS_MISMATCH),
        );

        assert!(
            !exists<CoinInfo<CoinType>>(account_addr),
            error::already_exists(ECOIN_INFO_ALREADY_PUBLISHED),
        );

        let coin_info = CoinInfo<CoinType> {
            name,
            symbol,
            decimals,
            supply: if (monitor_supply) { option::some(optional_aggregator::new(MAX_U128, false)) } else { option::none() },
        };
        move_to(account, coin_info);

        (BurnCapability<CoinType>{ }, FreezeCapability<CoinType>{ }, MintCapability<CoinType>{ })
  }
}
```

This ensures that this coin type has never been initialized before. Notice the check on lines 10 and 15 to ensure that the caller to `initialize` is the same one that actually published this module, and that there is no `CoinInfo` stored on their account. If both those conditions check, then a `CoinInfo` is stored and the caller obtains capabilities for burning, freezing, and minting.

<Aside type="note">
  MoonCoin calls this `initialize` function automatically upon package publishing.
</Aside>

***

#### Step 4.3.2: Registering a coin

To use a coin, an entity must register a `CoinStore` for it on their account:

```move
public entry fun registerCoinType(account: &signer) {
```

MoonCoin uses `ManagedCoin` that provides an entry function wrapper: `managed_coin::register`. Here is an example script for registration:

```move
script {
    fun register(account: &signer) {
        aptos_framework::managed_coin::register<MoonCoin::moon_coin::MoonCoin>(account)
    }
}
```

***

#### Step 4.3.3: Minting a coin

Minting coins requires the mint capability that was produced during initialization. the function `mint` (see below) takes in that capability and an amount, and returns back a `Coin<T>` struct containing that amount of coins. If the coin tracks supply, it will be updated.

```move
module 0x1::coin {
    public fun mint<CoinType>(
        amount: u64,
        _cap: &MintCapability<CoinType>,
    ): Coin<CoinType> acquires CoinInfo {
        if (amount == 0) {
            return zero<CoinType>()
        };

        let maybe_supply = &mut borrow_global_mut<CoinInfo<CoinType>>(coin_address<CoinType>()).supply;
        if (option::is_some(maybe_supply)) {
            let supply = option::borrow_mut(maybe_supply);
            optional_aggregator::add(supply, (amount as u128));
        };

        Coin<CoinType> { value: amount }
    }
}
```

`ManagedCoin` makes this easier by providing an entry function `managed_coin::mint`.

***

#### Step 4.3.4: Transferring a coin

Aptos provides several building blocks to support coin transfers:

- `coin::deposit<CoinType>`: Allows any entity to deposit a coin into an account that has already called `coin::register<CoinType>`.
- `coin::withdraw<CoinType>`: Allows any entity to extract a coin amount from their account.
- `aptos_account::transfer_coins<CoinType>`: Transfer coins of specific CoinType to a receiver.

<Aside type="note">
  There are two separate withdraw and deposit events instead of a single transfer event.
</Aside>

## Supporting documentation

- [Aptos CLI](/build/cli)
- [TypeScript SDK](/build/sdks/ts-sdk)
- [Python SDK](/build/sdks/python-sdk)
- [REST API specification](/rest-api)

# Your First Fungible Asset

> Build and deploy FACoin using the Fungible Asset Standard with built-in minting, transferring, and balance tracking capabilities.

import { Aside, Steps } from '@astrojs/starlight/components';

This tutorial will teach you how to create your own Fungible Asset (FA) named [FACoin](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/move-examples/fungible_asset/fa_coin). The [Fungible Asset Standard](/build/smart-contracts/fungible-asset) provides built-in support for minting, transferring, burning, and tracking account balances, so is useful for representing fungible assets. We will use the [TypeScript SDK](/build/sdks/ts-sdk) to deploy the contract and test it once it is on-chain.

At a high level, the Fungible Asset Standard works through two main Objects:

1. A `Metadata` Object to store information about the fungible asset.
2. `FungibleStore`s for each account that has the fungible asset to track their current account balance.

Sending a fungible asset to someone will cause them to receive a `FungibleStore` and update the balances in both accounts accordingly.

## Seeing Fungible Assets In Action

Here we will modify, deploy, and test the example [FACoin](https://github.com/aptos-labs/aptos-ts-sdk/blob/main/examples/typescript/move/facoin/sources/fa_coin.move) contract to see how the Fungible Asset Standard works. If you are writing your own fungible asset contract, you may also want to reference the Stablecoin example contract [here](https://learn.aptoslabs.com/en/code-examples/stablecoin).

<Steps>
  1. Install the [Aptos CLI](/build/cli)

     This will be used by the deploy scripts to publish the `FACoin` contract onchain.

  2. Clone the TypeScript SDK repo.

     This repo contains the Fungible Asset example code.

     ```shellscript filename="Terminal"
     git clone https://github.com/aptos-labs/aptos-ts-sdk.git
     ```

  3. Navigate to the top-level of the cloned repository.

     ```shellscript filename="Terminal"
     cd aptos-ts-sdk
     ```

  4. Install the SDKs dependencies.

     ```shellscript filename="Terminal"
     pnpm install
     ```

  5. Build the TypeScript SDK.

     The example requires the local build of the TypeScript SDK.

     ```shellscript filename="Terminal"
     pnpm build
     ```

  6. Open fa\_coin.move in an editor.

     You can find `fa_coin.move` at `examples/typescript/move/facoin/sources/fa_coin.move`.

     This is the Move file which contains the bulk of the contract logic. We will dive into the details of how this contract works after showing you an example of it in action.

  7. Edit the ASSET\_NAME to be the name of your new fungible asset.

     Ex. ‚ÄúTutorial Token‚Äù. The values you set here will show up in the deployed contract and when we are testing how things work.

  8. Navigate to examples/typescript.

     ```shellscript filename="Terminal"
     cd examples/typescript
     ```

  9. Install the dependencies for the examples.

     ```shellscript filename="Terminal"
     pnpm install
     ```

  10. Run your\_fungible\_asset.

      ```shellscript filename="Terminal"
      pnpm run your_fungible_asset
      ```

      You should see an output demonstrating how the fungible assets are created and transferred that looks like this:

      ```shellscript filename="Terminal"
      === Addresses ===
      Alice: 0xca2f64c81ea9ab92c1d8686950aaef0fd5a050b7c7d3bd48f63739b9c0ff565f
      Bob: 0x66f8bbe6c76ce6eadf0b4544b8fd9bbf5f44b2f3905ee4edeab41e4b07cfc74c
      Charlie: 0xc25829d44511842b5f60bbf3f198c847fbad731a05e6125aa876f8f91e5d042b

      === Compiling FACoin package locally ===
      In order to run compilation, you must have the `aptos` CLI installed.
      Running the compilation locally, in a real situation you may want to compile this ahead of time.
      aptos move build-publish-payload --json-output-file move/facoin/facoin.json --package-dir move/facoin --named-addresses FACoin=0xca2f64c81ea9ab92c1d8686950aaef0fd5a050b7c7d3bd48f63739b9c0ff565f --assume-yes
      Compiling, may take a little while to download git dependencies...
      UPDATING GIT DEPENDENCY https://github.com/aptos-labs/aptos-core.git
      INCLUDING DEPENDENCY AptosFramework
      INCLUDING DEPENDENCY AptosStdlib
      INCLUDING DEPENDENCY MoveStdlib
      BUILDING facoin

      ===Publishing FACoin package===
      Transaction hash: 0xacd2af8920731caa0e9873c25d380ecc1f289193b407fea8f42313d28cf01df2
      metadata address: 0xa0104ba8146b45bdaf1692c4e28aa7189cbb9ffb41523e025aab1a1600f4e331
      All the balances in this example refer to balance in primary fungible stores of each account.
      Alice's initial FACoin balance: 0
      Bob's initial FACoin balance: 0
      Charlie's initial balance: 0
      Alice mints Charlie 100 coins.
      Charlie's updated FACoin primary fungible store balance: 100
      Alice freezes Bob's account.
      Alice as the admin forcefully transfers the newly minted coins of Charlie to Bob ignoring that Bob's account is frozen.
      Bob's updated FACoin balance: 100
      Alice unfreezes Bob's account.
      Alice burns 50 coins from Bob.
      Bob's updated FACoin balance: 50
      Bob transfers 10 coins to Alice as the owner.
      Alice's updated FACoin balance: 10
      Bob's updated FACoin balance: 40
      done.
      ```
</Steps>

<Aside type="note">
  If you change the name of the token in the `fa_coin.move` contract you will see the output update with that name.
</Aside>

## Understanding the `fa_coin.move` Example Contract

The full contract for FACoin.move can be found [here](https://github.com/aptos-labs/aptos-ts-sdk/blob/main/examples/typescript/move/facoin/sources/fa_coin.move).

Let‚Äôs go step by step through how this contract is written.

<Steps>
  1. Move.toml

     The Move.toml file allows Move to import dependencies, determine which addresses to use, and includes metadata about the contract.

     Regardless of which features you add to your fungible asset, your Move.toml will likely have similar fields to this at a minimum. In this case, we have the primary contract address `FACoin` that needs specifying at deploy time (indicated by leaving the value as ‚Äú\_‚Äù). It also includes the GitHub dependency to import the Fungible Asset standard from ‚ÄúAptosFramework‚Äù.

     ```toml filename="Move.toml"
     [package]
     name = "facoin"
     version = "1.0.0"
     authors = []

     [addresses]
     FACoin = "_"

     [dependencies.AptosFramework]
     git = "https://github.com/aptos-labs/aptos-core.git"
     rev = "mainnet"
     subdir = "aptos-move/framework/aptos-framework"
     ```

  2. Imports

     The FACoin module uses several important modules:

     1. `fungible_asset` contains the logic for granting permission to mint, transfer, burn, and create your FungibleAsset.
     2. `object` allows for creating Aptos Objects.
     3. `primary_fungible_store` contains the logic to track account balances for the new Fungible Asset.

     ```move filename="fa_coin.move"
     module FACoin::fa_coin {
         use aptos_framework::fungible_asset::{Self, MintRef, TransferRef, BurnRef, Metadata, FungibleAsset};
         use aptos_framework::object::{Self, Object};
         use aptos_framework::primary_fungible_store;
         use std::error;
         use std::signer;
         use std::string::utf8;
         use std::option;
         use std::string;
     		//...
     }
     ```

     These imports are defined in the `Move.toml` file as GitHub dependencies.

  3. init\_module

     This function is called when the module is initially published in order to set up the proper permissions and Objects. For FACoin, this is used to initialize the asset‚Äôs `MetaData` Object (which contains things like the asset‚Äôs name and symbol), as well as getting the relevant ref‚Äôs for how our fungible asset will be used.

     The `ManagedFungibleAsset` standard helps keep track of which permissions this Module is allowed to use.

     ```move filename="fa_coin.move"
      fun init_module(admin: &signer) {
         let constructor_ref = &object::create_named_object(admin, ASSET_SYMBOL);
         primary_fungible_store::create_primary_store_enabled_fungible_asset(
               constructor_ref,
               option::none(),
               utf8(ASSET_NAME), /* name */
               utf8(ASSET_SYMBOL), /* symbol */
               8, /* decimals */
               utf8(b"http://example.com/favicon.ico"), /* icon */
               utf8(b"http://example.com"), /* project */
         );

         let mint_ref = fungible_asset::generate_mint_ref(constructor_ref);
         let burn_ref = fungible_asset::generate_burn_ref(constructor_ref);
         let transfer_ref = fungible_asset::generate_transfer_ref(constructor_ref);
         let metadata_object_signer = object::generate_signer(constructor_ref);
         move_to(
               &metadata_object_signer,
               ManagedFungibleAsset { mint_ref, transfer_ref, burn_ref }
         )
      }
     ```

  4. View Functions

     When creating your own fungible asset, it can be helpful to add view functions for any data that is needed later on. In this case, we wanted to see the name of the asset in order to report which asset was being traded in our example scenario.

     ```move filename="fa_coin.move"
     #[view]
     public fun get_metadata(): Object<Metadata> {
         let asset_address = object::create_object_address(&@FACoin, ASSET_SYMBOL);
         object::address_to_object<Metadata>(asset_address)
     }

     #[view]
     public fun get_name(): string::String {
         let metadata = get_metadata();
         fungible_asset::name(metadata)
     }
     ```

  5. Entry Functions

     Every fungible asset has a similar interface (mint, transfer, burn, freeze, unfreeze, deposit, and withdraw). Here‚Äôs an example of a minimal mint function, which mints and transfers the funds to the proper recipient:

     ```move filename="fa_coin.move"
      public entry fun mint(admin: &signer, to: address, amount: u64) acquires ManagedFungibleAsset {
         let asset = get_metadata();
         let managed_fungible_asset = authorized_borrow_refs(admin, asset);
         let to_wallet = primary_fungible_store::ensure_primary_store_exists(to, asset);
         let fa = fungible_asset::mint(&managed_fungible_asset.mint_ref, amount);
         fungible_asset::deposit_with_ref(&managed_fungible_asset.transfer_ref, to_wallet, fa);
      }
     ```
</Steps>

## Summary

If you want to build your own Fungible Asset, you can use [`fa_coin.move`](https://github.com/aptos-labs/aptos-ts-sdk/tree/main/examples/typescript/move/facoin) as a starting point, or look to other code examples [here](https://learn.aptoslabs.com/en/code-examples).

Regardless, the Fungible Asset Standard will help you mint, transfer, burn, and keep track of balances automatically for whichever fungible assets you want to represent on-chain.

You can find the [Move reference for Fungible Assets](/move-reference/mainnet/aptos-framework/fungible_asset) for more details on the function signatures and implementation details.

# Your First Move Module

> Learn to compile, test, publish, and interact with Move smart contracts on Aptos blockchain from setup to deployment.

import { Aside, Steps } from '@astrojs/starlight/components';

The Aptos blockchain allows developers to write Turing complete smart contracts (called ‚Äúmodules‚Äù) with the secure-by-design Move language. Smart contracts enable users to send money with the blockchain, but also write arbitrary code, even games! It all starts with the Aptos CLI creating an account which will store the deployed (‚Äùpublished‚Äù) Move module.

This tutorial will help you understand Move Modules by guiding you through setting up a minimal Aptos environment, then how to compile, test, publish and interact with Move modules on the Aptos Blockchain. You will learn how to:

1. Setup your environment, install the CLI
2. Create a devnet account and fund it
3. Compile and test a Move module
4. Publish (or "deploy") a Move module to the Aptos blockchain
5. Interact with the module
6. Keep building with Aptos (next steps)

<Aside type="note">
  This tutorial is not meant to teach you the fundamentals of Move. That is a longer topic best learned through the [Move Book](/build/smart-contracts/book).
</Aside>

## 1. Setup

Changes to the blockchain are called ‚Äútransactions‚Äù, and they require an account to pay the network fee (‚Äùgas fee‚Äù). We will need to create an account with some APT to pay that fee and own the published contract. In order to do that, we will need to use the Aptos CLI.

<Steps>
  1. Install the Aptos CLI

     [Install the Aptos CLI](/build/cli) (if you haven't already).

  2. Open a new terminal

     Open a new terminal window or tab.

  3. Verify the installation

     Run `aptos --version` to verify you have it installed.

     ```shellscript filename="Terminal"
     aptos --version
     ```

     You should see a response like `aptos 4.6.1`.

  4. Create a project folder

     Create a new folder for this tutorial by running:

     ```shellscript filename="Terminal"
     mkdir my-first-module
     ```

  5. Navigate to the project folder

     Run `cd my-first-module` to go into your new folder.

  6. Initialize your account

     Run `aptos init` and press 'enter' for each step of setup to create a test account on `devnet`.

     <Aside type="note">
       As we are configuring your Aptos CLI for this folder, notice that this setup follows the logic of the blockchain itself:

       1. Which network are we working with (default `devnet`, which refreshes every week)?
       2. What is the account we are transacting from (creating a unique private key, which in turn generates a cryptographic public key and account address)?
       3. How do I pay for "gas"? (For devnet, testnet, and local networks, the Aptos CLI will helpfully fund this account with Aptos Coin, APT).

       For now, just press 'enter' repeatedly to accept all the defaults.
     </Aside>

     You should see a success message like this:

     ```shellscript filename="Terminal"
     ---
     Aptos CLI is now set up for account 0x9ec1cfa30b885a5c9d595f32f3381ec16d208734913b587be9e210f60be9f9ba as profile default!
     {
       "Result": "Success"
     }
     ```

     <Aside type="note">
       What you might not have noticed is that the Aptos CLI has created a new hidden folder `.aptos/` with a `.gitignore` and `config.yaml` which contains the account information, including private key, public key, and account address.

       You can view hidden files with `ls -a` in Unix/Mac terminal or `dir /ah` in Windows.
     </Aside>
</Steps>

## 2. (Optional) Explore What You Just Did On-Chain

<Steps>
  1. Copy your account address

     Copy the address from the command line for your new account.

     The address looks like this `0x9ec1cfa30b885a5c9d595f32f3381ec16d208734913b587be9e210f60be9f9ba` and you can find it in the line:

     ```shellscript filename="Terminal"
     Aptos CLI is now set up for account 0x9ec1cfa30b885a5c9d595f32f3381ec16d208734913b587be9e210f60be9f9ba as profile default!
     ```

  2. Open the Aptos Explorer

     Go to the [Aptos Explorer](https://explorer.aptoslabs.com/?network=devnet).

     This is the primary way to quickly check what is happening on devnet, testnet, or mainnet. We will use it later on to view our deployed contracts.

  3. Ensure you are on Devnet network.

     Look for ‚ÄúDevnet" in the top right corner, or switch networks by clicking the ‚ÄúMainnet‚Äù dropdown and selecting Devnet

     ![Switching to Devnet network in Aptos Explorer](~/images/screenshots/explorer_devnet.png)

  4. Search for your account

     Paste your newly created address into the search bar.

     <Aside type="caution">
       Do not press enter! There is a known bug where searching with Enter does not work.
     </Aside>

  5. View the search results

     Wait for the results to appear, then click the top result.

  6. Check the transaction

     You should see your newly created account and a transaction with the faucet function, funding it with devnet tokens.

     ![Viewing Account in Aptos Explorer](~/images/screenshots/explorer_account.png)

  7. Verify your balance

     Click the "Coins" tab to see that you have 1 APT of the Aptos Coin. This will allow you to publish and interact with smart contracts on the aptos devnet.

     <Aside type="note">
       The explorer is an important tool to see the contracts we are deploying, and also offers a way to look up what a contract does. Just search for the address where a contract is deployed and you will be able to see the code for that module.
     </Aside>
</Steps>

## 3. Writing and Compiling Your First Module

Now that we have our environment set up and an account created, let's write and compile our first Move module. Unlike Ethereum where contracts exist independently, Move ties everything to accounts - both modules and their resources. Let's start with a simple example to understand the core concepts.

![Move Blockchain Diagram](~/images/screenshots/move_blockchain.png)

This diagram illustrates the relationship between module ownership, token ownership, and the Move blockchain state. It helps visualize how modules and resources are tied to accounts, emphasizing the unique aspects of Move's design compared to other blockchain platforms.

### What is a Move Module?

Move modules are similar to smart contracts in other blockchains, with some key differences:

- **Resources:** Unlike Solidity where state is stored in contract variables, Move uses "resources" - special data types that can only exist in one place at a time and are always tied to an account
- **Module-based**: Rather than deploying entire contracts as independent units like in Solidity, Move code is organized into reusable modules that can share and handle resources across boundaries. Modules are more like standard library packages that can be published together or separately, offering finer-grained control over code organization.
- **Safety by design:** Move's type system and resource semantics help prevent common smart contract vulnerabilities

<Aside type="note">
  If you're familiar with Rust, you'll find Move's syntax very similar. If you're coming from Solidity, think of modules as reusable smart contract libraries.
</Aside>

### Your First Move Module

Before we start, go to your VSCode (or Cursor) and install the [Move On Aptos](/build/smart-contracts/move-vscode-extension) VSCode extension.

<Steps>
  1. Open VSCode (or Cursor) and navigate to the Extensions tab.
  2. Search for `Move On Aptos` published by `aptoslabs` and install the extension.
</Steps>

This extension will help us with the syntax highlighting, auto-completion, and other features that will make our development experience easier.

Our first module will be a simple message storage system that allows accounts to store and retrieve messages. Let's create a new move project within our `my-first-module` folder:

<Steps>
  1. Initialize the project

     Initialize a new move project with `aptos move init --name my_first_module`

     This creates a project structure with a `sources` directory and a `Move.toml` file.

  2. Create the module file

     Create a new file `sources/message.move` with our module code:

     ```move filename="message.move"
     module my_first_module::message {
         use std::string;
         use std::signer;

         struct MessageHolder has key, store, drop {
             message: string::String,
         }

         public entry fun set_message(account: &signer, message: string::String) acquires MessageHolder {
             let account_addr = signer::address_of(account);

             if (exists<MessageHolder>(account_addr)) {
                 move_from<MessageHolder>(account_addr);
             };

             move_to(account, MessageHolder { message });
         }

         public fun get_message(account_addr: address): string::String acquires MessageHolder {
             assert!(exists<MessageHolder>(account_addr), 0);
             let message_holder = borrow_global<MessageHolder>(account_addr);
             message_holder.message
         }
     }
     ```

     Let's break down this module:

     - We define a `MessageHolder` resource type that can store a string message
     - `set_message` allows an account to store a message
     - `get_message` allows anyone to retrieve a stored message
     - The `acquires` keyword indicates which resources the functions need access to (MessageHolder, in this case)
     - `move_to` and `move_from` handle the storage of resources under accounts

     <Aside type="note">
       Move has some unique characteristics that make it different from other smart contract languages:

       1. Resource types are used to represent assets and state that can only exist in one place at a time
       2. Ability modifiers like `key`, `store`, and `drop` control how values can be used
       3. Explicit acquire annotations tell us which resources a function might access
     </Aside>

  3. Compile the module

     Compile the Move module we just created with `aptos move compile --named-addresses my_first_module=default`

     <Aside type="note">
       The `--named-addresses` flag maps our module name to our account's address. In Move, modules must be associated with an address at compile time - we're using `'default'` which points to the account we just created.
     </Aside>

     You should see a message like this if it succeeded:

     ```shellscript filename="Terminal"
     ‚ùØ aptos move compile --named-addresses my_first_module=default
     Compiling, may take a little while to download git dependencies...
     UPDATING GIT DEPENDENCY https://github.com/aptos-labs/aptos-framework.git
     INCLUDING DEPENDENCY AptosFramework
     INCLUDING DEPENDENCY AptosStdlib
     INCLUDING DEPENDENCY MoveStdlib
     BUILDING my_first_module
     {
       "Result": [
         "9ec1cfa30b885a5c9d595f32f3381ec16d208734913b587be9e210f60be9f9ba::message"
       ]
     }
     ```
</Steps>

Great job! We are now ready to test and debug.

## 4. Testing and Debugging

Testing and debugging are crucial parts of Move module development. Move has built-in support for unit testing and debug printing.

<Steps>
  1. Add debug prints

     First, let's modify our message module to add some debug prints. Update your `sources/message.move`:

     ```move filename="message.move"
     module my_first_module::message {
         use std::string;
         use std::signer;
         use std::debug;  // Add this for debug prints

         struct MessageHolder has key, store, drop {
             message: string::String,
         }

         public entry fun set_message(account: &signer, message: string::String) acquires MessageHolder {
             let account_addr = signer::address_of(account);
             debug::print(&message); // Print the message being set

             if (exists<MessageHolder>(account_addr)) {
                 debug::print(&string::utf8(b"Updating existing message")); // Print debug info
                 move_from<MessageHolder>(account_addr);
             } else {
                 debug::print(&string::utf8(b"Creating new message")); // Print when creating new
             };

             move_to(account, MessageHolder { message });
         }

         public fun get_message(account_addr: address): string::String acquires MessageHolder {
             assert!(exists<MessageHolder>(account_addr), 0);
             let message_holder = borrow_global<MessageHolder>(account_addr);
             debug::print(&message_holder.message); // Print the retrieved message
             message_holder.message
         }
     }
     ```

  2. Create test file

     Create our tests: a new file `sources/message_tests.move` with:

     ```move filename="message_tests.move"
      #[test_only]
      module my_first_module::message_tests {
         use std::string;
         use std::signer;
         use my_first_module::message;

         #[test(sender= @my_first_module)]
         fun test_set_and_get_message(sender: &signer) {
            // Test setting a message
            message::set_message(sender, string::utf8(b"Hello World"));

            // Verify the message was set correctly
            let stored_message = message::get_message(signer::address_of(sender));
            assert!(stored_message == string::utf8(b"Hello World"), 0)
         }

         #[test(sender=@my_first_module)]
         fun test_update_message(sender: &signer) {
            // Test setting a message
            message::set_message(sender, string::utf8(b"Hello World"));
            // Test updating the message
            message::set_message(sender, string::utf8(b"Hello Aptos"));

            // Verify the message was updated correctly
            let stored_message = message::get_message(signer::address_of(sender));
            assert!(stored_message == string::utf8(b"Hello Aptos"), 0)
         }
      }
     ```

  3. Run the tests

     Now run the tests with `aptos move test --named-addresses my_first_module=default`

     You should see output if the tests pass: (See below for how to handle errors)

     ```shellscript filename="Terminal"
      INCLUDING DEPENDENCY AptosFramework
      INCLUDING DEPENDENCY AptosStdlib
      INCLUDING DEPENDENCY MoveStdlib
      BUILDING my_first_module
      Running Move unit tests
      [debug] "Hello World"
      [debug] "Creating new message"
      [debug] "Hello World"
      [ PASS    ] 0x852a264419a80b27771f072b5cae8c8b358d4450e135e134e065247376a4357a::message_tests::test_set_and_get_message
      [debug] "Hello World"
      [debug] "Creating new message"
      [debug] "Hello Aptos"
      [debug] "Updating existing message"
      [debug] "Hello Aptos"
      [ PASS    ] 0x852a264419a80b27771f072b5cae8c8b358d4450e135e134e065247376a4357a::message_tests::test_update_message
      Test result: OK. Total tests: 2; passed: 2; failed: 0
      {
      "Result": "Success"
      }
     ```
</Steps>

**If you encounter errors while testing, here are some common issues and solutions:**

- Make sure all module dependencies are properly imported
- Check that your account address matches in the `-named-addresses` parameter
- Verify that test functions have the `#[test]` attribute
- Ensure string literals are properly encoded

<Aside type="note">
  ### Debugging Tips

  1. Use `debug::print()` in test functions
  2. Debug prints will show up automatically during test execution
  3. Remember that debug statements will only work in tests, not in production code. They will have no impact on code performance.
  4. To debug module state:
     - Print account addresses with `debug::print(&addr)`
     - Print string values with `debug::print(&some_string)`
     - Print boolean conditions with `debug::print(&some_bool)`
</Aside>

## 5. Publishing Your Module

After successfully compiling and testing your module, you can publish it to the Aptos blockchain. This process deploys your code so that it's accessible on-chain.

<Steps>
  1. Publish the module

     Publish your module with `aptos move publish --named-addresses my_first_module=default`

     You'll see output showing the compilation process and then a prompt asking about gas fees:

     ```shellscript filename="Terminal"
     Compiling, may take a little while to download git dependencies...
     UPDATING GIT DEPENDENCY https://github.com/aptos-labs/aptos-framework.git
     INCLUDING DEPENDENCY AptosFramework
     INCLUDING DEPENDENCY AptosStdlib
     INCLUDING DEPENDENCY MoveStdlib
     BUILDING my_first_module
     package size 1271 bytes
     Do you want to submit a transaction for a range of [141300 - 211900] Octas at a gas unit price of 100 Octas? [yes/no] >
     ```

  2. Confirm the transaction

     Type `y` and press Enter to confirm the transaction.

     After confirmation, you'll receive a response showing the transaction details:

     ```shellscript filename="Terminal"
     {
       "Result": {
         "transaction_hash": "0x95fce7344b066abda10c07dbf1ffa83e0d9c7bd400e2b143682a6c8a5f179dc2",
         "gas_used": 1413,
         "gas_unit_price": 100,
         "sender": "9ec1cfa30b885a5c9d595f32f3381ec16d208734913b587be9e210f60be9f9ba",
         "sequence_number": 0,
         "success": true,
         "timestamp_us": 1735351260227638,
         "version": 273029731,
         "vm_status": "Executed successfully"
       }
     }
     ```
</Steps>

### (Optional) Seeing Your Contract On-Chain

After successful publication, you can verify your module is on-chain by following these steps:

<Steps>
  1. Open the Explorer

     Go to the [Aptos Explorer](https://explorer.aptoslabs.com/?network=devnet)

  2. Check the transaction

     Search for your account address. You should notice that there is a new transaction in your account, the `code::publish_package_txn` function.

  3. View your balance

     Click the "Coins" tab to see that you now have less than 1 APT of the Aptos Coin.

     ![Explorer Coins View](~/images/screenshots/explorer_coins.png)

     You have spent a small amount on gas to deploy the contract so should have around `0.99855 APT` remaining.

  4. Find your module

     Look under the "Modules" tab

     ![Exporer Modules View](~/images/screenshots/explorer_modules.png)

  5. Verify the module

     You should see your "message" module listed

     <Aside type="note">
       You can share the explorer link to your module and others can even interact with the module by connecting a wallet.
     </Aside>
</Steps>

## 6. Interacting with Your Module

Now that your module is published, you can interact with it through the Aptos CLI:

<Steps>
  1. Set a message

     Set a message using the CLI:

     ```shellscript filename="Terminal"
     aptos move run --function-id 'default::message::set_message' --args 'string:Hello, Aptos!'
     ```

     You'll see a gas fee prompt similar to what you saw during publishing.

  2. Confirm the transaction

     After confirming with `y`, you should get a success response like:

     ```shellscript filename="Terminal"
     Transaction submitted: https://explorer.aptoslabs.com/txn/0x0c0b1e56a31d037280278327eb8fdfcc469a20213e5e65accf6e7c56af574449?network=devnet
     {
       "Result": {
         "transaction_hash": "0x0c0b1e56a31d037280278327eb8fdfcc469a20213e5e65accf6e7c56af574449",
         "gas_used": 445,
         "gas_unit_price": 100,
         "sender": "9ec1cfa30b885a5c9d595f32f3381ec16d208734913b587be9e210f60be9f9ba",
         "sequence_number": 1,
         "success": true,
         "timestamp_us": 1735351754495208,
         "version": 273137362,
         "vm_status": "Executed successfully"
       }
     }
     ```

  3. View your message

     View your stored message by checking under Resources on the Explorer.

  4. Celebrate!

     We did it!

     <Aside type="note">
       How long did it take you to get through this guide?  We want to hear from you!
     </Aside>
</Steps>

## Next Steps

Congratulations! You've successfully:

1. Compiled your first Move module
2. Added tests to help debug
3. Published your module on-chain
4. Used your contract through the CLI

Now your published Move module can be connected to just like an API via one of our [many Official SDKs](/build/sdks)!

Here are some **suggested next steps to get a deeper understanding of Move modules**:

1. Try modifying the module to add a new feature. You can use the [Move Book](/build/smart-contracts/book) to build your understanding of writing Move modules.
2. To understand how Move works on-chain, you can learn about Move's [resource system](/network/blockchain/resources).
3. If you're building an application to interact with contracts or look up data from on-chain, learn how to use the SDKs [here](/build/sdks).
4. Join the [Aptos Discord](https://discord.gg/aptoslabs) to connect with other developers.

## Supporting documentation

- [Account basics](/network/blockchain/accounts)
- [TypeScript SDK](/build/sdks/ts-sdk)
- [Python SDK](/build/sdks/python-sdk)
- [REST API specification](/rest-api)

# Your First Aptos Multisig (Python SDK)

> Create and manage multisig accounts requiring multiple approvals for transactions using Python SDK with practical examples.

import { Aside, Steps, TabItem, Tabs } from '@astrojs/starlight/components';

In this tutorial, you'll learn how to create and manage a multisig account that requires 2 out of 3 key holders to approve any transaction.
You'll learn how to:

1. Set up a development environment for Aptos
2. Create multiple accounts to act as key holders
3. Configure a multisig account requiring 2-of-3 signatures
4. Fund accounts and verify balances
5. Create and execute multisig transactions

<Aside type="note">
  If you're coming from Ethereum/Solidity, note that Aptos handles multisig accounts differently. Aptos implements [multisig directly at the protocol level](/network/blockchain/accounts), allowing accounts to require multiple signatures without deploying additional smart contracts.

  ![Multisig Diagram](~/images/multisig_chart.svg)

  We're interfacing with Aptos using the [Aptos Python SDK](/build/sdks/python-sdk).
</Aside>

Conceptually, a multisig (multi-signature) account works like a bank vault requiring multiple key holders to authorize access. In Aptos, this is implemented with digital signatures rather than physical keys, with each authorized signer providing their cryptographic approval.

## Setup

First, let's prepare our development environment. We'll create an isolated workspace and install all necessary dependencies.

<Steps>
  1. Open a terminal

     Open a new terminal window.

  2. Verify Python installation

     Run this command to check your Python version:

     <Tabs>
       <TabItem label="Mac/Linux">
         ```shellscript filename="Terminal"
         python3 --version
         ```
       </TabItem>

       <TabItem label="Windows">
         ```shellscript filename="Terminal"
         python --version
         ```
       </TabItem>
     </Tabs>

     You should see something like "Python 3.7" or higher.

     <Aside type="caution">
       If you see an error or your Python version is below version 3.7, download Python from [python.org](https://python.org/).
     </Aside>

  3. Create project directory

     Create a new folder for our project:

     ```shellscript filename="Terminal"
     mkdir my-first-multisig
     ```

  4. Navigate to project directory

     Move into this new folder:

     ```shellscript filename="Terminal"
     cd my-first-multisig
     ```

  5. Create virtual environment

     Set up an isolated Python environment:

     <Tabs>
       <TabItem label="Mac/Linux">
         ```shellscript filename="Terminal"
         python3 -m venv venv
         ```
       </TabItem>

       <TabItem label="Windows">
         ```shellscript filename="Terminal"
         python -m venv venv
         ```
       </TabItem>
     </Tabs>

     This command:

     - Creates an isolated Python environment
     - Installs a fresh Python instance
     - Keeps project dependencies separate from your system Python
     - Creates a `venv` folder (you can view but don't modify its contents!)

  6. Activate virtual environment

     <Tabs>
       <TabItem label="Mac/Linux">
         ```shellscript filename="Terminal"
         source venv/bin/activate
         ```
       </TabItem>

       <TabItem label="Windows">
         ```shellscript filename="Terminal"
         .\venv\Scripts\activate
         ```

         <Aside type="note">
           If you get an error about scripts not being allowed to run, you can enable them with PowerShell:

           ```powershell filename="Terminal"
           Set-ExecutionPolicy RemoteSigned -Scope CurrentUser
           ```

           Confirm by typing `[Y]` and pressing Enter, then retry the activation command.
         </Aside>
       </TabItem>
     </Tabs>

     This command:

     - Modifies your terminal's environment variables
     - Makes your terminal use the Python from `venv` instead of your system Python
     - You'll see `(venv)` appear at the start of your terminal line
     - To deactivate later, simply type `deactivate`

  7. Install Aptos SDK

     Install the required SDK:

     ```shellscript filename="Terminal"
     pip install aptos-sdk
     ```

     This command:

     - Downloads the Aptos SDK package from PyPI (Python Package Index)
     - Installs it inside your `venv` folder
     - Creates files in `venv/lib/python3.x/site-packages/aptos_sdk`
     - You can view these files by navigating to that directory
</Steps>

## Creating the Foundation

Let's start building our multisig implementation. First, we'll set up our imports, main loop, and base configuration.

<Steps>
  1. Create Python script

     Create an empty Python script file:

     <Tabs>
       <TabItem label="Mac/Linux">
         ```shellscript filename="Terminal"
         touch multisig.py
         ```
       </TabItem>

       <TabItem label="Windows">
         ```shellscript filename="Terminal"
         echo "" > multisig.py
         ```
       </TabItem>
     </Tabs>

  2. Add base code

     Open `multisig.py` in your IDE (we recommend VSCode or JetBrains) and add the following code:

     ```python filename="multisig.py"
     # Copyright ¬© Aptos Foundation
     # SPDX-License-Identifier: Apache-2.0

     import asyncio
     import subprocess
     import time

     from aptos_sdk.account import Account, RotationProofChallenge
     from aptos_sdk.account_address import AccountAddress
     from aptos_sdk.async_client import FaucetClient, RestClient
     from aptos_sdk.authenticator import Authenticator, MultiEd25519Authenticator
     from aptos_sdk.bcs import Serializer
     from aptos_sdk.ed25519 import MultiPublicKey, MultiSignature
     from aptos_sdk.transactions import (
         EntryFunction,
         RawTransaction,
         Script,
         ScriptArgument,
         SignedTransaction,
         TransactionArgument,
         TransactionPayload,
     )
     from aptos_sdk.type_tag import StructTag, TypeTag

     # Network configuration - using devnet for testing. Check current urls at:
     # https://github.com/aptos-labs/aptos-python-sdk/blob/main/examples/common.py
     NODE_URL = "https://fullnode.devnet.aptoslabs.com/v1"
     FAUCET_URL = "https://faucet.devnet.aptoslabs.com"

     should_wait = True

     # "wait" is used to make the terminal more interactive, so it's easier to follow what is happening.
     def wait():
         """Wait for user to press Enter before starting next section."""
         if should_wait:
             input("\nPress Enter to continue...")

     # Now we define our main function which calls everything else.
     # We will add all future additions inside this function.
     async def main(should_wait_input=True):
         # This is just used for this tutorial.
         global should_wait
         should_wait = should_wait_input

         # Initialize our blockchain clients
         rest_client = RestClient(NODE_URL)
         faucet_client = FaucetClient(FAUCET_URL, rest_client)

         ############# Add additional code here ###############


         ######################################################

     if __name__ == "__main__":
         asyncio.run(main())
     ```

     This code imports all the necessary modules from the Aptos SDK. The `aptos_sdk.account` module provides essential functionality for managing accounts and signatures, while `aptos_sdk.transactions` gives us the tools to create and submit blockchain transactions.

     <Aside type="note">
       You can get free test tokens on Aptos Devnet or Testnet by using the `FaucetClient`.
     </Aside>
</Steps>

## Creating Our Key Holders

Just like a bank vault needs designated key holders, our multisig needs authorized signers. Let's create the accounts for our key holders.

<Steps>
  1. Create key holder accounts

     Add the following code after `############# Add additional code here ###############`:

     ```python filename="multisig.py"
     # Create three accounts to act as our key holders
     alice = Account.generate()
     bob = Account.generate()
     chad = Account.generate()
     ```

     The `Account.generate()` function creates a new Aptos account with a fresh keypair. Each account will have its own private key (for signing) and public key (for verification). In our multisig setup, these accounts represent the key holders who will have authorization to sign transactions, similar to how each bank vault key holder would have their own unique physical key.

     <Aside type="note">
       Each time you run this script it will generate new accounts on the devnet. You'll need to save the private key and account address if you want to continue working with that account.
     </Aside>

  2. Add account information display

     Add this code below `chad = Account.generate()`:

     ```python filename="multisig.py"
     print("\n=== Account addresses ===")
     print(f"Alice: {alice.address()}")
     print(f"Bob:   {bob.address()}")
     print(f"Chad:  {chad.address()}")

     print("\n=== Authentication keys ===")
     print(f"Alice: {alice.auth_key()}")
     print(f"Bob:   {bob.auth_key()}")
     print(f"Chad:  {chad.auth_key()}")

     print("\n=== Public keys ===")
     print(f"Alice: {alice.public_key()}")
     print(f"Bob:   {bob.public_key()}")
     print(f"Chad:  {chad.public_key()}")

     wait()

     # Add additional code below this wait()
     ```

  3. Run the script

     Run our `multisig.py` from your terminal:

     <Tabs>
       <TabItem label="Mac/Linux">
         ```shellscript filename="Terminal"
         python3 multisig.py
         ```
       </TabItem>

       <TabItem label="Windows">
         ```shellscript filename="Terminal"
         python multisig.py
         ```
       </TabItem>
     </Tabs>

     You should see output showing the addresses, authentication keys, and public keys for each account. For example:

     ```shellscript filename="Terminal"
     === Account addresses ===
     Alice: 0x5323a06f21b04af53fc57367b50d3bbb5675c655bc9bc62f33b5e083d5d06b8b
     Bob:   0x9f3e94fc92e0076336c122a576304c0b9fa8def13a98c469dce05e0836b9fe5b
     Chad:  0x1d0e7b790493dcf7bc7ce60bf4ccdcca1d38ce0d7f8dd26d2791a6d3ff6da708

     === Authentication keys ===
     Alice: 0x5323a06f21b04af53fc57367b50d3bbb5675c655bc9bc62f33b5e083d5d06b8b
     Bob:   0x9f3e94fc92e0076336c122a576304c0b9fa8def13a98c469dce05e0836b9fe5b
     Chad:  0x1d0e7b790493dcf7bc7ce60bf4ccdcca1d38ce0d7f8dd26d2791a6d3ff6da708

     === Public keys ===
     Alice: 0x730264a36d4ec90af2e28e1cf9c4d686440598317123469a7c827d4fcdf74715
     Bob:   0xcf21e85337a313bdac33d068960a3e52d22ce0e6190e9acc03a1c9930e1eaf3e
     Chad:  0xa1a2aef8525eb20655387d3ed50b9a3ea1531ef6117f579d0da4bcf5a2e1f76d
     ```

     <Aside type="note">
       For each user, note the [account address](/network/blockchain/accounts#account-address) and [authentication key](/network/blockchain/accounts#authentication-key) are identical, but the [public key](/network/blockchain/accounts#creating-an-account) is different.

       The Aptos account model facilitates the unique ability to rotate an account's private key. Since an account's address is the _initial_ authentication key, the ability to sign for an account can be transferred to another private key without changing its public address.
     </Aside>
</Steps>

## Configuring the Multisig Vault

Now that we have our key holders (Alice, Bob, and Chad), let's set up our multisig configuration.

<Steps>
  1. Configure multisig account

     Add code to configure a 2-of-3 multisig account:

     ```python filename="multisig.py"
     # Configure a 2-of-3 multisig account
     threshold = 2

     multisig_public_key = MultiPublicKey(
         [alice.public_key(), bob.public_key(), chad.public_key()],
         threshold
     )

     multisig_address = AccountAddress.from_key(multisig_public_key)
     ```

     The `threshold = 2` sets our requirement for two signatures out of three possible signers. The `MultiPublicKey` combines all three public keys into a single multisig configuration.

     <Aside type="note">
       This is like setting up a bank vault's access rules: "Any two of these three people must approve to access the vault."
     </Aside>

  2. Display multisig information

     Print the multisig account information by adding this code below our newly defined `multisig_address`:

     ```python filename="multisig.py"
     print("\n=== 2-of-3 Multisig account ===")
     print(f"Account public key: {multisig_public_key}")
     print(f"Account address:    {multisig_address}")

     wait()

     # Add additional code here
     ```

  3. Run the script

     Verify the output:

     <Tabs>
       <TabItem label="Mac/Linux">
         ```shellscript filename="Terminal"
         python3 multisig.py
         ```
       </TabItem>

       <TabItem label="Windows">
         ```shellscript filename="Terminal"
         python multisig.py
         ```
       </TabItem>
     </Tabs>

     You should see output showing your multisig account's public key type and its unique address on the Aptos blockchain. For example:

     ```shellscript filename="Terminal"
     === 2-of-3 Multisig account ===
     Account public key: 2-of-3 Multi-Ed25519 public key
     Account address:    0x08cac3b7b7ce4fbc5b18bc039279d7854e4c898cbf82518ac2650b565ad4d364
     ```
</Steps>

## Funding Our Accounts

Just like new bank accounts need initial deposits, our blockchain accounts need funds to operate.

<Steps>
  1. Add funding code

     Add code to fund all accounts:

     ```python filename="multisig.py"
     print("\n=== Funding accounts ===")
     alice_start = 10_000_000
     bob_start = 20_000_000
     chad_start = 30_000_000
     multisig_start = 40_000_000

     # Fund all accounts concurrently
     alice_fund = faucet_client.fund_account(alice.address(), alice_start)
     bob_fund = faucet_client.fund_account(bob.address(), bob_start)
     chad_fund = faucet_client.fund_account(chad.address(), chad_start)
     multisig_fund = faucet_client.fund_account(multisig_address, multisig_start)
     await asyncio.gather(*[alice_fund, bob_fund, chad_fund, multisig_fund])
     ```

     The `fund_account()` function requests test tokens from the Aptos faucet to let us experiment without using real APT. We fund all accounts simultaneously rather than one at a time by first initializing them as `[name]_fund` and then awaiting the async function call that gathers them: `asyncio.gather()`.

  2. Check balances

     Add code to check all balances and print them out:

     ```python filename="multisig.py"
     # Check all balances
     alice_balance = rest_client.account_balance(alice.address())
     bob_balance = rest_client.account_balance(bob.address())
     chad_balance = rest_client.account_balance(chad.address())
     multisig_balance = rest_client.account_balance(multisig_address)
     [alice_balance, bob_balance, chad_balance, multisig_balance] = await asyncio.gather(
         *[alice_balance, bob_balance, chad_balance, multisig_balance]
     )

     print(f"Alice's balance:  {alice_balance}")
     print(f"Bob's balance:    {bob_balance}")
     print(f"Chad's balance:   {chad_balance}")
     print(f"Multisig balance: {multisig_balance}")

     wait()
     ```

     The `account_balance()` function queries the blockchain for each account's current balance. Again, we use `asyncio.gather()` to make all these queries efficiently in parallel.

  3. Run the script

     Verify funding success by running:

     <Tabs>
       <TabItem label="Mac/Linux">
         ```shellscript filename="Terminal"
         python3 multisig.py
         ```
       </TabItem>

       <TabItem label="Windows">
         ```shellscript filename="Terminal"
         python multisig.py
         ```
       </TabItem>
     </Tabs>

     The output should show each account with its respective balance. For example:

     ```shellscript filename="Terminal"
     === Funding accounts ===
     Alice's balance:  10000000
     Bob's balance:    20000000
     Chad's balance:   30000000
     Multisig balance: 40000000
     ```

     <Aside type="caution">
       If any balance shows as 0, you may need to rerun the funding command as the faucet occasionally has temporary issues.
     </Aside>

     <Aside type="note">
       Values are in octas (1 APT = 100\_000\_000 octas). This is similar to how 1 dollar = 100 cents.
     </Aside>
</Steps>

## Creating Our First Multisig Transaction

Now let's create a transaction that requires multiple signatures. We'll transfer 100 octas from the multisig account to Chad, similar to how a bank transfer would require two managers to approve a large withdrawal.

<Steps>
  1. Create transfer transaction

     Create the transfer transaction by defining its parameters:

     ```python filename="multisig.py"
     # Create the transfer transaction
     entry_function = EntryFunction.natural(
         module="0x1::coin",
         function="transfer",
         ty_args=[TypeTag(StructTag.from_str("0x1::aptos_coin::AptosCoin"))],
         args=[
             TransactionArgument(chad.address(), Serializer.struct),
             TransactionArgument(100, Serializer.u64),
         ],
     )

     # Build the raw transaction
     chain_id = await rest_client.chain_id()
     raw_transaction = RawTransaction(
         sender=multisig_address,
         sequence_number=0,
         payload=TransactionPayload(entry_function),
         max_gas_amount=2000,
         gas_unit_price=100,
         expiration_timestamps_secs=int(time.time()) + 600,
         chain_id=chain_id,
     )
     ```

     The code above:

     - Uses `EntryFunction.natural()` to create a transfer of 100 octas (APT's smallest unit) to Chad's address
     - Sets up transaction parameters like gas limits and expiration time
     - Creates a raw transaction that still needs signatures before it can be submitted

  2. Get signatures

     Get signatures from Alice and Bob:

     ```python filename="multisig.py"
     alice_signature = alice.sign(raw_transaction.keyed())
     bob_signature = bob.sign(raw_transaction.keyed())

     print("\n=== Individual signatures ===")
     print(f"Alice: {alice_signature}")
     print(f"Bob:   {bob_signature}")

     wait()
     ```

     The above code:

     - Has Alice sign the transaction with her private key
     - Has Bob sign the same transaction with his private key
     - Prints the signatures to verify they were created successfully

  3. Run the script

     After you add the code for creating the transaction and getting signatures, run the script:

     <Tabs>
       <TabItem label="Mac/Linux">
         ```shellscript filename="Terminal"
         python3 multisig.py
         ```
       </TabItem>

       <TabItem label="Windows">
         ```shellscript filename="Terminal"
         python multisig.py
         ```
       </TabItem>
     </Tabs>

     You should see something like:

     ```shellscript filename="Terminal"
     === Individual signatures ===
     Alice: 0x360e66c75b1ba787ec7b05998cbc14276d7fc0c006fb10c33d5cc3c4cc2ec4f53a8c0996b8e746fd6d86b09b4f8bb128cbf62d8b375f5b974faae040e889ac0d
     Bob:   0xdcfd1965e531deb79de9d8daf7f28f46023107ce4f11612ce76da33e808486a0a368b34563d4f89d6179a3957a266c1e8809691fddabba3c2a3d8be14d6f2f0c
     ```

     This shows that both Alice and Bob have signed the transaction. Each signature is a unique hash that proves they authorized the transaction with their private keys.

     <Aside type="note">
       Like gathering two bank managers to sign a withdrawal slip - we need both signatures before the transaction can proceed.

       Changing the number of managers required from two out of three to 13 out of 22 (or any K-of-N your business needs) is a few more lines of code.
     </Aside>
</Steps>

## Submitting the Multisig Transaction

Now we'll combine the signatures and submit the transaction. This is similar to gathering all the signed papers from bank managers and submitting them to process a large transfer.

<Steps>
  1. Combine signatures

     Combine the signatures into a multisig authenticator:

     ```python filename="multisig.py"
     # Combine the signatures (map from signatory public key index to signature)
     sig_map = [(0, alice_signature), (1, bob_signature)]
     multisig_signature = MultiSignature(sig_map)

     # Create the authenticator with our multisig configuration
     authenticator = Authenticator(
         MultiEd25519Authenticator(multisig_public_key, multisig_signature)
     )
     ```

     The `sig_map` links each signer's public key to their signature, proving that both Alice and Bob have approved this transaction. The `MultiSignature` and `Authenticator` objects package these signatures in a format the blockchain can verify.

  2. Submit transaction

     Create and submit the signed transaction:

     ```python filename="multisig.py"
     # Create and submit the signed transaction
     signed_transaction = SignedTransaction(raw_transaction, authenticator)

     print("\n=== Submitting transfer transaction ===")
     tx_hash = await rest_client.submit_bcs_transaction(signed_transaction)
     await rest_client.wait_for_transaction(tx_hash)
     print(f"Transaction hash: {tx_hash}")
     ```

     The `SignedTransaction` combines the original transaction data with the authenticator proving both required signatures are present. We then submit this to the blockchain using `submit_bcs_transaction()` and wait for confirmation.

  3. Check new balances

     Check the new account balances after transaction:

     ```python filename="multisig.py"
     print("\n=== New account balances ===")
     [alice_balance, bob_balance, chad_balance, multisig_balance] = await asyncio.gather(
         *[
             rest_client.account_balance(alice.address()),
             rest_client.account_balance(bob.address()),
             rest_client.account_balance(chad.address()),
             rest_client.account_balance(multisig_address),
         ]
     )

     print(f"Alice's balance:  {alice_balance}")
     print(f"Bob's balance:    {bob_balance}")
     print(f"Chad's balance:   {chad_balance}")
     print(f"Multisig balance: {multisig_balance}")
     ```

  4. Run the script

     To see the transaction results, run:

     <Tabs>
       <TabItem label="Mac/Linux">
         ```shellscript filename="Terminal"
         python3 multisig.py
         ```
       </TabItem>

       <TabItem label="Windows">
         ```shellscript filename="Terminal"
         python multisig.py
         ```
       </TabItem>
     </Tabs>

     You should see something like:

     ```shellscript filename="Terminal"
     === Submitting transfer transaction ===
     Transaction hash: 0x2f0b7fc8e69213f0c7e720e660f789b6e3d3564729a298f2b4f6794245833f2d

     === New account balances ===
     Alice's balance:  10000000
     Bob's balance:    20000000
     Chad's balance:   30000100        # Increased by 100 octas
     Multisig balance: 39999200        # Decreased by 100 octas plus gas fees
     ```

     Notice how:

     - Chad's balance increased by exactly 100 octas, but Alice and Bob's balances didn't change since they only signed
     - The multisig account paid for both the transfer amount and the gas fees

     <Aside type="note">
       You can verify transaction on Aptos Explorer:

       - Go to [Aptos Explorer](https://explorer.aptoslabs.com/)
       - Make sure Explorer is set to Devnet (check the top right corner)
         ![Switching to Devnet network in Aptos Explorer](~/images/screenshots/explorer_devnet.png)
       - Search for your multisig address or transaction hash
       - Review the transaction details and balance changes
     </Aside>
</Steps>

## Going Further: Advanced Features

You've completed the basics of Aptos multisig - creating a "vault" (multisig account), adding "key holders" (signers), and making a simple transfer that requires multiple approvals. But just like modern banking, there's much more we can do:

### Vanity Addresses

Like having a custom bank account number, Aptos lets you create "vanity" addresses that start with specific characters. Imagine being able to choose a memorable account number like "0xdd..." for your company "Digital Dynamics"!

### Account Rotation

Banks let you update your security credentials without changing your account number. Similarly, Aptos multisig accounts can "rotate" their authentication keys while keeping the same address - perfect for updating security without disrupting existing payment setups.

### Governance & Smart Contracts

Just as banks have complex approval systems for large corporate accounts, Aptos multisig can interact with smart contracts and governance systems. Imagine setting up automated rules like:

- Required approvals based on transaction size
- Time-locked transactions
- Integration with DAO voting systems

<Aside type="note">
  Let us know what excites you most about multisig on Aptos! Join our community channels to share your ideas and experiences.
</Aside>

## Next Steps

1. Review the [complete code example](https://github.com/aptos-labs/aptos-python-sdk/blob/main/examples/multisig.py) which include all the Advanced Features (see above).
2. Learn about [multisig governance in this tutorial](/build/cli/working-with-move-contracts/multi-signature-tutorial).
3. Explore [account abstraction in Aptos](/network/blockchain/accounts).
4. Join the [Aptos Discord](https://discord.gg/aptoslabs) for developer support.

# Your First Transaction

> Create and submit your first transaction on Aptos blockchain - transfer coins between accounts with TypeScript and Python examples.

import { Aside, Steps, TabItem, Tabs } from '@astrojs/starlight/components';

Transactions are the fundamental way to change data on the Aptos blockchain. Think of them like sending a package: you need to specify what you're sending, who it's going to, and then track it until delivery is confirmed. In blockchain terms, transactions allow you to transfer coins, call smart contract functions, and update on-chain state.

This tutorial will guide you through creating and submitting your first transaction on the Aptos blockchain. You'll learn how to:

1. Set up your development environment
2. Create test accounts and fund them
3. Build a transaction to transfer coins
4. Simulate the transaction to estimate costs
5. Sign and submit the transaction
6. Verify the transaction was executed successfully

<Aside type="note">
  This tutorial builds on concepts from the Aptos blockchain. If you're new to blockchain development, don't worry - we'll explain key concepts along the way.

  You can jump to the full code sample [here](#full-code-sample) or continue reading for a step-by-step walkthrough.
</Aside>

## 1. Setting Up Your Environment

<Tabs>
  <TabItem label="TypeScript">
    Before we can create transactions, we need to set up our development environment with the necessary tools and SDKs.

    <Steps>
      1. Install the TypeScript SDK

         Install the TypeScript SDK using your preferred package manager:

         <Tabs>
           <TabItem label="npm">
             ```shellscript filename="Terminal"
             npm install @aptos-labs/ts-sdk
             ```
           </TabItem>

           <TabItem label="yarn">
             ```shellscript filename="Terminal"
             yarn add @aptos-labs/ts-sdk
             ```
           </TabItem>

           <TabItem label="pnpm">
             ```shellscript filename="Terminal"
             pnpm add @aptos-labs/ts-sdk
             ```
           </TabItem>
         </Tabs>

      2. Create a project directory

         Create a new directory for your project:

         ```shellscript filename="Terminal"
         mkdir my-first-transaction
         cd my-first-transaction
         ```

      3. Create a new file

         Create a new file named `transaction.ts`:

         <Tabs>
           <TabItem label="Mac/Linux">
             ```shellscript filename="Terminal"
             touch transaction.ts
             ```
           </TabItem>

           <TabItem label="Windows">
             ```shellscript filename="Terminal"
             type nul > transaction.ts
             ```
           </TabItem>
         </Tabs>
    </Steps>
  </TabItem>

  <TabItem label="Python">
    Before we can create transactions, we need to set up our development environment with the necessary tools and SDKs.

    <Steps>
      1. Install the Python SDK

         Install the Python SDK using pip:

         ```shellscript filename="Terminal"
         pip install aptos-sdk
         ```

      2. Create a project directory

         Create a new directory for your project:

         ```shellscript filename="Terminal"
         mkdir my-first-transaction
         cd my-first-transaction
         ```

      3. Create a new file

         Create a new file named `transaction.py`:

         <Tabs>
           <TabItem label="Mac/Linux">
             ```shellscript filename="Terminal"
             touch transaction.py
             ```
           </TabItem>

           <TabItem label="Windows">
             ```shellscript filename="Terminal"
             type nul > transaction.py
             ```
           </TabItem>
         </Tabs>
    </Steps>
  </TabItem>
</Tabs>

## 2. Creating Test Accounts

<Tabs>
  <TabItem label="TypeScript">
    In blockchain, all transactions must come from an account. Let's create two test accounts: one to send coins (Alice) and one to receive them (Bob).

    <Steps>
      1. Set up the client

         First, we need to initialize the Aptos client that will connect to the blockchain. Open `transaction.ts` in your editor and add:

         ```typescript filename="transaction.ts"
         import {
           Account,
           Aptos,
           AptosConfig,
           Network,
         } from "@aptos-labs/ts-sdk";

         async function main() {
           // Initialize the Aptos client
           const config = new AptosConfig({ network: Network.DEVNET });
           const aptos = new Aptos(config);

           console.log("Connected to Aptos devnet");

           // More code will go here
         }

         main().catch(console.error);
         ```

         <Aside type="note">
           We're connecting to the Aptos devnet, which is a test network where you can experiment without using real coins. The devnet is reset periodically, so don't store anything important there. You can explore the full TypeScript SDK source code in the [aptos-ts-sdk repository](https://github.com/aptos-labs/aptos-ts-sdk).
         </Aside>

      2. Generate accounts

         Add this code inside your `main()` function to create two accounts - Alice (sender) and Bob (receiver):

         ```typescript filename="transaction.ts"
         // Generate two accounts
         const alice = Account.generate();
         const bob = Account.generate();

         console.log("=== Addresses ===");
         console.log(`Alice's address: ${alice.accountAddress}`);
         console.log(`Bob's address: ${bob.accountAddress}`);
         ```

         <Aside type="note">
           Each account has a unique address (like a bank account number) and a keypair (like your login credentials). The address is derived from the public key, while the private key is kept secret and used for signing transactions. For more details on how accounts work in Aptos, see [Account basics](/network/blockchain/accounts).
         </Aside>

      3. Fund the accounts

         Add this code after generating the accounts to get test coins from the faucet:

         ```typescript filename="transaction.ts"
         // Fund the accounts with test APT from the devnet faucet
         console.log("\n=== Funding accounts ===");
         await aptos.fundAccount({
           accountAddress: alice.accountAddress,
           amount: 100_000_000, // 1 APT = 100,000,000 octas
         });
         console.log("Accounts funded successfully");

         // Check initial balances
         const aliceBalance = await aptos.getAccountAPTAmount({
           accountAddress: alice.accountAddress,
         });
         const bobBalance = await aptos.getAccountAPTAmount({
           accountAddress: bob.accountAddress,
         });

         console.log("\n=== Initial Balances ===");
         console.log(`Alice: ${aliceBalance} octas`);
         console.log(`Bob: ${bobBalance} octas`);
         ```

      4. Run the code

         Let's test our code so far:

         ```shellscript filename="Terminal"
         npx ts-node transaction.ts
         ```

         You should see output similar to:

         ```
         Connected to Aptos devnet
         === Addresses ===
         Alice's address: 0x978c213990c4833df71548df7ce49d54c759d6b6d932de22b24d56060b7af2aa
         Bob's address: 0x7af2d6c93a2feafc9b69b5e8ad9d6b513b260f62f23f3a384a3a2e4a84694a9b

         === Funding accounts ===
         Accounts funded successfully

         === Initial Balances ===
         Alice: 100000000 octas
         Bob: 0 octas
         ```

         <Aside type="note">
           The addresses you see will be different from the ones shown here, as they are randomly generated each time.
         </Aside>
    </Steps>
  </TabItem>

  <TabItem label="Python">
    In blockchain, all transactions must come from an account. Let's create two test accounts: one to send coins (Alice) and one to receive them (Bob).

    <Steps>
      1. Set up the client

         First, we need to initialize the Aptos client that will connect to the blockchain. Open `transaction.py` in your editor and add:

         ```python filename="transaction.py"
         import asyncio
         from aptos_sdk.account import Account
         from aptos_sdk.async_client import FaucetClient, RestClient
         from aptos_sdk.transactions import EntryFunction, TransactionPayload, TransactionArgument, RawTransaction
         from aptos_sdk.bcs import Serializer
         import time

         # Network configuration
         NODE_URL = "https://fullnode.devnet.aptoslabs.com/v1"
         FAUCET_URL = "https://faucet.devnet.aptoslabs.com"

         async def main():
             # Initialize the clients
             rest_client = RestClient(NODE_URL)
             faucet_client = FaucetClient(FAUCET_URL, rest_client)

             print("Connected to Aptos devnet")

             # More code will go here

         if __name__ == "__main__":
             asyncio.run(main())
         ```

         <Aside type="note">
           We're connecting to the Aptos devnet, which is a test network where you can experiment without using real coins. The devnet is reset periodically, so don't store anything important there. You can explore the full Python SDK source code in the [aptos-python-sdk repository](https://github.com/aptos-labs/aptos-python-sdk).
         </Aside>

      2. Generate accounts

         Add this code inside your `main()` function to create two accounts - Alice (sender) and Bob (receiver):

         ```python filename="transaction.py"
         # Generate two accounts
         alice = Account.generate()
         bob = Account.generate()

         print("=== Addresses ===")
         print(f"Alice's address: {alice.address()}")
         print(f"Bob's address: {bob.address()}")
         ```

         <Aside type="note">
           Each account has a unique address (like a bank account number) and a keypair (like your login credentials). The address is derived from the public key, while the private key is kept secret and used for signing transactions. For more details on how accounts work in Aptos, see [Account basics](/network/blockchain/accounts).
         </Aside>

      3. Fund the accounts

         Add this code after generating the accounts to get test coins from the faucet:

         ```python filename="transaction.py"
         # Fund the accounts with test APT from the devnet faucet
         print("\n=== Funding accounts ===")
         alice_amount = 100_000_000  # 1 APT = 100,000,000 octas
         bob_amount = 0  # Bob starts with 0 APT

         await faucet_client.fund_account(alice.address(), alice_amount)
         print("Account funded successfully")

         # Check initial balances
         alice_balance = await rest_client.account_balance(alice.address())
         bob_balance = await rest_client.account_balance(bob.address())

         print("\n=== Initial Balances ===")
         print(f"Alice: {alice_balance} octas")
         print(f"Bob: {bob_balance} octas")
         ```

      4. Run the code

         Let's test our code so far:

         ```shellscript filename="Terminal"
         python transaction.py
         ```

         You should see output similar to:

         ```
         Connected to Aptos devnet
         === Addresses ===
         Alice's address: 0x978c213990c4833df71548df7ce49d54c759d6b6d932de22b24d56060b7af2aa
         Bob's address: 0x7af2d6c93a2feafc9b69b5e8ad9d6b513b260f62f23f3a384a3a2e4a84694a9b

         === Funding accounts ===
         Accounts funded successfully

         === Initial Balances ===
         Alice: 100000000 octas
         Bob: 0 octas
         ```

         <Aside type="note">
           The addresses you see will be different from the ones shown here, as they are randomly generated each time.
         </Aside>
    </Steps>
  </TabItem>
</Tabs>

## 3. Building a Transaction

<Tabs>
  <TabItem label="TypeScript">
    Now that we have funded accounts, let's create a transaction to transfer coins from Alice to Bob. This is like filling out a form specifying what you want to send and to whom.

    <Steps>
      1. Understand transaction structure

         A transaction in Aptos has several key components:

         1. **Sender**: The account initiating the transaction (Alice)
         2. **Function**: The on-chain function to call (in this case, a coin transfer)
         3. **Arguments**: Data needed by the function (recipient address and amount)
         4. **Gas parameters**: Maximum gas amount and gas unit price
         5. **Expiration time**: When the transaction is no longer valid if not executed
         6. **Sequence number**: A counter that prevents replay attacks

         <Aside type="note">
           All data in Aptos transactions is serialized using Binary Canonical Serialization (BCS), a compact and deterministic format designed for blockchain use. The SDK handles this serialization for you.

           BCS ensures that transaction data is consistently encoded across different platforms and languages, which is critical for a blockchain where the same transaction might be processed by nodes running different implementations.
         </Aside>

      2. Build the transaction

         Let's add code to build a transaction that transfers 1000 octas from Alice to Bob:

         Add this code to your `main()` function:

         ```typescript filename="transaction.ts"
         // 1. Build the transaction
         console.log("\n=== 1. Building the transaction ===");
         const transaction = await aptos.transaction.build.simple({
           sender: alice.accountAddress,
           data: {
             function: "0x1::aptos_account::transfer",
             functionArguments: [bob.accountAddress, 1000], // Transfer 1000 octas
           },
         });
         console.log("Transaction built successfully");

         // Access transaction details from the raw transaction
         const rawTxn = transaction.rawTransaction;
         console.log(`Sender: ${rawTxn.sender}`);
         console.log(`Sequence Number: ${rawTxn.sequence_number}`);
         console.log(`Max Gas Amount: ${rawTxn.max_gas_amount}`);
         console.log(`Gas Unit Price: ${rawTxn.gas_unit_price}`);
         console.log(`Expiration Timestamp: ${new Date(Number(rawTxn.expiration_timestamp_secs) * 1000).toISOString()}`);
         ```

         <Aside type="note">
           The function `0x1::aptos_account::transfer` is a built-in function in the Aptos framework that transfers coins between accounts. The `0x1` prefix indicates it's part of the core framework. Behind the scenes, this function calls the [Coin Move module source code](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/coin.move) to perform the actual transfer.
         </Aside>
    </Steps>
  </TabItem>

  <TabItem label="Python">
    Now that we have funded accounts, let's create a transaction to transfer coins from Alice to Bob. This is like filling out a form specifying what you want to send and to whom.

    <Steps>
      1. Understand transaction structure

         A transaction in Aptos has several key components:

         1. **Sender**: The account initiating the transaction (Alice)
         2. **Function**: The on-chain function to call (in this case, a coin transfer)
         3. **Arguments**: Data needed by the function (recipient address and amount)
         4. **Gas parameters**: Maximum gas amount and gas unit price
         5. **Expiration time**: When the transaction is no longer valid if not executed
         6. **Sequence number**: A counter that prevents replay attacks

         <Aside type="note">
           All data in Aptos transactions is serialized using Binary Canonical Serialization (BCS), a compact and deterministic format designed for blockchain use. The SDK handles this serialization for you.

           BCS ensures that transaction data is consistently encoded across different platforms and languages, which is critical for a blockchain where the same transaction might be processed by nodes running different implementations.
         </Aside>

      2. Build the transaction

         Add the following code to your `main()` function to build a transaction that transfers 1000 octas from Alice to Bob:

         ```python filename="transaction.py"
         # 1. Build the transaction
         print("\n=== 1. Building the transaction ===")

         # Create the entry function payload
         # This specifies which function to call and with what arguments
         entry_function = EntryFunction.natural(
             "0x1::aptos_account",  # Module address and name
             "transfer",            # Function name
             [],                    # Type arguments (empty for this function)
             [
                 # Function arguments with their serialization type
                 TransactionArgument(bob.address(), Serializer.struct),  # Recipient address
                 TransactionArgument(1000, Serializer.u64),              # Amount to transfer (1000 octas)
             ],
         )

         # Get the chain ID for the transaction
         chain_id = await rest_client.chain_id()

         # Get the sender's current sequence number
         account_data = await rest_client.account(alice.address())
         sequence_number = int(account_data["sequence_number"])

         # Create the raw transaction with all required fields
         raw_transaction = RawTransaction(
             sender=alice.address(),                                    # Sender's address
             sequence_number=sequence_number,                           # Sequence number to prevent replay attacks
             payload=TransactionPayload(entry_function),                # The function to call
             max_gas_amount=2000,                                       # Maximum gas units to use
             gas_unit_price=100,                                        # Price per gas unit in octas
             expiration_timestamps_secs=int(time.time()) + 600,         # Expires in 10 minutes
             chain_id=chain_id,                                         # Chain ID to ensure correct network
         )

         print("Transaction built successfully")
         print(f"Sender: {raw_transaction.sender}")
         print(f"Sequence Number: {raw_transaction.sequence_number}")
         print(f"Max Gas Amount: {raw_transaction.max_gas_amount}")
         print(f"Gas Unit Price: {raw_transaction.gas_unit_price}")
         print(f"Expiration Timestamp: {time.ctime(raw_transaction.expiration_timestamps_secs)}")
         ```

         <Aside type="note">
           The function `0x1::aptos_account::transfer` is a built-in function in the Aptos framework that transfers coins between accounts. The `0x1` prefix indicates it's part of the core framework. Behind the scenes, this function calls the [Coin Move module source code](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/coin.move) to perform the actual transfer.

           The Python SDK uses several key components to construct transactions:

           - `EntryFunction.natural()` creates a callable Move function reference
           - `TransactionArgument` with `Serializer` types ensures proper BCS serialization
           - `TransactionPayload` wraps the entry function for inclusion in the transaction
           - `RawTransaction` combines all transaction parameters into a complete transaction

           This layered approach gives you fine-grained control over transaction construction.
         </Aside>
    </Steps>
  </TabItem>
</Tabs>

## 4. Simulating the Transaction

<Tabs>
  <TabItem label="TypeScript">
    Before submitting a transaction, it's wise to simulate it first to estimate the gas cost. This is like checking shipping costs before sending a package.

    <Steps>
      1. Simulate the transaction

         Add this code after building the transaction:

         ```typescript filename="transaction.ts"
         // 2. Simulate the transaction
         console.log("\n=== 2. Simulating the transaction ===");
         const [simulationResult] = await aptos.transaction.simulate.simple({
           signerPublicKey: alice.publicKey,
           transaction,
         });

         const gasUsed = parseInt(simulationResult.gas_used);
         const gasUnitPrice = parseInt(simulationResult.gas_unit_price);
         console.log(`Estimated gas units: ${gasUsed}`);
         console.log(`Estimated gas cost: ${gasUsed * gasUnitPrice} octas`);
         console.log(`Transaction would ${simulationResult.success ? "succeed" : "fail"}`);
         ```

         <Aside type="note">
           Gas is the computational fee paid to process transactions on the blockchain. The total cost is calculated as `gas_used √ó gas_unit_price`. During simulation, the blockchain executes the transaction in a temporary environment to estimate these costs without making permanent changes to the blockchain state. This helps you avoid failed transactions due to insufficient gas.
         </Aside>
    </Steps>
  </TabItem>

  <TabItem label="Python">
    Before submitting a transaction, it's wise to simulate it first to estimate the gas cost. This is like checking shipping costs before sending a package.

    <Steps>
      1. Simulate the transaction

         Add this code after building the transaction:

         ```python filename="transaction.py"
         # 2. Simulate the transaction
         print("\n=== 2. Simulating the transaction ===")

         # Create a BCS transaction for simulation
         # This doesn't actually submit the transaction to the blockchain
         simulation_transaction = await rest_client.create_bcs_transaction(alice, TransactionPayload(entry_function))

         # Simulate the transaction to estimate gas costs and check for errors
         simulation_result = await rest_client.simulate_transaction(simulation_transaction, alice)

         # Extract and display the simulation results
         gas_used = int(simulation_result[0]['gas_used'])
         gas_unit_price = int(simulation_result[0]['gas_unit_price'])
         success = simulation_result[0]['success']

         print(f"Estimated gas units: {gas_used}")
         print(f"Estimated gas cost: {gas_used * gas_unit_price} octas")
         print(f"Transaction would {'succeed' if success else 'fail'}")
         ```

         <Aside type="note">
           Gas is the computational fee paid to process transactions on the blockchain. The total cost is calculated as `gas_used √ó gas_unit_price`. During simulation, the blockchain executes the transaction in a temporary environment to estimate these costs without making permanent changes to the blockchain state. This helps you avoid failed transactions due to insufficient gas.
         </Aside>
    </Steps>
  </TabItem>
</Tabs>

## 5. Signing and Submitting the Transaction

<Tabs>
  <TabItem label="TypeScript">
    Now that we've built and simulated the transaction, we need to sign it with Alice's private key and submit it to the blockchain.

    <Steps>
      1. Sign the transaction

         Signing proves that Alice authorized this transaction:

         Add this code after simulating the transaction:

         ```typescript filename="transaction.ts"
         // 3. Sign the transaction
         console.log("\n=== 3. Signing the transaction ===");
         const senderAuthenticator = aptos.transaction.sign({
           signer: alice,
           transaction,
         });
         console.log("Transaction signed successfully");
         ```

         <Aside type="note">
           Digital signatures work like a personal seal or signature in the physical world. They prove that the transaction was authorized by the account owner (who has the private key) and haven't been tampered with.
         </Aside>

      2. Submit the transaction

         Add this code after signing the transaction to submit the signed transaction to the blockchain:

         ```typescript filename="transaction.ts"
         // 4. Submit the transaction
         console.log("\n=== 4. Submitting the transaction ===");
         const pendingTransaction = await aptos.transaction.submit.simple({
           transaction,
           senderAuthenticator,
         });
         console.log(`Transaction submitted with hash: ${pendingTransaction.hash}`);
         ```

         <Aside type="note">
           The transaction hash is a unique identifier for your transaction, similar to a tracking number for a package. When submitting a transaction, the Aptos blockchain performs several validation checks, including verifying the transaction signature and ensuring the sequence number hasn't been used before (preventing replay attacks). You can use the hash to check the status of your transaction on the [Aptos Explorer](https://explorer.aptoslabs.com/) or via the [REST API](/build/apis/fullnode-rest-api).
         </Aside>
    </Steps>
  </TabItem>

  <TabItem label="Python">
    Now that we've built and simulated the transaction, we need to sign it with Alice's private key and submit it to the blockchain.

    <Steps>
      1. Sign the transaction

         Signing proves that Alice authorized this transaction:

         Add this code after simulating the transaction:

         ```python filename="transaction.py"
         # 3. Sign the transaction
         print("\n=== 3. Signing the transaction ===")

         # Sign the raw transaction with the sender's private key
         # This creates a cryptographic signature that proves the sender authorized this transaction
         signed_transaction = await rest_client.create_bcs_signed_transaction(
             alice,                           # Account with the private key
             TransactionPayload(entry_function),  # The payload from our transaction
             sequence_number=sequence_number  # Use the same sequence number as before
         )

         print("Transaction signed successfully")
         # We can't easily extract the signature from the signed transaction object,
         # but we can confirm it was created
         ```

         <Aside type="note">
           Digital signatures work like a personal seal or signature in the physical world. They prove that the transaction was authorized by the account owner (who has the private key) and haven't been tampered with.
         </Aside>

      2. Submit the transaction

         Add this code after signing the transaction to submit the signed transaction to the blockchain:

         ```python filename="transaction.py"
         # 4. Submit the transaction
         print("\n=== 4. Submitting the transaction ===")

         # Submit the signed transaction to the blockchain
         # This broadcasts the transaction to the network for processing
         tx_hash = await rest_client.submit_bcs_transaction(signed_transaction)

         print(f"Transaction submitted with hash: {tx_hash}")
         ```

         <Aside type="note">
           The transaction hash is a unique identifier for your transaction, similar to a tracking number for a package. When submitting a transaction, the Aptos blockchain performs several validation checks, including verifying the transaction signature and ensuring the sequence number hasn't been used before (preventing replay attacks). You can use the hash to check the status of your transaction on the [Aptos Explorer](https://explorer.aptoslabs.com/) or via the [REST API](/build/apis/fullnode-rest-api).
         </Aside>
    </Steps>
  </TabItem>
</Tabs>

## 6. Waiting for Confirmation

<Tabs>
  <TabItem label="TypeScript">
    After submitting a transaction, we need to wait for it to be processed by the blockchain. This is like waiting for a package to be delivered.

    <Steps>
      1. Wait for transaction completion

         Add this code after submitting the transaction:

         ```typescript filename="transaction.ts"
         // 5. Wait for the transaction to complete
         console.log("\n=== 5. Waiting for transaction completion ===");
         const txnResult = await aptos.waitForTransaction({
           transactionHash: pendingTransaction.hash,
         });
         console.log(`Transaction completed with status: ${txnResult.success ? "SUCCESS" : "FAILURE"}`);

         // If you want to see more details about the transaction:
         console.log(`VM Status: ${txnResult.vm_status}`);
         console.log(`Gas used: ${txnResult.gas_used}`);
         ```

      2. Verify the results

         Add this code after waiting for the transaction to check the balances and confirm the transfer worked:

         ```typescript filename="transaction.ts"
         // Check final balances
         const aliceFinalBalance = await aptos.getAccountAPTAmount({
           accountAddress: alice.accountAddress,
         });
         const bobFinalBalance = await aptos.getAccountAPTAmount({
           accountAddress: bob.accountAddress,
         });

         console.log("\n=== Final Balances ===");
         console.log(`Alice: ${aliceFinalBalance} octas (spent ${aliceBalance - aliceFinalBalance} octas on transfer and gas)`);
         console.log(`Bob: ${bobFinalBalance} octas (received 1000 octas)`);
         ```

      3. Run the complete code

         ```shellscript filename="Terminal"
         npx ts-node transaction.ts
         ```

         You should see output similar to:

         ```
         Connected to Aptos devnet
         === Addresses ===
         Alice's address: 0x978c213990c4833df71548df7ce49d54c759d6b6d932de22b24d56060b7af2aa
         Bob's address: 0x7af2d6c93a2feafc9b69b5e8ad9d6b513b260f62f23f3a384a3a2e4a84694a9b

         === Funding accounts ===
         Accounts funded successfully

         === Initial Balances ===
         Alice: 100000000 octas
         Bob: 0 octas

         === 1. Building the transaction ===
         Transaction built successfully
         Sender: 0x978c213990c4833df71548df7ce49d54c759d6b6d932de22b24d56060b7af2aa
         Sequence Number: 0
         Max Gas Amount: 20000
         Gas Unit Price: 100
         Expiration Timestamp: 2025-03-05T22:59:21.000Z

         === 2. Simulating the transaction ===
         Estimated gas units: 146
         Estimated gas cost: 14600 octas
         Transaction would succeed

         === 3. Signing the transaction ===
         Transaction signed successfully

         === 4. Submitting the transaction ===
         Transaction submitted with hash: 0x3a8a3e34a1c64ad9d7636a3a827b7ec3bb12d73825b36fa06d425c5a3b42cccc

         === 5. Waiting for transaction completion ===
         Transaction completed with status: SUCCESS
         VM Status: Executed successfully
         Gas used: 146

         === Final Balances ===
         Alice: 99984400 octas (spent 15600 octas on transfer and gas)
         Bob: 1000 octas (received 1000 octas)
         ```

         <Aside type="note">
           Notice that Alice's balance decreased by more than 1000 octas. The extra amount is the gas fee paid to process the transaction. Behind the scenes, when checking balances, the SDK queries the CoinStore resource for the AptosCoin (`0x1::coin::CoinStore<0x1::aptos_coin::AptosCoin>`) and reads the current stored value. This demonstrates how the SDK abstracts away complex blockchain interactions into simple function calls.
         </Aside>
    </Steps>
  </TabItem>

  <TabItem label="Python">
    After submitting a transaction, we need to wait for it to be processed by the blockchain. This is like waiting for a package to be delivered.

    <Steps>
      1. Wait for transaction completion

         Add this code after submitting the transaction:

         ```python filename="transaction.py"
         # 5. Wait for the transaction to complete
         print("\n=== 5. Waiting for transaction completion ===")

         # Wait for the transaction to be processed by the blockchain
         # This polls the blockchain until the transaction is confirmed
         await rest_client.wait_for_transaction(tx_hash)

         # Get the transaction details to check its status
         transaction_details = await rest_client.transaction_by_hash(tx_hash)
         success = transaction_details["success"]
         vm_status = transaction_details["vm_status"]
         gas_used = transaction_details["gas_used"]

         print(f"Transaction completed with status: {'SUCCESS' if success else 'FAILURE'}")
         print(f"VM Status: {vm_status}")
         print(f"Gas used: {gas_used}")
         ```

      2. Verify the results

         Add this code after waiting for the transaction to check the balances and confirm the transfer worked:

         ```python filename="transaction.py"
         # Check final balances
         alice_final_balance = await rest_client.account_balance(alice.address())
         bob_final_balance = await rest_client.account_balance(bob.address())

         print("\n=== Final Balances ===")
         print(f"Alice: {alice_final_balance} octas (spent {alice_balance - alice_final_balance} octas on transfer and gas)")
         print(f"Bob: {bob_final_balance} octas (received 1000 octas)")
         ```

      3. Run the complete code

         ```shellscript filename="Terminal"
         python transaction.py
         ```

         You should see output similar to:

         ```
         Connected to Aptos devnet
         === Addresses ===
         Alice's address: 0x978c213990c4833df71548df7ce49d54c759d6b6d932de22b24d56060b7af2aa
         Bob's address: 0x7af2d6c93a2feafc9b69b5e8ad9d6b513b260f62f23f3a384a3a2e4a84694a9b

         === Funding accounts ===
         Accounts funded successfully

         === Initial Balances ===
         Alice: 100000000 octas
         Bob: 0 octas

         === 1. Building the transaction ===
         Transaction built successfully
         Sender: 0x978c213990c4833df71548df7ce49d54c759d6b6d932de22b24d56060b7af2aa
         Sequence Number: 0
         Max Gas Amount: 2000
         Gas Unit Price: 100
         Expiration Timestamp: Wed Mar 05 22:59:21 2025

         === 2. Simulating the transaction ===
         Estimated gas units: 146
         Estimated gas cost: 14600 octas
         Transaction would succeed

         === 3. Signing the transaction ===
         Transaction signed successfully

         === 4. Submitting the transaction ===
         === 3. Signing the transaction ===
         Transaction signed successfully

         === 4. Submitting the transaction ===
         Transaction submitted with hash: 0x3a8a3e34a1c64ad9d7636a3a827b7ec3bb12d73825b36fa06d425c5a3b42cccc

         === 5. Waiting for transaction completion ===
         Transaction completed with status: SUCCESS
         VM Status: Executed successfully
         Gas used: 146

         === Final Balances ===
         Alice: 99984400 octas (spent 15600 octas on transfer and gas)
         Bob: 1000 octas (received 1000 octas)
         ```

         <Aside type="note">
           Notice that Alice's balance decreased by more than 1000 octas. The extra amount is the gas fee paid to process the transaction. Behind the scenes, when checking balances, the SDK queries the CoinStore resource for the AptosCoin (`0x1::coin::CoinStore<0x1::aptos_coin::AptosCoin>`) and reads the current stored value.
         </Aside>
    </Steps>
  </TabItem>
</Tabs>

## 7. (Optional) Explore Your Transaction On-Chain

Now that you've successfully executed a transaction, you can explore it on the Aptos Explorer. This will help you understand how transactions are recorded on the blockchain and what information is publicly available.

<Steps>
  1. Copy your transaction hash

     From your terminal output, copy the transaction hash that was printed after submission. It looks something like this:

     ```
     Transaction submitted with hash: 0x3a8a3e34a1c64ad9d7636a3a827b7ec3bb12d73825b36fa06d425c5a3b42cccc
     ```

  2. Open the Aptos Explorer

     Go to the [Aptos Explorer](https://explorer.aptoslabs.com/?network=devnet).

  3. Ensure you are on Devnet network

     Look for "Devnet" in the top right corner, or switch networks by clicking the dropdown and selecting Devnet.

     ![Switching to Devnet network in Aptos Explorer](~/images/screenshots/explorer_devnet.png)

  4. Search for your transaction

     Paste your transaction hash into the search bar in the middle of the page.

     <Aside type="caution">
       Do not press enter! There is a known bug where searching with Enter does not work.
     </Aside>

  5. View the transaction details

     Wait for the results to appear, then click on the transaction hash to view its details.

     You should see information about your transaction, including:

     - Status (should be "Success")
     - Timestamp
     - Gas used
     - Sender and recipient addresses
     - Amount transferred

  6. Explore further

     From the transaction details page, you can:

     - Click on the sender or recipient addresses to view their account details
     - See the exact changes made to the blockchain state
     - View the transaction payload and arguments

     <Aside type="note">
       The Explorer is a powerful tool for debugging transactions and understanding blockchain activity. Developers frequently use it to verify their transactions executed as expected and to investigate any issues.
     </Aside>
</Steps>

## 8. Next Steps

Congratulations! You've successfully created and executed your first transaction on the Aptos blockchain. Here are some suggestions for what to explore next:

**Learn about more complex transactions**:

- [Multi-Agent Signatures](/build/sdks/ts-sdk/building-transactions/multi-agent-transactions) - Transactions requiring multiple signers
- [Sponsoring Transactions](/build/sdks/ts-sdk/building-transactions/sponsoring-transactions) - Having another account pay gas fees
- [Batching Transactions](/build/sdks/ts-sdk/building-transactions/batching-transactions) - Sending multiple transactions efficiently

<Aside type="note">
  The above links are for the Typescript SDK but the principles are the same if you are using Python or Rust.
</Aside>

**Explore smart contracts or account basics**:

- [Your First Move Module](/build/guides/first-move-module) - Create your own smart contract
- [Account Basics](/network/blockchain/accounts)

[Join the Aptos Discord](https://discord.gg/aptoslabs) and share what you're building!

## Full Code Sample

The complete code samples below combine all the snippets we've covered in this tutorial:

<Tabs>
  <TabItem label="TypeScript">
    ```typescript filename="transaction.ts"
    import { Account, Aptos, AptosConfig, Network } from "@aptos-labs/ts-sdk";

    async function main() {
      // Initialize the Aptos client
      const config = new AptosConfig({ network: Network.DEVNET });
      const aptos = new Aptos(config);

      console.log("Connected to Aptos devnet");

      // More code will go here
      // Generate two accounts
      const alice = Account.generate();
      const bob = Account.generate();

      console.log("=== Addresses ===");
      console.log(`Alice's address: ${alice.accountAddress}`);
      console.log(`Bob's address: ${bob.accountAddress}`);

      // Fund the accounts with test APT from the devnet faucet
      console.log("\n=== Funding accounts ===");
      await aptos.fundAccount({
        accountAddress: alice.accountAddress,
        amount: 100_000_000, // 1 APT = 100,000,000 octas
      });
      await aptos.fundAccount({
        accountAddress: bob.accountAddress,
        amount: 0, // Bob starts with 0 APT
      });
      console.log("Accounts funded successfully");

      // Check initial balances
      const aliceBalance = await aptos.getAccountAPTAmount({
        accountAddress: alice.accountAddress,
      });
      const bobBalance = await aptos.getAccountAPTAmount({
        accountAddress: bob.accountAddress,
      });

      console.log("\n=== Initial Balances ===");
      console.log(`Alice: ${aliceBalance} octas`);
      console.log(`Bob: ${bobBalance} octas`);

      // 1. Build the transaction
      console.log("\n=== 1. Building the transaction ===");
      const transaction = await aptos.transaction.build.simple({
        sender: alice.accountAddress,
        data: {
          function: "0x1::aptos_account::transfer",
          functionArguments: [bob.accountAddress, 1000], // Transfer 1000 octas
        },
      });
      console.log("Transaction built successfully");
      // Use type assertion to bypass TypeScript's type checking
      const txnAny = transaction as any;
      console.log(`Sender: ${alice.accountAddress}`); // Use the known sender address
      console.log(`Sequence Number: ${txnAny.sequenceNumber || "N/A"}`);
      console.log(`Max Gas Amount: ${txnAny.maxGasAmount || "N/A"}`);
      console.log(`Gas Unit Price: ${txnAny.gasUnitPrice || "N/A"}`);
      console.log(
        `Expiration Timestamp: ${new Date(
          Number(txnAny.expirationTimestampSecs || 0) * 1000
        ).toISOString()}`
      );

      // 2. Simulate the transaction
      console.log("\n=== 2. Simulating the transaction ===");
      const [simulationResult] = await aptos.transaction.simulate.simple({
        signerPublicKey: alice.publicKey,
        transaction,
      });

      console.log(`Estimated gas units: ${simulationResult.gas_used}`);
      console.log(
        `Estimated gas cost: ${
          Number(simulationResult.gas_used) * Number(simulationResult.gas_unit_price)
        } octas`
      );
      console.log(
        `Transaction would ${simulationResult.success ? "succeed" : "fail"}`
      );

      // 3. Sign the transaction
      console.log("\n=== 3. Signing the transaction ===");
      const senderAuthenticator = aptos.transaction.sign({
        signer: alice,
        transaction,
      });
      console.log("Transaction signed successfully");
      // Use type assertion to bypass TypeScript's type checking
      const authAny = senderAuthenticator as any;
      const signatureStr = typeof authAny.signature === 'string'
        ? authAny.signature
        : JSON.stringify(authAny.signature || '');
      console.log(`Signature: ${signatureStr.slice(0, 20)}...`);

      // 4. Submit the transaction
      console.log("\n=== 4. Submitting the transaction ===");
      const pendingTransaction = await aptos.transaction.submit.simple({
        transaction,
        senderAuthenticator,
      });
      console.log(`Transaction submitted with hash: ${pendingTransaction.hash}`);

      // 5. Wait for the transaction to complete
      console.log("\n=== 5. Waiting for transaction completion ===");
      const txnResult = await aptos.waitForTransaction({
        transactionHash: pendingTransaction.hash,
      });
      console.log(
        `Transaction completed with status: ${
          txnResult.success ? "SUCCESS" : "FAILURE"
        }`
      );

      // If you want to see more details about the transaction:
      console.log(`VM Status: ${txnResult.vm_status}`);
      console.log(`Gas used: ${txnResult.gas_used}`);

      // Check final balances
      const aliceFinalBalance = await aptos.getAccountAPTAmount({
        accountAddress: alice.accountAddress,
      });
      const bobFinalBalance = await aptos.getAccountAPTAmount({
        accountAddress: bob.accountAddress,
      });

      console.log("\n=== Final Balances ===");
      console.log(
        `Alice: ${aliceFinalBalance} octas (spent ${
          aliceBalance - aliceFinalBalance
        } octas on transfer and gas)`
      );
      console.log(`Bob: ${bobFinalBalance} octas (received 1000 octas)`);
    }

    main().catch(console.error);
    ```
  </TabItem>

  <TabItem label="Python">
    ```python filename="transaction.py"
    import asyncio
    from aptos_sdk.account import Account
    from aptos_sdk.async_client import FaucetClient, RestClient
    from aptos_sdk.transactions import EntryFunction, TransactionPayload, TransactionArgument, RawTransaction
    from aptos_sdk.bcs import Serializer
    import time

    # Network configuration
    NODE_URL = "https://fullnode.devnet.aptoslabs.com/v1"
    FAUCET_URL = "https://faucet.devnet.aptoslabs.com"

    async def main():
        # Initialize the clients
        rest_client = RestClient(NODE_URL)
        faucet_client = FaucetClient(FAUCET_URL, rest_client)

        print("Connected to Aptos devnet")

        # Generate two accounts
        alice = Account.generate()
        bob = Account.generate()

        print("=== Addresses ===")
        print(f"Alice's address: {alice.address()}")
        print(f"Bob's address: {bob.address()}")
            # More code will go here
            # Fund the accounts with test APT from the devnet faucet
        print("\n=== Funding accounts ===")
        alice_amount = 100_000_000  # 1 APT = 100,000,000 octas
        bob_amount = 0  # Bob starts with 0 APT

        await faucet_client.fund_account(alice.address(), alice_amount)
        await faucet_client.fund_account(bob.address(), bob_amount)
        print("Accounts funded successfully")

        # Check initial balances
        alice_balance = await rest_client.account_balance(alice.address())
        bob_balance = await rest_client.account_balance(bob.address())

        print("\n=== Initial Balances ===")
        print(f"Alice: {alice_balance} octas")
        print(f"Bob: {bob_balance} octas")

        # 1. Build the transaction
        print("\n=== 1. Building the transaction ===")

        # Create the entry function payload
        # This specifies which function to call and with what arguments
        entry_function = EntryFunction.natural(
            "0x1::aptos_account",  # Module address and name
            "transfer",            # Function name
            [],                    # Type arguments (empty for this function)
            [
                # Function arguments with their serialization type
                TransactionArgument(bob.address(), Serializer.struct),  # Recipient address
                TransactionArgument(1000, Serializer.u64),              # Amount to transfer (1000 octas)
            ],
        )

        # Get the chain ID for the transaction
        chain_id = await rest_client.chain_id()

        # Get the sender's current sequence number
        account_data = await rest_client.account(alice.address())
        sequence_number = int(account_data["sequence_number"])

        # Create the raw transaction with all required fields
        raw_transaction = RawTransaction(
            sender=alice.address(),                                    # Sender's address
            sequence_number=sequence_number,                           # Sequence number to prevent replay attacks
            payload=TransactionPayload(entry_function),                # The function to call
            max_gas_amount=2000,                                       # Maximum gas units to use
            gas_unit_price=100,                                        # Price per gas unit in octas
            expiration_timestamps_secs=int(time.time()) + 600,         # Expires in 10 minutes
            chain_id=chain_id,                                         # Chain ID to ensure correct network
        )

        print("Transaction built successfully")
        print(f"Sender: {raw_transaction.sender}")
        print(f"Sequence Number: {raw_transaction.sequence_number}")
        print(f"Max Gas Amount: {raw_transaction.max_gas_amount}")
        print(f"Gas Unit Price: {raw_transaction.gas_unit_price}")
        print(f"Expiration Timestamp: {time.ctime(raw_transaction.expiration_timestamps_secs)}")

        # 2. Simulate the transaction
        print("\n=== 2. Simulating the transaction ===")

        # Create a BCS transaction for simulation
        # This doesn't actually submit the transaction to the blockchain
        simulation_transaction = await rest_client.create_bcs_transaction(alice, TransactionPayload(entry_function))

        # Simulate the transaction to estimate gas costs and check for errors
        simulation_result = await rest_client.simulate_transaction(simulation_transaction, alice)

        # Extract and display the simulation results
        gas_used = int(simulation_result[0]['gas_used'])
        gas_unit_price = int(simulation_result[0]['gas_unit_price'])
        success = simulation_result[0]['success']

        print(f"Estimated gas units: {gas_used}")
        print(f"Estimated gas cost: {gas_used * gas_unit_price} octas")
        print(f"Transaction would {'succeed' if success else 'fail'}")

        # 3. Sign the transaction
        print("\n=== 3. Signing the transaction ===")

        # Sign the raw transaction with the sender's private key
        # This creates a cryptographic signature that proves the sender authorized this transaction
        signed_transaction = await rest_client.create_bcs_signed_transaction(
            alice,                                  # Account with the private key
            TransactionPayload(entry_function),     # The payload from our transaction
            sequence_number=sequence_number         # Use the same sequence number as before
        )

        print("Transaction signed successfully")
        # We can't easily extract the signature from the signed transaction object,
        # but we can confirm it was created

        # 4. Submit the transaction
        print("\n=== 4. Submitting the transaction ===")

        # Submit the signed transaction to the blockchain
        # This broadcasts the transaction to the network for processing
        tx_hash = await rest_client.submit_bcs_transaction(signed_transaction)

        print(f"Transaction submitted with hash: {tx_hash}")

        # 5. Wait for the transaction to complete
        print("\n=== 5. Waiting for transaction completion ===")

        # Wait for the transaction to be processed by the blockchain
        # This polls the blockchain until the transaction is confirmed
        await rest_client.wait_for_transaction(tx_hash)

        # Get the transaction details to check its status
        transaction_details = await rest_client.transaction_by_hash(tx_hash)
        success = transaction_details["success"]
        vm_status = transaction_details["vm_status"]
        gas_used = transaction_details["gas_used"]

        print(f"Transaction completed with status: {'SUCCESS' if success else 'FAILURE'}")
        print(f"VM Status: {vm_status}")
        print(f"Gas used: {gas_used}")

        # Check final balances
        alice_final_balance = await rest_client.account_balance(alice.address())
        bob_final_balance = await rest_client.account_balance(bob.address())

        print("\n=== Final Balances ===")
        print(f"Alice: {alice_final_balance} octas (spent {alice_balance - alice_final_balance} octas on transfer and gas)")
        print(f"Bob: {bob_final_balance} octas (received 1000 octas)")
    if __name__ == "__main__":
        asyncio.run(main())
    ```
  </TabItem>
</Tabs>

# Account Key Rotation

> Advanced security feature for rotating account keys to maintain control while changing authentication credentials.

import { Aside, Steps } from '@astrojs/starlight/components';

<Aside type="caution">
  Account key rotation is an advanced feature that should be used with caution.
  Most users will never need to use this feature.
</Aside>

Aptos Move accounts have a public address, an authentication key, a public key,
and a private key. The public address is permanent, always matching the
account's initial authentication key, which is derived from the original private
key.

The Aptos account model facilitates the unique ability to rotate an account's
private key. Since an account's address is the _initial_ authentication key, the
ability to sign for an account can be transferred to another private key without
changing its public address.

In this guide, we show examples of how to rotate an account's authentication key
using the CLI and few of the various Aptos SDKs.

Here are the installation links for the SDKs we will cover in this example:

- [Aptos CLI](/build/cli)
- [Typescript SDK](/build/sdks/ts-sdk)
- [Python SDK](/build/sdks/python-sdk)

<Aside type="caution">
  Some of the following examples use private keys. Do not share your private
  keys with anyone.
</Aside>

## Proven and unproven key rotations

The onchain logic for key rotation is implemented through two Move APIs:

1. [`account::rotate_authentication_key`], which executes a "proven" rotation.
2. [`account::rotate_authentication_key_call`], which executes an "unproven"
   rotation.

### Proven key rotations

The [`account::rotate_authentication_key`] API requires a signed
[`account::RotationProofChallenge`], which proves that the rotation operation is
approved by the private key from both before _and_ after the operation. When the
operation is successful, the [`account::OriginatingAddress`] table is updated
with an entry that maps from the new authentication key to the corresponding
account address.

The [`account::OriginatingAddress`] table is a reverse lookup table that allows
users to query an account address associated with a given authentication key,
and only allows for one entry per authentication key. Hence the requirement of a
signed [`account::RotationProofChallenge`] to ensure that a malicious actor does
not rotate an account's authentication key to a key that is already in the
table, as this attack would prevent lookup of the valid originating address that
the holder of an authentication key had previously approved.

Notably, the [`account::OriginatingAddress`] table is _only_ updated upon key
rotation, not upon standard account generation. This means that with proven key
rotations, a given private key can theoretically authenticate up to two accounts
at the same time:

1. The account address derived from the private key during standard account
   generation, assuming the account has not undergone any key rotations.
2. A second arbitrary address, which has had its authentication key rotated to
   the given private key.

However, it is considered best practice to only authenticate _one_ account with
a given private key at a time, because whenever the
[`account::OriginatingAddress`] table is updated, the underlying logic first
checks if the rotating account's initial authentication key is in the table, and
if so, verifies that the rotating account's address is the one mapped to in the
table.

This means that if an arbitrary account's authentication key is rotated to
a given private key, the standard account whose address is originally derived
from the private key will not be able to execute its first authentication key
rotation while the associated authentication key is mapped to a second arbitrary
account address in the [`account::OriginatingAddress`] table, because this
operation would fail the check that the rotating account's address is the one
mapped to in the table (since the table is only updated during rotation, not
upon standard account generation).

To prevent this issue and ensure best practices are followed, you can always run
[`account::set_originating_address`] after generating a new account (see below
CLI tutorial).

### Unproven key rotations

Unlike [`account::rotate_authentication_key`], the
[`account::rotate_authentication_key_call`] does _not_ require a signed
[`account::RotationProofChallenge`]. This means that the operation is not proven
in the sense the private key from _after_ the operation has approved the
key rotation. Hence the [`account::OriginatingAddress`] table is _not_ updated
for unproven key rotations, and there is thus no restriction on the number of
accounts that can be authenticated with a given private key. Note that the
`aptos` CLI does not currently support unproven key rotations.

<Aside type="note" emoji="üß†">
  The [`account::rotate_authentication_key_call`] was introduced to support
  non-standard key algorithms, like passkeys, which cannot produce proofs of
  knowledge during rotation operations.
</Aside>

While it is technically possible to authenticate as many accounts as you want
with a given authentication key via unproven key rotations, it is not considered
best practice because this approach does not ensure one-to-one mapping.

If you execute an unproven key rotation, it is suggested that you follow up with
[`account::set_originating_address`] to ensure a one-to-one mapping from
authentication key to account address for ease of originating address lookup
(see below CLI tutorial).

## Key rotation with the Aptos CLI

<Steps>
  1. Start a localnet

     Start a localnet:

     ```shellscript filename="Terminal"
     aptos node run-localnet
     ```

     The localnet is ready when it prints out:

     ```shellscript filename="Terminal"
     Applying post startup steps...

     Setup is complete, you can now use the localnet!
     ```

     <Aside type="note" emoji="üß†">
       If you are on a UNIX-like system, the following command can be used to start a
       fresh localnet as a background process:

       ```shellscript filename="Terminal"
       mkdir -p localnet-data
       aptos node run-localnet \
           --assume-yes \
           --test-dir localnet-data \
           --force-restart &
       export LOCALNET_PID=$!
       ```

       You can then stop the localnet at any point with the following command:

       ```shellscript filename="Terminal"
       kill $LOCALNET_PID
       ```
     </Aside>

  2. Generate a private key

     Create a private key corresponding to an authentication key, and thus initial
     account address, that starts with the vanity prefix `0xaaa`:

     ```shellscript filename="Terminal"
     aptos key generate \
         --assume-yes \
         --output-file private-key-a \
         --vanity-prefix 0xaaa
     ```

     <details>
       <summary>Example output</summary>

       ```shellscript filename="Terminal"
       {
         "Result": {
           "Account Address:": "0xaaa5131b4d3fcef8d33ee465c4ee65727e36039f283455be87b1164200572e5b",
           "PublicKey Path": "private-key-a.pub",
           "PrivateKey Path": "private-key-a"
         }
       }
       ```
     </details>

     This will generate two files:

     1. A private key at `private-key-a`.
     2. A public key at `private-key-a.pub`.

     Since there is not yet an account associated with the authentication key, the
     following command should fail with a corresponding message:

     ```shellscript filename="Terminal"
     aptos account lookup-address \
         --public-key-file private-key-a.pub \
         --url http://localhost:8080
     ```

     <details>
       <summary>Example output</summary>

       ```shellscript filename="Terminal"
       {
         "Error": "API error: API error Error(AccountNotFound): Account not found by Address(0xaaafb224eb00e4d0ef520ce02038ede850893622562a4189b7f6e5d94454ccd9) and Ledger version(1206)"
       }
       ```
     </details>

  3. Initialize a profile

     Use the private key to initialize `test-profile-1` on the localnet:

     ```shellscript filename="Terminal"
     aptos init \
         --assume-yes \
         --network local \
         --private-key-file private-key-a \
         --profile test-profile-1
     ```

     <details>
       <summary>Example output</summary>

       ```shellscript filename="Terminal"
       Configuring for profile test-profile-1
       Configuring for network Local
       Using command line argument for private key
       Account 0xaaa5131b4d3fcef8d33ee465c4ee65727e36039f283455be87b1164200572e5b doesn\'t exist, creating it and funding it with 100000000 Octas
       Account 0xaaa5131b4d3fcef8d33ee465c4ee65727e36039f283455be87b1164200572e5b funded successfully

       ---
       Aptos CLI is now set up for account 0xaaa5131b4d3fcef8d33ee465c4ee65727e36039f283455be87b1164200572e5b as profile test-profile-1!  Run `aptos --help` for more information about commands
       {
         "Result": "Success"
       }
       ```
     </details>

     Note that you can always view the profile with:

     ```shellscript filename="Terminal"
     aptos config show-profiles --profile test-profile-1
     ```

     <details>
       <summary>Example output</summary>

       ```shellscript filename="Terminal"
       {
         "Result": {
           "test-profile-1": {
             "has_private_key": true,
             "public_key": "0xe0bfe46f41c5be40e7a068e8dff4d6016126b226d947a39262f5b2347217a7e3",
             "account": "aaa5131b4d3fcef8d33ee465c4ee65727e36039f283455be87b1164200572e5b",
             "rest_url": "http://localhost:8080",
             "faucet_url": "http://localhost:8081"
           }
         }
       }
       ```
     </details>

     However, this will not show the private key, which is hidden by default. If you
     would like to show the private key:

     ```shellscript filename="Terminal"
     aptos config show-private-key --profile test-profile-1
     ```

     <details>
       <summary>Example output</summary>

       ```shellscript filename="Terminal"
       {
         "Result": "0xcc3b0c38ad99e171263a7af930464313d1fb105d0d8e6a4b13f9b1140563a7dd"
       }
       ```
     </details>

  4. Look up address

     Now that there is an onchain account associated with the authentication key,
     you can look up the account address using `aptos account lookup-address`:

     ```shellscript filename="Terminal"
     aptos account lookup-address \
         --public-key-file private-key-a.pub \
         --url http://localhost:8080
     ```

     <details>
       <summary>Example output</summary>

       ```shellscript filename="Terminal"
       {
         "Result": "aaa5131b4d3fcef8d33ee465c4ee65727e36039f283455be87b1164200572e5b"
       }
       ```
     </details>

     Store this address in a shell variable:

     ```shellscript filename="Terminal"
     ADDRESS_A=aaa...
     ```

     <Aside type="note" emoji="üß†">
       If you are using a UNIX-like machine that has `jq`, you can easily store the account address via:

       ```shellscript filename="Terminal"
       export ADDRESS_A=$(
           aptos account lookup-address \
               --public-key-file private-key-a.pub \
               --url http://localhost:8080 \
                   | jq -r '.Result'
       )
       echo $ADDRESS_A
       ```
     </Aside>

  5. Look up authentication key

     Recall that the address of an account is identical to its authentication key
     when it is initially created, which means that the account address `aaa...` is
     identical to the account's authentication key:

     ```shellscript filename="Terminal"
     aptos move view \
         --args address:$ADDRESS_A \
         --function-id 0x1::account::get_authentication_key \
         --url http://localhost:8080
     ```

     <details>
       <summary>Example output</summary>

       ```shellscript filename="Terminal"
       {
         "Result": [
           "0xaaa5131b4d3fcef8d33ee465c4ee65727e36039f283455be87b1164200572e5b"
         ]
       }
       ```
     </details>

     Hence, store the authentication key in a shell variable:

     ```shellscript
     AUTH_KEY_A=$ADDRESS_A
     ```

     Note, however, since the account has not yet had its authentication key rotated,
     there is no corresponding entry in the [`account::OriginatingAddress`] table:

     ```shellscript filename="Terminal"
     aptos move view \
         --args address:$AUTH_KEY_A \
         --function-id 0x1::account::originating_address \
         --url http://localhost:8080
     ```

     <details>
       <summary>Example output</summary>

       ```shellscript filename="Terminal"
       {
         "Result": [
           {
             "vec": []
           }
         ]
       }
       ```
     </details>

  6. Set originating address

     To ensure an entry in the [`account::OriginatingAddress`] table for this new account,
     you can run [`account::set_originating_address`]:

     ```shellscript filename="Terminal"
     aptos move run \
         --assume-yes \
         --function-id 0x1::account::set_originating_address \
         --profile test-profile-1
     ```

     <details>
       <summary>Example output</summary>

       ```shellscript filename="Terminal"
       {
         "Result": {
           "transaction_hash": "0x216992ef37a3c2f42aa9f8fed8f94d9f945a00e952dfe96b46123bb5c387ab6c",
           "gas_used": 444,
           "gas_unit_price": 100,
           "sender": "aaa5131b4d3fcef8d33ee465c4ee65727e36039f283455be87b1164200572e5b",
           "sequence_number": 0,
           "success": true,
           "timestamp_us": 1717809169531279,
           "version": 3268,
           "vm_status": "Executed successfully"
         }
       }
       ```
     </details>

     Then you should see an entry in the [`account::OriginatingAddress`] table:

     ```shellscript filename="Terminal"
     aptos move view \
         --args address:$AUTH_KEY_A \
         --function-id 0x1::account::originating_address \
         --url http://localhost:8080
     ```

     <details>
       <summary>Example output</summary>

       ```shellscript filename="Terminal"
       {
         "Result": [
           {
             "vec": [
               "0xaaa5131b4d3fcef8d33ee465c4ee65727e36039f283455be87b1164200572e5b"
             ]
           }
         ]
       }
       ```
     </details>

  7. Rotate authentication key

     Generate a new private key:

     ```shellscript filename="Terminal"
     aptos key generate \
         --assume-yes \
         --output-file private-key-b \
         --vanity-prefix 0xbbb
     ```

     <details>
       <summary>Example output</summary>

       ```shellscript filename="Terminal"
       {
         "Result": {
           "PrivateKey Path": "private-key-b",
           "Account Address:": "0xbbbdb12f4fa23b8fe8711b77f4ab7108f3a22077c5dfe787eed3d048a0b82734",
           "PublicKey Path": "private-key-b.pub"
         }
       }
       ```
     </details>

     Rotate the authentication key of the existing onchain account to the new
     private key:

     ```shellscript filename="Terminal"
     aptos account rotate-key \
         --assume-yes \
         --new-private-key-file private-key-b \
         --profile test-profile-1 \
         --save-to-profile test-profile-2
     ```

     <details>
       <summary>Example output</summary>

       ```shellscript filename="Terminal"
       {
         "Result": {
           "message": "Saved new profile test-profile-2",
           "transaction": {
             "transaction_hash": "0xe561b710390511203511d15eee6f019a2e43ba32f8e3b7ce6bf812232e3bd27f",
             "gas_used": 449,
             "gas_unit_price": 100,
             "sender": "aaa8dc0f5e7a6e820f7b1906d99864412b12274ed259ad06bc2c2d8ee7b51e51",
             "sequence_number": 1,
             "success": true,
             "timestamp_us": 1717810059696079,
             "version": 1109,
             "vm_status": "Executed successfully"
           }
         }
       }
       ```
     </details>

  8. Compare profiles

     Compare `test-profile-1` (which is now stale) with `test-profile-2` (which is
     current) noting that the public key has changed, but not the account address:

     ```shellscript filename="Terminal"
     aptos config show-profiles --profile test-profile-1
     aptos config show-profiles --profile test-profile-2
     ```

     <details>
       <summary>Example output</summary>

       ```shellscript filename="Terminal"
       {
         "Result": {
           "test-profile-1": {
             "has_private_key": true,
             "public_key": "0xb517173e68f4116e99c7fa1677058a6ee786a3b9e12447000db7fd85ab99dbdd",
             "account": "aaa8dc0f5e7a6e820f7b1906d99864412b12274ed259ad06bc2c2d8ee7b51e51",
             "rest_url": "http://localhost:8080",
             "faucet_url": "http://localhost:8081"
           }
         }
       }
       {
         "Result": {
           "test-profile-2": {
             "has_private_key": true,
             "public_key": "0xadc3dd795fdd8569f59dc7b9900b38a5d7b95348b815de4eb5f00e2c2da07916",
             "account": "aaa8dc0f5e7a6e820f7b1906d99864412b12274ed259ad06bc2c2d8ee7b51e51",
             "rest_url": "http://localhost:8080",
             "faucet_url": "http://localhost:8081"
           }
         }
       }
       ```
     </details>

     Lookup the new authentication key:

     ```shellscript filename="Terminal"
     aptos move view \
         --args address:$ADDRESS_A \
         --function-id 0x1::account::get_authentication_key \
         --url http://localhost:8080
     ```

     <details>
       <summary>Example output</summary>

       ```shellscript filename="Terminal"
       {
         "Result": [
           "0xbbbdb12f4fa23b8fe8711b77f4ab7108f3a22077c5dfe787eed3d048a0b82734"
         ]
       }
       ```
     </details>

     Store the authentication key in a shell variable:

     ```shellscript filename="Terminal"
     AUTH_KEY_B=bbb...
     ```

     <Aside type="note" emoji="üß†">
       If you are using a UNIX-like machine that has `jq`, you can easily store the authentication key via:

       ```shellscript filename="Terminal"
       export AUTH_KEY_B=$(
           aptos move view \
               --args address:$ADDRESS_A \
               --function-id 0x1::account::get_authentication_key \
               --url http://localhost:8080 \
               | jq -r '.Result[0]'
       )
       echo $AUTH_KEY_B
       ```
     </Aside>

  9. Look up originating addresses

     Check the originating address for the new authentication key:

     ```shellscript filename="Terminal"
     aptos move view \
         --args address:$AUTH_KEY_B \
         --function-id 0x1::account::originating_address \
         --url http://localhost:8080
     ```

     <details>
       <summary>Example output</summary>

       ```shellscript filename="Terminal"
       {
         "Result": [
           {
             "vec": [
               "0xaaa8dc0f5e7a6e820f7b1906d99864412b12274ed259ad06bc2c2d8ee7b51e51"
             ]
           }
         ]
       }
       ```
     </details>

     Check the originating address for the old authentication key:

     ```shellscript filename="Terminal"
     aptos move view \
         --args address:$AUTH_KEY_A \
         --function-id 0x1::account::originating_address \
         --url http://localhost:8080
     ```

     <details>
       <summary>Example output</summary>

       ```shellscript filename="Terminal"
       {
         "Result": [
           {
             "vec": []
           }
         ]
       }
       ```
     </details>

  10. Attempt invalid rotation (same key)

      Attempt an invalid rotation where the current authentication key is identical
      to the new authentication key:

      ```shellscript filename="Terminal"
      aptos account rotate-key \
          --assume-yes \
          --new-private-key-file private-key-b \
          --profile test-profile-2 \
          --skip-saving-profile
      ```

      <details>
        <summary>Example output</summary>

        ```shellscript filename="Terminal"
        {
          "Error": "Invalid arguments: New public key cannot be the same as the current public key"
        }
        ```
      </details>

  11. Attempt invalid rotation (new key already mapped)

      Create another private key:

      ```shellscript filename="Terminal"
      aptos key generate \
          --assume-yes \
          --output-file private-key-c \
          --vanity-prefix 0xccc
      ```

      <details>
        <summary>Example output</summary>

        ```shellscript filename="Terminal"
        {
          "Result": {
            "PrivateKey Path": "private-key-c",
            "PublicKey Path": "private-key-c.pub",
            "Account Address:": "0xccc79d46b2963cb87f2ff32c51eb6c6361e8aa108d334d3183c3016389542958"
          }
        }
        ```
      </details>

      Initialize a new profile:

      ```shellscript filename="Terminal"
      aptos init \
          --assume-yes \
          --network local \
          --private-key-file private-key-c \
          --profile test-profile-3
      ```

      <details>
        <summary>Example output</summary>

        ```shellscript filename="Terminal"
        Configuring for profile test-profile-3
        Configuring for network Local
        Using command line argument for private key
        Account 0xccc79d46b2963cb87f2ff32c51eb6c6361e8aa108d334d3183c3016389542958 doesn\'t exist, creating it and funding it with 100000000 Octas
        Account 0xccc79d46b2963cb87f2ff32c51eb6c6361e8aa108d334d3183c3016389542958 funded successfully

        ---
        Aptos CLI is now set up for account 0xccc79d46b2963cb87f2ff32c51eb6c6361e8aa108d334d3183c3016389542958 as profile test-profile-3!  Run `aptos --help` for more information about commands
        {
          "Result": "Success"
        }
        ```
      </details>

      Attempt an invalid rotation where the new authentication key is already mapped:

      ```shellscript filename="Terminal"
      aptos account rotate-key \
          --assume-yes \
          --max-gas 100000 \
          --new-private-key-file private-key-b \
          --profile test-profile-3 \
          --skip-saving-profile
      ```

      (`--max-gas` is specified here to skip local simulation, which does not print
      out as descriptive of an error as the actual transaction.)

      <details>
        <summary>Example output</summary>

        ```shellscript filename="Terminal"
        {
          "Error": "API error: Unknown error Transaction committed on chain, but failed execution: Move abort in 0x1::account: ENEW_AUTH_KEY_ALREADY_MAPPED(0x10015): The new authentication key already has an entry in the `OriginatingAddress` table"
        }
        ```
      </details>

  12. Attempt invalid rotation (invalid originating address)

      Rotate the authentication key for account `0xaaa...` to use the authentication
      key for account `0xccc...`:

      ```shellscript filename="Terminal"
      aptos account rotate-key \
          --assume-yes \
          --new-private-key-file private-key-c \
          --profile test-profile-2 \
          --save-to-profile test-profile-4
      ```

      <details>
        <summary>Example output</summary>

        ```shellscript filename="Terminal"
        {
          "Result": {
            "message": "Saved new profile test-profile-4",
            "transaction": {
              "transaction_hash": "0xa5dec792d82ef7471cdf82b9c957fc79b5815da770ad1dd9232ae4692e4f0895",
              "gas_used": 449,
              "gas_unit_price": 100,
              "sender": "aaa8dc0f5e7a6e820f7b1906d99864412b12274ed259ad06bc2c2d8ee7b51e51",
              "sequence_number": 2,
              "success": true,
              "timestamp_us": 1717812312772580,
              "version": 5355,
              "vm_status": "Executed successfully"
            }
          }
        }
        ```
      </details>

      Then try to rotate the authentication key for account `0xccc...` for the first
      time, an operation that is blocked because an entry for the authentication key
      was established in the [`account::OriginatingAddress`] table during the last
      operation:

      ```shellscript filename="Terminal"
      aptos account rotate-key \
          --assume-yes \
          --max-gas 100000 \
          --new-private-key-file private-key-b \
          --profile test-profile-3 \
          --skip-saving-profile
      ```

      (`--max-gas` is specified here to skip local simulation, which does not print
      out as descriptive of an error as the actual transaction.)

      <details>
        <summary>Example output</summary>

        ```shellscript filename="Terminal"
        {
          "Error": "API error: Unknown error Transaction committed on chain, but failed execution: Move abort in 0x1::account: EINVALID_ORIGINATING_ADDRESS(0x6000d): Abort the transaction if the expected originating address is different from the originating address on-chain"
        }
        ```
      </details>

  13. Clean up

      Delete the test profiles:

      ```shell filename="Terminal"
      aptos config delete-profile --profile test-profile-1
      aptos config delete-profile --profile test-profile-2
      aptos config delete-profile --profile test-profile-3
      aptos config delete-profile --profile test-profile-4
      ```

      Then you can stop the localnet and delete the private and public key files.

      <Aside type="note" emoji="üß†">
        If you are using a UNIX-like machine:

        ```shell filename="Terminal"
        aptos config delete-profile --profile test-profile-1
        aptos config delete-profile --profile test-profile-2
        aptos config delete-profile --profile test-profile-3
        aptos config delete-profile --profile test-profile-4
        rm private-key-*
        kill $LOCALNET_PID
        rm -fr localnet-data
        ```
      </Aside>

  14. Rotate keys for a Ledger

      You can also perform authentication key rotation with a private key that is
      securely stored on a Ledger hardware wallet. For more information, see the
      [Ledger authentication key rotation guide](/build/cli/trying-things-on-chain/ledger#authentication-key-rotation).
</Steps>

## TypeScript key rotation example

This program creates two accounts on devnet, Alice and Bob, funds them, then
rotates the Alice's authentication key to that of Bob's.

View the full example for this code
[here](https://github.com/aptos-labs/aptos-ts-sdk/blob/main/examples/typescript/rotate_key.ts).

The function to rotate is very simple:

{/* TODO CODE EXAMPLE */}

Commands to run the example script:

### Navigate to the typescript SDK directory, install dependencies and run

rotate\_key.ts

```shellscript filename="Terminal"
cd ~/aptos-core/ecosystem/typescript/sdk/examples/typescript-esm
pnpm install && pnpm rotate_key
```

### rotate\_key.ts output

```shell filename="Terminal"
Account Address Auth Key Private Key Public Key
------------------------------------------------------------------------------------------------
Alice 0x213d...031013 '0x213d...031013' '0x00a4...b2887b' '0x859e...08d2a9'
Bob 0x1c06...ac3bb3 0x1c06...ac3bb3 0xf2be...9486aa 0xbbc1...abb808

...rotating...

Alice 0x213d...031013 '0x1c06...ac3bb3' '0xf2be...9486aa' '0xbbc1...abb808'
Bob 0x1c06...ac3bb3 0x1c06...ac3bb3 0xf2be...9486aa 0xbbc1...abb808
```

## Python key rotation example

This program creates two accounts on devnet, Alice and Bob, funds them, then
rotates the Alice's authentication key to that of Bob's.

View the full example for this code
[here](https://github.com/aptos-labs/aptos-python-sdk/blob/main/examples/rotate_key.py).

Here's the relevant code that rotates Alice's keys to Bob's:

{/* TODO CODE EXAMPLE */}

Commands to run the example script:

### Navigate to the python SDK directory, install dependencies and run

rotate\_key.ts

```shellscript filename="Terminal"
cd aptos-core/ecosystem/python/sdk
poetry install && poetry run python -m examples.rotate-key
```

### rotate\_key.py output

```shellscript filename="Terminal"
Account Address Auth Key Private Key Public Key
------------------------------------------------------------------------------------------------
Alice 0x213d...031013 '0x213d...031013' '0x00a4...b2887b' '0x859e...08d2a9'
Bob 0x1c06...ac3bb3 0x1c06...ac3bb3 0xf2be...9486aa 0xbbc1...abb808

...rotating...

Alice 0x213d...031013 '0x1c06...ac3bb3' '0xf2be...9486aa' '0xbbc1...abb808'
Bob 0x1c06...ac3bb3 0x1c06...ac3bb3 0xf2be...9486aa 0xbbc1...abb808
```

[`account::rotate_authentication_key`]: https://github.com/aptos-labs/aptos-core/blob/acb6c891cd42a63b3af96561a1aca164b800c7ee/aptos-move/framework/aptos-framework/sources/account.move#L326

[`account::rotate_authentication_key_call`]: https://github.com/aptos-labs/aptos-core/blob/acb6c891cd42a63b3af96561a1aca164b800c7ee/aptos-move/framework/aptos-framework/sources/account.move#L294

[`account::RotationProofChallenge`]: https://github.com/aptos-labs/aptos-core/blob/acb6c891cd42a63b3af96561a1aca164b800c7ee/aptos-move/framework/aptos-framework/sources/account.move#L79

[`account::OriginatingAddress`]: https://github.com/aptos-labs/aptos-core/blob/acb6c891cd42a63b3af96561a1aca164b800c7ee/aptos-move/framework/aptos-framework/sources/account.move#L70

[`account::set_originating_address`]: https://github.com/alnoki/aptos-core/blob/5ba4a8d1344b0bb6e22665525a96e787b9a44e55/aptos-move/framework/aptos-framework/sources/account.move#L528

# Manage Fungible Assets with Multisig

> Enhance fungible asset security by combining multisig accounts with the Fungible Asset Standard for protected management.

import { Aside } from '@astrojs/starlight/components';

This tutorial introduces a practical use case that combines Aptos framework
multisig account with fungible asset standard to enhance the security margin of
the management of fungible assets. Make sure you have understood module
publishing and Aptos framework multisig account before moving on to the
tutorial. If not, it is highly recommended to try out the following tutorials
first:

- [Your First Move Module](/build/guides/first-move-module)

## Step 1: Pick an SDK

This tutorial was created for the [TypeScript SDK](/build/sdks/ts-sdk).

Other developers are invited to add support for
the [Python SDK](/build/sdks/python-sdk), [Rust SDK](/build/sdks/rust-sdk),
[Go SDK](/build/sdks/go-sdk) and [Unity SDK](/build/sdks/unity-sdk)!

## Step 2: Publish the module

To create a fungible asset controlled by an Aptos framework multisig account
with all the administrative operations (mint, transfer, burn, freeze/unfreeze),
a well-designed smart contract based on fungible asset standard is a
prerequisite. The Aptos team provides an example code in `aptos-core` repo.

Clone the `aptos-core` repo:

```shellscript filename="Terminal"
git clone git@github.com:aptos-labs/aptos-core.git ~/aptos-core
```

Navigate to the `managed_fungible_asset` directory and then publish this package
onto your `default` account using CLI:

```shellscript filename="Terminal"
cd ~/aptos-core/aptos-move/move-examples/fungible_asset/managed_fungible_asset
aptos move publish --named-addresses example_addr=default
```

Navigate to the `multisig_managed_coin` directory and then publish this package
onto your `default` account using CLI too:

```shellscript filename="Terminal"
cd ~/aptos-core/aptos-move/move-examples/fungible_asset/multisig_managed_coin
aptos move publish --named-addresses example_addr=default
```

For this tutorial, `multisig_managed_coin` need to call functions defined
in `managed_fungible_asset` on the same address. So both modules have to be
published.

<Aside type="note">
  Do not forget to fund the account with faucet before publishing modules.
</Aside>

## Step 3: Start The example

```shellscript filename="Terminal"
cd ~/aptos-core/ecosystem/typescript/sdk/examples/typescript
```

Run the `multisig_managed_coin` example:

```shellscript filename="Terminal"
MODULE_ADDR=${DEFAULT_ACCOUNT_ADDRESS} pnpm run multisig_managed_coin
```

<Aside type="note">
  This example uses the Aptos devnet, which has historically been reset each
  Thursday.
  Make sure devnet is live when you try running the example! If you are running
  localnet with faucet, you can run the following command instead:

  ```shellscript filename="Terminal"
  export APTOS_NODE_URL=http://0.0.0.0:8080
  export APTOS_FAUCET_URL=http://0.0.0.0:8081
  export MODULE_ADDR=${DEFAULT_ACCOUNT_ADDRESS}
  pnpm run multisig_managed_coin
  ```
</Aside>

The example script should execute successfully without any errors. Then you are
able to see what it did by searching the `owner1` and `owner2` addresses printed
to the console on Aptos explorer.

Let's follow the script to understand what it does:

### Generate single signer accounts

First, we will generate three single signer accounts, owner1, owner2 and owner3
who will co-own an Aptos framework multisig account.

{/* TODO Code snippet
  typescript title=Generate 3 single signers"
  /sdks/typescript/examples/typescript/multisig_managed_coin.ts
  section_1
  */}

### Create an Aptos framework multisig account with a managed fungible asset

Next, let owner1 call the `initialize()` function defined
in `multisig_managed_coin.move`, which first create an Aptos framework multisig
account owned by owner1 and add both owner2 and owner3 as owners. Also, it
creates a fungible asset called "meme coin" with customized settings denoted in
the argument list and make the multisig account the admin of the fungible asset.
Also, each proposal needs at least 2 approvals to execute.

{/* TODO Code snippet
  typescript title=Query the multisig account and then call the initialize function"
  /sdks/typescript/examples/typescript/multisig_managed_coin.ts
  section_2
  */}

### Mint

Then we mint 1000 and 2000 meme coin to owner2 and owner3, respectively. The
proposed transaction is submitted by owner2 and gets an additional approval from
owner3.

{/* TODO Code snippet
  typescript title="Mint 1000 to owner2 and 2000 to owner3"
  /sdks/typescript/examples/typescript/multisig_managed_coin.ts
  section_3
  */}

### Freeze

After minting, the example shows how to freeze account owner1. The proposed
transaction is again submitted by owner2 and approved by owner3 in addition.

{/* TODO Code snippet
  typescript title=""Freeze owner1"
  /sdks/typescript/examples/typescript/multisig_managed_coin.ts
  section_4
  */}

<Aside type="note">
  Unfreeze is similar that just replace the last argument of
  `set_primary_stores_frozen_status` function to `false`.
</Aside>

### Force transfer

When owner1 is frozen, normal transfer cannot withdraw from or deposit to that
account. But as the admin of "meme coin", the multisig account has the
capability to do that.
Next, Owner2 proposed a transaction to force transfer 1000 meme coins from
owner3 to owner1. This time, owner1 approves it.

{/* TODO Code snippet
  typescript title=""Force transfer 1000 meme coins from owner3 to owner1"
  /sdks/typescript/examples/typescript/multisig_managed_coin.ts
  section_5
  */}

### Burn

Finally, all the three owners have 1000 meme coins. Let's burn all the coins!
Owner2 makes the proposal and owner1 approves it.

{/* TODO Code snippet
  typescript title="Burn 1000 meme coins from all the three owners' accounts"
  /sdks/typescript/examples/typescript/multisig_managed_coin.ts
  section_6
  */}

## Conclusion

This tutorial shows an e2e flow of using Aptos framework multisig account to
administrate fungible asset. Similarly, you can create your own module and
leverage our powerful SDK to create the administration schema that fits your
needs.

# Use Oracles in Your Aptos Applications

> Reference guide for integrating various oracle providers like Pyth Network to access off-chain data in smart contracts.

import { Aside } from '@astrojs/starlight/components';

This reference guide presents various Oracles that you can use while building on Aptos. Oracles supply off-chain data
to the blockchain, enabling smart contracts to access a diverse range of information.  Currently, there are two oracles
documented here in this guide: Chainlink and Pyth Network.

## Chainlink

[Chainlink](https://chain.link/) is the industry-standard oracle platform bringing the capital markets on-chain and powering the majority of decentralized finance.

The only all-in-one oracle platform for creating workflows across blockchains and legacy systems while embedding critical data, compliance, and privacy capabilities, which are then represented as a single line of code that runs in a verifiable decentralized runtime.

Many of the world‚Äôs largest financial services institutions and DeFi protocols have adopted Chainlink‚Äôs standards and infrastructure.

### Chainlink Data Feeds

By adopting the Chainlink standard for high-quality data, Aptos now has seamless access to the tamper-proof data needed to support the development of highly secure applications on the network.

Chainlink Data Feeds provide a secure, reliable, and decentralized source of real-world data to power unique smart contract use cases across decentralized and traditional finance.

1. Data providers aggregate raw price data from a multitude of centralized and decentralized exchanges, accounting for time, volume, and outliers.
2. Independent Chainlink nodes fetch market price data from various data providers and combine the results into an aggregated value.
3. Multiple Chainlink nodes then aggregate their results together off-chain to generate an ‚Äòoracle report,‚Äô which is made available to smart contracts.

**Key Data Feeds developer tools**

- [Data Feeds on Aptos](https://docs.chain.link/data-feeds/price-feeds/addresses?page=1\&testnetPage=1\&network=aptos) ‚Äî view all relevant addresses and details to use Aptos with Data Feeds.
- [Data Feeds official documentation](https://data.chain.link/feeds) ‚Äî learn how to use Chainlink Data Feeds.

### Chainlink CCIP

Chainlink Cross-Chain Interoperability Protocol (CCIP) is the standard for interoperability. CCIP enables developers to build secure cross-chain applications that can transfer tokens, send messages, and initiate actions across blockchains.

Through the [Cross-Chain Token (CCT) standard](https://blog.chain.link/ccip-v-1-5-upgrade/), CCIP enables token developers to integrate new and existing tokens with CCIP in a self-serve manner within minutes, without requiring vendor lock-in, hard-coded functions, or external dependencies that may limit future optionality.

CCTs offer several benefits:

- Self-serve deployments
- Full control and ownership for developers
- Zero-slippage transfers
- Enhanced programmability via configurable rate limits
- Reliability features such as Smart Execution

CCIP is powered by Chainlink decentralized oracle networks (DONs)‚Äîa proven standard with a track record of securing tens of billions of dollars and enabling over $25 trillion in on-chain transaction value.
**Key CCIP developer tools**

- [CCIP Directory](https://docs.chain.link/ccip/directory/mainnet/chain/aptos-mainnet) ‚Äî view all relevant addresses and details needed to use Aptos with CCIP.
- [CCIP official documentation](https://docs.chain.link/ccip) ‚Äî start integrating CCIP into your cross-chain application.
- [CCIP Token Manager](https://tokenmanager.chain.link/) ‚Äî an intuitive front-end web interface for the deployment of new and management of existing CCTs by their developers, including no-code guided deployments and configuration tools.
- [CCIP SDK](https://docs.chain.link/ccip/ccip-javascript-sdk) ‚Äî a software development kit that streamlines the process of integrating CCIP, allowing developers to use JavaScript to create a token transfer frontend dApp.

## Pyth Network

The [Pyth Network](https://pyth.network/) is one of the largest first-party Oracle networks, delivering real-time data across [a vast number of chains](https://docs.pyth.network/price-feeds/contract-addresses).

The network comprises some of the world‚Äôs [largest exchanges, market makers, and financial services providers](https://pyth.network/publishers). These publish proprietary data on-chain for aggregation and distribution to smart contract applications.

### How to Use Pyth Real-Time Data in Aptos Contracts

This guide explains how to use real-time Pyth data in Aptos applications.

### Configuring the `Move.toml` file

Add the Pyth Contract to your project dependencies in the `Move.toml` file:

```toml copy
[dependencies]
Pyth = { git = "https://github.com/pyth-network/pyth-crosschain.git", subdir = "target_chains/aptos/contracts", rev = "main" }
```

The named addresses of `pyth`, `wormhole`, and `deployers` must be defined at compile time. These addresses are used to interact with the Pyth contract on Aptos.

```toml copy
[addresses]
pyth = "0x7e783b349d3e89cf5931af376ebeadbfab855b3fa239b7ada8f5a92fbea6b387"
deployer = "0xb31e712b26fd295357355f6845e77c888298636609e93bc9b05f0f604049f434"
wormhole = "0x5bc11445584a763c1fa7ed39081f1b920954da14e04b32440cba863d03e19625"
```

Consult [Aptos Contract Addresses](https://docs.pyth.network/price-feeds/contract-addresses/aptos) for the complete list of contract addresses on different Aptos networks.

### Write Contract Code

The code snippet below provides an example module fetching the BTC/USD price from Pyth price feeds:

```rust {21} copy
module example::example {
    use pyth::pyth;
    use pyth::price::Price;
    use pyth::price_identifier;
    use aptos_framework::coin;

    // Add the pyth_price_update argument to any method on your contract that needs to read the Pyth price.
    // See https://docs.pyth.network/price-feeds/fetch-price-updates for more information on how to fetch the pyth_price_update.
    public fun get_btc_usd_price(user: &signer, pyth_price_update: vector<vector<u8>>): Price {

        // First update the Pyth price feeds
        let coins = coin::withdraw(user, pyth::get_update_fee(&pyth_price_update));
        pyth::update_price_feeds(pyth_price_update, coins);

        // Read the current price from a price feed.
        // Each price feed (e.g., BTC/USD) is identified by a price feed ID.
        // The complete list of feed IDs is available at https://pyth.network/developers/price-feed-ids
        // Note: Aptos uses the Pyth price feed ID without the `0x` prefix.
        let btc_price_identifier = x"e62df6c8b4a85fe1a67db44dc12de5db330f7ac66b72dc658afedf0f4a415b43";
        let btc_usd_price_id = price_identifier::from_byte_vec(btc_price_identifier);
        pyth::get_price(btc_usd_price_id)
    }
}

```

<Aside type="note" emoji="‚ÑπÔ∏è">
  The `pyth_price_update` argument contains verified prices from Pyth. Calling
  `pyth::update_price_feeds` with this value updates the on-chain Pyth price and
  ensures your application has recent price data. The pyth\_price\_update can be
  fetched from Hermes; Consult [Fetch Price Updates](https://docs.pyth.network/price-feeds/fetch-price-updates) for
  more information on how to fetch the `pyth_price_update`.
</Aside>

The code snippet above does the following things:

1. Call `pyth::get_update_fee` to get the fee required to update the Pyth price feeds.
2. Call `pyth::update_price_feeds` and pass `pyth_price_update` to update the Pyth price feeds.
3. Call `pyth::get_price` to read the current price, providing the [price feed ID](https://pyth.network/developers/price-feed-ids) you wish to read.

### Additional Resources

You may find these additional resources helpful for developing your Aptos application.

#### Sponsored Feeds on Aptos

The price feeds listed in the table below are currently sponsored in **Aptos mainnet**.

Update Parameters: **1 second heartbeat or 0.5% price deviation**

| Name      | Price Feed Id                                                      |
| --------- | ------------------------------------------------------------------ |
| APT/USD   | `03ae4db29ed4ae33d323568895aa00337e658e348b37509f5372ae51f0af00d5` |
| BTC/USD   | `e62df6c8b4a85fe1a67db44dc12de5db330f7ac66b72dc658afedf0f4a415b43` |
| ETH/USD   | `ff61491a931112ddf1bd8147cd1b641375f79f5825126d665480874634fd0ace` |
| SOL/USD   | `ef0d8b6fda2ceba41da15d4095d1da392a0d2f8ed0c6c7bc0f4cfac8c280b56d` |
| USDC/USD  | `eaa020c61cc479712813461ce153894a96a6c00b21ed0cfc2798d1f9a9e9c94a` |
| USDT/USD  | `2b89b9dc8fdf9f34709a5b106b472f0f39bb6ca9ce04b0fd7f2e971688e2e53b` |
| CAKE/USD  | `2356af9529a1064d41e32d617e2ce1dca5733afa901daba9e2b68dee5d53ecf9` |
| SUI/USD   | `23d7315113f5b1d3ba7a83604c44b94d79f4fd69af77f804fc7f920a6dc65744` |
| CETUS/USD | `e5b274b2611143df055d6e7cd8d93fe1961716bcd4dca1cad87a83bc1e78c1ef` |
| BNB/USD   | `2f95862b045670cd22bee3114c39763a4a08beeb663b145d283c31d7d1101c4f` |
| WBTC/USD  | `c9d8b075a5c69303365ae23633d4e085199bf5c520a3b90fed1322a0342ffc33` |
| THL/USD   | `74e3fbb0d33e0ed8c0078b56134dcebdae38852f0858a8ea4de4c5ea7474bd42` |
| USDY/USD  | `e393449f6aff8a4b6d3e1165a7c9ebec103685f3b41e60db4277b5b6d10e7326` |
| WETH/USD  | `9d4294bbcd1174d6f2003ec365831e64cc31d9f6f15a2b85399db8d5000960f6` |
| THAPT/USD | `b29276972267db5d64ae718fb7f107ad9e72a79cabf9992f0e9bc75ad451a7f6` |
| EZETH/USD | `06c217a791f5c4f988b36629af4cb88fad827b2485400a358f3b02886b54de92` |
| WEETH/USD | `9ee4e7c60b940440a261eb54b6d8149c23b580ed7da3139f7f08f4ea29dad395` |
| USDM/USD  | `a6a0dfa49b6b3a93510658245618099f5e842514970f596cf64fad9e0d658193` |
| STONE/USD | `4dcc2fb96fb89a802ef9712f6bd2246d3607cf95ca5540cb24490d37003f8c46` |

For more details on sponsored feeds, check [here](https://docs.pyth.network/price-feeds/sponsored-feeds)

#### API Reference

The [Aptos API reference](https://docs.pyth.network/price-feeds/api-reference/aptos) lets you interactively explore the complete API of the Pyth contract.

#### Example Applications

- [Minimal on-chain contract](https://github.com/pyth-network/pyth-examples/blob/main/price_feeds/aptos/fetch_btc_price/sources/example.move), which updates and returns the BTC/USD price from Pyth price feeds.
- [Mint NFT](https://github.com/pyth-network/pyth-examples/tree/main/price_feeds/aptos/mint_nft), a minting application that uses Pyth price feeds to mint an NFT.

# Orderless Transactions

> Execute transactions out of order for multi-machine signing scenarios while maintaining replay protection and security.

As outlined
in [AIP-123](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-123.md),
orderless transactions allow for transactions to be executed out of order, which
is particularly useful in scenarios where multiple machines need to sign for a
single sending account, but the order in which they sign does not affect the
outcome of the transaction or matter to the creator.  Replay is protected by a
nonce, which is a unique identifier for a transaction.  This allows for the
transaction to be executed at any time within the expiration time, regardless of
the order in which the machines sign the transaction, but not be able to be
replayed after the nonce has expired.  The maximum expiration time is 60 seconds
for orderless transactions, which is not the same for sequence number
transactions.

## Process Overview

Orderless transactions are dependent on the transaction payload specified in
[AIP-129](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-129.md).
The process for building and executing an orderless transaction is as follows:

1. Build a transaction with a `replayProtectionNonce` and a `TransactionPayload::TransactionPayloadPayload` that defines the operation to be executed.
2. Sign and submit the transaction as any other transaction, but with the
   `replayProtectionNonce` set.  Ideally, the nonce should be a random u64 value.

Note, that the behavior of the `replayProtectionNonce` is similar to a sequence
number, but it does not guarantee ordered execution of transactions. Instead, it
ensures that the transaction is unique and cannot be replayed (executed twice)
with the same nonce.

## SDK Support

These are demonstrations of sponsored transactions:

- The [TypeScript SDK](/build/sdks/ts-sdk/building-transactions/orderless-transactions) has documentation
- The [Go SDK](https://github.com/aptos-labs/aptos-go-sdk/tree/main/examples/orderless_transaction) has an example

# Sponsored Transactions

> Allow applications to pay transaction fees for users, simplifying onboarding by removing the need for gas tokens.

As outlined
in [AIP-39](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-39.md),
sponsored transactions allow one account to pay the fees associated with
executing a transaction for another account, essentially setting up a fee payer.
Sponsored transactions simplify the process for onboarding users into applications
by allowing the application to cover all associated fees for interacting with the
Aptos blockchain. Here are two examples:

- [MerkleTrade](https://merkle.trade/) offers low cost trading to those with
  Ethereum wallets by creating an Aptos wallet for users and covering all
  transaction fees so that the user does not need to acquire utility tokens for
  Aptos.
- Community engagement applications
  like [Graffio](https://medium.com/aptoslabs/graffio-web3s-overnight-sensation-81a6cf18b626)
  offered to cover transaction fees for custodial accounts to support the
  collaborative drawing application for those without wallets.

## Process Overview

The process for sending a sponsored transaction follows:

- The sender of the transaction determines upon an operation, as defined by
  a `RawTransaction`.
- The sender generates a `RawTransactionWithData::MultiAgentWithFeePayer`
  structure
  - Prior to the framework 1.8 release, this must contain the fee payer's
    address.
  - After framework release 1.8, this can optionally be set to `0x0`.
- (Optionally) the sender aggregates signatures from other signers.
- The sender can forward the signed transaction to the fee payer to sign and
  forward it to the blockchain.
- Upon execution of the transaction, the sequence number of the sender account
  is incremented, all gas fees are deducted from the gas fee payer, and all
  refunds are sent to the gas fee payer.

Alternatively, if the fee payer knows the operation and all signers involved,
the fee payer could generate and sign the transaction and send it back to the
other signers to sign.

## Technical Details

In Aptos, a sponsored transaction reuses the same SignedTransaction as any other
user transaction:

```rust
pub struct SignedTransaction {
    /// The raw transaction
    raw_txn: RawTransaction,

    /// Public key and signature to authenticate
    authenticator: TransactionAuthenticator,
}
```

The difference is in the `TransactionAuthenticator`, which stores the
authorization from the fee payer of the transaction to extract utility fees from
their account:

```rust
pub enum TransactionAuthenticator {
...
    /// Optional Multi-agent transaction with a fee payer.
    FeePayer {
        sender: AccountAuthenticator,
        secondary_signer_addresses: Vec<AccountAddress>,
        secondary_signers: Vec<AccountAuthenticator>,
        fee_payer_address: AccountAddress,
        fee_payer_signer: AccountAuthenticator,
    },
...
}
```

To prepare a sponsored transaction for an account, the account must first exist
on-chain. This is a requirement that is being removed with the 1.8 framework
release.

As of the 1.8 framework release, an account does not need to exist on-chain.
However, the first transaction for an account requires enough gas to not only
execute the transaction and cover the costs associated with account creation,
even if an account already exists. Future improvements to the account model
intend to eliminate this requirement.

During signing of the transaction, all parties sign the following:

```rust
pub enum RawTransactionWithData {
...
    MultiAgentWithFeePayer {
        raw_txn: RawTransaction,
        secondary_signer_addresses: Vec<AccountAddress>,
        fee_payer_address: AccountAddress,
    },
}
```

Prior to framework release 1.8, all signers were required to know the actual fee
payer address prior to signing. As of framework release 1.8, signers can
optionally set the address to `0x0` and only the fee payer must sign with their
address set.

## SDK Support

These are demonstrations of sponsored transactions:

- The TypeScript SDK
  has [several examples](https://github.com/aptos-labs/aptos-ts-sdk/tree/main/examples/typescript-esm/sponsored_transactions)
- The Python SDK has an example
  in [fee\_payer\_transfer\_coin.py](https://github.com/aptos-labs/aptos-python-sdk/blob/main/examples/fee_payer_transfer_coin.py).
- The Rust SDK has a test case
  in [the API tests](https://github.com/aptos-labs/aptos-core/blob/0a62e54e13bc5da604ceaf39efed5c012a292078/api/src/tests/transactions_test.rs#L255).

# Application Integration Guide

> Legacy integration guide for system integrators - deprecated in favor of the exchange integration guide.

import { Aside } from '@astrojs/starlight/components';

<Aside type="note">
  This guide is currently in progress of being replaced.  Please check out the [exchange integration guide](/build/guides/exchanges)
  for more up-to-date information.
</Aside>

If you provide blockchain services to your customers and wish to add the Aptos
blockchain to your platform, then this guide is for you. This system integrators
guide will walk you through all you need to integrate the Aptos blockchain into
your platform.

## Overview

This document will guide you through the following tasks to integrate with
Aptos:

1. Prepare an environment for testing.
2. Create an account on the blockchain.
3. Exchange account identifiers with another entity on the blockchain, for
   example, to perform swaps.
4. Create a transaction.
5. Obtain a gas estimate and validate the transaction for correctness.
6. Submit the transaction to the blockchain.
7. Wait for the outcome of the transaction.
8. Query historical transactions and interactions for a given account with a
   specific account, i.e., withdraws and deposits.

## Getting Started

In order to get started you'll need to select a network and pick your set of
tools. There are also a handful of SDKs to help accelerate development.

### SDKs and tools

Aptos has multiple SDKs across many different languages and platforms, please
check out [SDKs](/build/sdks) for more information.

Almost all developers will benefit from exploring the CLI.
[Using the CLI](/build/cli) demonstrates how the CLI can be used to create
accounts, transfer coins, publish Move modules, and more.

## Accounts on Aptos

An [account](/network/blockchain/accounts) represents
an entity on the Aptos blockchain that can send transactions. Each account is
identified by a particular 32-byte account address and is a container for
[Move modules and resources](/network/blockchain/resources).
On Aptos, accounts must be created on-chain prior to any blockchain operations
involving that account. The Aptos framework supports implicitly creating
accounts when transferring Aptos coin via [`aptos_account::transfer`](https://github.com/aptos-labs/aptos-core/blob/88c9aab3982c246f8aa75eb2caf8c8ab1dcab491/aptos-move/framework/aptos-framework/sources/aptos_account.move#L18)
or explicitly via [`aptos_account::create_account`](https://github.com/aptos-labs/aptos-core/blob/88c9aab3982c246f8aa75eb2caf8c8ab1dcab491/aptos-move/framework/aptos-framework/sources/aptos_account.move#L13).

At creation, an [Aptos account](https://github.com/aptos-labs/aptos-core/blob/88c9aab3982c246f8aa75eb2caf8c8ab1dcab491/aptos-move/framework/aptos-framework/sources/account.move#L23) contains:

- A [resource containing Aptos Coin](https://github.com/aptos-labs/aptos-core/blob/60751b5ed44984178c7163933da3d1b18ad80388/aptos-move/framework/aptos-framework/sources/coin.move#L50)
  and deposit and withdrawal of coins from that resource.
- An authentication key associated with their current public, private key(s).
- A strictly
  increasing [sequence number](/network/blockchain/accounts#account-sequence-number)
  that represents the account's next transaction's sequence number to prevent
  replay attacks.
- A strictly increasing number that represents the next distinct GUID creation
  number.
- An [event handle](/network/blockchain/events) for all new types of coins added to
  the account.
- An event handle for all key rotations for the account.

Read more about [Accounts](/network/blockchain/accounts)
and [set one up](/build/cli/setup-cli).

## Transactions

Aptos [transactions](/network/blockchain/txns-states) are encoded
in [Binary Canonical Serialization (BCS)](https://github.com/diem/bcs).
Transactions contain information such as the sender‚Äôs account address,
authentication from the sender, the desired operation to be performed on the
Aptos blockchain, and the amount of gas the sender is willing to pay to execute
the transaction.

Read more in [Transactions and States](/network/blockchain/txns-states).

### Generating transactions

Aptos supports two methods for constructing transactions:

- Using the Aptos client libraries to generate native BCS transactions.
- Constructing JSON-encoded objects and interacting with the REST API to
  generate native transactions.

The preferred approach is to directly generate native BCS transactions.
Generating them via the REST API enables rapid development at the cost of
trusting the fullnode to generate the transaction correctly.

#### BCS-encoded transactions

BCS-encoded transactions can be submitted to the `/transactions` endpoint but
must specify `Content-Type: application/x.aptos.signed_transaction+bcs` in the
HTTP headers. This will return a transaction submission result that, if
successful, contains a transaction hash in
the `hash` [field](https://github.com/aptos-labs/aptos-core/blob/9b85d41ed8ef4a61a9cd64f9de511654fcc02024/ecosystem/python/sdk/aptos_sdk/client.py#L138).

### Types of transactions

Within a given transaction, the target of execution can be one of two types:

- An entry function
- A Move script

All official SDKs support the generation of transactions that target entry functions. This guide
points out many of those entry functions, such as `aptos_account::transfer`
and `aptos_account::create_account`.

Most basic operations on the Aptos blockchain should be available via entry
point calls. While one could submit multiple transactions calling entry points
in series, such operations benefit from being called atomically from a single
transaction. A script payload transaction can call any public (entry) function
defined within any module. Here's an
example [Move script](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/move-examples/scripts/two_by_two_transfer)
that uses a MultiAgent transaction to extract funds from two accounts and
deposit them into two other accounts. This is
a [Python example](https://github.com/aptos-labs/aptos-python-sdk/blob/main/examples/transfer_two_by_two.py)
that uses the bytecode generated by compiling that script.

### Status of a transaction

Obtain transaction status by querying the
API [`/transactions/by_hash/{hash}`](https://api.devnet.aptoslabs.com/v1/spec#/operations/get_transaction_by_hash)
with the hash returned during the submission of the transaction.

A reasonable strategy for submitting transactions is to limit their lifetime to
30 to 60 seconds, and polling that API at regular intervals until success or
several seconds after that time has elapsed. If there is no commitment on-chain,
the transaction was likely discarded.

All SDKs support this automatically for waiting for transactions.

### Testing transactions or transaction pre-execution

To facilitate evaluation of transactions as well as gas estimation, Aptos
supports a simulation API that does not require and should not contain valid
signatures on transactions.

The simulation API is a synchronous API that executes a transaction and returns
the output inclusive of gas usage. The simulation API can be accessed by
submitting a transaction
to [`/transactions/simulate`](https://api.devnet.aptoslabs.com/v1/spec#/operations/simulate_transaction).

Both
the [Typescript SDK](https://github.com/aptos-labs/aptos-ts-sdk/blob/main/src/api/transactionSubmission/simulate.ts)
and [Python SDK](https://github.com/aptos-labs/aptos-python-sdk/blob/main/examples/simulate_transfer_coin.py)
support the simulation API. Note the output and gas used may change based upon
the state of the account. For gas estimations, we recommend that the maximum gas
amount be larger than the amount quoted by this API.

## Viewing current and historical state

Most integrations into the Aptos blockchain benefit from a holistic and
comprehensive overview of the current and historical state of the blockchain.
Aptos provides historical transactions, state, and events, all the result of
transaction execution.

- Historical transactions specify the execution status, output, and tie to
  related events. Each transaction has a unique version number associated with
  it that dictates its global sequential ordering in the history of the
  blockchain ledger.
- The state is the representation of all transaction outputs up to a specific
  version. In other words, a state version is the accumulation of all
  transactions inclusive of that transaction version.
- As transactions execute, they may emit events. [Events](/network/blockchain/events)
  are hints about changes in on-chain data.

The storage service on a node employs two forms of pruning that erase data from
nodes:

- state
- events, transactions, and everything else

While either of these may be disabled, storing the state versions is not
particularly sustainable.

Events and transactions pruning can be disabled via setting
the [`enable_ledger_pruner`](https://github.com/aptos-labs/aptos-core/blob/cf0bc2e4031a843cdc0c04e70b3f7cd92666afcf/config/src/config/storage_config.rs#L141)
to `false`. This is default behavior in Mainnet. In the near future, Aptos will
provide indexers that mitigate the need to directly query from a node.

The REST API offers querying transactions and events in these ways:

- [Transactions for an account](https://api.devnet.aptoslabs.com/v1/spec#/operations/get_account_transactions)
- [Transaction by version](https://api.devnet.aptoslabs.com/v1/spec#/operations/get_transaction_by_version)
- [Events by event handle](https://api.devnet.aptoslabs.com/v1/spec#/operations/get_events_by_event_handle)

## Exchanging and tracking fungible assets

Aptos has a
standard [Fungible Asset](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/fungible_asset.move).
Different types of fungible asset (FA) can be represented in this standard
through the use of distinct metadata object.

A user's FA is stored in `FungibleStore` objects owned by them. For each type of
FA, every account has one primary store for that FA and
optional multiple secondary stores. The difference between primary and secondary
stores is the address of primary store
is deterministic based on the addresses of user account and metadata object.

### Transferring FAs between users

FAs, including APT, can be transferred between users' primary stores via
the [`primary_fungible_store::transfer`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/primary_fungible_store.move#L142)
function.
For any `FungibleStore`
s, [`fungible_asset::transfer`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/fungible_asset.move#L347)
would be invoked with `FungibleStore` object addresses.

It is noted in the migration phase from coin to FA, withdraw/deposit/transfer FA paired from coin should
call `0x1::coin::deposit/withdraw/transfer`(coin module API) to transfer the asset because the account may have the asset in both
form but fungible asset API can only move FA part but not the coin part. In contrast, coin API could move both parts. For other FA,
since it does not have a paired coin type, only fungible asset API can be used to move assets.
To know which API to call, please refer to [`concurrent_fungible_asset_balance`](/build/indexer/indexer-api/fungible-asset-balances) table `standard` field, where "v1" means using coin API and "v2" means using fungible asset API.

### Current balance for Fungible Asset

Indexer users can just query [`concurrent_fungible_asset_balance`](/build/indexer/indexer-api/fungible-asset-balances) to get the balance.

For node API, the current balance for an APT FA of FungibleStore is available at the account resources URL: `https://{rest_api_server}/accounts/{fungible_store_object_address}/resource/0x1::fungible_asset::FungibleStore`. The balance is stored as `balance`. The resource also contains a metadata object of the FA type and the frozen status. The address of the primary fungible store can be calculated as `sha3_256(32-byte account address | 32-byte metadata object address | 0xFC)`. The metadata object address of APT FA is `0xA`.

Aptos users have the option to upgrade to concurrent fungible balance to allow parallelization of balance updates, improving the performance of a single account. When a user has upgraded a fungible store balance to support concurrent update, the fungible store object will have another resource `ConcurrentFungibleBalance` that contains the balance of the store, and the `balance` field of FungibleStore will be set to 0. The current balance for an APT FA of `ConcurrentFungibleBalance` (if exists) is available at the account resources URL: `https://{rest_api_server}/accounts/{fungible_store_object_address}/resource/0x1::fungible_asset::ConcurrentFungibleBalance`.

Therefore, to get the total balance of a fungible asset, it is either the non-zero balance of `FungibleStore` or the `balance` field of `ConcurrentFungibleBalance` if it exists and the balance of `FungibleStore` is 0.

```json
{
  "type": "0x1::fungible_asset::FungibleStore",
  "data": {
    "balance": "233910778869",
    "frozen": false,
    "metadata": {
      "inner": "0xedc2704f2cef417a06d1756a04a16a9fa6faaed13af469be9cdfcac5a21a8e2e"
    }
  }
}
```

```json
{
    "type": "0x1::fungible_asset::ConcurrentFungibleBalance",
    "data": {
        "balance": "233910778869"
    }
}
```

## Exchanging and tracking coins

Aptos has a standard
[Coin type](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/coin.move).
Different types of coins can be represented in this type through the use of
distinct structs that represent the type parameter or generic for `Coin<T>`.

Coins are stored within an account under the resource `CoinStore<T>`. At account
creation, each user has the resource `CoinStore<0x1::aptos_coin::AptosCoin>`
or `CoinStore<AptosCoin>`, for short. Within this resource is the Aptos
coin: `Coin<AptosCoin>`.

### Transferring coins between users

Coins, including APT, can be transferred between users via
the [`aptos_account::transfer_coins`](https://github.com/aptos-labs/aptos-core/blob/d1610e1bb5214689a37a9cab59cf9254e8eb2be1/aptos-move/framework/aptos-framework/sources/aptos_account.move#L92)
function for all coins
and [`aptos_account::transfer`](https://github.com/aptos-labs/aptos-core/blob/88c9aab3982c246f8aa75eb2caf8c8ab1dcab491/aptos-move/framework/aptos-framework/sources/aptos_account.move#L18)
for Aptos coins.

<Aside type="caution">
  It is important to note that if an account has not registered a
  `CoinStore<T />`
  for a given `T`, then any transfer of type `T` to that account will fail.
</Aside>

### Current balance for a coin

To retrieve the balance of a coin, or a coin that was migrated to a fungible asset, you can use
the `0x1::coin::balance<CoinType>(account address)` view function.  This will combine the coin and coin migrated to fungible asset balances.

```typescript filename="example.ts"
import { Aptos, AptosConfig, Network } from "@aptos-labs/ts-sdk";

const config = new AptosConfig({ network: Network.DEVNET });
const aptos = new Aptos(config);

const coinType = "0x1::aptos_coin::AptosCoin";
const account = "0x00000000000000000000000000000001";
const [balanceStr] = await aptos.view<[string]>({
  payload: {
    function: "0x1::coin::balance",
    typeArguments: [coinType],
    functionArguments: [account]
  }
});
const balance = parseInt(balanceStr, 10);
```

### Querying transactions

In Aptos, each transaction is committed as a distinct version to the
blockchain. This allows for the convenience of sharing committed transactions
by their version number; to do so, query:
`https://{rest_server_api}/transactions/by_version/{version}`

Transactions submitted by an account can also be queried via the following URL
where the `sequence_number` matches the sequence number of the transaction:
`https://{rest_server_api}/account/{address}/transactions?start={sequence_number}&limit=1`

A transfer transaction would appear as follows:

```json
{
  "version": "13629679",
  "gas_used": "4",
  "success": true,
  "vm_status": "Executed successfully",
  "changes": [
    {
      "address": "0xb258b91eee04111039320a85b0c24a2dd433909e14a6b5c32ee722e0fdecfddc",
      "data": {
        "type": "0x1::coin::CoinStore<0x1::aptos_coin::AptosCoin>",
        "data": {
          "coin": {
            "value": "1000"
          },
          "deposit_events": {
            "counter": "1",
             "guid": {
               "id": {
                 "addr": "0x5098df8e7969b58ab3bd2d440c6203f64c60a1fd5c08b9d4abe6ae4216246c3e",
                 "creation_num": "2"
               }
             }
          },
          ...
        }
      },
      "type": "write_resource"
    },
    ...
  ],
  "sender": "0x810026ca8291dd88b5b30a1d3ca2edd683d33d06c4a7f7c451d96f6d47bc5e8b",
  "sequence_number": "0",
  "max_gas_amount": "2000",
  "gas_unit_price": "1",
  "expiration_timestamp_secs": "1660616127",
  "payload": {
    "function": "0x1::aptos_account::transfer",
    "arguments": [
      "0x5098df8e7969b58ab3bd2d440c6203f64c60a1fd5c08b9d4abe6ae4216246c3e",
      "1000"
    ],
    "type": "entry_function_payload"
  },
  "events": [
    {
      "key": "0x0300000000000000810026ca8291dd88b5b30a1d3ca2edd683d33d06c4a7f7c451d96f6d47bc5e8b",
      "guid": {
        "id": {
          "addr": "0x810026ca8291dd88b5b30a1d3ca2edd683d33d06c4a7f7c451d96f6d47bc5e8b",
          "creation_num": "3"
        }
      },
      "sequence_number": "0",
      "type": "0x1::coin::WithdrawEvent",
      "data": {
        "amount": "1000"
      }
    },
    {
      "key": "0x02000000000000005098df8e7969b58ab3bd2d440c6203f64c60a1fd5c08b9d4abe6ae4216246c3e",
      "guid": {
        "id": {
          "addr": "0x5098df8e7969b58ab3bd2d440c6203f64c60a1fd5c08b9d4abe6ae4216246c3e",
          "creation_num": "2"
        }
      },
      "sequence_number": "0",
      "type": "0x1::coin::DepositEvent",
      "data": {
        "amount": "1000"
      }
    }
  ],
  "timestamp": "1660615531147935",
  "type": "user_transaction"
}
```

Here is a breakdown of the information in a transaction:

- `version` indicates the globally unique identifier for this transaction, its
  ordered position in all the committed transactions on the blockchain
- `sender` is the account address of the entity that submitted the transaction
- `gas_used` is the units paid for executing the transaction
- `success` and `vm_status` indicate whether the transaction successfully
  executed and any reasons why it might not have
- `changes` include the final values for any state resources that have been
  modified during the execution of the transaction
- `events` contain all the events emitted during the transaction execution
- `timestamp` is the near real-time timestamp of the transaction's execution

If `success` is false, then `vm_status` will contain an error code or message
that resulted in the transaction failing to succeed. When `success` is
false, `changes` will be limited to gas deducted from the account and the
sequence number incrementing. There will be no `events`.

Each event in `events` is differentiated by a `key`. The `key` is derived from
the `guid` in `changes`. Specifically, the `key` is a 40-byte hex string where
the first eight bytes (or 16 characters) are the little-endian representation
of the `creation_num` in the `guid` of the `changes` event, and the remaining
characters are the account address.

As events do not dictate what emitted them, it is imperative to track the path
in `changes` to determine the source of an event. In particular,
each `CoinStore<T>` has both a `WithdrawEvent` and a `DepositEvent`, based
upon the type of coin. In order to determine which coin type is used in a
transaction, an indexer can compare the `guid::creation_num` in a `changes`
event combined with the address to the `key` for events in `events`.

Using the above example, `events[1].guid` is equivalent
to `changes[0].data.data.deposit_events.guid`, which
is

```json
{"addr": "0x5098df8e7969b58ab3bd2d440c6203f64c60a1fd5c08b9d4abe6ae4216246c3e", "creation_num": "2"}
```

<Aside type="note">
  The `key` field will be going away in favor of `guid`
</Aside>

### Querying events

Aptos provides clear and canonical events for all withdraw and deposit of
coins. This can be used in coordination with the associated transactions to
present to a user the change of their account balance over time, when that
happened, and what caused it. With some amount of additional parsing, metadata
such as the transaction type and the other parties involved can also be shared.

Query events by handle
URL: `https://{rest_api_server}/accounts/{address}/events/0x1::coin::CoinStore<0x1::aptos_coin::AptosCoin>/withdraw_events`

```json
[
  {
    "version":"13629679",
    "key": "0x0300000000000000cb2f940705c44ba110cd3b4f6540c96f2634938bd5f2aabd6946abf12ed88457",
    "guid": {
      "id": {
        "addr": "0x810026ca8291dd88b5b30a1d3ca2edd683d33d06c4a7f7c451d96f6d47bc5e8b",
        "creation_num": "3"
      }
    },
    "sequence_number": "0",
    "type": "0x1::coin::WithdrawEvent",
    "data": {
      "amount": "1000"
    }
  }
]
```

Gather more information from the transaction that generated the event by
querying `https://{rest_server_api}/transactions/by_version/{version}`
where `{version}` is the same value as the `{version}` in the event query.

<Aside type="note">
  When tracking full movement of coins, normally events are
  sufficient. `0x1::aptos_coin::AptosCoin`, however, requires
  considering `gas_used` for each transaction sent from the given account
  since it represents gas in Aptos. To reduce unnecessary overhead, extracting
  gas fees due to transactions does not emit an event. All transactions for an
  account can be retrieved from this API:
  `https://{rest_server_api}/accounts/{address}/transactions`
</Aside>

### Tracking coin balance changes

Consider the transaction from the earlier section, but now with an arbitrary
coin `0x1337::my_coin::MyCoin` and some gas parameters changed:

```json
{
  "version": "13629679",
  "gas_used": "20",
  "success": true,
  "vm_status": "Executed successfully",
  "changes": [
    {
      "address": "0xb258b91eee04111039320a85b0c24a2dd433909e14a6b5c32ee722e0fdecfddc",
      "data": {
        "type": "0x1::coin::CoinStore<0x1337::my_coin::MyCoin>",
        "data": {
          "coin": {
            "value": "1000"
          },
          "deposit_events": {
            "counter": "1",
            "guid": {
              "id": {
                "addr": "0x5098df8e7969b58ab3bd2d440c6203f64c60a1fd5c08b9d4abe6ae4216246c3e",
                  "creation_num": "2"
              }
            }
          },
        ...
        }
      },
      "type": "write_resource"
    },
    ...
  ],
  "sender": "0x810026ca8291dd88b5b30a1d3ca2edd683d33d06c4a7f7c451d96f6d47bc5e8b",
  "sequence_number": "0",
  "max_gas_amount": "2000",
  "gas_unit_price": "110",
  "expiration_timestamp_secs": "1660616127",
  "payload": {
    "function": "0x1::aptos_account::transfer_coins",
    "type_arguments": [
      "0x1337::my_coin::MyCoin"
    ],
    "arguments": [
      "0x5098df8e7969b58ab3bd2d440c6203f64c60a1fd5c08b9d4abe6ae4216246c3e",
      "1000"
    ],
    "type": "entry_function_payload"
  },
  "events": [
    {
      "key": "0x0300000000000000810026ca8291dd88b5b30a1d3ca2edd683d33d06c4a7f7c451d96f6d47bc5e8b",
      "guid": {
        "id": {
          "addr": "0x810026ca8291dd88b5b30a1d3ca2edd683d33d06c4a7f7c451d96f6d47bc5e8b",
          "creation_num": "3"
        }
      },
      "sequence_number": "0",
      "type": "0x1::coin::WithdrawEvent",
      "data": {
        "amount": "1000"
      }
    },
    {
      "key": "0x02000000000000005098df8e7969b58ab3bd2d440c6203f64c60a1fd5c08b9d4abe6ae4216246c3e",
      "guid": {
        "id": {
          "addr": "0x5098df8e7969b58ab3bd2d440c6203f64c60a1fd5c08b9d4abe6ae4216246c3e",
          "creation_num": "2"
        }
      },
      "sequence_number": "0",
      "type": "0x1::coin::DepositEvent",
      "data": {
        "amount": "1000"
      }
    }
  ],
  "timestamp": "1660615531147935",
  "type": "user_transaction"
}
```

There are three balance changes in this transaction:

1. A withdrawal of `1000` of `0x1337::my_coin::MyCoin` from the transaction
   sending account `0x810026ca8291dd88b5b30a1d3ca2edd683d33d06c4a7f7c451d96f6d47bc5e8b`
2. A deposit of `1000` of `0x1337::my_coin::MyCoin` to receiving account `0x5098df8e7969b58ab3bd2d440c6203f64c60a1fd5c08b9d4abe6ae4216246c3e`
3. A gas fee `2200` of `0x1::aptos_coin::AptosCoin` from the sending account `0x810026ca8291dd88b5b30a1d3ca2edd683d33d06c4a7f7c451d96f6d47bc5e8b`

To retrieve the withdrawal information:

1. Scan the `changes` for `0x1::coin::CoinStore<CoinType>`. Note the
   `CoinType`
   is a generic signifying which coin is stored in the store. In this example,
   the `CoinType` is `0x1337::my_coin::MyCoin`.
2. Retrieve the `guid` for `withdraw_events`. In this example, the `guid`
   contains `addr`
   `0x810026ca8291dd88b5b30a1d3ca2edd683d33d06c4a7f7c451d96f6d47bc5e8b`
   and `creation_num` `3`.
3. Scan for events with this `guid` and extract the event associated with it.
   In
   this example, it is the `0x1::coin::WithdrawEvent`.
4. Note the `amount` field will be the number of `CoinType` removed from the
   account in the `guid`. In this example, it is `1000`.

To retrieve the deposit information, it's the same as withdrawal except:

1. The `guid` used is under `deposit_events`
2. The `amount` will be a positive increase on the account's balance.
3. The event's name will be: `0x1::coin::DepositEvent`

To retrieve the gas fee:

1. The `gas_used` field must be multiplied times the `gas_unit_price`. In this
   example, `gas_used=20` and `gas_unit_price=110` so the total gas coins
   withdrawn is `2200`.
2. Gas is always: `0x1::aptos_coin::AptosCoin`

To retrieve information about the number of decimals of the coin:

1. You can retrieve the number of decimals for a coin via
   its: `0x1::coin::CoinInfo<CoinType>`
2. This will be located at the address of the coin type. In this example, you
   would need to look up `0x1::coin::CoinInfo<0x1337::my_coin::MyCoin>` at  address `0x1337`.

<Aside type="note">
  If you always use the events in this manner, you won't miss any balance
  changes
  for an account.
  By monitoring the events, you will find all balance changes in
  the `0x1::coin::CoinStore`:

  1. Coin mints
  2. Coin burns
  3. Coin transfers
  4. Staking coins
  5. Withdrawing staked coins
  6. Transfers not derived from `coin::transfer`
</Aside>

To create some sample data to explore,
conduct ["Your first transaction"](/build/guides/first-transaction).
To learn more about coin creation,
make ["Your First Coin"](/build/guides/first-coin).

# Transaction Management

> Build scalable transaction management systems on Aptos with proper account handling and sequence number management.

This guide explains how to build a transaction management harness that can scale
on the Aptos blockchain.

## Background

In Aptos, transactions are mapped back to an account in terms of the entity that
signs or authorizes that transaction and provides an account-based sequence
number. When the Aptos network receives a new transaction, several rules are
followed with respect to this:

- The transaction sent from an account must be authorized correctly by that
  account.
- The current time as defined by the most recent ledger update must be before
  the expiration timestamp of the transaction.
- The transaction's sequence number must be equal to or greater than the
  sequence number on-chain for that account.

Once the initial node has accepted a transaction, the transaction makes its way
through the system by an additional rule. If a transactions sequence number is
higher than the current on-chain sequence number, it can only progress toward
consensus if every node in the path has seen a transaction with the sequence
number between the on-chain state and the current sequence number.

Example:

Alice owns an account whose current on-chain sequence number is 5.

Alice submits a transaction to node Bob with sequence number 6.

Bob the node accepts the transaction but does not forward it, because Bob has
not seen 5.

In order to make progress, Alice must either send Bob transaction number 5 or
Bob must be notified from consensus that 5 was committed. In the latter, Alice
submitted the transaction through another node.

Beyond this there are two remaining principles:

- A single account can have at most 100 uncommitted transactions submitted to
  the blockchain. Any more than that and the transactions will be rejected. This
  can happen silently if Alice submits the first 100 to Bob the node and the
  next 100 to Carol the node. If both those nodes share a common upstream, then
  that upstream will accept Alice's 100 sent via Bob but silently reject Alice's
  100 sent via Carol.
- Submitting to distinct transactions to multiple nodes will result in slow
  resolution as transactions will not make progress from the submitted node
  until the submitted knows that all preceding transactions have been committed.
  For example, if Alice sends the first 50 via Bob and the next 50 via Carol.

## Building a Transaction Manager

Now that we understand the nuances of transactions, let's dig into building a
robust transaction manager. This consists of the following core components:

- A sequence number generator that allocates and manages available sequence
  numbers for a single account.
- A transaction manager that receives payloads from an application or a user,
  sequence numbers from the sequence number generator, and has access to the
  account key to combine the three pieces together into a viable signed
  transaction. It then also takes the responsibility for pushing the transaction
  to the blockchain.
- An on-chain worker, leader harness that lets multiple accounts share the
  signer of a single shared account.

Currently, this framework assumes that the network builds no substantial queue,
that is a transaction that is submitted executes and commits with little to no
delay. In order to address high demand, this work needs to be extended with the
following components:

- Optimizing `base_gas_unit` price to ensure priority transactions can be
  committed to the blockchain.
- Further handling of transaction processing rates to ensure that the expiration
  timer is properly set.
- Handling of transaction failures to either be ignored or resubmitted based
  upon desired outcome.

Note, an account should be managed by a single instance of the transaction
manager. Otherwise, each instance of the transaction manager will likely have
stale in-memory state resulting in overlapping sequence numbers.

### Implementations

- Python
  - [Sequence number manager](https://github.com/aptos-labs/aptos-core/pull/7987)
  - [Transaction manager](https://github.com/aptos-labs/aptos-core/pull/7987)
- [Worker-leader smart contract](https://github.com/aptos-labs/aptos-core/pull/7986)

### Managing Sequence Numbers

Each transaction requires a distinct sequence number that is sequential to
previously submitted transactions. This can be provided by the following
process:

1. At startup, query the blockchain for the account‚Äôs current sequence number.
2. Support up to 100 transactions in flight at the same time, that is 100
   sequence numbers can be allocated without confirming that any have been
   committed.
3. If there are 100 transactions in flight, determine the actual committed state
   by querying the network. This will update the current sequence number.
4. If there are less than 100 transactions in flight, return to step 2.
5. Otherwise, sleep for .1 seconds and continue to re-evaluate the current
   on-chain sequence number.
6. All transactions should have an expiration time. If the expiration time has
   passed, assume that there has been a failure and reset the sequence number.
   The trivial case is to only monitor for failures when the maximum number of
   transactions are in flight and to let other services manages this otherwise.

In parallel, monitor new transactions submitted. Once the earliest transaction
expiration time has expired synchronize up to that transaction. Then repeat the
process for the next transaction.

If there is any failure, wait until all outstanding transactions have timed out
and leave it to the application to decide how to proceed, e.g., replay failed
transactions. The best method to waiting for outstanding transactions is to
query the ledger timestamp and ensure it is at least elapsed the maximum timeout
from the last transactions submit time. From there, validate with mempool that
all transactions since the last known committed transaction are either committed
or no longer exist within the mempool. This can be done by querying the REST API
for transactions of a specific account, specifying the currently being evaluated
sequence number and setting a limit to 1. Once these checks are complete, the
local transaction number can be resynchronized.

These failure handling steps are critical for the following reasons:

- Mempool does not immediate evict expired transactions.
- A new transaction cannot overwrite an existing transaction, even if it is
  expired.
- Consensus, i.e., the ledger timestamp, dictates expirations, the local node
  will only expire after it sees a committed timestamp after the transactions
  expiration time and a garbage collection has happened.

### Managing Transactions

Once a transaction has been submitted it goes through a variety of steps:

1. Submission to a REST endpoint.
2. Pre-execution validation in the Mempool during submission.
3. Transmission from Mempool to Mempool with pre-execution validation happening
   on each upstream node.
4. Inclusion in a consensus proposal.
5. One more pre-execution validation.
6. Execution and committing to storage.

There are many potential failure cases that must be considered:

- Failure during transaction submission (1 and 2):
  - Visibility: The application will receive an error either that the network is
    unavailable or that the transaction failed pre-execution validation.
  - If the error is related to availability or duplicate sequence numbers, wait
    until access is available and the sequence number has re-synchronized.
  - Pre-execution validation failures are currently out of scope, outside of
    those related to duplicate sequence numbers, account issues are likely
    related to an invalid key for the account or the account lacks sufficient
    funds for gas.
- Failure between submission and execution (3, 4, and 5):
  - Visibility: Only known by waiting until the transaction has expired.
  - These are the same as other pre-execution validation errors due to changes
    to the account as earlier transactions execute. It is likely either
    duplicate sequence numbers or the account lacks sufficient funds for gas.
- Failure during execution (6):
  - Visibility: These are committed to the blockchain.
  - These errors occur as a result of on-chain state issues, these tend to be
    application specific, such as an auction where a new bid might not actually
    be higher than the current bid.

### Workers and Identity

Using the above framework, a single account can push upwards of 100 transactions
from the start of a block to the end of a block. Assuming that all 100
transactions are consumed within 1 block, it will take a bit of time for the
next 100 slots to be available. This is due to the network delays as well as the
multi-staged validator pipeline.

To fully leverage the blockchain for massive throughput, using a single user
account is not enough. Instead, Aptos supports the concept of worker accounts
that can share the responsibility of pushing work through a shared account, also
known as a resource account.

In this model, each worker has access to the `SignerCap` of the shared account,
which enables them to impersonate the shared account or generate the `signer`
for the shared account. Upon gaining the `signer`, the transaction can execute
the logic that is gated by the signer of the shared account.

Another model, if viable, is to decouple the `signer` altogether away from
permissions and to make an application specific capability. Then this capability
can be given to each worker that lets them operate on the shared infrastructure.

Note that parallelization on the shared infrastructure can be limited if any
transaction would have any read or write conflicts. This won‚Äôt prevent multiple
transactions from executing within a block, but can impact maximum blockchain
performance.

# Your First NFT

> Learn to create, mint, and transfer digital assets (NFTs) on Aptos using the TypeScript SDK with step-by-step examples.

import { Aside, Steps } from '@astrojs/starlight/components';

This tutorial will guide you through the process of using the Aptos TypeScript SDK (`@aptos-labs/ts-sdk`) to create a new digital asset (often referred to as an NFT) on Aptos. By the end of this tutorial, you will know how to:

1. Create a collection of digital assets (NFTs).
2. Mint a new digital asset (NFT) within that collection.
3. Transfer the digital asset (NFT) between accounts.
4. Verify the digital asset's (NFT's) movement by checking the updated balances.

<Aside type="note">
  This tutorial assumes you are comfortable with using the [Aptos CLI](/build/cli), have Node.js and npm installed, and understand basic JavaScript/TypeScript concepts. If you need more info, check out [Node.js Introduction](https://nodejs.org/en/learn/getting-started/introduction-to-nodejs) or the [Aptos TypeScript SDK](/build/sdks/ts-sdk) documentation.
</Aside>

## Walking Through The Code

Below is the step-by-step explanation of how to create, transfer, and interact with a digital asset on-chain. We'll go through how the example code (shown in full at the end) does it. To skip to just getting the code running, see [**Running An Example**](#running-an-example).

### Code Walkthrough

<Steps>
  1. Setup the Client

     We import and configure the `Aptos` client from the SDK to connect to the specified network:

     ```tsx filename="index.ts"
     const APTOS_NETWORK = NetworkToNetworkName[process.env.APTOS_NETWORK] || Network.DEVNET;
     const config = new AptosConfig({ network: APTOS_NETWORK });
     const aptos = new Aptos(config);
     ```

     This `aptos` object allows us to interact with the Aptos blockchain (funding accounts, creating assets, submitting transactions, etc.).

  2. Create and Fund Accounts

     We generate two accounts, Alice and Bob. On devnet, we can easily fund them with test APT.

     ```tsx filename="index.ts"
     const alice = Account.generate();
     const bob = Account.generate();

     await aptos.fundAccount({ accountAddress: alice.accountAddress, amount: INITIAL_BALANCE });
     await aptos.fundAccount({ accountAddress: bob.accountAddress, amount: INITIAL_BALANCE });
     ```

  3. Create a Collection

     We create a collection in Alice's account. A collection acts like a "folder" or "category" for digital assets. In this case, we are creating `"Example Collection"`.

     ```tsx filename="index.ts"
     const createCollectionTransaction = await aptos.createCollectionTransaction({
       creator: alice,
       description: "This is an example collection.",
       name: "Example Collection",
       uri: "aptos.dev",
     });

     const committedTxn = await aptos.signAndSubmitTransaction({
       signer: alice,
       transaction: createCollectionTransaction,
     });
     await aptos.waitForTransaction({ transactionHash: committedTxn.hash });
     ```

     <Aside type="note">
       Always wait for the transaction to complete using `waitForTransaction` before proceeding. This ensures the collection is ready before you try minting.
     </Aside>

  4. Mint a Digital Asset

     With the collection created, we can now mint a digital asset (an NFT) for the collection. This involves providing details like the name, description, and a URI (often linking to metadata like images).

     ```tsx filename="index.ts"
     const mintTokenTransaction = await aptos.mintDigitalAssetTransaction({
       creator: alice,
       collection: "Example Collection",
       description: "This is an example digital asset.",
       name: "Example Asset",
       uri: "https://aptos.dev/asset.png",
     });

     const mintTxn = await aptos.signAndSubmitTransaction({
       signer: alice,
       transaction: mintTokenTransaction,
     });
     await aptos.waitForTransaction({ transactionHash: mintTxn.hash });
     ```

     <Aside type="note">
       You can change these values to customize your Digital Asset on-chain.
     </Aside>

  5. Transfer the Digital Asset

     Once minted, the asset belongs to Alice. We can verify this by fetching Alice's digital assets. Then we build and submit a transaction to transfer this asset to Bob.

     ```tsx filename="index.ts"
     const aliceDigitalAssets = await aptos.getOwnedDigitalAssets({ ownerAddress: alice.accountAddress });
     const digitalAssetAddress = aliceDigitalAssets[0].token_data_id;

     const transferTransaction = await aptos.transferDigitalAssetTransaction({
       sender: alice,
       digitalAssetAddress,
       recipient: bob.accountAddress,
     });

     const transferTxn = await aptos.signAndSubmitTransaction({
       signer: alice,
       transaction: transferTransaction,
     });
     await aptos.waitForTransaction({ transactionHash: transferTxn.hash });
     ```

     After completion, the asset should now appear in Bob's account.

  6. Verify the Balances

     Finally, we check both Alice's and Bob's accounts to ensure that Alice no longer has the asset and Bob now has it.

     ```tsx filename="index.ts"
     const aliceDigitalAssetsAfter = await aptos.getOwnedDigitalAssets({ ownerAddress: alice.accountAddress });
     const bobDigitalAssetsAfter = await aptos.getOwnedDigitalAssets({ ownerAddress: bob.accountAddress });

     console.log(`Alice's digital asset balance: ${aliceDigitalAssetsAfter.length}`);
     console.log(`Bob's digital asset balance: ${bobDigitalAssetsAfter.length}`);
     ```
</Steps>

## Running An Example

### Getting Started

<Steps>
  1. Set up Your Project

     Create a new directory for your project and initialize a Node.js project:

     ```shellscript filename="Terminal"
     mkdir aptos-digital-asset-tutorial
     cd aptos-digital-asset-tutorial
     npm init -y
     ```

     This will create a `package.json` file, allowing you to install dependencies and run scripts.

  2. Install Dependencies

     You will need the Aptos TypeScript SDK and `dotenv` to manage environment variables:

     ```shellscript filename="Terminal"
     npm install @aptos-labs/ts-sdk dotenv
     npm install --save-dev @types/node
     ```

  3. Create tsconfig.json

     Create a `tsconfig.json` file with the following:

     ```json filename="tsconfig.json"
     {
       "compilerOptions": {
         "target": "es2020",
         "module": "commonjs",
         "esModuleInterop": true,
         "forceConsistentCasingInFileNames": true,
         "strict": true,
         "skipLibCheck": true,
         "types": ["node"],
         "lib": ["es2020"]
       }
     }
     ```

     This configuration ensures TypeScript properly recognizes Node.js types and provides appropriate type checking.

  4. Configure Environment Variables

     Create a `.env` file with the following:

     ```shellscript filename="Terminal"
     APTOS_NETWORK=devnet
     ```

     <Aside type="note">
       By default, we'll use `devnet`, but you can also choose `testnet` or `mainnet` depending on your needs.
     </Aside>

  5. Adding index.ts

     Create an `index.ts` file with the following:

     ```tsx filename="index.ts"
     // Update the TODOs below to customize this digital asset to your needs.
     // You will want to customize the Collection values and individual Digital Asset values.
     // This example demonstrates creating a collection, populating it with digital assets, and transferring them.

     import "dotenv/config";
     import {
         Account,
         Aptos,
         AptosConfig,
         Network,
         NetworkToNetworkName,
     } from "@aptos-labs/ts-sdk";

     // Verify environment variables are loaded
     console.log("Environment variables loaded:", {
         APTOS_NETWORK: process.env.APTOS_NETWORK || "not set"
     });

     const INITIAL_BALANCE = 100_000_000;

     console.log("Step 1: Setting up a client to connect to Aptos");
     const APTOS_NETWORK = NetworkToNetworkName[process.env.APTOS_NETWORK!] || Network.DEVNET;
     const config = new AptosConfig({ network: APTOS_NETWORK });
     const aptos = new Aptos(config);

     async function example() {
         console.log("\n=== Step 2: Creating and funding accounts ===\n");
         const alice = Account.generate();
         const bob = Account.generate();

         console.log(`Alice's address: ${alice.accountAddress}`);
         console.log(`Bob's address: ${bob.accountAddress}`);

         console.log("Funding Alice's account...");
         await aptos.fundAccount({ accountAddress: alice.accountAddress, amount: INITIAL_BALANCE });
         console.log("Alice's account funded!");

         console.log("Funding Bob's account...");
         await aptos.fundAccount({ accountAddress: bob.accountAddress, amount: INITIAL_BALANCE });
         console.log("Bob's account funded!");

         console.log("\n=== Step 3: Creating a collection ===\n");
         // TODO: Update these values to customize your Digital Asset!
         const collectionName = "Example Collection";
         const collectionDescription = "This is an example collection.";
         const collectionURI = "aptos.dev";

         console.log("Building the collection creation transaction...");
         const createCollectionTransaction = await aptos.createCollectionTransaction({
             creator: alice,
             description: collectionDescription,
             name: collectionName,
             uri: collectionURI,
         });

         console.log("Submitting the collection creation transaction...");
         const committedTxn = await aptos.signAndSubmitTransaction({
             signer: alice,
             transaction: createCollectionTransaction,
         });

         console.log("Waiting for the collection creation transaction to complete...");
         await aptos.waitForTransaction({ transactionHash: committedTxn.hash });
         console.log("Collection created successfully!");

         console.log("\n=== Step 4: Minting a digital asset ===\n");
         // TODO: Update the values of the Digital Assets you are minting!
         const tokenName = "Example Asset";
         const tokenDescription = "This is an example digital asset.";
         const tokenURI = "aptos.dev/asset";

         console.log("Building the mint transaction...");
         const mintTokenTransaction = await aptos.mintDigitalAssetTransaction({
             creator: alice,
             collection: collectionName,
             description: tokenDescription,
             name: tokenName,
             uri: tokenURI,
         });
         console.log(mintTokenTransaction)

         console.log("Submitting the mint transaction...");
         const mintTxn = await aptos.signAndSubmitTransaction({
             signer: alice,
             transaction: mintTokenTransaction,
         });
         console.log(mintTxn)

         console.log("Waiting for the mint transaction to complete...");
         await aptos.waitForTransaction({ transactionHash: mintTxn.hash });
         console.log("Digital asset minted successfully!");

         console.log("\n=== Step 5: Transferring the digital asset ===\n");

         // Wait for the indexer to update with the latest data from on-chain
         await new Promise((resolve) => setTimeout(resolve, 5000));

         const aliceDigitalAssets = await aptos.getOwnedDigitalAssets({
             ownerAddress: alice.accountAddress,
         });

         // Check if Alice has any digital assets before accessing them
         if (aliceDigitalAssets.length === 0) {
             console.error("No digital assets found for Alice. Make sure the minting was successful.");
             return;
         }

         const digitalAssetAddress = aliceDigitalAssets[0].token_data_id;

         console.log("Building the transfer transaction...");
         const transferTransaction = await aptos.transferDigitalAssetTransaction({
             sender: alice,
             digitalAssetAddress,
             recipient: bob.accountAddress,
         });

         console.log("Submitting the transfer transaction...");
         const transferTxn = await aptos.signAndSubmitTransaction({
             signer: alice,
             transaction: transferTransaction,
         });

         console.log("Waiting for the transfer transaction to complete...");
         await aptos.waitForTransaction({ transactionHash: transferTxn.hash });
         console.log("Digital asset transferred successfully!");

         console.log("\n=== Step 6: Verifying digital asset balances ===\n");
         const aliceDigitalAssetsAfter = await aptos.getOwnedDigitalAssets({
             ownerAddress: alice.accountAddress,
         });
         const bobDigitalAssetsAfter = await aptos.getOwnedDigitalAssets({
             ownerAddress: bob.accountAddress,
         });

         console.log(`Alice's digital asset balance: ${aliceDigitalAssetsAfter.length}`);
         console.log(`Bob's digital asset balance: ${bobDigitalAssetsAfter.length}`);

         console.log("\n=== Step 7: Transaction hashes for explorer ===\n");
         console.log(`Collection creation transaction: ${committedTxn.hash}`);
         console.log(`Mint transaction: ${mintTxn.hash}`);
         console.log(`Transfer transaction: ${transferTxn.hash}`);
         console.log("\nYou can view these transactions on the Aptos Explorer:");
         console.log("https://explorer.aptoslabs.com/?network=devnet");
     }

     example();
     ```

  6. Run the code

     ```shellscript filename="Terminal"
     npx ts-node index.ts
     ```

     If everything is set up correctly, you will see output logs detailing each step, transaction hashes, and final balances.

  7. View Your Transactions on the Explorer

     After running the code, you'll see transaction hashes in the console output, especially in Step 7 which displays all transaction hashes for easy reference:

     ```shellscript filename="Terminal"
     === Step 7: Transaction hashes for explorer ===

     Collection creation transaction: 0x8c5d2a4ce32d76349bfb4f3830740c1c103399e8cbc31d6e2c7a871c88e6ad48
     Mint transaction: 0x673d2cbb9fef468fe41f271c0fcf20872e9fa79afb6a2000368394000071b02e
     Transfer transaction: 0x3a1e99d6fd3f8e7e962c311f3dfd92c11e468da5b6084123b8f7e0248a37ffa7

     You can view these transactions on the Aptos Explorer:
     https://explorer.aptoslabs.com/?network=devnet
     ```

     You can view these transactions on the Aptos Explorer:

     1. Copy the transaction hash from your console
     2. Visit [Aptos Explorer](https://explorer.aptoslabs.com/?network=devnet)
     3. Make sure you're on the correct network (Devnet)
     4. Paste the transaction hash in the search bar
     5. View the details of your transaction, including:
        - The sender and recipient addresses
        - The exact time the transaction was processed
        - Gas fees paid
        - The digital asset that was transferred

     This is a great way to verify your transactions and understand how they're recorded on the blockchain.
</Steps>

### Further Reading & Resources

- [aptos ts-sdk docs](/build/sdks/ts-sdk)
- [Account basics](/network/blockchain/accounts)
- [REST API specification](/rest-api)

# Indexer

> Query indexed blockchain data using GraphQL API, create custom processors with the Indexer SDK, or stream raw transactions from Aptos blockchain

import { Aside, CardGrid, LinkCard } from '@astrojs/starlight/components';

import { GraphQLEditor } from '~/components/react/GraphQLEditor';

We have several offerings for getting indexed data from the Aptos blockchain.

1. Query the [Indexer API](/build/indexer/indexer-api) to get basic data about transactions, fungible assets, and tokens
2. Index your custom contract with the [Indexer SDK](/build/indexer/indexer-sdk)
3. Stream raw transactions from [Transaction Stream Service](/build/indexer/txn-stream) to your processor or service

## Indexer API

The Aptos Indexer is an API you can use to get:

1. Aggregate data (ex. How many NFTs exist?)
2. Historical data (ex. What transactions has this account submitted?)
3. Data that is hard to get from the simpler [Aptos Node API](/build/apis/fullnode-rest-api) (ex. What account owns a token named "ExampleToken"?).

For example, you can use the Indexer API to look up the fungible asset balances of any account like so:

<GraphQLEditor
  query={`query GetFungibleAssetBalances($address: String, $offset: Int) {
  current_fungible_asset_balances(
    where: { owner_address: { _eq: $address } }
    offset: $offset
    limit: 100
    order_by: { amount: desc }
  ) {
    asset_type
    amount
    __typename
  }
}`}
  variables={`{
  "address": "0x0000000000000000000000000000000000000000000000000000000000000001",
  "offset": 0
}`}
/>

<Aside type="note">
  The Indexer tracks every transaction that happens on-chain, then exposes that data through a GraphQL API.
</Aside>

## Using the Indexer API

Learn how to use the Indexer API, what each table represents, and the architecture.

<CardGrid>
  <LinkCard href="/build/indexer/indexer-api" title="Accessing the API" description="Learn how to query the Indexer API." />

  <LinkCard href="/build/indexer/indexer-api/indexer-reference" title="Indexer Table Reference" description="Detailed reference for Indexer tables and their schemas." />

  <LinkCard href="/build/indexer/indexer-api/architecture" title="Architecture" description="Detailed layout of the Indexer's architecture." />

  <LinkCard href="/build/indexer/indexer-api/self-hosted" title="Self-hosted Indexer API" description="Host your own Indexer API" />
</CardGrid>

### Example Queries

To help get you started, here are the most common queries the Indexer is used for.

<CardGrid>
  <LinkCard href="/build/indexer/indexer-api/fungible-asset-balances" title="Get Fungible Asset Balances" description="Get all fungible assets an account currently owns." />

  <LinkCard href="/build/indexer/indexer-api/account-transactions" title="Get Account Transactions" description="Get all transactions impacting an account." />

  <LinkCard href="/build/indexer/indexer-api/ans-lookup" title="Get Aptos Name" description="Retrieve the Aptos name associated with an account (via the ANS)." />

  <LinkCard href="/build/indexer/indexer-api/fungible-asset-info" title="Get Fungible Asset Info" description="Get detailed information about a specific fungible asset." />

  <LinkCard href="/build/indexer/indexer-api/get-nft-collections" title="Get NFT Collections" description="Retrieve NFT collections owned by a specific account." />

  <LinkCard href="/build/indexer/indexer-api/get-nfts" title="Get NFTs" description="Retrieve individual NFTs owned by a specific account." />

  <LinkCard href="/build/indexer/indexer-api/token-metadata" title="Get Token Metadata" description="Get metadata information for a specific token." />

  <LinkCard href="/build/indexer/indexer-api/get-delegators" title="Count Delegators in Staking Pool" description="Retrieve the number of active delegators in a staking pool." />
</CardGrid>

## Indexer SDK

If the hosted Indexer API is not enough or if you want to index your custom contract, you can create a processor with the [Indexer SDK](/build/indexer/indexer-sdk).

<CardGrid>
  <LinkCard href="/build/indexer/indexer-sdk/quickstart" title="Quickstart Guide" description="Get started with the Indexer SDK" />

  <LinkCard href="/build/indexer/indexer-sdk/documentation" title="Documentation" description="Read documentation about the Indexer SDK" />
</CardGrid>

## Transaction Stream Service

Transaction Stream Service is a GRPC service that streams raw transactions to your processor or service.
If you're using the Indexer SDK, you'll need an authorization token to connect to Transaction Stream Service.

<CardGrid>
  <LinkCard href="/build/indexer/txn-stream/aptos-hosted-txn-stream" title="Aptos-Hosted Transaction Stream Service" description="Get access to the Aptos-hosted Transaction Stream Service" />
</CardGrid>

## Legacy Indexer

Find information about the legacy indexer [here](/build/indexer/legacy).

# Indexer API Access

> Access Aptos Indexer GraphQL API for historical data, transactions, fungible assets, and tokens with SDK integration and direct endpoints

import { Aside, CardGrid, LinkCard } from '@astrojs/starlight/components';

{/* <IndexerBetaNotice /> */}

Aptos Labs hosts a public version of the Indexer GraphQL API that anyone can use to get basic historical and aggregate data about transactions, fungible assets, and tokens from on-chain.

You can explore it by hand by viewing the Hasura Explorer below for the network you are interested in.

You can also access the API via the GraphQL endpoints below. For more information on the format of data in each field / table, please see the [table reference page](/build/indexer/indexer-api/indexer-reference).

## SDK Access (Primary Method)

The primary way to use the Indexer is to access it through the [TypeScript SDK](/build/sdks/ts-sdk/fetch-data-via-sdk).

The TypeScript SDK will automatically handle rate limits, and can seamlessly allow for both [Fullnode REST API](/build/apis/fullnode-rest-api) access and Indexer access depending on what data is needed.

## Hasura Explorer (Manual Queries)

<Aside type="note">
  For detailed reference material about the contents of these tables, see the [Indexer Table Reference page](/build/indexer).
</Aside>

Choose a network to explore the free Aptos-Hosted Indexer API using the Hasura Explorer:

<CardGrid>
  <LinkCard href="https://cloud.hasura.io/public/graphiql?endpoint=https://api.mainnet.aptoslabs.com/v1/graphql" title="Mainnet" description="Hasura GraphQL Explorer for Aptos Mainnet" target="_blank" />

  <LinkCard href="https://cloud.hasura.io/public/graphiql?endpoint=https://api.testnet.aptoslabs.com/v1/graphql" title="Testnet" description="Hasura GraphQL Explorer for Aptos Testnet" target="_blank" />

  <LinkCard href="https://cloud.hasura.io/public/graphiql?endpoint=https://api.devnet.aptoslabs.com/v1/graphql" title="Devnet" description="Hasura GraphQL Explorer for Aptos Devnet" target="_blank" />
</CardGrid>

## GraphQL API Endpoints (Direct Access)

If you need to directly make GraphQL queries to the Aptos-Labs hosted Indexer API, then use the following endpoints:

- **Mainnet:** `https://api.mainnet.aptoslabs.com/v1/graphql`
- **Testnet:** `https://api.testnet.aptoslabs.com/v1/graphql`
- **Devnet:** `https://api.devnet.aptoslabs.com/v1/graphql`

### Rate limits

Learn more about the rate limits that apply to the Aptos Labs hosted indexer API by reading the [Geomi docs](https://geomi.dev/docs/admin/billing).

If you need a higher rate limit, consider the following solutions:

1. Get an API Key from [Geomi](https://geomi.dev/). Learn more about API keys at the [Geomi docs site](https://geomi.dev/docs/api-keys).
2. Run the Aptos Indexer API yourself. See the guide to self-hosting [here](/build/indexer/txn-stream/self-hosted).

# Get Account Transactions Data

> Retrieve historical transaction data for accounts using GraphQL queries with transaction versions and chronological ordering

import { GraphQLEditor } from '~/components/react/GraphQLEditor';

import { Aside } from '@astrojs/starlight/components';

`AccountTransactionsData` retrieves `transaction_version`s of transactions that affect a specified account address, ordered in descending order. `transaction_version` is a unique id given to each transaction on-chain that increases by 1 each time.

This query is essential for applications that require a historical log of transactions for audit, tracking, or display purposes.

<Aside type="note">
  Experiment and see the results! Modify the address, limit, and offset in the variables below to customize your query.
</Aside>

<GraphQLEditor
  query={`query GetAccountTransactionsData($address: String, $limit: Int) {
  account_transactions(
    where: { account_address: { _eq: $address } }
    order_by: { transaction_version: desc }
    limit: $limit
  ) {
    transaction_version
    __typename
  }
}`}
  variables={`{
  "address": "0xffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff",
  "limit": 10
}`}
/>

#### Variables:

- `$address`: **String** - The blockchain account address for which to query transaction data. Example: `"0x1abcdef1234567890abcdef1234567890abcdef1234567890abcdef1234567890abcdef"`.
- `$limit`: **Integer** - Specifies the maximum number of transaction versions to return. Helps manage the volume of data retrieved. Example: `10`.
- `$offset`: **Integer** - The offset from which to start fetching the transaction versions. Useful for paginating results. Example: `0`.

<br />

# Getting Recent Transactions

A helpful variant of the above query limits results to just ones that happened after a specific `transaction_version`. All results will have a `transaction_version` greater than `$gt`.

<GraphQLEditor
  query={`query GetAccountTransactionsData($address: String, $limit: Int, $gt: bigint) {
  account_transactions(
    where: {
      account_address: { _eq: $address }
      transaction_version: { _gt: $gt }
    }
    order_by: { transaction_version: desc }
    limit: $limit
  ) {
    transaction_version
    __typename
  }
}`}
  variables={`{
  "address": "0xffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff",
  "limit": 10,
  "gt": 599296148
}`}
/>

#### Variables:

- `$address`: **String** - The blockchain account address for which to query transaction data. Example: `"0xffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff"`.
- `$limit`: **Integer** - Specifies the maximum number of transaction versions to return. This helps limit the results to a manageable size. Example: `10`.
- `$gt`: **bigint** - The transaction version number above which transactions should be fetched. A transaction version is a sequentially increasing number that increments for every transaction.
  Transaction version 0 is the first transaction (genesis transaction), and a transaction version 100 is the 101st transaction in the blockchain.
  Example: `599296148`.

# Get Aptos Name From Address

> Look up registered Aptos Name Service (ANS) domain names for account addresses with reverse domain lookup functionality

import { GraphQLEditor } from '~/components/react/GraphQLEditor';

import { Aside } from '@astrojs/starlight/components';

`getNameFromAddress` looks for a registered domain name for a given account. For example, a user could register their account with the Aptos Name Service to be associated to `love.apt`. You can learn more by going to [https://www.aptosnames.com/](https://www.aptosnames.com/).

<Aside type="caution">
  This only returns _active_ names. Name registrations can expire if not renewed, which may explain some empty results.
</Aside>

<Aside type="note">
  Try it yourself! You can customize the variables at the bottom of the editor.
</Aside>

<GraphQLEditor
  query={`query getNameFromAddress($registered_address: String) {
  current_aptos_names(
    where: {
      registered_address: { _eq: $registered_address }
      is_active: { _eq: true }
    }
    order_by: [
      { is_primary: desc }
      { last_transaction_version: desc }
      { expiration_timestamp: desc }
    ]
    limit: 1
  ) {
    domain
    subdomain
  }
}`}
  variables={`{
  "registered_address": "0xca4349ce902a656570a4f344cc8f360fb13fd41b5fae77bcc9ee82252d67539e"
}`}
/>

#### Variables:

- `$registered_address`: **String** - The account address you want to find any associated active domain names for. Ex. `"0xca4349ce902a656570a4f344cc8f360fb13fd41b5fae77bcc9ee82252d67539e"`.

# Indexer Architecture

> Understanding Aptos Indexer architecture: Transaction Stream Service, custom processors, database integration, and API structure

import { ThemedImage } from '~/components/ThemedImage';

The Aptos Indexer stores data from on-chain (via the Transaction Stream Service). It indexes basic data about transactions, fungible assets, tokens, collections, accounts, ANS (Aptos Name Service) names, and more. Apps can query that data via the Indexer API.

Aptos Labs hosts a free version of the Indexer API to help the community get access to data such as:

1. Historical data - Ex. [What transactions have impacted this account?](/build/indexer/indexer-api/account-transactions)
2. Aggregate data - Ex. [How many delegators are in this staking pool?](/build/indexer/indexer-api/get-delegators)
3. Specific info best searched via query - Ex. [What NFTs does an account own?](/build/indexer/indexer-api/get-nfts)

### High Level Breakdown

Here is how the Indexer creates that API at a high-level:

<center>
  <ThemedImage
    alt="Signed Transaction Flow"
    sources={{
light: '~/images/indexer-architecture-light.svg',
dark: '~/images/indexer-architecture-dark.svg',
}}
  />
</center>

The Indexer uses the [Transaction Stream Service](/build/indexer/txn-stream) and custom processors written with the [Indexer SDK](/build/indexer/indexer-sdk) to update a database with rich tables. Then it exposes an API for Aptos apps to access the consolidated data.

For situations where you need to go beyond the Aptos hosted Indexer API data, you will want to create a custom processor with the [Indexer SDK](/build/indexer/indexer-sdk).

Writing a custom processor can help you:

1. Get access to different types of data.
2. Store additional information beyond what the Aptos Labs hosted Indexer API is saving.
3. Change how transactions are processed.

If you would like to operate your own Indexer API as a service, see how to [host your own Indexer](/build/indexer/indexer-api/self-hosted).

## Detailed Overview

You can use the below diagram for a much more in-depth diagram explaining how the Indexer code actually works behind the scenes.

<div style={{textAlign:"center"}}>
  <div style={{marginBottom: 20}}>
    <iframe style={{border: "1px solid rgba(0, 0, 0, 0.1)", width: "100%", height: "750px"}} src="https://embed.figma.com/board/sVhSOGR7ZT4CdeUzlXyduD/Detailed-Overview?node-id=18675-303&embed-host=share" allowfullscreen />
  </div>
</div>

# Get Fungible Asset Balances

> Query current fungible asset balances for accounts with real-time holdings data and backwards compatibility for coins

import { GraphQLEditor } from '~/components/react/GraphQLEditor';

import { Aside } from '@astrojs/starlight/components';

`GetFungibleAssetBalances` retrieves the current balances for various fungible asset types associated with a specified account address. This is crucial for platforms requiring real-time information on account asset holdings. This is backwards compatible with looking up `Coin`s.

<Aside type="note">
  Try it yourself! Adjust the query variables below in the editor to fetch data for different addresses.
</Aside>

<GraphQLEditor
  query={`query GetFungibleAssetBalances(
  $address: String
  $offset: Int
  $token_standard: String
) {
  current_fungible_asset_balances(
    where: {
      owner_address: { _eq: $address }
      token_standard: { _eq: $token_standard }
    }
    offset: $offset
    limit: 100
    order_by: { amount: desc }
  ) {
    asset_type
    amount
    __typename
  }
}`}
  variables={`{
  "address": "0x0000000000000000000000000000000000000000000000000000000000000001",
  "token_standard": "v1",
  "offset": 0
}`}
/>

#### Variables:

- `$address`: **String** - The account address for which to fetch fungible asset balances. Example: `"0x0000000000000000000000000000000000000000000000000000000000000001"`.
- `token_standard`: **String** - The token standard for the asset: `"v1"` is the previous token standard and `"v2"` is the new standard.
- `$offset`: **Integer** (Optional) - The pagination offset to start fetching balances from. Default: `0`.

# Get Fungible Asset Info

> Query fungible asset information including symbol, name, decimals, and asset types with backwards compatibility for coins

import { GraphQLEditor } from '~/components/react/GraphQLEditor';

import { Aside } from '@astrojs/starlight/components';

By providing a list of fungible asset types, `GetFungibleAssetInfo` can fetch data such as the symbol, name, decimals, and the asset type itself. This is particularly useful for applications needing to display token details. This is backwards compatible with looking up `Coin` info.

<Aside type="note">
  Try it yourself! You can customize the variables at the bottom of the editor.
</Aside>

<GraphQLEditor
  query={`query GetFungibleAssetInfo($in: [String!], $offset: Int) {
  fungible_asset_metadata(
    where: { asset_type: { _in: $in } }
    offset: $offset
    limit: 100
  ) {
    symbol
    name
    decimals
    asset_type
    __typename
  }
}`}
  variables={`{
  "in": ["0x1::aptos_coin::AptosCoin", "0x1::example_coin::ExampleCoin"],
  "offset": 0
}`}
/>

## Variables:

- `$in`: **List of String** - This variable should contain a list of fungible asset types you want to query information for. Ex. `["0x1::aptos_coin::AptosCoin"]`
- `$offset`: **Integer** (Optional) - This variable can be used to paginate through results, specifying how many records to skip before starting to return results.

# Count Number of Active Delegators for a Pool

> Query active delegator counts for staking pools with GraphQL API for delegation pool participation analysis

import { GraphQLEditor } from '~/components/react/GraphQLEditor';

import { Aside } from '@astrojs/starlight/components';

`getNumberOfDelegators` retrieves the count of active delegators for a specified pool address. This query is especially valuable for platforms that need to analyze participation in staking or delegation pools.

<Aside type="note">
  Try it now! Customize the variable below in the editor to explore different pool addresses.
</Aside>

<GraphQLEditor
  query={`query getNumberOfDelegators($poolAddress: String) {
  num_active_delegator_per_pool(
    where: {
      pool_address: { _eq: $poolAddress }
      num_active_delegator: { _gt: "0" }
    }
    distinct_on: pool_address
  ) {
    num_active_delegator
  }
}`}
  variables={`{
  "poolAddress": "0x06099edbe54f242bad50020dfd67646b1e46282999483e7064e70f02f7ea3c15"
}`}
/>

#### Variables:

- `$poolAddress`: **String** - The address of the pool for which to query the number of active delegators. Example: `"0x06099edbe54f242bad50020dfd67646b1e46282999483e7064e70f02f7ea3c15"`.

# Retrieve NFT Collections Owned by an Account

> Fetch NFT collection details owned by accounts including collection metadata, token counts, and comprehensive collection attributes

import { GraphQLEditor } from '~/components/react/GraphQLEditor';

import { Aside } from '@astrojs/starlight/components';

`GetAccountNftCollections` fetches detailed information about NFT collections owned by a specific account address. This includes data such as the collection ID, distinct token count within each collection, and detailed attributes of each collection. It's particularly useful for applications that need to display comprehensive details about NFT holdings associated with an account.

<Aside type="note">
  Try it yourself! You can customize the variables at the bottom of the editor.
</Aside>

<GraphQLEditor
  query={`query GetAccountNftCollections($address: String) {
  current_collection_ownership_v2_view(
    where: { owner_address: { _eq: $address } }
    limit: 1000000
    offset: 0
    order_by: [{ last_transaction_version: desc }, { collection_id: asc }]
  ) {
    collection_id
    distinct_tokens
    last_transaction_version
    owner_address
    current_collection {
      collection_id
      collection_name
      creator_address
      current_supply
      description
      last_transaction_timestamp
      last_transaction_version
      max_supply
      mutable_description
      mutable_uri
      table_handle_v1
      token_standard
      total_minted_v2
      uri
      __typename
    }
    __typename
  }
}`}
  variables={`{
  "address": "0x8824ebb6e0d60656f6d4d5bbc408805d9ca6b984aad78b16f42b1dae545d6762"
}`}
/>

#### Variables:

- `$address`: **String** - The Aptos account address for which you want to query NFT collection data. Ex. `"0x8824ebb6e0d60656f6d4d5bbc408805d9ca6b984aad78b16f42b1dae545d6762"`

# Get NFTs Owned by an Account

> Query NFTs owned by an account using GraphQL API with comprehensive token details, collection metadata, and ownership information

import { GraphQLEditor } from '~/components/react/GraphQLEditor';

import { Aside } from '@astrojs/starlight/components';

`GetAccountNfts` retrieves a list of NFTs owned by a specified account address. This query provides comprehensive details about each token, including its collection details, description, and unique identifiers. It is ideal for platforms that need to display the NFT portfolios of users or provide insights into the NFT market holdings.

<Aside type="note">
  Try it yourself! You can customize the variables at the bottom of the editor.
</Aside>

<GraphQLEditor
  query={`query GetAccountNfts($address: String) {
  current_token_ownerships_v2(
    where: { owner_address: { _eq: $address }, amount: { _gt: "0" } }
  ) {
    current_token_data {
      collection_id
      largest_property_version_v1
      current_collection {
        collection_id
        collection_name
        description
        creator_address
        uri
        __typename
      }
      description
      token_name
      token_data_id
      token_standard
      token_uri
      __typename
    }
    owner_address
    amount
    __typename
  }
}`}
  variables={`{
  "address": "0x8824ebb6e0d60656f6d4d5bbc408805d9ca6b984aad78b16f42b1dae545d6762"
}`}
/>

#### Variables:

- `$address`: **String** - The Aptos account address for which you want to query NFT data. Ex. `"0x8824ebb6e0d60656f6d4d5bbc408805d9ca6b984aad78b16f42b1dae545d6762"`

# Indexer API Reference

> Complete GraphQL API reference for Aptos Indexer with table schemas, query examples, and field documentation for tokens and accounts

import { Aside } from '@astrojs/starlight/components';

The Indexer API allows you to access rich data about tokens, fungible assets, and accounts on-chain using GraphQL queries. **You can access it [here](/build/indexer/indexer-api).**

For common queries, check out the sidebar for examples to work from. When building your own, this reference guide should help you determine which tables are most relevant, and how to format your queries.

<Aside type="caution">
  Before relying on a table for production services, check the bottom of this page to see if that table is deprecated. If so, use the note section for guidance on what to do to migrate to a non-deprecated table.
</Aside>

<Aside type="note">
  If you are looking up a table with the `_by_pk` suffix, search for the table name without that suffix. `_by_pk` tables are automatically generated for convenience to allow querying by primary key.
</Aside>

<br />

# Indexer Table Reference

<Aside type="note">
  Remember to use Ctrl + F to find the table you are interested in! When in doubt, you may also want to query the Hasura tables linked in the [Indexer API Access](/build/indexer/indexer-api) page to see examples of the data inside.
</Aside>

## Filtering (with `where` clauses)

To ensure your queries filter data efficiently, check out the available indexes for each table.
Some indexes are composite B-tree indexes, meaning they consist of multiple columns.
B-tree indexes are ordered and perform optimally when queries utilize a left-most prefix of the indexed columns.

{/* Indexed columns are generated from https://docs.google.com/spreadsheets/d/1sQnMimoJnP5sVaLCCRK4H6AHXGCwsehAuBF9AD_0IyY/edit?gid=47194642#gid=47194642 */}

## General

### `user_transactions`

Transactions filtered to user\_transactions (not system).

| Index Name                                        | Indexed Columns          |
| ------------------------------------------------- | ------------------------ |
| user\_transactions\_pkey                          | version                  |
| user\_transactions\_sender\_sequence\_number\_key | sender, sequence\_number |
| ut\_epoch\_index                                  | epoch                    |
| ut\_insat\_index                                  | inserted\_at             |
| ut\_sender\_seq\_index                            | sender, sequence\_number |

### `block_metadata_transactions`

A type of system transaction emitted once per block, useful for mapping to timestamp or epoch.

| Index Name                                        | Indexed Columns |
| ------------------------------------------------- | --------------- |
| block\_metadata\_transactions\_block\_height\_key | block\_height   |
| block\_metadata\_transactions\_pkey               | version         |
| bmt\_insat\_index                                 | inserted\_at    |

### `account_transactions`

_Has an aggregate view for summary data called `account_transactions_aggregate`_

| Index Name                  | Indexed Columns                        |
| --------------------------- | -------------------------------------- |
| account\_transactions\_pkey | account\_address, transaction\_version |
| at\_insat\_index            | inserted\_at                           |
| at\_version\_index          | transaction\_version DESC              |

This table maps accounts and transactions that interact with that account.

| Field                            | Type    | Primary Key | Description                                                                                                                                       |
| -------------------------------- | ------- | ----------- | ------------------------------------------------------------------------------------------------------------------------------------------------- |
| delegated\_staking\_activities   | Join    |             | Use the [Hasura explorer](https://cloud.hasura.io/public/graphiql?endpoint=https://api.mainnet.aptoslabs.com/v1/graphql) to see these sub-fields. |
| fungible\_asset\_activities      | Join    |             | References [fungible\_asset\_activities](#fungible_asset_activities).                                                                             |
| token\_activities                | Join    |             | Use the [Hasura explorer](https://cloud.hasura.io/public/graphiql?endpoint=https://api.mainnet.aptoslabs.com/v1/graphql) to see these sub-fields. |
| token\_activities\_aggregate     | Join    |             | Use the [Hasura explorer](https://cloud.hasura.io/public/graphiql?endpoint=https://api.mainnet.aptoslabs.com/v1/graphql) to see these sub-fields. |
| token\_activities\_v2            | Join    |             | References [token\_activities\_v2](#token_activities_v2).                                                                                         |
| token\_activities\_v2\_aggregate | Join    |             | References [token\_activities\_v2](#token_activities_v2).                                                                                         |
| account\_address                 | String! | Yes         | This is an Aptos account address. Ex. "0x50bc83f01d48ab3b9c00048542332201ab9cbbea61bda5f48bf81dc506caa78a"                                        |
| transaction\_version             | bigint! | Yes         | Blockchain version of the transaction. Ex. 10000000                                                                                               |

### `ledger_infos`

This table shares what chain is currently being queried.

| Field     | Type | Primary Key | Description                                                                                       |
| --------- | ---- | ----------- | ------------------------------------------------------------------------------------------------- |
| chain\_id | int  | Yes         | The unique identifier for the chain you are accessing. Ex. 1 (for Mainnet), 2 (for Testnet), etc. |

### `processor_status`

This table shares how current this processor's data is.

gives you latest version processed per ‚Äúprocessor‚Äù

| Field                        | Type   | Primary Key | Description                                                                              |
| ---------------------------- | ------ | ----------- | ---------------------------------------------------------------------------------------- |
| last\_success\_version       | bigint | Yes         | The version number of the last successful processor run. Ex. 5000000                     |
| last\_transaction\_timestamp | String |             | Timestamp of the last processed transaction. Ex. "2024-04-17T02:14:25.68771"             |
| last\_updated                | String |             | Timestamp of the last update to this processor's status. Ex. "2024-04-17T02:14:25.68771" |
| processor                    | String | Yes         | Name of the processor. Ex. "transaction\_processor"                                      |

## NFT

### `token_activities_v2`

_Has an aggregate view for summary data called `token_activities_v2_aggregate`_

| Index Name                  | Indexed Columns                    |
| --------------------------- | ---------------------------------- |
| ta2\_from\_type\_index      | from\_address, type                |
| ta2\_insat\_index           | inserted\_at                       |
| ta2\_owner\_type\_index     | event\_account\_address, type      |
| ta2\_tid\_index             | token\_data\_id                    |
| ta2\_to\_type\_index        | to\_address, type                  |
| token\_activities\_v2\_pkey | transaction\_version, event\_index |

This table tracks token activities and is especially useful for tracking NFT activity. This includes both v1 and v2 data.

| Field                         | Type    | Primary Key | Description                                                                                                                                                                                                                                                                                                |
| ----------------------------- | ------- | ----------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| aptos\_names\_from            | Join    |             | Use the [Hasura explorer](https://cloud.hasura.io/public/graphiql?endpoint=https://api.mainnet.aptoslabs.com/v1/graphql) to see these sub-fields.                                                                                                                                                          |
| aptos\_names\_from\_aggregate | Join    |             | Use the [Hasura explorer](https://cloud.hasura.io/public/graphiql?endpoint=https://api.mainnet.aptoslabs.com/v1/graphql) to see these sub-fields.                                                                                                                                                          |
| aptos\_names\_to              | Join    |             | Use the [Hasura explorer](https://cloud.hasura.io/public/graphiql?endpoint=https://api.mainnet.aptoslabs.com/v1/graphql) to see these sub-fields.                                                                                                                                                          |
| aptos\_names\_to\_aggregate   | Join    |             | Use the [Hasura explorer](https://cloud.hasura.io/public/graphiql?endpoint=https://api.mainnet.aptoslabs.com/v1/graphql) to see these sub-fields.                                                                                                                                                          |
| current\_token\_data          | Join    |             | Use the [Hasura explorer](https://cloud.hasura.io/public/graphiql?endpoint=https://api.mainnet.aptoslabs.com/v1/graphql) to see these sub-fields.                                                                                                                                                          |
| after\_value                  | String  |             | The value of a token property after the transaction. Ex. "100"                                                                                                                                                                                                                                             |
| before\_value                 | String  |             | The value of a token property before the transaction. Ex. "50"                                                                                                                                                                                                                                             |
| entry\_function\_id\_str      | String  |             | The identifier of the function called in this transaction. Ex. "0x1::aptos\_account::transfer"                                                                                                                                                                                                             |
| event\_account\_address       | String  |             | This is an Aptos account address related to the event. This address must be 66 characters long, and so may be 0 padded. Ex. "0x50bc83f01d48ab3b9c00048542332201ab9cbbea61bda5f48bf81dc506caa78a"                                                                                                           |
| event\_index                  | bigint  | Yes         | Index of the event within the transaction. Ex. 1                                                                                                                                                                                                                                                           |
| from\_address                 | String  |             | This is an Aptos account address from which the token was sent. This address must be 66 characters long, and so may be 0 padded. Ex. "0x50bc83f01d48ab3b9c00048542332201ab9cbbea61bda5f48bf81dc506caa78a"                                                                                                  |
| is\_fungible\_v2              | Boolean |             | Indicates whether the token is fungible. Soon to be deprecated. Ex. False for NFTs.                                                                                                                                                                                                                        |
| property\_version\_v1         | bigint  |             | The version of the token's properties under schema version 1. This field is only for token standard v1. It is always 0 for v2. Ex. 0                                                                                                                                                                       |
| to\_address                   | String  |             | This is an Aptos account address to which the token was sent. This address must be 66 characters long, and so may be 0 padded. Ex. "0x50bc83f01d48ab3b9c00048542332201ab9cbbea61bda5f48bf81dc506caa78a"                                                                                                    |
| token\_amount                 | bigint  |             | The amount of the token transferred in this activity. Ex. 3                                                                                                                                                                                                                                                |
| token\_data\_id               | String  |             | Unique identifier for this particular token's data. For token standard v1, this is derived from a combination of creator\_address, collection\_name, and token\_name. This ID must be 66 characters long, and so may be 0 padded. Ex. "0x50bc83f01d48ab3b9c00048542332201ab9cbbea61bda5f48bf81dc506caa78a" |
| token\_standard               | String  |             | Aptos standard that the collection adheres to. Ex. "v1"                                                                                                                                                                                                                                                    |
| transaction\_timestamp        | String  |             | Timestamp when the transaction occurred. Ex. "2024-04-17T02:14:25.68771"                                                                                                                                                                                                                                   |
| transaction\_version          | bigint  | Yes         | Blockchain version of the transaction. Ex. 10000000                                                                                                                                                                                                                                                        |
| type                          | String  |             | Type of transfer - like "deposit" or "withdrawal". Ex. "0x3::token::DepositEvent"                                                                                                                                                                                                                          |

### `nft_metadata_crawler_parsed_asset_uris`

This table allows you to look up the cdn and uris for NFT images / content.

| Field                              | Type   | Primary Key | Description                                                                                                                                  |
| ---------------------------------- | ------ | ----------- | -------------------------------------------------------------------------------------------------------------------------------------------- |
| animation\_optimizer\_retry\_count | Int    |             | Number of retries to optimize animation. Ex. 3                                                                                               |
| asset\_uri                         | String | Yes         | URI of the asset. Ex. "[https://example.com/nft/123](https://example.com/nft/123)"                                                           |
| cdn\_animation\_uri                | String |             | Content Delivery Network URI for animation. Ex. "[https://cdn.example.com/animations/123](https://cdn.example.com/animations/123)"           |
| cdn\_image\_uri                    | String |             | Content Delivery Network URI for image. Ex. "[https://cdn.example.com/images/123](https://cdn.example.com/images/123)"                       |
| cdn\_json\_uri                     | String |             | Content Delivery Network URI for JSON metadata. Ex. "[https://cdn.example.com/metadata/123.json](https://cdn.example.com/metadata/123.json)" |
| raw\_animation\_uri                | String |             | Original URI for animation before CDN optimization. Ex. "[https://example.com/raw/animations/123](https://example.com/raw/animations/123)"   |
| raw\_image\_uri                    | String |             | Original URI for image before CDN optimization. Ex. "[https://example.com/raw/images/123](https://example.com/raw/images/123)"               |

| Index Name                | Indexed Columns     |
| ------------------------- | ------------------- |
| nft\_inserted\_at         | inserted\_at        |
| nft\_raw\_animation\_uri  | raw\_animation\_uri |
| nft\_raw\_image\_uri      | raw\_image\_uri     |
| parsed\_asset\_uris\_pkey | asset\_uri          |

### `current_token_ownerships_v2`

_Has an aggregate view for summary data called `current_token_ownerships_v2_aggregate`_

This table tracks who owns which NFTs. This includes both v1 and v2 tokens. Fungible tokens are not tracked as consistently.

| Field                          | Type    | Primary Key | Description                                                                                                                                                                                |
| ------------------------------ | ------- | ----------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| composed\_nfts\_aggregate      | Join    |             | Aggregate information about the composed NFTs, such as count or other statistics.                                                                                                          |
| current\_token\_data           | Join    |             | Detailed information about the token's current data; structure is defined in a related table.                                                                                              |
| amount                         | bigint  |             | The amount of the token owned. Example: 1 for an NFT.                                                                                                                                      |
| composed\_nfts                 | Array   |             | An array containing the IDs of NFTs that compose this token, if applicable.                                                                                                                |
| is\_fungible\_v2               | Boolean |             | Indicates whether the token is fungible. Example: true or null                                                                                                                             |
| is\_soulbound\_v2              | Boolean |             | Indicates whether the token is soulbound (non-transferable once owned). Example: true or null                                                                                              |
| last\_transaction\_timestamp   | String  |             | Timestamp of the last transaction involving the token. Example: "2024-04-17T02:14:25.68771"                                                                                                |
| last\_transaction\_version     | bigint  |             | The version number of the last transaction involving the token. Example: 20747031                                                                                                          |
| non\_transferrable\_by\_owner  | Boolean |             | Indicates whether the token is non-transferrable by the owner. Example: true or null                                                                                                       |
| owner\_address                 | String  | Yes         | The Aptos account address that currently owns the token. Addresses must be 66 characters so may be 0 padded. Example: "0xa815a9a09105973084bfc31530e7c8f002846787c2f0521e1e34dc144ad83b89" |
| property\_version\_v1          | bigint  | Yes         | The version number of the token's properties as of the last update. This field is only for token standard v1. It is always 0 for v2. Example: 0                                            |
| storage\_id                    | String  | Yes         | A unique identifier used for storage purposes. IDs must be 66 characters long, so may be 0 padded. Ex. "0xd8d41ff9f67d17d7dee061b5b683b92013b420cb6a30c21fc7c287454792d7a8"                |
| table\_type\_v1                | String  |             | The Move function type. Example: "0x3::token::TokenStore"                                                                                                                                  |
| token\_data\_id                | String  | Yes         | A unique identifier for the token data, typically a hash or a numeric ID. Ex. "0x3d911af2dc3e47848fbba17b8694cf526942be183b84f8393a6c048232fb976d"                                         |
| token\_properties\_mutated\_v1 | Object  |             | Properties of the token that have been mutated from the original. Often in JSON or similar format. Example: { }                                                                            |
| token\_standard                | String  |             | The standard used to generate this token. Ex. "v1" or "v2"                                                                                                                                 |

| Index Name                           | Indexed Columns                                                     |
| ------------------------------------ | ------------------------------------------------------------------- |
| curr\_to2\_insat\_index              | inserted\_at                                                        |
| curr\_to2\_owner\_index              | owner\_address                                                      |
| curr\_to2\_wa\_index                 | storage\_id                                                         |
| current\_token\_ownerships\_v2\_pkey | token\_data\_id, property\_version\_v1, owner\_address, storage\_id |

### `current_token_datas_v2`

This table tracks the metadata associated with each NFT (Ex. URI, supply, etc.). This tracks both v1 and v2 tokens.

| Field                                 | Type    | Primary Key | Description                                                                                                                                       |
| ------------------------------------- | ------- | ----------- | ------------------------------------------------------------------------------------------------------------------------------------------------- |
| cdn\_asset\_uris                      | Join    |             | Use the [Hasura explorer](https://cloud.hasura.io/public/graphiql?endpoint=https://api.mainnet.aptoslabs.com/v1/graphql) to see these sub-fields. |
| current\_collection                   | Join    |             | Use the [Hasura explorer](https://cloud.hasura.io/public/graphiql?endpoint=https://api.mainnet.aptoslabs.com/v1/graphql) to see these sub-fields. |
| current\_token\_ownerships            | Join    |             | Use the [Hasura explorer](https://cloud.hasura.io/public/graphiql?endpoint=https://api.mainnet.aptoslabs.com/v1/graphql) to see these sub-fields. |
| current\_token\_ownerships\_aggregate | Join    |             | Use the [Hasura explorer](https://cloud.hasura.io/public/graphiql?endpoint=https://api.mainnet.aptoslabs.com/v1/graphql) to see these sub-fields. |
| aptos\_name                           | String  |             | This is a name tied to this token using the Aptos Name Service (ANS). Ex. "EpicDragon"                                                            |
| collection\_id                        | String  | Yes         | Identifier for the collection that includes this token. Ex. "0x360f6eeabb4d7a9d2fab1f35b01e02831e3b5c4b73c7fd6c98dcc1c301c817c8"                  |
| decimals                              | bigint  |             | Number of decimal places for token value, typically for fungible tokens. Ex. 18                                                                   |
| description                           | String  |             | Description of the token. Ex. "A legendary dragon from the mystical lands."                                                                       |
| is\_fungible\_v2                      | Boolean |             | Whether the token is fungible. Ex. False for NFTs                                                                                                 |
| largest\_property\_version\_v1        | bigint  |             | The largest version number of the token's properties under the first schema. Ex. 1                                                                |
| last\_transaction\_timestamp          | bigint  |             | Unix timestamp of the last transaction involving this token. Ex. 2024-03-27T07:41:58.800893                                                       |
| last\_transaction\_version            | bigint  |             | Blockchain version of the last transaction involving this token. Ex. 30000000                                                                     |
| maximum                               | bigint  |             | Maximum possible quantity of this token, relevant for fungibles. Ex. 1000000                                                                      |
| supply                                | bigint  |             | Current supply of the token in circulation. Ex. 500000                                                                                            |
| token\_data\_id                       | String  |             | Unique identifier for the token's data. Ex. "0xa815a9a09105973084bfc31530e7c8f002846787c2f0521e1e34dc144ad83b89"                                  |
| token\_name                           | String  |             | The formal name of the token. Ex. "Mystic Dragon"                                                                                                 |
| token\_properties                     | Object  |             | Use the [Hasura explorer](https://cloud.hasura.io/public/graphiql?endpoint=https://api.mainnet.aptoslabs.com/v1/graphql) to see these sub-fields. |
| token\_standard                       | String  |             | Aptos standard that the collection adheres to. Ex. "v1"                                                                                           |
| token\_uri                            | String  |             | URI linking to further information about the token. Ex. "[https://example.com/tokens/987654321](https://example.com/tokens/987654321)"            |

| Index Name                      | Indexed Columns             |
| ------------------------------- | --------------------------- |
| cur\_td2\_cid\_name\_index      | collection\_id, token\_name |
| cur\_td2\_insat\_index          | inserted\_at                |
| current\_token\_datas\_v2\_pkey | token\_data\_id             |

### `current_collections_v2`

This table tracks the metadata associated with each NFT collection (Ex. collection\_id, creator\_address, etc.). This tracks both v1 and v2 tokens.

| Field                        | Type    | Primary Key | Description                                                                                                                                                                                          |
| ---------------------------- | ------- | ----------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| cdn\_asset\_uris             | Join    |             | Use the [Hasura explorer](https://cloud.hasura.io/public/graphiql?endpoint=https://api.mainnet.aptoslabs.com/v1/graphql) to see these sub-fields.                                                    |
| collection\_id               | String  | Yes         | Unique identifier for the collection. IDs must be 66 characters long, and so may be 0 padded. Ex. "0xa815a9a09105973084bfc31530e7c8f002846787c2f0521e1e34dc144ad83b88"                               |
| collection\_name             | String  |             | The formal name of the collection. Ex. "Mythic Dragons"                                                                                                                                              |
| creator\_address             | String  |             | This is an Aptos account address that created the collection. Addresses must be 66 characters long, and so may be 0 padded. Ex. "0x50bc83f01d48ab3b9c00048542332201ab9cbbea61bda5f48bf81dc506caa78a" |
| current\_supply              | bigint  |             | Current supply of tokens in this collection. Ex. 500                                                                                                                                                 |
| description                  | String  |             | Description of the collection. Ex. "A collection of rare digital dragons."                                                                                                                           |
| last\_transaction\_timestamp | String  |             | Timestamp of the last transaction involving this collection. Ex. "2024-04-17T02:14:25.68771"                                                                                                         |
| last\_transaction\_version   | bigint  |             | Blockchain version of the last transaction involving this collection. Ex. 3000000002                                                                                                                 |
| max\_supply                  | bigint  |             | Maximum possible quantity of tokens in this collection. If the max supply is 0, there is no limit on the supply. Ex. 1000                                                                            |
| mutable\_description         | String  |             | Changeable description of the collection. Ex. "Updated collection description."                                                                                                                      |
| mutable\_uri                 | Boolean |             | True if the uri is changeable by the creator. Ex. True                                                                                                                                               |
| table\_handle\_v1            | String  |             | Legacy identifier handle for the collection in earlier schema versions. Ex. "handle\_12345"                                                                                                          |
| token\_standard              | String  |             | Aptos standard that the collection adheres to. Ex. "v1"                                                                                                                                              |
| total\_minted\_v2            | bigint  |             | Total number of tokens minted in this collection under schema version 2. Ex. 800                                                                                                                     |
| uri                          | String  |             | This is a URI to  where the image live. This can also be JSON data. Ex. "[https://example.com/collections/9876543210](https://example.com/collections/9876543210)"                                   |

| Index Name                     | Indexed Columns                    |
| ------------------------------ | ---------------------------------- |
| cur\_col2\_crea\_cn\_index     | creator\_address, collection\_name |
| cur\_col2\_insat\_index        | inserted\_at                       |
| current\_collections\_v2\_pkey | collection\_id                     |

### `current_collection_ownership_v2_view`

_Has an aggregate view for summary data called `current_collection_ownership_v2_view_aggregate`_

This table maps collections to who owns them and helps count how much of a collection is owned by other accounts.

| Field                      | Type   | Primary Key | Description                                                                                                                                                                                            |
| -------------------------- | ------ | ----------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| current\_collection        | Join   |             | Use the [Hasura explorer](https://cloud.hasura.io/public/graphiql?endpoint=https://api.mainnet.aptoslabs.com/v1/graphql) to see these sub-fields.                                                      |
| collection\_id             | String | Yes         | Unique identifier for the collection. IDs must be 66 characters long, and so may be 0 padded. Ex. "0xa815a9a09105973084bfc31530e7c8f002846787c2f0521e1e34dc144ad83b89"                                 |
| collection\_name           | String |             | The formal name of the collection. Ex. "Mythic Dragons"                                                                                                                                                |
| collection\_uri            | String |             | URI linking to further information about the collection. Ex. "[https://example.com/collections/9876543210](https://example.com/collections/9876543210)"                                                |
| creator\_address           | String |             | This is an Aptos account address that created the collection. Addresses must be 66 characters long, and so may be 0 padded. Ex. "0x50bc83f01d48ab3b9c00048542332201ab9cbbea61bda5f48bf81dc506caa78a"   |
| distinct\_tokens           | bigint |             | The count of distinct tokens owned within this collection. Ex. 150                                                                                                                                     |
| last\_transaction\_version | bigint |             | The version number of the last transaction involving this collection. Ex. 3000000002                                                                                                                   |
| owner\_address             | String | Yes         | This is an Aptos account address that currently owns the token. Addresses must be 66 characters long, and so may be 0 padded. Ex. "0x50bc83f01d48ab3b9c00048542332201ab9cbbea61bda5f48bf81dc506caa78a" |
| single\_token\_uri         | String |             | URI linking to information about a specific token within the collection. Ex. "[https://example.com/tokens/9876543210](https://example.com/tokens/9876543210)"                                          |
| token\_standard            | String |             | Aptos standard that the collection adheres to. Ex. "v1"                                                                                                                                                |

## Fungible Assets

### `fungible_asset_metadata`

This tracks the metadata tied to each fungible asset (ex. decimals of precision). It includes v1 token data. This is a current\_ table.

| Field                                 | Type   | Primary Key | Description                                                                                                                                                                                     |
| ------------------------------------- | ------ | ----------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| asset\_type                           | String | Yes         | The type of the asset, described by a Move resource. Ex. "0x1::aptos\_coin::AptosCoin"                                                                                                          |
| creator\_address                      | String |             | This is an Aptos account address that created the asset. Addresses must be 66 characters long, and so may be 0 padded. Ex. "0x50bc83f01d48ab3b9c00048542332201ab9cbbea61bda5f48bf81dc506caa78a" |
| decimals                              | bigint |             | Number of decimal places for token value, typically for fungible tokens. Ex. 18                                                                                                                 |
| icon\_uri                             | String |             | URI for the icon of the asset. Ex. "[https://cdn.example.com/icons/123](https://cdn.example.com/icons/123)"                                                                                     |
| last\_transaction\_timestamp          | String |             | Timestamp of the last transaction involving this asset. Ex. "2024-04-17T02:14:25.68771"                                                                                                         |
| last\_transaction\_version            | bigint |             | Blockchain version of the last transaction involving this asset. Ex. 10000000                                                                                                                   |
| name                                  | String |             | The formal name of the asset. Ex. "Digital Gold"                                                                                                                                                |
| project\_uri                          | String |             | URI linking to the project information associated with this asset. Ex. "[https://www.example.com/project\\\_name/](https://www.example.com/project\\_name/)"                                    |
| supply\_aggregator\_table\_handle\_v1 | String |             | Legacy handle for the supply aggregator table from an earlier schema version. Ex. "handle\_67890"                                                                                               |
| supply\_aggregator\_table\_key\_v1    | String |             | Legacy key for accessing the supply aggregator table in earlier schema versions. Ex. "key\_12345"                                                                                               |
| symbol                                | String |             | The trading symbol of the asset. Ex. "DGOLD"                                                                                                                                                    |
| token\_standard                       | String |             | Standard that the asset adheres to. Ex. "v1"                                                                                                                                                    |

| Index Name                      | Indexed Columns  |
| ------------------------------- | ---------------- |
| fam\_creator\_index             | creator\_address |
| fam\_insat\_index               | inserted\_at     |
| fungible\_asset\_metadata\_pkey | asset\_type      |

### `fungible_asset_activities`

This tracks the activity of fungible assets. It includes v1 token data.

| Field                          | Type    | Primary Key | Description                                                                                                                                                                                                        |
| ------------------------------ | ------- | ----------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| owner\_aptos\_names            | Join    |             | References [owner\_aptos\_names](#current_aptos_names).                                                                                                                                                            |
| owner\_aptos\_names\_aggregate | Join    |             | References [owner\_aptos\_names](#current_aptos_names).                                                                                                                                                            |
| amount                         | bigint  |             | The amount of the asset involved in the activity. Ex. 1000                                                                                                                                                         |
| asset\_type                    | String  | Yes         | The type of the asset, described by a Move resource. For fungible assets, this will be the address of the metadata object. Ex. "0x1::aptos\_coin::AptosCoin"                                                       |
| block\_height                  | bigint  |             | The blockchain id at which this activity occurred. Ex. 1500000                                                                                                                                                     |
| entry\_function\_id\_str       | String  |             | The identifier of the function called in this transaction. Ex. "0x1::aptos\_account::transfer"                                                                                                                     |
| event\_index                   | bigint  |             | Index of the event within the transaction. Ex. 1                                                                                                                                                                   |
| gas\_fee\_payer\_address       | String  |             | This is an Aptos account address that paid the gas fee for the transaction. Addresses must be 66 characters long, and so may be 0 padded. Ex. "0x50bc83f01d48ab3b9c00048542332201ab9cbbea61bda5f48bf81dc506caa78a" |
| is\_frozen                     | Boolean |             | True if this activity is a freeze asset activity. Ex. null                                                                                                                                                         |
| is\_gas\_fee                   | Boolean |             | Indicates whether this activity involved a gas fee. Ex. True                                                                                                                                                       |
| is\_transaction\_success       | Boolean |             | Indicates whether the transaction was successful. Ex. True                                                                                                                                                         |
| metadata                       | Object  |             | Use the [Hasura explorer](https://cloud.hasura.io/public/graphiql?endpoint=https://api.mainnet.aptoslabs.com/v1/graphql) to see fields for `metadata` in this table.                                               |
| owner\_address                 | String  |             | This is an Aptos account address that owns the asset. Addresses must be 66 characters long, and so may be 0 padded. Ex. "0xa815a9a09105973084bfc31530e7c8f002846787c2f0521e1e34dc144ad83b89"                       |
| storage\_id                    | String  |             | Identifier for the storage used in the transaction. IDs must be 66 characters long, and so may be 0 padded. Ex. "0xa815a9a09105973084bfc31530e7c8f002846787c2f0521e1e34dc144ad83b89"                               |
| storage\_refund\_amount        | bigint  |             | Amount refunded for storage after the transaction. This is always in APT [octas](/network/glossary#Octa). Ex. 50                                                                                                   |
| token\_standard                | String  |             | Aptos standard that the collection adheres to. Ex. "v1"                                                                                                                                                            |
| transaction\_timestamp         | String  |             | Timestamp when the transaction occurred. Ex. "2024-04-17T02:14:25.68771"                                                                                                                                           |
| transaction\_version           | bigint  |             | Blockchain version of the transaction. Ex. 2                                                                                                                                                                       |
| type                           | String  |             | Type of the transaction, described by a Move entry function. Ex. "0x1::coin::WithdrawEvent"                                                                                                                        |

| Index Name                        | Indexed Columns                    |
| --------------------------------- | ---------------------------------- |
| faa\_at\_index                    | asset\_type                        |
| faa\_gfpa\_index                  | gas\_fee\_payer\_address           |
| faa\_insat\_idx                   | inserted\_at                       |
| faa\_owner\_type\_index           | owner\_address, type               |
| faa\_si\_index                    | storage\_id                        |
| fungible\_asset\_activities\_pkey | transaction\_version, event\_index |

### `current_fungible_asset_balances`

_Has an aggregate view for summary data called `current_fungible_asset_balances_aggregate`_

This tracks the asset balances of each account on-chain. It includes v1 token data.

| Field                        | Type    | Primary Key | Description                                                                                                                                                                                                                |
| ---------------------------- | ------- | ----------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| amount                       | bigint  |             | The amount of the asset owned. Ex. 2000                                                                                                                                                                                    |
| asset\_type                  | String  |             | The type of the asset, described by a Move resource. For v2 tokens this is the address of the fungible asset metadata object. For v1 it's the fully qualified path of the move resource. Ex. "0x1::aptos\_coin::AptosCoin" |
| is\_frozen                   | Boolean |             | Indicates whether the account is frozen. Ex. False                                                                                                                                                                         |
| is\_primary                  | Boolean |             | Indicates whether this is the primary balance of the owner. Ex. True                                                                                                                                                       |
| last\_transaction\_timestamp | String  |             | Timestamp of the last transaction involving this balance. Ex. "2024-04-17T02:14:25.68771"                                                                                                                                  |
| last\_transaction\_version   | bigint  |             | Blockchain version of the last transaction involving this balance. Ex. 30000000                                                                                                                                            |
| metadata                     | Object  |             | Use the [Hasura explorer](https://cloud.hasura.io/public/graphiql?endpoint=https://api.mainnet.aptoslabs.com/v1/graphql) to see fields for `metadata` in `current_fungible_asset_balances`.                                |
| owner\_address               | String  |             | This is an Aptos account address that owns the asset. Addresses must be 66 characters long, and so may be 0 padded. Ex. "0xa815a9a09105973084bfc31530e7c8f002846787c2f0521e1e34dc144ad83b89"                               |
| storage\_id                  | String  | Yes         | Identifier for the storage associated with this balance. IDs must be 66 characters long, and so may be 0 padded. Ex. "0xa815a9a09105973084bfc31530e7c8f002846787c2f0521e1e34dc144ad83b89"                                  |
| token\_standard              | String  |             | Aptos standard that the collection adheres to. Ex. "v1"                                                                                                                                                                    |

| Index Name                                        | Indexed Columns             |
| ------------------------------------------------- | --------------------------- |
| cufab\_insat\_index                               | inserted\_at                |
| cufab\_owner\_at\_index                           | owner\_address, asset\_type |
| current\_unified\_fungible\_asset\_balances\_pkey | storage\_id                 |

## Delegated Staking

With [AIP-6](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-6.md) we added the ability for staking pools to be formed with delegated funds (delegation pools). Once these pools hold over 1M APT, they can become a staking pool (validator node).

### `current_delegated_staking_pool_balances`

This table tracks the current balances of each account in a delegated staking pool.

| Field                            | Type   | Primary Key | Description                                                                            |
| -------------------------------- | ------ | ----------- | -------------------------------------------------------------------------------------- |
| staking\_pool\_address           | String | Yes         | The address of the delegation pool.                                                    |
| total\_coins                     | bigint |             | Amount of APT in the staking pool.                                                     |
| total\_shares                    | bigint |             | The total number of shares in the delegation pool.                                     |
| operator\_commission\_percentage | bigint |             | The commission percentage taken by the staking pool operator.                          |
| inactive\_table\_handle          | String |             | The table handle for the inactive table.                                               |
| active\_table\_handle            | String |             | The table handle for the active table.                                                 |
| last\_transaction\_version       | int8   |             | Transaction version (identifier) for the last transaction involving this staking pool. |
| inserted\_at                     | String |             | The timestamp when the record was inserted.                                            |

| Index Name                                        | Indexed Columns        |
| ------------------------------------------------- | ---------------------- |
| current\_delegated\_staking\_pool\_balances\_pkey | staking\_pool\_address |

### `current_delegated_voter`

This table tracks the current delegated voters of a delegation pool.

| Field                        | Type      | Primary Key | Description                                                                             |
| ---------------------------- | --------- | ----------- | --------------------------------------------------------------------------------------- |
| delegation\_pool\_address    | String    | Yes         | The address of the delegation pool.                                                     |
| delegator\_address           | String    | Yes         | The address of the delegator.                                                           |
| table\_handle                | String    |             | The table handle tracking this position.                                                |
| voter                        | String    |             | The address of the current voter in the delegation pool.                                |
| pending\_voter               | String    |             | The address of the pending voter awaiting confirmation.                                 |
| last\_transaction\_version   | bigint    |             | The transaction version (identifier) of the last transaction involving this delegation. |
| last\_transaction\_timestamp | Timestamp |             | The block timestamp of the last transaction involving this delegation.                  |
| inserted\_at                 | Timestamp |             | The timestamp when the record was inserted into the database.                           |

| Index Name                      | Indexed Columns                               |
| ------------------------------- | --------------------------------------------- |
| current\_delegated\_voter\_pkey | delegation\_pool\_address, delegator\_address |
| cdv\_da\_index                  | delegator\_address                            |

### `current_delegator_balances`

This table tracks the current balances of each account in a delegated staking pool.

| Field                      | Type      | Primary Key | Description                                                                            |
| -------------------------- | --------- | ----------- | -------------------------------------------------------------------------------------- |
| delegator\_address         | String    | Yes         | The address of the delegator.                                                          |
| pool\_address              | String    |             | The address of the delegator pool.                                                     |
| pool\_type                 | String    |             | If the shares are active or inactive                                                   |
| table\_handle              | String    |             | The table handle for the pool.                                                         |
| shares                     | bigint    |             | The number of shares in the pool.                                                      |
| parent\_table\_handle      | String    |             | The table handle for the parent table.                                                 |
| last\_transaction\_version | bigint    |             | Transaction version (identifier) for the last transaction involving this staking pool. |
| inserted\_at               | Timestamp |             | The timestamp when the record was inserted.                                            |

| Index Name                         | Indexed Columns                                              |
| ---------------------------------- | ------------------------------------------------------------ |
| current\_delegator\_balances\_pkey | delegator\_address, pool\_address, pool\_type, table\_handle |

### `current_staking_pool_voter`

This table tracks the current voters of a staking pool.

| Field                      | Type      | Primary Key | Description                                                                            |
| -------------------------- | --------- | ----------- | -------------------------------------------------------------------------------------- |
| staking\_pool\_address     | String    | Yes         | The address of the staking pool.                                                       |
| voter\_address             | String    |             | The address of the voter.                                                              |
| operator\_address          | String    |             | The address of the operator.                                                           |
| last\_transaction\_version | bigint    |             | Transaction version (identifier) for the last transaction involving this staking pool. |
| inserted\_at               | Timestamp |             | The timestamp when the record was inserted.                                            |

| Index Name                          | Indexed Columns        |
| ----------------------------------- | ---------------------- |
| current\_staking\_pool\_voter\_pkey | staking\_pool\_address |
| ctpv\_va\_index                     | voter\_address         |
| ctpv\_insat\_index                  | inserted\_at           |

### `delegated_staking_activities`

This table tracks delegated staking events.

| Field                | Type      | Primary Key | Description                                                            |
| -------------------- | --------- | ----------- | ---------------------------------------------------------------------- |
| transaction\_version | bigint    |             | Transaction version (identifier) for activity                          |
| event\_index         | bigint    |             | The index of the event. Ex. 1                                          |
| delegator\_address   | String    |             | The address of the delegator.                                          |
| pool\_address        | String    |             | The address of the pool.                                               |
| event\_type          | String    |             | DistributeRewards, AddStake, UnlikeStake, ReactiveStake, WithdrawStake |
| amount               | bigint    |             | The amount being staked. Ex. 1000                                      |
| inserted\_at         | Timestamp |             | The timestamp when the record was inserted.                            |

| Index Name                           | Indexed Columns                                                       |
| ------------------------------------ | --------------------------------------------------------------------- |
| delegated\_staking\_activities\_pkey | transaction\_version, event\_index                                    |
| dsa\_pa\_da\_index                   | pool\_address, delegator\_address, transaction\_version, event\_index |
| dsa\_insat\_index                    | inserted\_at                                                          |

### `delegated_staking_pool_balances`

This table tracks the historical balances of each account in a delegated staking pool.

| Field                            | Type   | Primary Key | Description                                                   |
| -------------------------------- | ------ | ----------- | ------------------------------------------------------------- |
| transaction\_version             | bigint |             | Transaction version (identifier) for activity                 |
| staking\_pool\_address           | String |             | The address of the delegation pool.                           |
| total\_coins                     | bigint |             | Amount of APT in the staking pool.                            |
| total\_shares                    | bigint |             | The total number of shares in the delegation pool.            |
| operator\_commission\_percentage | bigint |             | The commission percentage taken by the staking pool operator. |
| inactive\_table\_handle          | String |             | The table handle for the inactive table.                      |
| active\_table\_handle            | String |             | The table handle for the active table.                        |
| inserted\_at                     | String |             | The timestamp when the record was inserted.                   |

| Index Name                               | Indexed Columns                              |
| ---------------------------------------- | -------------------------------------------- |
| delegated\_staking\_pool\_balances\_pkey | transaction\_version, staking\_pool\_address |

### `delegated_staking_pools`

This table tracks when a delegated pool was created.

| Field                       | Type      | Primary Key | Description                                                                  |
| --------------------------- | --------- | ----------- | ---------------------------------------------------------------------------- |
| staking\_pool\_address      | String    |             | The address of the staking pool.                                             |
| first\_transaction\_version | bigint    |             | The version number of the first transaction involving this pool. Ex. 5000000 |
| inserted\_at                | Timestamp |             | The timestamp when the record was inserted.                                  |

| Index Name                      | Indexed Columns        |
| ------------------------------- | ---------------------- |
| delegated\_staking\_pools\_pkey | staking\_pool\_address |

### `delegator_balances`

This table tracks the historical balances of each account in a delegation pool.

| Field                     | Type      | Primary Key | Description                                        |
| ------------------------- | --------- | ----------- | -------------------------------------------------- |
| transaction\_version      | bigint    |             | The version number of the transaction. Ex. 5000000 |
| write\_set\_change\_index | bigint    |             | The index of the write set change. Ex. 1           |
| delegator\_address        | String    |             | The address of the delegator.                      |
| pool\_address             | String    |             | The address of the delegator pool.                 |
| pool\_type                | String    |             | The type of the pool. Ex. "delegated"              |
| table\_handle             | String    |             | The table handle for the pool.                     |
| shares                    | bigint    |             | The number of shares in the pool.                  |
| parent\_table\_handle     | String    |             | The table handle for the parent table.             |
| inserted\_at              | Timestamp |             | The timestamp when the record was inserted.        |

| Index Name                | Indexed Columns                                 |
| ------------------------- | ----------------------------------------------- |
| delegator\_balances\_pkey | transaction\_version, write\_set\_change\_index |

## Aptos Naming Service (ANS)

### `current_aptos_names`

_Has an aggregate view for summary data called `current_aptos_names_aggregate`_

This view of [`current_ans_lookup_v2`](#current_ans_lookup_v2) helps query by name instead of account.

| Field                      | Type    | Primary Key | Description                                                                                                                                                                                       |
| -------------------------- | ------- | ----------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| domain                     | String  |             | The domain associated with this Aptos name. Ex. "example.crypto"                                                                                                                                  |
| domain\_with\_suffix       | String  |             | The full domain name including any suffix. Ex. "example.crypto.aptos"                                                                                                                             |
| expiration\_timestamp      | String  |             | Timestamp when the domain registration expires. Ex. "2024-04-17T02:14:25.68771"                                                                                                                   |
| is\_active                 | Boolean |             | Indicates whether the domain is currently active. Ex. True                                                                                                                                        |
| is\_domain\_owner          | Boolean |             | Indicates whether the registered address is the owner of the domain. Ex. False                                                                                                                    |
| is\_primary                | Boolean |             | Indicates whether this is the primary domain for the registered address. Ex. True                                                                                                                 |
| last\_transaction\_version | bigint  |             | The version number of the last transaction involving this domain. Ex. 5000000                                                                                                                     |
| owner\_address             | String  |             | This is an Aptos account address that owns the domain. Addresses must be 66 characters long, and so may be 0 padded. Ex. "0x123abc456def7890abcdef1234567890abcdef1234"                           |
| registered\_address        | String  |             | This is an Aptos account address registered to the domain. Addresses must be 66 characters long, and so may be 0 padded. Ex. "0x50bc83f01d48ab3b9c00048542332201ab9cbbea61bda5f48bf81dc506caa78a" |
| subdomain                  | String  |             | Any subdomain part of the domain name. Ex. "sub.example"                                                                                                                                          |
| token\_name                | String  |             | The name of the token associated with this domain. Ex. "ExampleToken"                                                                                                                             |
| token\_standard            | String  |             | Aptos standard that the collection adheres to. Ex. "v1"                                                                                                                                           |

### `current_ans_lookup_v2`

This table maps tokens, standards, and addresses to human readable names.

| Field                      | Type    | Primary Key | Description                                                                                                                                                                                       |
| -------------------------- | ------- | ----------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| domain                     | String  | Yes         | The domain associated with this Aptos name. Ex. "example.crypto"                                                                                                                                  |
| expiration\_timestamp      | String  |             | Timestamp when the domain registration expires. Ex. "2024-04-17T02:14:25.68771"                                                                                                                   |
| is\_deleted                | Boolean |             | Indicates whether the domain registration has been deleted. Ex. False                                                                                                                             |
| last\_transaction\_version | bigint  |             | The version number of the last transaction involving this domain. Ex. 5000000                                                                                                                     |
| registered\_address        | String  |             | This is an Aptos account address registered to the domain. Addresses must be 66 characters long, and so may be 0 padded. Ex. "0x50bc83f01d48ab3b9c00048542332201ab9cbbea61bda5f48bf81dc506caa78a" |
| subdomain                  | String  | Yes         | Any subdomain part of the domain name. Ex. "sub.example"                                                                                                                                          |
| token\_name                | String  |             | The name of the token associated with this domain. Ex. "ExampleToken"                                                                                                                             |
| token\_standard            | String  | Yes         | Aptos standard that the collection adheres to. Ex. "v1"                                                                                                                                           |

| Index Name                     | Indexed Columns                    |
| ------------------------------ | ---------------------------------- |
| ans\_v2\_et\_index             | expiration\_timestamp              |
| ans\_v2\_insat\_index          | inserted\_at                       |
| ans\_v2\_ra\_index             | registered\_address                |
| ans\_v2\_tn\_index             | token\_name, token\_standard       |
| current\_ans\_lookup\_v2\_pkey | domain, subdomain, token\_standard |

## Deprecated Tables

The following tables are planned for deprecation, or are already deprecated. See the notes section for any direct replacements or notes on how to migrate if you currently depend on one of these tables. Please do not use any of the below tables for production services.

| Table                                   | Notes                                                                                                                                                           |
| --------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| address\_version\_from\_move\_resources | Replace with account\_transactions                                                                                                                              |
| address\_events\_summary                | To query custom events, you should create a [No-Code Indexer](https://geomi.dev/docs/no-code-indexing)                                                          |
| address\_version\_from\_events          | To query custom events, you should create a [No-Code Indexer](https://geomi.dev/docs/no-code-indexing)                                                          |
| coin\_activities                        | Replace with fungible\_asset\_activities                                                                                                                        |
| coin\_balances                          | Replace with current\_fungible\_asset\_balances                                                                                                                 |
| coin\_infos                             | Replace with fungible\_asset\_metadata                                                                                                                          |
| coin\_supply                            | No replacement; non-realtime APT coin supply is available with this [query](https://github.com/aptos-labs/explorer/blob/main/analytics/apt_supply.sql)          |
| collection\_datas                       | Replace with current\_collections\_v2                                                                                                                           |
| current\_ans\_lookup                    | Replace with current\_ans\_lookup\_v2                                                                                                                           |
| current\_coin\_balances                 | Replace with current\_fungible\_asset\_balances                                                                                                                 |
| current\_collection\_datas              | Replace with current\_collections\_v2                                                                                                                           |
| current\_token\_datas                   | Replace with current\_token\_datas\_v2                                                                                                                          |
| current\_token\_ownerships              | Replace with current\_token\_ownerships\_v2                                                                                                                     |
| events\_view                            | To query custom events, you should create a [No-Code Indexer](https://geomi.dev/docs/no-code-indexing)                                                          |
| move\_resources                         | Replace with account\_transactions                                                                                                                              |
| move\_resources\_view                   | Replace with account\_transactions                                                                                                                              |
| nft\_marketplace\_v2\_\*                | Replace with [NFT Aggregator API](/build/indexer/nft-aggregator)                                                                                                |
| token\_activities                       | Replace with token\_activities\_v2                                                                                                                              |
| token\_datas                            | Replace with current\_token\_datas\_v2                                                                                                                          |
| token\_ownerships                       | Replace with current\_token\_ownerships\_v2                                                                                                                     |
| tokens                                  | Replace with current\_token\_datas\_v2                                                                                                                          |
| transactions                            | No replacement; non-realtime data is available in [BigQuery](https://console.cloud.google.com/marketplace/product/bigquery-public-data/crypto-aptos-mainnet-us) |
| transactions\_view                      | No replacement; non-realtime data is available in [BigQuery](https://console.cloud.google.com/marketplace/product/bigquery-public-data/crypto-aptos-mainnet-us) |

# Self-Hosted Indexer API

> Deploy your own Aptos Indexer API with custom processors, database setup, and transaction stream integration for private data access

import { Aside } from '@astrojs/starlight/components';

{/* <IndexerBetaNotice /> */}

This guide will walk you through setting up a self-hosted Indexer API.

<Aside type="caution">
  Currently this guide only explains how to run processor part of the Indexer API. By the end of this guide you will have a running processor that consumes transactions from the Transaction Stream Service, parses them, and stores them in the database. Unfortunately this guide does not explain how to attach an API to this system right now.
</Aside>

## Prerequisites

- A running PostgreSQL instance is required, with a valid user and database. In this example we call the user `postgres` and the database `indexer`.
- If you wish to use Docker, you must have Docker installed. [Installation Guide](https://docs.docker.com/get-docker/).

## Configuration

To run the service we need to define a config file. We will start with this template:

```yaml filename="config.yaml"
health_check_port: 8084
server_config:
  processor_config:
    type: default_processor
  postgres_connection_string: postgresql://postgres:@localhost:5432/indexer
  indexer_grpc_data_service_address: 127.0.0.1:50051
  indexer_grpc_http2_ping_interval_in_secs: 60
  indexer_grpc_http2_ping_timeout_in_secs: 10
  auth_token: AUTH_TOKEN
```

From here you will likely want to change the values of some of these fields. Let's go through some of them.

### `processor_name`

<Aside type="note">
  A single instance of the service only runs a single processor. If you want to run multiple processors, you must run multiple instances of the service. In this case, it is up to you whether to use the same database or not.
</Aside>

This is the processor you want to run. You can see what processors are available [here](https://github.com/aptos-labs/aptos-indexer-processors-v2/tree/main/processor/src/processors). Some examples:

- `coin_processor`
- `ans_processor`
- `token_v2_processor`

### `postgres_connection_string`

This is the connection string to your PostgreSQL database. It should be in the format `postgresql://<username>:<password>@<host>:<port>/<database>`.

<Aside type="caution">
  If you're running this from a Docker Desktop environment (which you likely are if you're using MacOS or Windows) you must set `postgres_connection_string` to `postgresql://host.docker.internal:5432/indexer` instead. With Docker Desktop this is how the binary can reach the host network.
</Aside>

### `indexer_grpc_data_service_address`

This is the URL for the Transaction Stream Service. If you are using the Labs-Hosted instance you can find the URLs for each network at [this page](/build/indexer/indexer-api). Make sure to select the correct URL for the network you want to index. If you are running this service locally the value should be `127.0.0.1:50051`.

### `auth_token`

This is the auth token used to connect to the Transaction Stream Service. If you are using the Labs-Hosted instance you can use the API Gateway to get an API key. Learn more at [this page](/build/indexer/indexer-api).

## Run with source code

Clone the repo:

```shellscript filename="Terminal"
# SSH
git clone git@github.com:aptos-labs/aptos-indexer-processors-v2.git

# HTTPS
git clone https://github.com/aptos-labs/aptos-indexer-processors-v2.git
```

Navigate to the directory for the service:

```shellscript filename="Terminal"
cd aptos-indexer-processors
cd rust/processor
```

Run the service:

```shellscript filename="Terminal"
cargo run --release -- -c config.yaml
```

## Run with Docker

{/* <!--
  This doesn't actually work this very moment because:

  1. We don't yet publish the image as indexer-processor-rust
  2. We don't tag it as latest.

  We'll do that soon though: https://aptos-org.slack.com/archives/C04PRP1K1FZ/p1692732083583659
  --> */}

To run the service with Docker, use the following command:

```shellscript filename="Terminal"
docker run -it --network host --mount type=bind,source=/tmp/config.yaml,target=/config.yaml aptoslabs/indexer-processor-rust -c /config.yaml
```

This command binds the container to the host network and mounts the config file from the host into the container. This specific invocation assumes that your config file in the host is at `/tmp/config.yaml`.

See the image on DockerHub here: [https://hub.docker.com/r/aptoslabs/indexer-processor-rust/tags](https://hub.docker.com/r/aptoslabs/indexer-processor-rust/tags).

# Get Token Metadata by Name

> Retrieve token metadata URIs by token names within collections for marketplace and NFT platform integration

import { GraphQLEditor } from '~/components/react/GraphQLEditor';

import { Aside } from '@astrojs/starlight/components';

`GetTokensDataByName` retrieves metadata URIs for tokens by their names within a specified collection. This query is particularly useful for marketplaces to show metadata from tokens within a collection.

<Aside type="note">
  Explore the capabilities of this query! Modify the variables below to tailor the query to your needs.
</Aside>

<GraphQLEditor
  query={`query GetTokensDataByName($token_name: String, $collectionId: String) {
  current_token_datas_v2(
    where: {
      token_name: { _eq: $token_name }
      collection_id: { _eq: $collectionId }
    }
  ) {
    token_uri
    __typename
  }
}`}
  variables={`{
  "token_name": "The Mexican",
  "collectionId": "0xe6a7399d10406b993e25d8a3bf24842413ba8f1a08444dbfa5f1c31b09f0d16e"
}`}
/>

#### Variables:

- `$token_name`: **String** - The name of the token to search within the collection. Example: `"The Mexican"`.
- `$collectionId`: **String** - The collection id calculated based on collection name and creator address. Example: `"0xe6a7399d10406b993e25d8a3bf24842413ba8f1a08444dbfa5f1c31b09f0d16e"`.

### Note

To get the collection id, you can use the python code snippet to get:

```python
import hashlib

def standardized_address(creator_address: str) -> str:
    # Strip the '0x' prefix if it exists and format the address to be 64 characters long
    handle = creator_address.removeprefix("0x") if creator_address.startswith("0x") else creator_address
    return f"0x{handle:0>64}"

def sha256_hex(creator_address: str, collection_name: str) -> str:
    # Process the creator address
    processed_address = standardized_address(creator_address)
    
    # Combine processed creator address and collection name
    combined_string = f"{creator_address}::{collection_name}"
    # Compute SHA256 hash and return as a hexadecimal string
    return standardized_address(hashlib.sha256(combined_string.encode()).hexdigest())

# Example usage
creator_address = "0xc0e3fbf8ae61056d66ce624d71ccf1888f879355cc4e364ef117249b5e3160a8"
collection_name = "Aptomingos"
# Collection Id is `0xe6a7399d10406b993e25d8a3bf24842413ba8f1a08444dbfa5f1c31b09f0d16e`
print(sha256_hex(creator_address, collection_name))

```

# Indexer SDK

> Create custom data processors for Aptos blockchain using the Indexer SDK to index smart contracts and build tailored data pipelines

import { CardGrid, LinkCard } from '@astrojs/starlight/components';

{/* <IndexerBetaNotice /> */}

While the Indexer API is a powerful tool for querying basic on-chain data, it may not always provide the exact data you need.
In most cases, you want to index your own contract and to do that, you can create your own custom processor using the Indexer SDK.

## Using the Indexer SDK

Learn how to use the Indexer SDK through guides and documentation.

<CardGrid>
  <LinkCard href="/build/indexer/indexer-sdk/quickstart" title="Quickstart Guide" description="Get started with the Indexer SDK" />

  <LinkCard href="/build/indexer/indexer-sdk/documentation" title="Documentation" description="Read documentation about the Indexer SDK" />
</CardGrid>

## Example Processors

As a reference, you can see all Aptos-Hosted processors that comprise the Indexer API [here](https://github.com/aptos-labs/aptos-indexer-processors-v2).

# Migrate to Indexer SDK

> Step-by-step migration guide from legacy custom processors to modern Aptos Indexer SDK with code examples and best practices

This guide contains instructions on how to migrate your legacy custom processor (that's written in the [old way](https://github.com/aptos-labs/aptos-indexer-processors/blob/aptos-indexer-processors-v1.20.0/rust/processor/src/processors/events_processor.rs)) to Indexer SDK.

## 1. Clone the example repo

We use example events processor in `aptos-indexer-processor-example` as a starting point for the migration.

```shellscript
git clone https://github.com/aptos-labs/aptos-indexer-processor-example.git
```

## 2. Migrate your processor config

Previously, you would create a branch of `aptos-indexer-processors` and update the processor config to include your custom processor.
This legacy approach made it very difficult to upgrade your processor.
To address this, the SDK no longer depends on `aptos-indexer-processors`.
As a result, you'll need to define your own `IndexerProcessorConfig` and `ProcessorConfig` structs.

The `IndexerProcessorConfig` defines the base configuration for all processors that you'll be running.
The `ProcessorConfig` is an enum that contains all the individual processor configs.

Update the following files in your project:

- [`ProcessorConfig`](https://github.com/aptos-labs/aptos-indexer-processor-example/blob/main/aptos-indexer-processor-example/src/config/processor_config.rs): Replace `EventsProcessor` with your processor.
- [`IndexerProcessorConfig`](https://github.com/aptos-labs/aptos-indexer-processor-example/blob/main/aptos-indexer-processor-example/src/config/indexer_processor_config.rs): Update the `.run()` method to include your processor.

If you'd like to read more about configuration in the SDK, take a look at the [Create a Processor](/build/indexer/indexer-sdk/documentation/create-processor) guide.

## 3. Migrate processing logic to steps

In the old way, you defined your processor's logic by implementing `ProcessorTrait`'s `process_transactions` method.

Example events processor written with the old way:

```rust
#[async_trait]
impl ProcessorTrait for EventsProcessor {
    async fn process_transactions(
        ...
    ) -> anyhow::Result<ProcessingResult> {
        // Extract events from transactions 
        let events: Vec<EventModel> = process_events(transactions);

        // Store the events in the database
        let tx_result = insert_to_db(
            self.get_pool(),
            self.name(),
            start_version,
            end_version,
            &events,
            &self.per_table_chunk_sizes,
        )
        .await;

        return tx_result;
    }
}

async fn insert_to_db(
    conn: ArcDbPool,
    name: &'static str,
    start_version: u64,
    end_version: u64,
    events: &[EventModel],
    per_table_chunk_sizes: &AHashMap<String, usize>,
) -> Result<(), diesel::result::Error> {
    tracing::trace!(
        name = name,
        start_version = start_version,
        end_version = end_version,
        "Inserting to db",
    );
    execute_in_chunks(
        conn,
        insert_events_query,
        events,
        get_config_table_chunk_size::<EventModel>("events", per_table_chunk_sizes),
    )
    .await?;
    Ok(())
}
```

With the SDK, we've introduced the concept of steps, which represent independent units of processing logic.
In the `EventsProcessor` example, the extraction of events and storing them in the database can be broken down into two steps.

To migrate your processor to the SDK, you'll need to define these steps in your processor.
You can use the `EventsExtractor` and `EventsStorer` steps in the example as a starting point for defining your own steps.

Make the following changes to [`events_extractor.rs`](https://github.com/aptos-labs/aptos-indexer-processor-example/blob/main/aptos-indexer-processor-example/src/processors/events/events_extractor.rs).

```rust
// TODO: Update the step name
pub struct EventsExtractor
where
    Self: Sized + Send + 'static, {}

#[async_trait]
impl Processable for EventsExtractor {
    type Input = Vec<Transaction>;
    // TODO: Update the output type
    // This should be the data model you're extracting from the transactions
    type Output = Vec<EventModel>;
    type RunType = AsyncRunType;

    async fn process(
        &mut self,
        item: TransactionContext<Vec<Transaction>>,
    ) -> Result<Option<TransactionContext<Vec<EventModel>>>, ProcessorError> {
        // TODO: Update extraction logic. 
        // This should be the same as the extraction logic in the old `process_transactions` method
        let events = item
            .data
            .par_iter()
            .map(|txn| {
                process_events(txn)
            })
            .flatten()
            .collect::<Vec<EventModel>>();

        Ok(Some(TransactionContext {
            data: events,
            metadata: item.metadata,
        }))
    }
}
```

Make the following changes to [`events_storer.rs`](https://github.com/aptos-labs/aptos-indexer-processor-example/blob/main/aptos-indexer-processor-example/src/processors/events/events_processor.rs).

```rust
pub struct EventsStorer
where
    Self: Sized + Send + 'static,
{
    conn_pool: ArcDbPool,
    processor_config: DefaultProcessorConfig,
}

impl EventsStorer {
    pub fn new(conn_pool: ArcDbPool, processor_config: DefaultProcessorConfig) -> Self {
        Self {
            conn_pool,
            processor_config,
        }
    }
}

#[async_trait]
// TODO: Update step name
impl Processable for EventsStorer {
    // TODO: Update input type for the step. 
    // The input type should match the output type of the extractor step.
    type Input = Vec<EventModel>;
    type Output = ();
    type RunType = AsyncRunType;

    async fn process(
        &mut self,
        events: TransactionContext<Vec<EventModel>>,
    ) -> Result<Option<TransactionContext<()>>, ProcessorError> {
        let per_table_chunk_sizes: AHashMap<String, usize> = AHashMap::new();
        let execute_res = execute_in_chunks(
            self.conn_pool.clone(),
            // TODO: Update this to the insertion query of your old processor
            insert_events_query,
            &events.data,
            get_config_table_chunk_size::<EventModel>("events", &per_table_chunk_sizes),
        )
        .await;
        match execute_res {
            Ok(_) => {
                Ok(Some(TransactionContext {
                    data: (),
                    metadata: events.metadata,
                }))
            },
            Err(e) => Err(ProcessorError::DBStoreError {
                message: format!(
                    "Failed to store events versions {} to {}: {:?}",
                    events.metadata.start_version, events.metadata.end_version, e,
                ),
                query: None,
            }),
        }
    }
}

impl AsyncStep for EventsStorer {}

impl NamedStep for EventsStorer {
    fn name(&self) -> String {
        "EventsStorer".to_string()
    }
}
```

## 4. Migrate your processor

Now that we've migrated the processing logic to steps, we need to also migrate the processor to instantiate the steps and connect them together.
In [`events_processor.rs`](https://github.com/aptos-labs/aptos-indexer-processor-example/blob/main/aptos-indexer-processor-example/src/processors/events/events_processor.rs), make the following changes:

```rust
// TODO: Update processor name
pub struct EventsProcessor {
    pub config: IndexerProcessorConfig,
    pub db_pool: ArcDbPool,
    // If you have any other fields in your processor, add them here
    // You can instantiate them accordingly in the processor's `new` method
}
```

In the `run_processor` method, you'll need to update the code to use the steps you created in [Step 3](#3-migrate-processing-logic-to-steps).

```rust
pub async fn run_processor(self) -> Result<()> {
    {...}

    // Define processor steps
    let transaction_stream_config = self.config.transaction_stream_config.clone();
    let transaction_stream = TransactionStreamStep::new(TransactionStreamConfig {
        starting_version: Some(starting_version),
        ..transaction_stream_config
    })
    .await?;
    // TODO: Replace the next 2 lines with your steps 
    let events_extractor = EventsExtractor {};
    let events_storer = EventsStorer::new(self.db_pool.clone());
    
    let version_tracker = VersionTrackerStep::new(
        get_processor_status_saver(self.db_pool.clone(), self.config.clone()),
        DEFAULT_UPDATE_PROCESSOR_STATUS_SECS,
    );

    // Connect processor steps together
    let (_, buffer_receiver) = ProcessorBuilder::new_with_inputless_first_step(
        transaction_stream.into_runnable_step(),
    )
    // TODO: Replace the next 2 lines with your steps
    .connect_to(events_extractor.into_runnable_step(), 10)
    .connect_to(events_storer.into_runnable_step(), 10)
    .connect_to(version_tracker.into_runnable_step(), 10)
    .end_and_return_output_receiver(10);

    {...}
}
```

## 5. Update your `config.yaml`

`IndexerProcessorConfig` reworks the format of the `config.yaml` file.
Use the example [`config.yaml`](https://github.com/aptos-labs/aptos-indexer-processor-example/blob/main/aptos-indexer-processor-example/config.yaml).

```yaml
health_check_port: 8085
server_config:
  processor_config:
    # TODO: Update with processor type
    type: "events_processor" 
  transaction_stream_config:
    indexer_grpc_data_service_address: "https://grpc.testnet.aptoslabs.com:443"
    # TODO: Update auth token
    auth_token: "AUTH_TOKEN"
    # TODO: Update with processor name
    request_name_header: "events-processor"
  db_config:
    # TODO: Update with your database connection string
    postgres_connection_string: postgresql://postgres:@localhost:5432/example
  # backfill_config:
  #   backfill_alias: "events_processor_backfill_1"
```

## 6. Run your migrated processor

```shellscript
cd ~/{DIRECTORY_OF_PROJECT}/aptos-indexer-processor-example
cargo run --release -- -c config.yaml
```

In your terminal, you should start to see logs like this:

```shellscript
{"timestamp":"2025-01-13T21:23:21.785452Z","level":"INFO","message":"[Transaction Stream] Successfully connected to GRPC stream","stream_address":"https://grpc.mainnet.aptoslabs.com/","connection_id":"ec67ecc4-e041-4f17-a2e2-441e7ff21487","start_version":2186504987,"filename":"/Users/reneetso/.cargo/git/checkouts/aptos-indexer-processor-sdk-2f3940a333c8389d/e6867c5/aptos-indexer-processors-sdk/transaction-stream/src/transaction_stream.rs","line_number":349,"threadName":"tokio-runtime-worker","threadId":"ThreadId(4)"}
{"timestamp":"2025-01-13T21:23:21.785664Z","level":"INFO","message":"Spawning polling task","step_name":"TransactionStreamStep","filename":"/Users/reneetso/.cargo/git/checkouts/aptos-indexer-processor-sdk-2f3940a333c8389d/e6867c5/aptos-indexer-processors-sdk/sdk/src/traits/pollable_async_step.rs","line_number":112,"threadName":"tokio-runtime-worker","threadId":"ThreadId(23)"}
{"timestamp":"2025-01-13T21:23:21.785693Z","level":"INFO","message":"Spawning processing task","step_name":"TransactionStreamStep","filename":"/Users/reneetso/.cargo/git/checkouts/aptos-indexer-processor-sdk-2f3940a333c8389d/e6867c5/aptos-indexer-processors-sdk/sdk/src/traits/pollable_async_step.rs","line_number":204,"threadName":"tokio-runtime-worker","threadId":"ThreadId(23)"}
{"timestamp":"2025-01-13T21:23:21.785710Z","level":"INFO","message":"Spawning processing task","step_name":"FungibleAssetExtractor","filename":"/Users/reneetso/.cargo/git/checkouts/aptos-indexer-processor-sdk-2f3940a333c8389d/e6867c5/aptos-indexer-processors-sdk/sdk/src/traits/async_step.rs","line_number":87,"threadName":"tokio-runtime-worker","threadId":"ThreadId(4)"}
{"timestamp":"2025-01-13T21:23:21.785912Z","level":"INFO","message":"Spawning processing task","step_name":"FungibleAssetStorer","filename":"/Users/reneetso/.cargo/git/checkouts/aptos-indexer-processor-sdk-2f3940a333c8389d/e6867c5/aptos-indexer-processors-sdk/sdk/src/traits/async_step.rs","line_number":87,"threadName":"tokio-runtime-worker","threadId":"ThreadId(4)"}
{"timestamp":"2025-01-13T21:23:21.785978Z","level":"INFO","message":"Spawning polling task","step_name":"VersionTrackerStep: ()","filename":"/Users/reneetso/.cargo/git/checkouts/aptos-indexer-processor-sdk-2f3940a333c8389d/e6867c5/aptos-indexer-processors-sdk/sdk/src/traits/pollable_async_step.rs","line_number":112,"threadName":"tokio-runtime-worker","threadId":"ThreadId(14)"}
{"timestamp":"2025-01-13T21:23:21.786018Z","level":"INFO","message":"Spawning processing task","step_name":"VersionTrackerStep: ()","filename":"/Users/reneetso/.cargo/git/checkouts/aptos-indexer-processor-sdk-2f3940a333c8389d/e6867c5/aptos-indexer-processors-sdk/sdk/src/traits/pollable_async_step.rs","line_number":204,"threadName":"tokio-runtime-worker","threadId":"ThreadId(14)"}
```

## 7. Backfilling with the SDK

With the SDK, we've made some improvements to the backfilling process.
There are two options on backfilling:

1. You can keep following the old way of backfilling, which is to run a second instance of the processor and updating `starting_version` to the backfill version.
2. The SDK introduces an improvement where you can track progress of a backfill and start and stop the backfill as needed.
   If you'd like to use the new backfilling process, update your `config.yaml` like so:

```yaml
health_check_port: 8085
server_config:
  processor_config:
    # TODO: Update with processor type
    type: "events_processor" 
  transaction_stream_config:
    indexer_grpc_data_service_address: "https://grpc.testnet.aptoslabs.com:443"
    # TODO: Update with backfill version
    starting_version: {backfill version}
    # TODO: Update auth token
    auth_token: "AUTH_TOKEN"
    # TODO: Update with processor name
    request_name_header: "events-processor"
  db_config:
    # TODO: Update with your database connection string
    postgres_connection_string: postgresql://postgres:@localhost:5432/example
  backfill_config:
    # TODO: Update with your backfill alias. This should be unique for each backfill
    backfill_alias: "events_processor_backfill_1"
```

# Testing Processor

> Comprehensive testing strategies for Aptos processors including validation, transformation testing, and data accuracy verification

import { Aside } from '@astrojs/starlight/components';

### What Is a Processor?

A processor is a core component of the Aptos Indexer that handles blockchain transaction processing. It validates, transforms, and stores transactions into a database, enabling downstream applications like analytics, indexing, and querying. Testing the processor ensures that all transactions are correctly handled, maintaining data accuracy and consistency.

### What Are We Testing With This?

- **Transaction correctness**: Ensure that each transaction is processed and stored accurately.
- **Schema consistency**: Verify that the database schema is correctly set up and maintained throughout the tests.

### General Flow of how Processor Testing Works

1. You specify the transactions to test
2. Testing framework SDK spins up a mock gRPC Service with the transactions you specified to return when the processor requests transactions.
3. Processor processes the transactions and writes the output to a database.
4. Optionally, you can generate expected database output for validation.

Type of Scenarios it Supports:

1. A single transaction
2. A single batch of multiple transactions
   Input \[A, B, C]
   1. Processor processes A, B, and C
3. Sequential multiple transaction batches:
   Input \[A, B, C]
   1. Processor processes A and B
   2. Processor processes C

## Prerequisites

1. Ensure Docker Desktop is running for PostgreSQL container support.
   - **Docker Desktop Installation**: Install Docker Desktop following [this guide](https://docs.docker.com/desktop/) on your machine.
   - Start Docker Desktop if it's not running
2. Identify the transactions to test.
   - Use imported transactions or write your own custom Move scripts to generate test transactions. Refer to [Importing Transaction Guide](/build/indexer/indexer-sdk/advanced-tutorials/txn-importer) and [Generating Transaction using Move Script Guide](/build/indexer/indexer-sdk/advanced-tutorials/txn-script) for detailed instructions.
3. Import aptos-indexer-testing-framework to your Cargo.toml

<Aside type="note"> - This tutorial assumes you are using Postgres as the database. </Aside>

- **Adapting to Other Databases**:
  - Replace PostgreSQL-specific code with relevant database code you intend to use (e.g., MySQL).
  - Update schema initialization and query methods.
- **References to Processor Tests**:
  - Example: [Event Processor Tests](https://github.com/aptos-labs/aptos-indexer-processors/blob/main/rust/integration-tests/src/sdk_tests/events_processor_tests.rs#L139).

## Steps to Write a Test

### 1. Set Up the Test Environment

Before setting up the test environment, it‚Äôs important to understand the configurations being used in this step:

**What Are These Configurations?**

`generate_file_flag`

- If `generate_file_flag` is true, the test will overwrite any saved database outputs from previous test runs. If `generate_file_flag` is false, the test will only compare the actual database output with the expected database output and log differences.

`custom_output_path`

- An optional configuration to specify a custom path where the expected database output will be stored.
  If not provided, the test will use the default path defined by DEFAULT\_OUTPUT\_FOLDER.

`DEFAULT_OUTPUT_FOLDER`

- This constant defines the default folder where the system stores output files for the tests.
  Example: "sdk\_expected\_db\_output\_files".
  Modify this value in your configuration if you prefer a different default directory.

```rust
let (generate_file_flag, custom_output_path) = get_test_config();
let output_path = custom_output_path.unwrap_or_else(|| format!("{}/imported_mainnet_txns", DEFAULT_OUTPUT_FOLDER));

// Setup DB and replace as needed
let mut db = PostgresTestDatabase::new();
db.setup().await.unwrap();

let mut test_context = SdkTestContext::new(&[CONST_VARIABLE_OF_YOUR_TEST_TRANSACTION]); // Replace with your test transaction
if test_context.init_mock_grpc().await.is_err() {
    panic!("Failed to initialize mock grpc");
};
```

**Explanation of Each Component:**

`get_test_config():`

This function fetches the configurations (diff\_flag and custom\_output\_path) for the test.
Modify or extend this function if you want to support additional custom flags or configurations.
output\_path:

Combines DEFAULT\_OUTPUT\_FOLDER with the subfolder imported\_mainnet\_txns if no custom\_output\_path is specified.
This ensures all output files are stored in a predictable location.

`PostgresTestDatabase::new():`

Creates a new PostgreSQL database instance for testing.
This database is isolated, ensuring no interference with production or other test environments.

`SdkTestContext::new():`

Initializes the test context with the transaction(s) you want to test.
Replace CONST\_VARIABLE\_OF\_YOUR\_TEST\_TRANSACTION with the appropriate variable or constant representing the transaction(s) to be tested.

`init_mock_grpc():`

Initializes a mock gRPC service for the test.
This allows the processor to simulate transactions without interacting with live blockchain data.

### 2. Configure the Processor

<Aside type="note">
  - Each test runs in an isolated environment using a PostgreSQL container to prevent interference.
</Aside>

```rust
let db_url = db.get_db_url();
let transaction_stream_config = test_context.create_transaction_stream_config();
let postgres_config = PostgresConfig {
    connection_string: db_url.to_string(),
    db_pool_size: 100,
};

let db_config = DbConfig::PostgresConfig(postgres_config);
let default_processor_config = DefaultProcessorConfig {
    per_table_chunk_sizes: AHashMap::new(),
    channel_size: 100,
    deprecated_tables: HashSet::new(),
};

let processor_config = ProcessorConfig::DefaultProcessor(default_processor_config);
let processor_name = processor_config.name();
```

### 3. Create the Processor

```rust
let processor = DefaultProcessor::new(indexer_processor_config)
    .await
    .expect("Failed to create processor");
```

Note: Replace `DefaultProcessor` with the processor you are testing.

### 4. Setup a Query

Set up a query to load data from the local database and compare it with expected results, see [example loading function](https://github.com/aptos-labs/aptos-indexer-processors/blob/a8f9c5915f4e3f1f596ed3412b8eb01feca1aa7b/rust/integration-tests/src/diff_test_helper/default_processor.rs#L45)

### 5. Setup a Test Context run function

Use the test\_context.run() function to execute the processor, validate outputs using your query, and optionally generate database output files:

<Aside type="note">
  Key Considerations:

  - Each test runs in an isolated environment using a PostgreSQL container to prevent interference.
  - Proper handling of versions ensures transactions are processed and validated in the correct order.
  - Validation logic must detect changes or issues by comparing processor output with the expected baseline.
</Aside>

```rust
    let txn_versions: Vec<i64> = test_context
        .get_test_transaction_versions()
        .into_iter()
        .map(|v| v as i64)
        .collect();

    let db_values = test_context
        .run(
            &processor,
            generate_file_flag,
            output_path.clone(),
            custom_file_name,
            move || {
                let mut conn = PgConnection::establish(&db_url).unwrap_or_else(|e| {
                    eprintln!("[ERROR] Failed to establish DB connection: {:?}", e);
                    panic!("Failed to establish DB connection: {:?}", e);
                });

                let db_values = match load_data(&mut conn, txn_versions.clone()) {
                    Ok(db_data) => db_data,
                    Err(e) => {
                        eprintln!("[ERROR] Failed to load data {}", e);
                        return Err(e);
                    },
                };

                if db_values.is_empty() {
                    eprintln!("[WARNING] No data found for versions: {:?}", txn_versions);
                }

                Ok(db_values)
            },
        )
```

### 6. Run the Processor Test

Once you have your test ready, run the following command to generate the expected output for validation:

```shellscript
cargo test sdk_tests -- generate-output
```

Arguments:
generate-output: Set this true if you want to generate or overwrite saved database output, or false if you want to compare database outputs in diff mode.
output-path: it's an optional argument to specify the output path for the db output.

The expected database output will be saved in the specified output\_path or `sdk_expected_db_output_files` by default.

***

## FAQ

### What Types of Tests Does It Support?

- The testing framework allows you to write tests that compare the database outputs of processors. It helps you catch changes in database output when you're updating or developing your processor.

### What Is `TestContext`?

`TestContext` is a struct that manages:

- `transaction_batches`: A collection of transaction batches.
- `postgres_container`: A PostgreSQL container for test isolation.

It initializes and manages the database and transaction context for tests.

#### What Does `TestContext.run` Do?

This function executes the processor, applies validation logic, and optionally generates output files.

#### Key Features:

- Flexible Validation: Accepts a user-provided verification function.
- Multi-Table Support: Handles data across multiple tables.
- Retries: Uses exponential backoff and timeout for retries.
- Optional File Generation: Controlled by a flag.

#### Example Usage:

```rust
pub async fn run<F>(
    &mut self,
    processor: &impl ProcessorTrait,
    txn_version: u64,
    generate_files: bool,             // Flag to control file generation
    output_path: String,              // Output path
    custom_file_name: Option<String>, // Custom file name
    verification_f: F,                // Verification function
) -> anyhow::Result<HashMap<String, Value>>
where
```

### How to Generate Expected DB Output?

Run the following command:

```shellscript
cargo test sdk_tests -- --nocapture generate-output
```

Supported Test Args:

1. `generate-output`
2. `output_path`

***

## Troubleshooting and Tips

1. **Isolate Tests**: Use Docker containers for database isolation.
2. **Handle Non-Deterministic Fields**: Use helpers like `remove_inserted_at` to clean up timestamps before validation.
3. **Enable Debugging**: Use `eprintln!` for detailed error logging.

#### How to Debug Test Failures?

run following command to get detailed logs:

```shellscript
cargo test sdk_tests -- --nocapture
```

# Aptos Indexer Testing Framework Overview

> Testing framework for Aptos indexer processors with transaction import and Move script generation for comprehensive testing scenarios

The Aptos Indexer Testing Framework provides two ways to generate test transactions: **by Importing Transactions from Network** and **By writing a Move Scripts**. Both approaches are suited for specific scenarios based on your development and testing requirements, enabling you to test how your system handles various transaction types.

## When to Import transactions

Imported transactions are primarily used to validate processor logic or database integrity by replaying transactions from live networks.

## When to Use **Move Script** to generate transactions

Scripted transactions are primarily used to create and test transaction scenarios that are not yet live on the network. In most cases, you should use transaction importing to test your processor logic.

## Summary

Aptos-indexer-transaction-generator tool is an essential tool in the Aptos Indexer Testing Framework. Import transactions for replaying and analyzing real-world transactions, while generating transactions with **Move Scripts** is best for testing new AIPs that may impact processing logic. Choose the method that aligns with your testing goals to ensure a comprehensive validation process.

## Next Steps

For detailed instructions on how to use these methods, refer to the following guides:

1. [Importing Transactions](/build/indexer/indexer-sdk/advanced-tutorials/txn-importer)
2. [Generating Transactions with Move Scripts](/build/indexer/indexer-sdk/advanced-tutorials/txn-script)

# Importing Transactions

> Import Aptos network transactions for processor testing using transaction generator tools with local development support

## Overview

This guide explains how to import Aptos transactions for testing using the `aptos-indexer-transaction-generator` tool. These test transactions can be used to test your custom processors and support their local development.

## General Flow of Transaction Importing

First, identify the transaction versions you need to fetch from the Aptos network. This tool interacts with the [Transaction Stream](/build/indexer/txn-stream) to retrieve transaction data in JSON format. The transactions are then consolidated into a Rust file, where each transaction is represented as a constant variable. These constants can be seamlessly used as mocked inputs in processor automated tests. During testing, the processor fetches the specified transactions, processes them, and writes the results to a database. You can then verify the outcomes by loading the written data and validating it against the expected data.

## Prerequisites

1. A valid API key to connect to [Transaction Stream](/build/indexer/txn-stream/aptos-hosted-txn-stream)
2. Clone the [aptos-core](https://github.com/aptos-labs/aptos-core) repository:
   - Navigate to the `aptos-core/ecosystem/indexer-grpc/indexer-transaction-generator` directory.

## How to Import Test Transactions

### 1. Specify Versions to Import

Locate and make a copy of the file:

```shellscript
ecosystem/indexer-grpc/indexer-transaction-generator/imported_transactions/imported_transactions.yaml
```

In this file, specify the versions to import from Devnet|Testnet|Mainnet by configuring the appropriate endpoint, API key, and mapping version numbers to descriptive output names. An example configuration is shown below:

```yaml
testnet:
  transaction_stream_endpoint: https://grpc.testnet.aptoslabs.com:443
  api_key: TESTNET_API_KEY  # <--- Replace this with your API key to generate files locally
  versions_to_import:
    # Replace these with the versions you want to import
    1: 1_genesis
    2: 2_new_block_event
    3: 3_empty_txn
    278556781: 278556781_v1_coin_register_fa_metadata
    1255836496: 1255836496_v2_fa_metadata
    5979639459: 5979639459_coin_register
    5992795934: 5992795934_fa_activities
    5523474016: 5523474016_validator_txn

mainnet:
  transaction_stream_endpoint: https://grpc.mainnet.aptoslabs.com:443
  api_key: MAINNET_API_KEY
  versions_to_import:
    308783012: 308783012_fa_transfer
```

### 2. Run the Command to Import Transactions

Navigate to the `indexer-transaction-generator` directory:

```shellscript
cd aptos-core/ecosystem/indexer-grpc/indexer-transaction-generator
```

To import the specified transaction versions, execute the following command:

```shellscript
cargo run -- --testing-folder  /path/to/your/imported_transactions.yaml --output-folder /path/to/your/processor-repo/src --mode=import --network=testnet
```

This command will:

1. Read the configuration from the `imported_transactions.yaml` file located in the folder specified by the --testing-folder flag.
2. Fetch the specified transaction versions from the selected network (Devnet, Testnet or Mainnet).
3. Store the resulting JSON files in the specified output folder (/path/to/your/processor-repo/src/json\_transactions).
4. Generate a Rust file (`generated_transactions.rs`) that converts the generated transaction JSON files into constant variables for use in tests.

Note: Replace /path/to/your/processor-repo with the path to your processor repository or preferred storage location.

**Explanation of Command Flags**

1. `--testing-folder`
   What is the --testing-folder flag?
   The --testing-folder flag specifies the directory containing the imported\_transactions.yaml configuration file. The tool uses this folder to read versions you wish to import.

- Ensure the folder path matches the location of your imported\_transactions.yaml file.
- By default, this guide assumes the configuration is stored in ./imported\_transactions. Adjust the flag value if you place the file elsewhere.

2. `--output-folder`
   Specifies the destination directory where the generated transaction JSON files and Rust constants will be saved.

- Replace /path/to/your/processor-repo with your processor repository src directory or desired storage location.
- Ensure this folder is part of your version control setup if these files need to be shared.

3. `--mode`
   Specifies that the transaction generator should operate in script mode, meaning it will execute Move scripts and generate corresponding transaction data. By default, the mode is set to import, which fetches transactions from the network.
   or Use Import Mode to fetch transactions from the network. By default, the mode is set to import.

Options available:

- import
- script

4. `--network`
   Specifies the network to fetch transactions from. Options available:

- devnet
- testnet
- mainnet

## How to Use the Testing Transactions

### Export the Generated File

Update the `mod.rs` file to include the generated Rust file containing the transaction constants. If `mod.rs` doesn‚Äôt exist, create one in the target folder:

[Reference mod.rs](https://github.com/aptos-labs/aptos-indexer-processor-example/blob/main/test-transactions-example/src/json_transactions/mod.rs).

### Export the `json_transactions` Folder

Since the `generated_transactions.rs` reles on the `json_transactions` Ensure the `json_transactions` folder is properly exported in the library file for your tests have direct access to the transaction data.

[Reference lib.rs](https://github.com/aptos-labs/aptos-indexer-processor-example/blob/main/test-transactions-example/src/lib.rs).

### Integrate into Test Cases

Use the exported transaction constants directly in your test cases to simulate real transactions and validate processing logic.

[Example Crate](https://github.com/aptos-labs/aptos-indexer-processor-example/tree/main/test-transactions-example).

## Next Steps

Once the transaction constants are integrated, you can use them in processor tests to validate functionality. For detailed instructions on writing processor tests, refer to Writing Processor Tests.

# Generating Transactions with Move Scripts

> Create custom test transactions using Move scripts for processor testing with smart contract interaction simulation

import { Aside, Steps } from '@astrojs/starlight/components';

## Overview:

This section outlines how to create test transactions with Move scripts.

## Prerequisites

1. Clone the [aptos-core](https://github.com/aptos-labs/aptos-core) repository:
   - Navigate to the `aptos-core/ecosystem/indexer-grpc/indexer-transaction-generator` directory.

## How to Generate Test Transactions using Move Script

<Steps>
  1. Set up move\_fixtures folder

     Before proceeding, ensure you have the `move_fixtures` folder set up in the appropriate location:

     1. Location:
        The `move_fixtures` folder should be created in the `aptos-core/ecosystem/indexer-grpc/indexer-transaction-generator/imported_transactions` directory. This is the folder where Move scripts and their configurations for test transactions will be stored.

        <Aside type="note"> **Note:** Do not create the `move_fixtures` folder in your processor repository. All Move-related files should reside in the `aptos-core` repository under the specified directory. </Aside>
     2. Steps to set up the folder:
        - if starting fresh, remove all existing files and projects in the `move_fixtures` folder in the aptos-core repo
        - Create your own Move projects/scripts in the move\_fixtures folder (detailed in the next step)

  2. Create Your Move Project and Write your Move Script

     Create your Move project and write a module to output the scenario that you would like to test in your processor. You can refer to an example [here](https://github.com/aptos-labs/aptos-core/tree/main/ecosystem/indexer-grpc/indexer-transaction-generator/imported_transactions/move_fixtures).

  3. Set Up Test Accounts

     1. These accounts will be used to deploy your module.
     2. Set up as many accounts as you need. These accounts will be used to send the scripted transactions. Refer to the guide [here](/build/cli/setup-cli) to create accounts.
     3. Update [`aptos-core/ecosystem/indexer-grpc/indexer-transaction-generator/imported_transactions/testing_accounts.yaml`](https://github.com/aptos-labs/aptos-core/blob/main/ecosystem/indexer-grpc/indexer-transaction-generator/imported_transactions/testing_accounts.yaml) with your accounts.

     <Aside type="note"> **Note:** Do not use real accounts here. Only use **test accounts** created in the CLI specifically for testing. Always select **devnet** when setting up a test account, as it will be required later in the script to configure the account profile and fund it using the faucet. </Aside>

  4. Create a Configuration File

     Each configuration file defines a sequences of transactions for a test scenario.

     1. Create a configuration file in the `move_fixtures` [directory](https://github.com/aptos-labs/aptos-core/blob/main/ecosystem/indexer-grpc/indexer-transaction-generator/imported_transactions/move_fixtures). Name the configuration file according to the test scenario it corresponds to.
     2. This configuration file should contain unique transaction names and details for each transaction. The transactions should be listed in the order they are to be executed.
        The configuration file should be structured like this:

        - output\_name: This field specifies the name of the output file where the results of the transaction will be saved.
        - script\_path: This field holds the path to the Move script file that will be executed as part of the transaction.
        - sender\_address: : This field contains the address of the account that will send the transaction.

        The number of output is totally up to you, but the output name should be unique for each transaction. Add as many transactions as you need to test your processor.

        ```yaml
        transactions:
          - output_name: simple_user_script1
            script_path: simple_user_script
            sender_address: <account_address>
          - output_name: simple_user_script2
            script_path: simple_user_script2
            sender_address: <account_address>
        ```

  5. Generate JSON Files and Rust File

     Once the Move files and configuration are set up, run the same command used to import transactions but with extra flag `mode`:

     - testing-folder is where your Move files are stored.
     - output-folder can be set to any folder where you want to store the generated files.
     - The `--mode=script` flag specifies that the transaction generator should operate in script mode, meaning it will execute Move scripts and generate corresponding transaction data. By default, the mode is set to import, which fetches transactions from the network.

     ```shellscript
         cd ~/aptos-core/ecosystem/indexer-grpc/indexer-transaction-generator
         cargo run -- --testing-folder ./imported_transactions --output-folder ../indexer-test-transactions/src/ --script
     ```

     This command will:

     1. Read the configuration in the `move_fixtures` folder.
     2. Execute the specified Move scripts.
     3. Output the generated JSON files to the designated folder (`~/aptos-core/ecosystem/indexer-grpc/indexer-test-transactions/src/json_transactions`).
     4. Overwrite `generated_transactions.rs` with the new transaction data based on the generated JSON files. This file contains the transaction constants that can be used in tests.

  6. Verification

     Verify that the json\_transactions folder in the target directory contains the generated JSON files with the specified names from the configuration file, and ensure that generated\_transactions.rs has been updated accordingly.
</Steps>

## How to Use Test Transactions

### Export the Generated File

Update the `mod.rs` file to include the generated Rust file containing the transaction constants. If `mod.rs` doesn't exist, create one in the target folder:

[Reference mod.rs](https://github.com/aptos-labs/aptos-indexer-processor-example/blob/main/test-transactions-example/src/json_transactions/mod.rs).

### Export the `json_transactions` Folder

Since the `generated_transactions.rs` relies on the `json_transactions` Ensure the `json_transactions` folder is properly exported in the library file for your tests have direct access to the transaction data.

[Reference lib.rs](https://github.com/aptos-labs/aptos-indexer-processor-example/blob/main/test-transactions-example/src/lib.rs).

### Integrate into Test Cases

If you decided to output the rust file in a different crate, you can update you cargo.toml to import the crate containing the generated file as a dependency. Otherwise, you can simply import the generated file directly in your test file.
[Example](https://github.com/aptos-labs/aptos-indexer-processors-v2/blob/main/integration-tests/Cargo.toml#L19).

## Next Steps

Once the transaction constants are integrated, you can use them in processor tests to validate functionality. For detailed instructions on writing processor tests, refer to Writing Processor Tests.

[Example](https://github.com/aptos-labs/aptos-indexer-processors-v2/blob/main/integration-tests/src/sdk_tests/events_processor_tests.rs)

# Documentation

> Complete documentation for Aptos Indexer SDK architecture, processor development, and custom data pipeline implementation

import { ThemedImage } from '~/components/ThemedImage';

## Architecture of the Indexer SDK

In the Aptos indexing stack, a processor indexes a specific subset of data from the blockchain and writes the data into an external database.

Each processor follows this general flow:

1. Receive a stream of transactions from [Transaction Stream](/build/indexer/txn-stream)
2. Extract the relevant data from the transactions and transform it into a standardized schema
3. Store the transformed data into a database
4. Keep track of the transaction versions that have been processed

The Indexer SDK allows you to write a processor as a directed graph of independent steps.
Each `Step` has an input and output, and the output of each `Step` is connected to the input of the next `Step` by a [Kanal channel](https://github.com/fereidani/kanal).

<center>
  <ThemedImage
    alt="Indexer SDK Custom Processor Architecture"
    sources={{
light: '~/images/indexer-custom-processor-light.svg',
dark: '~/images/indexer-custom-processor-dark.svg',
}}
  />
</center>

## When to use the Indexer SDK

The Indexer SDK is useful when you want to index a custom contract or you realize you need a new kind of data that isn't available in the [Indexer API](/build/indexer/indexer-api).

The general flow to write a custom processor with the Indexer SDK is:

1. Define your database schema
2. Create a new processor
3. Create `Step`s that extract and transform data into your storage schema
4. Customize your processor by adding and connecting steps
5. Run your processor and see the data indexed into your database

## Benefits of the Indexer SDK

The Indexer SDK's architecture simplifies writing custom processors in several ways:

1. You can reuse `Step` implementations across processors which reduces duplication of common data extraction logic.
2. The SDK collects basic performance metrics, like the number of transactions processed, for each `Step`, which enables observability into subcomponents of the processor.
3. Since each `Step` is independent, you can safely customize parts of the processor without breaking the other pieces.
   For example, you can add additional `Step`'s to pre/post-process data or batch data writes. Each `Step` can also be tested in isolation from the rest of the processor.

# Advanced Tutorials

> Advanced processor development tutorials for migration, testing, and complex data processing scenarios with Aptos Indexer SDK



# Connecting Steps

> Connect processing steps in Aptos Indexer SDK to build complete data pipelines with step chaining and flow control

## Pre-requisite

At this point, you'd have already followed the [Creating a Processor](/build/indexer/indexer-sdk/documentation/create-processor) and [Creating a Step](/build/indexer/indexer-sdk/documentation/steps) guides.
Our next goal is to put those two pieces together and connect steps within the processor.

## How to connect steps

Now that you have created a step, you can connect it to other steps.
To do so, we use a builder class called `ProcessorBuilder` to specify a sequence of steps that make up a processor.

1. After you've instantiated your steps, you need to convert them into [`RunnableStep`](https://github.com/aptos-labs/aptos-indexer-processor-sdk/blob/main/aptos-indexer-processors-sdk/sdk/src/traits/runnable_step.rs#L6).
   `RunnableStep` is a trait that wraps around a step.
   It provides the necessary input and output channels that feed into the step and allows the step to be spawned in a task.
   The SDK provides a helper function [`.into_runnable_step`](https://github.com/aptos-labs/aptos-indexer-processor-sdk/blob/main/aptos-indexer-processors-sdk/sdk/src/traits/into_runnable_step.rs#L13) to convert a step into a `RunnableStep`.
2. Setup your first step with [`ProcessorBuilder::new_with_inputless_first_step`](https://github.com/aptos-labs/aptos-indexer-processor-sdk/blob/main/aptos-indexer-processors-sdk/sdk/src/builder/processor_builder.rs#L222).
   In almost all cases, the first step should be a `TransactionStreamStep`. {/* <!-- Add link --> */}
3. Connect the previous step to the next step using [`.connect_to`](https://github.com/aptos-labs/aptos-indexer-processor-sdk/blob/main/aptos-indexer-processors-sdk/sdk/src/builder/processor_builder.rs#L303).
   `connect_to` uses trait bounds to ensure at compile time that the output type of the previous step matches the input type of the next step.
   When calling `.connect_to`, a channel gets created with size `channel_size` and connects the previous and next steps.
   It also spawns a task that continuously loops the previous step -- reading data from its input channel, processing the data, and sending the output to its output channel.
4. Repeat step 3 for each step in your processor.
5. To close off the `ProcessorBuilder`, use [`.end_and_return_output_receiver`](https://github.com/aptos-labs/aptos-indexer-processor-sdk/blob/main/aptos-indexer-processors-sdk/sdk/src/builder/processor_builder.rs#L400).
   This returns an [`InstrumentedAsyncReceiver`](https://github.com/aptos-labs/aptos-indexer-processor-sdk/blob/main/aptos-indexer-processors-sdk/instrumented-channel/src/lib.rs#L88) which you can use to process the output of the last step in the graph.

Here's a simple example of connecting two steps:

```rust
let (processor_builder, buffer_receiver) = ProcessorBuilder::new_with_inputless_first_step(
      transaction_stream_step.into_runnable_step(),
  )
  .connect_to(extractor_step.into_runnable_step(), 10)
  .end_and_return_output_receiver(10);
```

Here's a [full example](https://github.com/aptos-labs/aptos-indexer-processor-example/blob/main/aptos-indexer-processor-example/src/processors/events/events_processor.rs#L75) from `aptos-indexer-processor-example`.

{/* <!-- Add link to common SDK steps --> */}

## Visualizing the processor

As you connect steps, `ProcessorBuilder` in the background is constructing a graphical representation of the steps in your processor using [`petgraph`](https://docs.rs/petgraph/latest/petgraph/).
You can see the visual representation of the graph by calling

```rust
let dot = processor_builder.graph.dot();
println!("{}", dot);
```

This will output a graph in the [DOT language](https://graphviz.gitlab.io/_pages/doc/info/lang.html) that you can visualize using tools like [Graphviz](https://graphviz.org/).

# Creating a Processor

> Step-by-step guide to create custom processors using Aptos Indexer SDK with templates and implementation patterns

This guide will walk you through setting up the basic template for a new processor.

## Pre-requisites

You've already set up your environment and have the Indexer SDK `aptos-indexer-sdk` installed.
If you haven't, follow the [Indexer SDK installation guide](/build/indexer/indexer-sdk/documentation/setup).

## Overview

Creating and running a processor will require several pieces:

1. `IndexerProcessorConfig`
2. `ProcessorConfig`
3. The processor itself. This is where you'll define a processor's config, the processor setup, and the steps that will be run to index transactions.
4. `main.rs` - The main file that will run the processor.

The next section goes through each of these pieces more explicitly and provides code examples.

## How to define `IndexerProcessorConfig`

The `IndexerProcessorConfig` defines the base configuration for all processors that you'll be running.
It should include configuration for things that are shared across multiple processors, like the database configuration and [Transaction Stream](/build/indexer/txn-stream) configuration.

`ServerArgs` parses a `config.yaml` file and bootstraps a server with all the common pieces to run a processor.

To setup the configuration for your processor and make it work with `ServerArgs`, you'll need to define a `IndexerProcessorConfig` that implements the `RunnableConfig` trait.
It also triggers a run method, which can be invoked in `main.rs`.

For basic cases, you can copy the [`IndexerProcessorConfig` from the `aptos-indexer-processor-example`](https://github.com/aptos-labs/aptos-indexer-processor-example/blob/main/aptos-indexer-processor-example/src/config/indexer_processor_config.rs) repository and modify it to fit your needs.

## How to define `ProcessorConfig`

`ProcessorConfig` is an enum that contains all the individual processor configs.
It's used by `IndexerProcessorConfig.run()` to map the processor name to the right `ProcessorConfig`.

You can see a basic example of a `ProcessorConfig` [here](https://github.com/aptos-labs/aptos-indexer-processor-example/blob/main/aptos-indexer-processor-example/src/config/processor_config.rs).
An example of a more complex setup that includes multiple processors and configurations is [`aptos-indexer-processors`](https://github.com/aptos-labs/aptos-indexer-processors-v2/blob/main/processor/src/config/processor_config.rs#L84).

## How to create a processor

Now that you've got the configuration pieces set up, the next step is to create the processor.
The processor is represented by a struct and is usually named `{PROCESSOR_NAME}Processor`, like `EventsProcessor` or `TokenV2Processor`, depending on the type of data it's indexing.

```rust
pub struct EventsProcessor {
    pub config: IndexerProcessorConfig,
    pub db_pool: ArcDbPool,
}
```

The processor's constructor should be defined like so:

```rust
pub async fn new(config: IndexerProcessorConfig) -> Result<Self> {
    // Processor setup code here, if needed
}
```

It takes in the `IndexerProcessorConfig` that you've defined and performs any setup required to instantiate the processor.
Next, your processor needs to implement the [`ProcessorTrait`](https://github.com/aptos-labs/aptos-indexer-processor-sdk/blob/a56b641a6aaca60092fcc9bbd98252f3cd703299/aptos-indexer-processors-sdk/sdk/src/traits/processor_trait.rs#L4).

```rust
#[async_trait::async_trait]
impl ProcessorTrait for EventsProcessor {
    fn name(&self) -> &'static str {
        self.config.processor_config.name()
    }

    async fn run_processor(&self) -> Result<()> {
        // Processor logic here
    }
}
```

The `run_processor` method is the most important method in the processor.

If you're using a migration-based database, like PostgreSQL, running the migrations can go inside of `run_processor`.
This is also where we implement logic to determine the appropriate starting version for the processor, verify the chain ID using [Transaction Stream](/build/indexer/txn-stream), and validate the processor's configuration.

`run_processor` also contains the instantiation of the processor's `Step`s and the specification of how these `Step`s are connected together by channels.

```rust
// Instantiate processor steps
let transaction_stream = TransactionStreamStep::new(TransactionStreamConfig {
    starting_version: Some(starting_version),
    ..self.config.transaction_stream_config.clone()
})
.await?;
// ... Instantiate the rest of your processor's steps ...

// Connect processor steps
let (_, buffer_receiver) = ProcessorBuilder::new_with_inputless_first_step(
    transaction_stream.into_runnable_step(),
)
.connect_to(extractor_step.into_runnable_step(), channel_size)
.connect_to(storer_step.into_runnable_step(), channel_size)
.connect_to(version_tracker_step.into_runnable_step(), channel_size)
.end_and_return_output_receiver(channel_size);

// Read the results from the output of the last step
loop {
    match buffer_receiver.recv().await {
        // Do something with th output
    }
}
```

You can see a full example of a processor that indexes raw Aptos events in [`aptos-indexer-processor-example`](https://github.com/aptos-labs/aptos-indexer-processor-example/blob/main/aptos-indexer-processor-example/src/processors/events/events_processor.rs).
As a reference, you can also see all of the processors that make up the [Indexer API](/build/indexer/indexer-api) in [`aptos-indexer-processors`](https://github.com/aptos-labs/aptos-indexer-processors-v2/tree/main/processor/src/processors).

## How to define `main.rs`

You may copy the [`main.rs`](https://github.com/aptos-labs/aptos-indexer-processor-example/blob/main/aptos-indexer-processor-example/src/main.rs) file from the `aptos-indexer-processor-example`.

These lines of code uses the `ServerArgs` and the `IndexerProcessorConfig` that we've defined earlier:

```rust
let args = ServerArgs::parse();
args.run::<IndexerProcessorConfig>(tokio::runtime::Handle::current())
    .await
```

# Defining a Data Schema

> Design optimized database schemas for custom processors with performance considerations and query optimization strategies

The first step with indexing is choosing a database and defining a schema for the data that you want to store.

## Schema Considerations

When designing an indexer data schema, consider the following:

- Customizability: A schema serves as an interface for your dApp to access data tailored to your specific contract or application.
  Ensure your schema is customized to meet your dApp's unique requirements.
- Query Optimization: A well-designed schema can enable more efficient data retrieval, supporting advanced operations such as aggregations, complex filtering, and table joins.
- Enhanced Performance: Schema design can significantly improve your dApp's performance.
  By using the indexer, a single indexer query can often replace multiple queries to the fullnode.

## Aptos Core Processors

All data exposed by the [Indexer API](/build/indexer/indexer-api) is initially indexed using custom processors.
Each core processor indexes a specific type of data.
You can explore the [full list of processors](https://github.com/aptos-labs/aptos-indexer-processors-v2/blob/main/processor/src/db/schema.rs).

The Aptos core processors and the [Quickstart Guide](/build/indexer/indexer-sdk/quickstart) use [PostgreSQL](https://www.postgresql.org/) as the database and [Diesel](https://diesel.rs/) as the ORM.
If you'd also like to use PostgreSQL and Diesel, you can follow the instructions in [PostgreSQL Installation](/build/indexer/indexer-sdk/quickstart#postgresql-installation).

You're free to use whatever database and ORM you prefer.
Popular alternatives include [SeaORM](https://www.sea-ql.org/SeaORM/) and [SQLx](https://github.com/launchbadge/sqlx).
If you need guidance, refer to the tutorials linked above for more information.

# Running Your Processor

> Configure and run custom processors with config.yaml setup, database connections, and production deployment guidelines

## Pre-requisites

Please first read [Creating a Processor](/build/indexer/indexer-sdk/documentation/create-processor), [Creating a Step](/build/indexer/indexer-sdk/documentation/steps), and [Connecting Steps](/build/indexer/indexer-sdk/documentation/connect-steps), which will set up your processor and connect your processor steps.

## How to setup your `config.yaml`

To run a processor, you'll need to create a `config.yaml` file.
The format of the `config.yaml` file should follow the format you've defined in your `IndexerProcessorConfig`.
For example, if you're using the `IndexerProcessorConfig` from [`aptos-indexer-processor-example`](https://github.com/aptos-labs/aptos-indexer-processor-example/blob/main/aptos-indexer-processor-example/src/config/indexer_processor_config.rs), a basic `config.yaml` would look like this:

```yaml
health_check_port: 8085
server_config:
  processor_config:
    type: "events_processor"
  transaction_stream_config:
    indexer_grpc_data_service_address: "https://grpc.mainnet.aptoslabs.com:443"
    starting_version: 0
    auth_token: "{AUTH_TOKEN}"
    request_name_header: "events-processor"
  db_config:
    postgres_connection_string: postgresql://postgres:@localhost:5432/example
```

The `processor_config` field should match how `ProcessorConfig` is defined in the `IndexerProcessorConfig`, and the same applies for `db_config` and `DbConfig`.

`TransactionStreamConfig` is a config provided by the `transaction-stream` crate.
It requires `indexer_grpc_data_service_address`, `auth_token`, and `request_name_header` to be set.
To get the `indexer_grpc_data_service_address` and `auth_token`, you can follow the guide [here](/build/indexer/txn-stream/aptos-hosted-txn-stream).

`TransactionStreamConfig` also supports more optional fields to modify the connection to [Transaction Stream](/build/indexer/txn-stream), which you can learn more about [here](https://github.com/aptos-labs/aptos-indexer-processor-sdk/tree/main/aptos-indexer-processors-sdk/transaction-stream).

## Running your processor

Once your `config.yaml` is setup, you can run your processor with:

```shellscript
cd /path/to/your/processor/crate
cargo run --release -- -c config.yaml
```

In your terminal, you should start to see logs like this:

```shellscript
{"timestamp":"2025-01-13T21:23:21.785452Z","level":"INFO","message":"[Transaction Stream] Successfully connected to GRPC stream","stream_address":"https://grpc.mainnet.aptoslabs.com/","connection_id":"ec67ecc4-e041-4f17-a2e2-441e7ff21487","start_version":2186504987,"filename":"/Users/reneetso/.cargo/git/checkouts/aptos-indexer-processor-sdk-2f3940a333c8389d/e6867c5/aptos-indexer-processors-sdk/transaction-stream/src/transaction_stream.rs","line_number":349,"threadName":"tokio-runtime-worker","threadId":"ThreadId(4)"}
{"timestamp":"2025-01-13T21:23:21.785664Z","level":"INFO","message":"Spawning polling task","step_name":"TransactionStreamStep","filename":"/Users/reneetso/.cargo/git/checkouts/aptos-indexer-processor-sdk-2f3940a333c8389d/e6867c5/aptos-indexer-processors-sdk/sdk/src/traits/pollable_async_step.rs","line_number":112,"threadName":"tokio-runtime-worker","threadId":"ThreadId(23)"}
{"timestamp":"2025-01-13T21:23:21.785693Z","level":"INFO","message":"Spawning processing task","step_name":"TransactionStreamStep","filename":"/Users/reneetso/.cargo/git/checkouts/aptos-indexer-processor-sdk-2f3940a333c8389d/e6867c5/aptos-indexer-processors-sdk/sdk/src/traits/pollable_async_step.rs","line_number":204,"threadName":"tokio-runtime-worker","threadId":"ThreadId(23)"}
{"timestamp":"2025-01-13T21:23:21.785710Z","level":"INFO","message":"Spawning processing task","step_name":"FungibleAssetExtractor","filename":"/Users/reneetso/.cargo/git/checkouts/aptos-indexer-processor-sdk-2f3940a333c8389d/e6867c5/aptos-indexer-processors-sdk/sdk/src/traits/async_step.rs","line_number":87,"threadName":"tokio-runtime-worker","threadId":"ThreadId(4)"}
{"timestamp":"2025-01-13T21:23:21.785912Z","level":"INFO","message":"Spawning processing task","step_name":"FungibleAssetStorer","filename":"/Users/reneetso/.cargo/git/checkouts/aptos-indexer-processor-sdk-2f3940a333c8389d/e6867c5/aptos-indexer-processors-sdk/sdk/src/traits/async_step.rs","line_number":87,"threadName":"tokio-runtime-worker","threadId":"ThreadId(4)"}
{"timestamp":"2025-01-13T21:23:21.785978Z","level":"INFO","message":"Spawning polling task","step_name":"VersionTrackerStep: ()","filename":"/Users/reneetso/.cargo/git/checkouts/aptos-indexer-processor-sdk-2f3940a333c8389d/e6867c5/aptos-indexer-processors-sdk/sdk/src/traits/pollable_async_step.rs","line_number":112,"threadName":"tokio-runtime-worker","threadId":"ThreadId(14)"}
{"timestamp":"2025-01-13T21:23:21.786018Z","level":"INFO","message":"Spawning processing task","step_name":"VersionTrackerStep: ()","filename":"/Users/reneetso/.cargo/git/checkouts/aptos-indexer-processor-sdk-2f3940a333c8389d/e6867c5/aptos-indexer-processors-sdk/sdk/src/traits/pollable_async_step.rs","line_number":204,"threadName":"tokio-runtime-worker","threadId":"ThreadId(14)"}
```

# Initial Setup

> Set up Aptos Indexer SDK dependencies and configuration for custom processor development with Cargo.toml configuration

If you're creating a custom processor from scratch, we recommend following the [Quickstart Guide](/build/indexer/indexer-sdk/quickstart).
The quickstart guide provides a template processor and includes all of this setup.

If you're migrating an existing processor to the Indexer SDK, follow the steps below.

Add `aptos-indexer-processor-sdk` to your `Cargo.toml`.

```toml
[dependencies]
aptos-indexer-processor-sdk = { git = "https://github.com/aptos-labs/aptos-indexer-processor-sdk.git", rev = "aptos-indexer-processor-sdk-v1.0.0" }
```

`aptos-indexer-processor-sdk` includes the following features:

1. `postgres_full` - Interface layer to integrate Postgres with your processor.
2. `testing_framework` - An e2e testing framework for testing processors. If you want to write tests for your processor, add this feature to the crate.

{/* <!-- Add list of SDK releases once we have that --> */}

# Creating a Step

> Build processing steps as building blocks for Aptos Indexer SDK processors with extraction, transformation, and storage logic

import { Aside } from '@astrojs/starlight/components';

## What is a step?

A step is a unit of processing logic in the SDK and can be used to define logic for the extraction, transformation, or storing of data.
Steps are the building blocks of a processor.
The Aptos core processors represent (1) getting a stream of transactions from [Transaction Stream](/build/indexer/txn-stream), (2) extracting the data, (3) writing to a database, and (4) tracking the progress, each as separate steps.

There are two types of steps in the SDK:

1. **AsyncStep**: Processes a batch of input items and returns a batch of output items.
2. **PollableAsyncStep**: Does the same as `AsyncStep`, but it also periodically polls its internal state and returns a batch of output items if available.

## How to create a Step

To create a step with the SDK, follow these instructions:

1. Implement the `Processable` trait. This trait defines several important details about the step: the input and output types, the processing logic, and the run type (either `AsyncStepRunType` or `PollableAsyncStepRunType`).

   ```rust
   #[async_trait]
   impl Processable for MyExtractorStep {
       // The Input is a vec of Transaction 
       type Input = Vec<Transaction>;
       // The Output is a vec of MyData
       type Output = Vec<MyData>;

       // Depending on the type of step this is, the RunType is either
       // - AsyncRunType
       // - PollableAsyncRunType
       type RunType = AsyncRunType;

   	// Processes a batch of input items and returns a batch of output items.
       async fn process(
           &mut self,
           input: TransactionContext<Vec<Transaction>>,
       ) -> Result<Option<TransactionContext<Vec<MyData>>>, ProcessorError> {
           let transactions = input.data;
           let data = transactions.iter().map(|transaction| {
               // Define the processing logic to extract MyData from a Transaction
           }).collect();
           
           Ok(Some(TransactionContext {
               data,
               metadata: input.metadata,
           }))
       }
   }
   ```

   <Aside type="note">
     In most cases, you're going to be processing a list of inputs to a list of outputs.
     To speed up the processing, we recommend using [`rayon`](https://docs.rs/rayon/latest/rayon/) to process sequential computations in parallel.
     You can see an example of how we use [`rayon.par_iter`](https://docs.rs/rayon/latest/rayon/#basic-usage-and-the-rayon-prelude) to parallelize the processing [here](https://github.com/aptos-labs/aptos-indexer-processor-example/blob/main/aptos-indexer-processor-example/src/processors/events/events_extractor.rs#L30).
   </Aside>

   In the example code above, you'll notice that the input and output types are wrapped within a `TransactionContext`.
   `TransactionContext` contains relevant metadata about the batch of data being processed, such as the transaction versions and timestamp, and are used for metrics and logging.

2. Implement the `NamedStep` trait. This is used for logging.

   ```rust
   impl NamedStep for MyExtractorStep {
       fn name(&self) -> String {
           "MyExtractorStep".to_string()
       }
   }
   ```

3. Implement either `AsyncStep` trait or `PollableAsyncStep` trait, which defines how the step will be run in the processor.
   1. If you're using `AsyncStep`, add this to your code:

      ```rust
      impl AsyncStep for MyExtractorStep {}
      ```

   2. If you're creating a `PollableAsyncStep`, you will need to define the poll interval and what the step should do every time it polls.

      ```rust
      #[async_trait]
      impl<T: Send + 'static> PollableAsyncStep for MyPollStep<T>
      where
          Self: Sized + Send + Sync + 'static,
          T: Send + 'static,
      {
          fn poll_interval(&self) -> std::time::Duration {
              // Define duration
          }

          async fn poll(&mut self) -> Result<Option<Vec<TransactionContext<T>>>, ProcessorError> {
              // Define code here on what this step should do every time it polls
              // Optionally return a batch of output items
          }
      }
      ```

## Parsing Transactions

When building the extractor step, you'll need to define how you want to parse your data from transactions.
Read more about how to parse your data from transactions [here](/build/indexer/indexer-sdk/documentation/steps/parsing-txns).

## Common SDK steps

The SDK comes with a set of [common steps](https://github.com/aptos-labs/aptos-indexer-processor-sdk/tree/main/aptos-indexer-processors-sdk/sdk/src/common_steps) that you can use to build your processor.

1. `TransactionStreamStep` provides a stream of Aptos transactions to the processor. Read more about it [here](/build/indexer/indexer-sdk/documentation/steps/transaction-stream).
2. `TimedBufferStep` buffers a batch of items and periodically polls to release the items to the next step
3. `VersionTrackerStep` tracks the progress of the processor and checkpoints the processor's progress. Read more about it [here](/build/indexer/indexer-sdk/documentation/version-tracking).
4. `OrderByVersionStep` orders transaction contextx by their starting versions. It buffers ordered these contexts and releases them at every poll interval.
5. `WriteRateLimitStep` limits the number of bytes written to the database per second.

# Parsing Transactions

> Parse and extract data from Aptos blockchain transactions using processor steps with event filtering and data transformation

import { Aside } from '@astrojs/starlight/components';

{/* <IndexerBetaNotice /> */}

{/* <!--
  Things to add:
  - We should have tabs for each language that mentions helper functions for extracting the thing you want. For example, if the user is trying to extract the entry function arguments, there should be a function like `get_entry_function_arguments` and we show how to use it in each language and where it comes from in the SDK.
  --> */}

Fundamentally an indexer processor is just something that consumes a stream of a transactions and writes processed data to storage. Let's dive into what a transaction is and what kind of information you can extract from one.

## What is a transaction?

A transaction is a unit of execution on the Aptos blockchain. If the execution of the program in a transaction (e.g. starting with an entry function in a Move module) is successful, the resulting change in state will be applied to the ledger. Learn more about the transaction lifecycle at [this page](/network/blockchain/blockchain-deep-dive#life-of-a-transaction).

There are four types of transactions on Aptos:

- Genesis
- Block metadata transactions
- State checkpoint transactions
- User transactions

The first 3 of these are internal to the system and are not relevant to most processors; we do not cover them in this guide.

Generally speaking, most user transactions originate from a user calling an entry function in a Move module deployed on chain, for example `0x1::coin::transfer`. In all other cases they originate from [Move scripts](/build/smart-contracts/scripts). You can learn more about the different types of transactions [here](/network/blockchain/txns-states#types-of-transaction-payloads).

A user transaction that a processor handles contains a variety of information. At a high level it contains:

- The payload that was submitted.
- The changes to the ledger resulting from the execution of the function / script.

We'll dive into this in the following sections.

## What is important in a transaction?

### Payload

The payload is what the user submits to the blockchain when they wish to execute a Move function. Some of the key information in the payload is:

- The sender address
- The address + module name + function name of the function being executed.
- The arguments to the function.

There is other potentially interesting information in the payload that you can learn about at [this page](/network/blockchain/txns-states#contents-of-a-transaction).

### Events

Events are emitted during the execution of a transaction. Each Move module can define its own events and choose when to emit the events during execution of a function.

For example, in Move you might have the following:

```move filename="member_invited_event.move"
struct MemberInvitedEvent has store, drop {
    member: address,
}

public entry fun invite_member(member: address) {
    event::emit_event(
        &mut member_invited_events,
        MemberInvitedEvent { member },
    );
}
```

If `invite_member` is called, you will find the `MemberInvitedEvent` in the transaction.

<Aside type="note">
  Why emit events?

  This is a good question! In some cases, you might find it unnecessary to emit events since you can just parse the writesets. However, sometimes it is quite difficult to get all the data you need from the different "locations" in the transaction, or in some cases it might not even be possible, e.g. if you want to index data that isn't included in the writeset. In these cases, events are a convenient way to bundle together everything you want to index.
</Aside>

### Writesets

When a transaction executes, it doesn't directly affect on-chain state right then. Instead, it outputs a set of changes to be made to the ledger, called a writeset. The writeset is applied to the ledger later on after all validators have agreed on the result of the execution.

Writesets show the end state of the on-chain data after the transaction has occurred. They are the source of truth of what data is stored on-chain. There are several types of write set changes:

- Write module / delete module
- Write resource / delete resource
- Write table item / delete table item

{/* <!-- Add more information about writesets, ideally once have the helper functions. --> */}

# Transaction Stream Step

> Core transaction streaming step for processors with gRPC connections, batch fetching, and resilient connection management

The `TransactionStreamStep` is a foundational component in the transaction processing pipeline. It establishes a gRPC connection with the `TransactionStream` service, fetches transactions in batches, and outputs them for further processing. This step also manages connection retries and reconnections in case of transient failures. Typically, this is the initial step in a processor, responsible for streaming transactions for downstream steps.

## Key Responsibilities

1. **Fetch Transactions**: Retrieves transaction batches from a gRPC service.
2. **Manage Connections**: Handles gRPC reconnections to ensure a resilient stream.
3. **Provide Metadata**: Attaches contextual information like versions and timestamps to the transactions.

## Struct Definition

The `TransactionStreamStep` struct is defined as follows:

```rust
pub struct TransactionStreamStep
where
    Self: Sized + Send + 'static,
{
    transaction_stream_config: TransactionStreamConfig,
    pub transaction_stream: Mutex<TransactionStreamInternal>,
}
```

## How It Works

- The `TransactionStreamStep` connects to the gRPC `TransactionStream` service.
- It continuously polls for new transactions using the `poll` method.
- Each batch is wrapped in a `TransactionContext`, which includes metadata such as:
  - Start and end versions.
  - Timestamps of transactions.
  - Batch size in bytes.
- If the connection is interrupted, it attempts to reconnect seamlessly.

# Version Tracking

> Implement version tracking in processors using VersionTrackerStep for reliable data processing state management

## Version Tracking

The `VersionTrackerStep` is a [common step in the SDK](https://github.com/aptos-labs/aptos-indexer-processors-v2/blob/main/processor/src/processors/events/events_processor.rs#L125) method as other steps.  Upon a successfully processed batch, the `VersionTrackerStep` will [call](https://github.com/aptos-labs/aptos-indexer-processor-sdk/blob/main/aptos-indexer-processors-sdk/sdk/src/common_steps/version_tracker_step.rs#L57) the trait implementation of `save_processor_status()`.

### ProcessorStatusSaver

The `ProcessorStatusSaver` trait requires the implementation of the method `save_processor_status` with the following signature:

```rust
async fn save_processor_status(
        &self,
        last_success_batch: &TransactionContext<()>,
    ) -> Result<(), ProcessorError>;
```

This method is where checkpointing should be written.
If you're writing to Postgres, you can use the SDK's Postgres implementation [here](https://github.com/aptos-labs/aptos-indexer-processor-sdk/blob/main/aptos-indexer-processors-sdk/sdk/src/postgres/utils/checkpoint.rs#L66).
It is possible to checkpoint progress in different ways by using enums.
The SDK's Postgres implementation inserts using a simple [`processor_status` model](https://github.com/aptos-labs/aptos-indexer-processor-sdk/blob/main/aptos-indexer-processors-sdk/sdk/src/postgres/models/processor_status.rs).

## Restart Behavior

Now that the processor successfully writes to the chosen store for version tracking, upon restarting it needs to retrieve the latest successful version from that store.
[Here is an example](https://github.com/aptos-labs/aptos-indexer-processor-sdk/blob/main/aptos-indexer-processors-sdk/sdk/src/postgres/utils/checkpoint.rs#L118) of a `get_starting_version()` method that returns the latest processed version saved.
This `starting_version: u64` can then be used as below.
If there is no checkpoint, the processor will start from the beginning of the chain.

```rust
 let transaction_stream = TransactionStreamStep::new(TransactionStreamConfig {
            starting_version: Some(starting_version),
            ..self.config.transaction_stream_config.clone()
        })
        .await?;
```

## Backfilling

The SDK does not provide an implementation of `ProcessorStatusSaver` that will save backfill progress.
To enable saving backfill progress, `IndexerProcessorConfig`, `ProcessorStatusSaver` and `get_starting_version()` need some updates.
Without these changes, it is difficult to run a live processor at the latest transaction version as well as a backfill processor.

### Updates to Config

[Add an additional field](https://github.com/aptos-labs/aptos-indexer-processors-v2/blob/main/processor/src/config/processor_mode.rs#L29) on your `IndexerProcessorConfig` for a `BackfillConfig`.
In this implementation, the `BackfillConfig` is part of an enum `ProcessorMode` that is used to determine the mode the processor is running in.
In backfill mode, the processor starts from a different version and the progress is saved in a separate table.

### Updates to `config.yaml`

Add the `backfill_config` section to `server_config` in your yaml file to set `backfill_alias`. [Example](https://github.com/aptos-labs/aptos-indexer-processors-v2/blob/main/processor/example-backfill-config.yaml)

### Backfill Processor Status Table

Use a separate table for backfill processor status to avoid write conflicts. This table (`backfill_processor_status_table`) uses `backfill_alias` as the primary key instead of `processor_name` to prevent conflicts with the main `processor_status` table when running head and backfill processors concurrently.
Create multiple backfill processors with differing `backfill_alias` and transaction version ranges for a faster backfill.
Expand on this [implementation](https://github.com/aptos-labs/aptos-indexer-processors-v2/blob/main/processor/src/db/backfill_processor_status.rs).
This model introduces a new state, `BackfillStatus`, which is either `InProgress` or `Complete` which will determine the backfilling restart behavior.

### Updates to ProcessorStatusSaver

Expand your `ProcessorStatusSaver` implementation to include a `Backfill` variant that extracts the `backfill_alias` from the `BackfillConfig`, and the `backfill_start_version` `backfill_end_version` from `IndexerProcessorConfig.transaction_stream_config` [like this](https://github.com/aptos-labs/aptos-indexer-processors-v2/blob/main/processor/src/processors/processor_status_saver.rs#L96).
Update the corresponding write query to write to the new `backfill_processor_status` table.

### Updates to get\_starting\_version

Add a [statement](https://github.com/aptos-labs/aptos-indexer-processors-v2/blob/main/processor/src/processors/processor_status_saver.rs#L190) in your `get_starting_version` method to query the `backfill_processor_status_table` when the `BackfillConfig` field is present in `IndexerProcessorConfig` .

# Quickstart Guide on Aptos Indexer SDK

> Get started with Aptos Indexer SDK to build custom Rust processors for indexing blockchain events into PostgreSQL databases

## What to expect from this guide

This guide will walk you through setting up and running a Rust processor to index events on the Aptos blockchain into PostgreSQL.
We provide a template processor that you can customize to index events from your custom contracts.
By the end of the guide, you should have a basic understanding of how a processor works and be able to customize the processor for your indexing needs.

## Get started

To get started, clone
the [aptos-indexer-processor-sdk](https://github.com/aptos-labs/aptos-indexer-processor-sdk) repo.

```text
# HTTPS
https://github.com/aptos-labs/aptos-indexer-processor-sdk.git

# SSH
git@github.com:aptos-labs/aptos-indexer-processor-sdk.git
```

Processors consume transactions from the Transaction Stream Service. In order to use the Labs-Hosted Transaction Stream
Service you need an authorization token.
Follow [this guide](/build/indexer/txn-stream/aptos-hosted-txn-stream#authorization-via-api-key)
to guide to get a token from the Developer Portal. Create an API Key for `Testnet`, as this tutorial is for `Testnet`.
Once you‚Äôre done, you should have a token that looks like this:

```text
aptoslabs_yj4bocpaKy_Q6RBP4cdBmjA8T51hto1GcVX5ZS9S65dx
```

You also need the following tools:

- Rust 1.79: [Installation Guide](https://www.rust-lang.org/tools/install)
- Cargo: [Installation Guide](https://doc.rust-lang.org/cargo/getting-started/installation.html#install-rust-and-cargo)

We use [PostgreSQL](https://www.postgresql.org/) as our database and [Diesel](https://diesel.rs/guides/getting-started) as our ORM in this tutorial. You‚Äôre free to use whatever you want, but this tutorial is geared
towards PostgreSQL for the sake of simplicity. We use the following database configuration and tools:

### PostgreSQL Installation (for macOS)

1. `brew install libpq` ([this is a postgres C API library](https://formulae.brew.sh/formula/libpq)). Also perform all export commands post-installation

```shellscript
export PATH="/opt/homebrew/opt/libpq/bin:$PATH"
export LDFLAGS="-L/opt/homebrew/opt/libpq/lib"
export CPPFLAGS="-I/opt/homebrew/opt/libpq/include"
```

2. `brew install postgres`
3. `pg_ctl -D /opt/homebrew/var/postgres start` or `brew services start postgresql`
4. `/opt/homebrew/bin/createuser -s postgres`
5. Ensure you're able to do: `psql postgres`
6. `cargo install diesel_cli --no-default-features --features postgres`
7. Make sure that you're in the DB folder (run `cd src/db/postgres` from base directory), run `diesel migration run --database-url postgresql://localhost/postgres`
   a. If for some reason this database is already being used, try a different db. e.g.
   `DATABASE_URL=postgres://postgres@localhost:5432/indexer_v2 diesel database reset`

- We will use a database hosted on `localhost` on the port `5432`, which should be the default.
- When you create your username, keep track of it and the password you use for it.
- To easily view your database data, consider using a GUI like [DBeaver](https://dbeaver.io/)
  _recommended_, [pgAdmin](https://www.pgadmin.org/), or [Postico](https://eggerapps.at/postico2/).

## Set up your environment

Make sure to start the `postgresql` service:

The command for Linux/WSL might be something like:

```shellscript
sudo service postgresql start
```

For mac, if you‚Äôre using brew, start it up with:

```shellscript
brew services start postgresql
```

## **Configure your processor**

Now let‚Äôs set up the configuration details for the actual indexer processor we‚Äôre going to use.

### **Set up your config.yaml file**

In the example folder, there is a sample config.yaml file that should look something like this:

```yaml
# This is a template yaml for the processor
health_check_port: 8085
server_config:
  transaction_stream_config:
    indexer_grpc_data_service_address: "https://grpc.mainnet.aptoslabs.com:443"
    auth_token: "AUTH_TOKEN"
    request_name_header: "events-processor"
    starting_version: 0
  postgres_config:
    connection_string: postgresql://postgres:@localhost:5432/example
```

Open the `config.yaml` file and update these fields:

- `auth_token` - the auth token you got from the Developer Portal
- `postgres_connection_string` - connection string to your PostgreSQL database

### More customization with config.yaml

You can customize additional configuration with the `config.yaml` file.

To start at a specific ledger version, you can specify the version in the `config.yaml` file with:

```yaml
starting_version: <Starting Version>
```

To stop processing at a specific ledger version, you can specify the ending version with:

```yaml
request_ending_version: <Ending Version>
```

If you want to use a different network, change the `indexer_grpc_data_service_address` field to the corresponding
desired value:

```yaml
# Devnet
indexer_grpc_data_service_address: grpc.devnet.aptoslabs.com:443

# Testnet
indexer_grpc_data_service_address: grpc.testnet.aptoslabs.com:443

# Mainnet
indexer_grpc_data_service_address: grpc.mainnet.aptoslabs.com:443
```

In this tutorial, we are using `testnet` so update the `indexer_grpc_data_service_address` to `grpc.testnet.aptoslabs.com:443`.

## Create the events processor

At a high level, each processor is responsible for receiving a stream of transactions, parsing and transforming the
relevant data, and storing the data into a database.

### Define the database schema

In `src/db/migrations`, you will see the events migration, which defines the database schema that will be used to store the events.

```sql up.sql
CREATE TABLE events (
    sequence_number BIGINT NOT NULL,
    creation_number BIGINT NOT NULL,
    account_address VARCHAR(66) NOT NULL,
    transaction_version BIGINT NOT NULL,
    transaction_block_height BIGINT NOT NULL,
    type TEXT NOT NULL,
    data JSONB NOT NULL,
    inserted_at TIMESTAMP NOT NULL DEFAULT NOW(),
    event_index BIGINT NOT NULL,
    indexed_type VARCHAR(300) NOT NULL,
    PRIMARY KEY (transaction_version, event_index)
);
```

When you apply migrations, diesel will re-generate the `schema.rs` file, which looks like this:

```rust schema.rs
diesel::table! {
    events (transaction_version, event_index) {
        sequence_number -> Int8,
        creation_number -> Int8,
        #[max_length = 66]
        account_address -> Varchar,
        transaction_version -> Int8,
        transaction_block_height -> Int8,
        #[sql_name = "type"]
        type_ -> Text,
        data -> Jsonb,
        inserted_at -> Timestamp,
        event_index -> Int8,
        #[max_length = 300]
        indexed_type -> Varchar,
    }
}
```

In `schema.rs`, you'll see two other important tables:

- `ledger_infos` which tracks the chain id of the ledger being indexed
- `processor_status` which tracks the `last_success_version` of the processor

### Define the processing logic

The file `src/main.rs` contains the code which defines the events processor. The key components are:

1. `insert_events_query` defines the diesel query to insert events into the database.
   ```rust
   fn insert_events_query(
       items_to_insert: Vec<EventModel>,
   ) -> impl QueryFragment<Pg> + diesel::query_builder::QueryId + Send {
       use crate::schema::events::dsl::*;
       diesel::insert_into(crate::schema::events::table)
           .values(items_to_insert)
           .on_conflict((transaction_version, event_index))
           .do_nothing()
   }
   ```
2. `process` is a helper function that wraps around a regular processor.
   In the background, this powerful function handles connecting to Transaction Stream, processing transactions given a transform function that you define, applying database migrations, and tracking the processor's status.

   ```rust
   process(
           "events_processor".to_string(), // name of the processor that will be used to track the processor status
           MIGRATIONS, // migrations to be applied to the database
           async |transactions, conn_pool| {
             // transform from transaction to events and insert the events into the database
           },
   ).await?;
   ```

## Run the processor

With the `config.yaml` you created earlier, you‚Äôre ready to run the events processor:

```shellscript
cd examples/postgres-basic-events-example
cargo run --release -- -c config.yaml
```

You should see the processor start to index Aptos blockchain events!

```text
{"timestamp":"2024-08-15T01:06:35.169217Z","level":"INFO","message":"[Transaction Stream] Received transactions from GRPC.","stream_address":"https://grpc.testnet.aptoslabs.com/","connection_id":"5575cb8c-61fb-498f-aaae-868d1e8773ac","start_version":0,"end_version":4999,"start_txn_timestamp_iso":"1970-01-01T00:00:00.000000000Z","end_txn_timestamp_iso":"2022-09-09T01:49:02.023089000Z","num_of_transactions":5000,"size_in_bytes":5708539,"duration_in_secs":0.310734,"tps":16078,"bytes_per_sec":18371143.80788713,"filename":"/Users/reneetso/.cargo/git/checkouts/aptos-indexer-processor-sdk-2f3940a333c8389d/e1e1bdd/rust/transaction-stream/src/transaction_stream.rs","line_number":400,"threadName":"tokio-runtime-worker","threadId":"ThreadId(6)"}
{"timestamp":"2024-08-15T01:06:35.257756Z","level":"INFO","message":"Events version [0, 4999] stored successfully","filename":"src/processors/events/events_storer.rs","line_number":75,"threadName":"tokio-runtime-worker","threadId":"ThreadId(10)"}
{"timestamp":"2024-08-15T01:06:35.257801Z","level":"INFO","message":"Finished processing events from versions [0, 4999]","filename":"src/processors/events/events_processor.rs","line_number":90,"threadName":"tokio-runtime-worker","threadId":"ThreadId(17)"}
```

## Customize the processor

In most cases, you want to index events from your own contracts. The example processor offers a good starting point to
creating your own custom processor.

To customize the processor to index events from your custom contract, you can make these changes:

1. Change the database schema to a format that better matches your dapp or API.
   a. Create a new migration with diesel:

```shellscript
  diesel migration generate {migration_name}
```

b. Add your migration changes to `up.sql` and `down.sql`, then apply the migration:

```shellscript
  diesel migration run --database-url={YOUR_DATABASE_URL}
```

c. The `schema.rs` file will be updated automatically. You can then create a diesel query that uses the new schema.
2\. Update the transform logic in `process()`. You can filter by specific event types and extract specific event data from your custom contract

## Migrate from legacy processors

If you're migrating from the legacy processors, you can still start with the same steps above to create a new processor with the Indexer SDK.

You'll also need to follow these:

1. Copy your migration files to `src/db/`.
2. With the legacy processors, the processing logic is defined inside the `process_transactions` method.

```rust
// Example with the legacy processors
#[async_trait]
impl ProcessorTrait for EventsProcessor {
    async fn process_transactions(
        ...
    ) -> anyhow::Result<ProcessingResult> {
        // Extract events from transactions
        let events: Vec<EventModel> = process_events(transactions);

        // Store the events in the database
        let tx_result = insert_to_db(
            self.get_pool(),
            self.name(),
            start_version,
            end_version,
            &events,
            &self.per_table_chunk_sizes,
        )
        .await;

        return tx_result;
    }
}
```

Migrate to the SDK by copying over the logic in `process_transactions` method to the SDK `process` transform function.

```rust
// Example with SDK processor
    process(
        "events_processor".to_string(),
        MIGRATIONS,
        async |transactions, conn_pool| {
          // Extract events from transactions
          let events: Vec<EventModel> = process_events(transactions);

          // Store events in the database
          let execute_res = execute_in_chunks(
              conn_pool.clone(),
              insert_events_query,
              &events,
              MAX_DIESEL_PARAM_SIZE / EventModel::field_count(),
          )
          .await;
        },
    )
    .await?;
```

3. Update the `config.yaml` file to the new format. Update `starting_version` to the version that is last saved in the `processor_status` table.

# Legacy Indexer

> Deprecated indexer system for Aptos blockchain - migration guide to new Transaction Stream Service and Indexer SDK

import { Aside } from '@astrojs/starlight/components';

<Aside type="caution">
  Deprecation Alert

  From Now - end of Q2, 2024: We will not be adding any new features to the legacy Indexer. However, we will continue to generally support the community, and will make sure that any changes made on the blockchain level does not break the existing legacy processors.

  After Q2, 2024: We will remove the indexer crates from the [aptos-core](https://github.com/aptos-labs/aptos-core) repo and the legacy indexer will no longer be supported. Please look at our new [Transaction Stream Service](/build/indexer/txn-stream) and updated [Indexer API](/build/indexer)
</Aside>

# Custom Data Model

> Legacy custom data model documentation for deprecated indexer - migrate to modern Indexer SDK for custom processors

import { Aside } from '@astrojs/starlight/components';

<Aside type="caution">
  This is documentation for the legacy indexer. To learn how to write a custom processor with the latest indexer stack, see [Custom Processors](/build/indexer/indexer-sdk/documentation/create-processor).
</Aside>

## Define your own data model

Use this method if you want to develop your custom indexer for the Aptos ledger data.

<Aside type="note">
  When should you use the custom indexer?

  Currently Aptos-provided indexing service (see above) supports the following core Move modules:

  - `0x1::coin`.
  - `0x3::token`.
  - `0x3::token_transfers`.

  If you need an indexed database for any other Move modules and contracts, then you should develop your custom indexer.
</Aside>

Creating a custom indexer involves the following steps. Refer to the indexing block diagram at the start of this document.

1. Define new table schemas, using an ORM like [Diesel](https://diesel.rs/). In this document Diesel is used to describe the custom indexing steps ("Business logic" and the data queries in the diagram).
2. Create new data models based on the new tables ("Business logic" in the diagram).
3. Create a new transaction processor, or optionally add to an existing processor. In the diagram this step corresponds to processing the ledger database according to the new business logic and writing to the indexed database.
4. Integrate the new processor. Optional if you are reusing an existing processor.

In the below detailed description, an example of indexing and querying for the coin balances is used. You can see this in the [`coin_processor.rs`](https://github.com/aptos-labs/aptos-core/blob/main/crates/indexer/src/processors/coin_processor.rs).

### 1. Define new table schemas

In this example we use [PostgreSQL](https://www.postgresql.org/) and [Diesel](https://diesel.rs/) as the ORM. To make sure that we make backward-compatible changes without having to reset the database at every upgrade, we use [Diesel migrations](https://docs.rs/diesel_migrations/latest/diesel_migrations/) to manage the schema. This is why it is very important to start with generating a new Diesel migration before doing anything else.

Make sure you clone the Aptos-core repo by running `git clone https://github.com/aptos-labs/aptos-core.git` and then `cd` into `aptos-core/tree/main/crates/indexer` directory. Then proceed as below.

a. The first step is to create a new Diesel migration. This will generate a new folder under [migrations](https://github.com/aptos-labs/aptos-core/tree/main/crates/indexer/migrations) with `up.sql` and `down.sql`

```shellscript filename="Terminal"
DATABASE_URL=postgres://postgres@localhost:5432/postgres diesel migration generate add_coin_tables
```

b. Create the necessary table schemas. This is just PostgreSQL code. In the code shown below, the `up.sql` will have the new changes and `down.sql` will revert those changes.

```sql filename="up.sql / down.sql"
-- up.sql
-- coin balances for each version
CREATE TABLE coin_balances (
  transaction_version BIGINT NOT NULL,
  owner_address VARCHAR(66) NOT NULL,
  -- Hash of the non-truncated coin type
  coin_type_hash VARCHAR(64) NOT NULL,
  -- creator_address::name::symbol<struct>
  coin_type VARCHAR(5000) NOT NULL,
  amount NUMERIC NOT NULL,
  transaction_timestamp TIMESTAMP NOT NULL,
  inserted_at TIMESTAMP NOT NULL DEFAULT NOW(),
  -- Constraints
  PRIMARY KEY (
    transaction_version,
    owner_address,
    coin_type_hash
  )
);
-- latest coin balances
CREATE TABLE current_coin_balances {...}
-- down.sql
DROP TABLE IF EXISTS coin_balances;
DROP TABLE IF EXISTS current_coin_balances;
```

See the [full source for `up.sql` and `down.sql`](https://github.com/aptos-labs/aptos-core/tree/main/crates/indexer/migrations/2022-10-04-073529_add_coin_tables).

c. Run the migration. We suggest running it multiple times with `redo` to ensure that both `up.sql` and `down.sql` are implemented correctly. This will also modify the [`schema.rs`](https://github.com/aptos-labs/aptos-core/blob/main/crates/indexer/src/schema.rs) file.

```shellscript filename="Terminal"
DATABASE_URL=postgres://postgres@localhost:5432/postgres diesel migration run
DATABASE_URL=postgres://postgres@localhost:5432/postgres diesel migration redo
```

### 2. Create new data schemas

We now have to prepare the Rust data models that correspond to the Diesel schemas. In the case of coin balances, we will define `CoinBalance` and `CurrentCoinBalance` as below:

```rust filename="coin_balance.rs"
#[derive(Debug, Deserialize, FieldCount, Identifiable, Insertable, Serialize)]
#[diesel(primary_key(transaction_version, owner_address, coin_type))]
#[diesel(table_name = coin_balances)]
pub struct CoinBalance {
    pub transaction_version: i64,
    pub owner_address: String,
    pub coin_type_hash: String,
    pub coin_type: String,
    pub amount: BigDecimal,
    pub transaction_timestamp: chrono::NaiveDateTime,
}

#[derive(Debug, Deserialize, FieldCount, Identifiable, Insertable, Serialize)]
#[diesel(primary_key(owner_address, coin_type))]
#[diesel(table_name = current_coin_balances)]
pub struct CurrentCoinBalance {
    pub owner_address: String,
    pub coin_type_hash: String,
    pub coin_type: String,
    pub amount: BigDecimal,
    pub last_transaction_version: i64,
    pub last_transaction_timestamp: chrono::NaiveDateTime,
}
```

We will also need to specify the parsing logic, where the input is a portion of the transaction. In the case of coin balances, we can find all the details in `WriteSetChanges`, specifically where the write set change type is `write_resources`.

**Where to find the relevant data for parsing**: This requires a combination of understanding the Move module and the structure of the transaction. In the example of coin balance, the contract lives in [coin.move](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/coin.move), specifically the coin struct (search for `struct Coin`) that has a `value` field. We then look at an [example transaction](https://api.testnet.aptoslabs.com/v1/transactions/by_version/259518) where we find this exact structure in `write_resources`:

```shellscript filename="Terminal"
"changes": [
  {
    ...
    "data": {
      "type": "0x1::coin::CoinStore<0x1::aptos_coin::AptosCoin>",
      "data": {
        "coin": {
          "value": "49742"
      },
      ...
```

See the full code in [coin\_balances.rs](https://github.com/aptos-labs/aptos-core/blob/main/crates/indexer/src/models/coin_models/coin_balances.rs).

### 3. Create a new processor

Now that we have the data model and the parsing function, we need to call that parsing function and save the resulting model in our Postgres database. We do this by creating (or modifying) a `processor`. We have abstracted a lot already from that class, so the only function that should be implemented is `process_transactions` (there are a few more functions that should be copied, those should be obvious from the example).

The `process_transactions` function takes in a vector of transactions with a start and end version that are used for tracking purposes. The general flow should be:

- Loop through transactions in the vector.
- Aggregate relevant models. Sometimes deduping is required, e.g. in the case of `CurrentCoinBalance`.
- Insert the models into the database in a single Diesel transaction. This is important, to ensure that we do not have partial writes.
- Return status (error or success).

<Aside type="note">
  See [coin\_processor.rs](https://github.com/aptos-labs/aptos-core/blob/main/crates/indexer/src/processors/coin_processor.rs) for a relatively straightforward example. You can search for `coin_balances` in the page for the specific code snippet related to coin balances.
</Aside>

**How to decide whether to create a new processor:** This is completely up to you. The benefit of creating a new processor is that you are starting from scratch, so you will have full control over exactly what gets written to the indexed database. The downside is that you will have to maintain a new fullnode, since there is a 1-to-1 mapping between a fullnode and the processor.

### 4. Integrate the new processor

This is the easiest step and involves just a few additions.

1. To start with, make sure to add the new processor in the Rust code files: [`mod.rs`](https://github.com/aptos-labs/aptos-core/blob/main/crates/indexer/src/processors/mod.rs) and [`runtime.rs`](https://github.com/aptos-labs/aptos-core/blob/main/crates/indexer/src/runtime.rs). See below:

[**mod.rs**](https://github.com/aptos-labs/aptos-core/blob/main/crates/indexer/src/processors/mod.rs)

```rust filename="mod.rs"
pub enum Processor {
  CoinProcessor,
  ...
}
...
  COIN_PROCESSOR_NAME => Self::CoinProcessor,
```

[**runtime.rs**](https://github.com/aptos-labs/aptos-core/blob/main/crates/indexer/src/runtime.rs)

```rust filename="runtime.rs"
Processor::CoinProcessor => Arc::new(CoinTransactionProcessor::new(conn_pool.clone())),
```

2. Create a `fullnode.yaml` with the correct configuration and test the custom indexer by starting a fullnode with this `fullnode.yaml`.

**fullnode.yaml**

```yaml filename="fullnode.yaml"
storage:
  enable_indexer: true
  storage_pruner_config:
    ledger_pruner_config:
      enable: false

indexer:
  enabled: true
  check_chain_id: true
  emit_every: 1000
  postgres_uri: "postgres://postgres@localhost:5432/postgres"
  processor: "coin_processor"
  fetch_tasks: 10
  processor_tasks: 10
```

Test by starting an Aptos fullnode by running the below command. You will see many logs in the terminal output, so use the `grep` filter to see only indexer log output, as shown below:

```shellscript filename="Terminal"
cargo run -p aptos-node --features "indexer" --release -- -f ./fullnode_coin.yaml | grep -E "_processor"
```

See the full instructions on how to start an indexer-enabled fullnode in [Indexer Fullnode](/build/indexer/legacy/indexer-fullnode).

# Run an Indexer Fullnode

> Legacy indexer fullnode setup documentation - deprecated in favor of modern Transaction Stream Service architecture

import { Aside } from '@astrojs/starlight/components';

<Aside type="caution">
  This is documentation for the legacy indexer. To learn how to run the underlying infrastructure for the latest indexer stack, see [Transaction Stream Service](/build/indexer/txn-stream).
</Aside>

<Aside type="caution">
  The below installation steps are verified only on macOS with Apple Silicon. They might require minor tweaking when running on other builds.
</Aside>

## Summary

To run an indexer fullnode, these are the steps in summary:

1. Make sure that you have all the required tools and packages described below in this document.
2. Follow the instructions to [set up a public fullnode](/network/nodes/full-node/verify-pfn) but do not start the fullnode yet.
3. Edit the `fullnode.yaml` as described below in this document.
4. Run the indexer fullnode per the instructions below.

## Prerequisites

Install the packages below. Note, you may have already installed many of these while [preparing your development environment](/network/nodes/building-from-source). You can confirm by running `which command-name` and ensuring the package appears in the output (although `libpq` will not be returned even when installed).

> Important: If you are on macOS, you will need to [install Docker following the official guidance](https://docs.docker.com/desktop/install/mac-install/) rather than `brew`.

For an Aptos indexer fullnode, install these packages:

- [`brew`](https://brew.sh/) - `/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"` Run the commands emitted in the output to add the command to your path and install any dependencies
- [`cargo` Rust package manager](https://www.rust-lang.org/tools/install) - `curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh`
- [`docker`](https://docs.docker.com/get-docker/) - `brew install docker`
- [libpq Postgres C API library containing the `pg_ctl` command](https://formulae.brew.sh/formula/libpq) - `brew install libpq`
  Make sure to perform all export commands after the installation.
- [`postgres` PostgreSQL server](https://www.postgresql.org/) - `brew install postgresql`
- [`diesel`](https://diesel.rs/) - `brew install diesel`

## Set up the database

1. Start the PostgreSQL server:
   `brew services start postgresql`
2. Ensure you can run `psql postgres` and then exit the prompt by entering: `\q`
3. Create a PostgreSQL user `postgres` with the `createuser` command (find it with `which`):
   ```shellscript filename="Terminal"
   /path/to/createuser -s postgres
   ```
4. Clone `aptos-core` repository if you have not already:
   ```shellscript filename="Terminal"
   git clone https://github.com/aptos-labs/aptos-core.git
   ```
5. Navigate (or `cd`) into `aptos-core/crates/indexer` directory.
6. Create the database schema:
   ```shellscript filename="Terminal"
   diesel migration run --database-url postgresql://localhost/postgres
   ```
   This will create a database schema with the subdirectory `migrations` located in this `aptos-core/crates/indexer` directory. If for some reason this database is already in use, try a different database. For example: `DATABASE_URL=postgres://postgres@localhost:5432/indexer_v2 diesel database reset`

## Start the fullnode indexer

1. Follow the instructions to set up a [public fullnode](/network/nodes/full-node/verify-pfn) and prepare the setup, but **do not** yet start the indexer (with `cargo run` or `docker run`).
2. Pull the latest indexer Docker image with:
   ```shellscript filename="Terminal"
   docker pull aptoslabs/validator:nightly_indexer
   ```
3. Edit the `./fullnode.yaml` and add the following configuration:

   ```yaml filename="fullnode.yaml"
   storage:
     enable_indexer: true
     # This is to avoid the node being pruned
     storage_pruner_config:
       ledger_pruner_config:
         enable: false

   indexer:
     enabled: true
     postgres_uri: "postgres://postgres@localhost:5432/postgres"
     processor: "default_processor"
     check_chain_id: true
     emit_every: 500
   ```

<Aside type="note">
  Bootstrapping the fullnode

  Instead of syncing your indexer fullnode from genesis, which may take a long period of time, you can choose to bootstrap your fullnode using backup data before starting it. To do so, follow the instructions to [restore from a backup](/network/nodes/bootstrap-fullnode/aptos-db-restore).

  Note: indexers cannot be bootstrapped using [a snapshot](/network/nodes/bootstrap-fullnode) or [fast sync](/network/nodes/configure/state-sync#fast-syncing).
</Aside>

1. Run the indexer fullnode with either `cargo run` or `docker run` depending upon your setup. Remember to supply the arguments you need for your specific node:
   ```shellscript filename="Terminal"
   docker run -p 8080:8080 \
     -p 9101:9101 -p 6180:6180 \
     -v $(pwd):/opt/aptos/etc -v $(pwd)/data:/opt/aptos/data \
     --workdir /opt/aptos/etc \
     --name=aptos-fullnode aptoslabs/validator:nightly_indexer aptos-node \
     -f /opt/aptos/etc/fullnode.yaml
   ```
   or:
   ```shellscript filename="Terminal"
   cargo run -p aptos-node --features "indexer" --release -- -f ./fullnode.yaml
   ```

## Restart the indexer

To restart the PostgreSQL server:

1. [Shut down the server](https://www.postgresql.org/docs/8.1/postmaster-shutdown.html) by searching for the `postmaster` process and killing it:

   ```shellscript filename="Terminal"
   ps -ef | grep -i postmaster
   ```

2. Copy the process ID (PID) for the process and pass it to the following command to shut it down:

   ```shellscript filename="Terminal"
   kill -INT PID
   ```

3. Restart the PostgreSQL server with:
   ```shellscript filename="Terminal"
   brew services restart postgresql@14
   ```

# Migrate to Transaction Stream Service

> Migration guide from legacy indexer to modern Transaction Stream Service with hosted and self-hosted deployment options

This guide contains information on how to migrate to using the Transaction Stream Service if you are currently running a legacy indexer.

The old indexer stack requires running an archival fullnode with additional threads to process the transactions which is difficult and expensive to maintain. Adding more custom logic either requires a bulkier machine, or running several fullnodes that scale linearly.

This new way of indexing uses the [Transaction Stream Service](/build/indexer/txn-stream). You can either use the [Labs-Hosted Transaction Stream Service](/build/indexer/txn-stream/aptos-hosted-txn-stream) or [run your own instance of Transaction Stream Service](/build/indexer/txn-stream/self-hosted).

## 1. Clone the repo

```shellscript filename="Terminal"
# SSH
git clone git@github.com:aptos-labs/aptos-indexer-processors.git

# HTTPS
git clone https://github.com/aptos-labs/aptos-indexer-processors.git
```

Navigate to the directory for the service:

```shellscript filename="Terminal"
cd aptos-indexer-processors
cd rust/processor
```

## 2. Migrate processors to Transaction Stream Service

For each processor you're migrating, you'll need to create a config file using the template below. You can find more information about each field of the config file [here](/build/indexer/txn-stream/self-hosted#configuration).

```yaml filename="config.yaml"
health_check_port: 8084
server_config:
  processor_config:
    type: default_processor
  postgres_connection_string: <postgres_uri, e.g. postgresql://postgres:@localhost:5432/indexer>
  indexer_grpc_data_service_address: <url_from_api_gateway>
  indexer_grpc_http2_ping_interval_in_secs: 60
  indexer_grpc_http2_ping_timeout_in_secs: 10
  auth_token: <auto_token_from_api_gateway>
  starting_version: 0 # optional
  ending_version: 0 # optional
```

To connect the processor to the Transaction Stream Service, you need to set the URL for `indexer_grpc_data_service_address`. Choose one of the following options.

### Option A: Connect to Labs-Hosted Transaction Stream Service

The main benefit of using the Labs-Hosted Transaction Stream Service is that you no longer need to run an archival fullnode to get a stream of transactions. This service is rate-limited. Instructions to connect to Labs-Hosted Transaction Stream can be found [here](/build/indexer/txn-stream/aptos-hosted-txn-stream).

### Option B: Run a Self-Hosted Transaction Stream Service

If you choose to, you can run a self-hosted instance of the Transaction Stream Service and connect your processors to it. Instructions to run a Self-Hosted Transaction Stream can be found [here](/build/indexer/txn-stream/self-hosted).

## 3. (Optional) Migrate custom processors to Transaction Stream Service

If you have custom processors written with the old indexer, we highly recommend starting from scratch with a new database. Using a new database ensures that all your custom database migrations will be applied during this migration.

### a. Migrate custom table schemas

Migrate your custom schemas by copying over each of your custom migrations to the [`migrations`](https://github.com/aptos-labs/aptos-indexer-processors/tree/main/rust/processor/src/db/postgres/migrations) folder.

### b. Migrate custom processors code

Migrate the code by copying over your custom processors to the [`processors`](https://github.com/aptos-labs/aptos-indexer-processors/tree/main/rust/processor) folder and any relevant custom models to the [`models`](https://github.com/aptos-labs/aptos-indexer-processors/tree/main/rust/processor/src/db/common/models) folder. Integrate the custom processors with the rest of the code by adding them to the following Rust code files.

[`mod.rs`](https://github.com/aptos-labs/aptos-indexer-processors/blob/main/rust/processor/src/processors/mod.rs)

```rust filename="mod.rs"
pub enum Processor {
    ...
    CoinProcessor,
    ...
}

impl Processor {
    ...
    COIN_PROCESSOR_NAME => Self::CoinProcessor,
    ...
}
```

[`worker.rs`](https://github.com/aptos-labs/aptos-indexer-processors/blob/main/rust/processor/src/worker.rs)

```rust filename="worker.rs"
Processor::CoinProcessor => {
    Arc::new(CoinTransactionProcessor::new(self.db_pool.clone()))
},
```

## 4. Backfill Postgres database with Diesel

Even though the new processors have the same Postgres schemas as the old ones, we recommend you do a complete backfill (ideally writing to a new DB altogether) because some fields are a bit different as a result of the protobuf conversion.

These instructions assume you are familiar with using [Diesel migrations](https://docs.rs/diesel_migrations/latest/diesel_migrations/). Run the full database migration with the following command:

```shellscript filename="Terminal"
DATABASE_URL=postgres://postgres@localhost:5432/postgres diesel migration run
```

## 5. Run the migrated processors

To run a single processor, use the following command:

```shellscript filename="Terminal"
cargo run --release -- -c config.yaml
```

If you have multiple processors, you'll need to run a separate instance of the service for each of the processors.

{/* TODO: Add instructions for running with Docker */}

If you'd like to run the processor as a Docker image, the instructions are listed here.

## FAQs

### 1. Will the protobuf ever be updated, and what do I need to do at that time?

The protobuf schema may be updated in the future. Backwards incompatible changes will be communicated in release notes.

### 2. What if I already have custom logic written in the old indexer? Is it easy to migrate those?

Since the new indexer stack has the same Postgres schema as the old indexer stack, it should be easy to migrate your processors. We still highly recommend creating a new DB for this migration so that any custom DB migrations are applied.

Follow Step 3 in this guide to migrate your custom logic over to the new processors stack.

# NFT Aggregator API

> Universal NFT aggregator for Aptos ecosystem with normalized marketplace data, GraphQL API, and analytics for all major NFT platforms

import { Aside } from '@astrojs/starlight/components';

We've built a **universal NFT aggregator** for the Aptos ecosystem - normalized activity across all major marketplaces, including **Tradeport**, **Wapal**, **Bluemove**, **Rarible**, and more. We also maintain historical data for deprecated marketplaces like **Topaz**.

At its core, the aggregator captures marketplace events in real-time (like listings, token offers, and collection-wide offers) and converts them into clean, structured data. This allows developers to work with a unified data format ‚Äî no need to handle different marketplace-specific formats manually.

## What We Provide

- **[GraphQL API](/build/indexer/nft-aggregator/graphql-api)** for querying activities
- **[Analytics REST API](/build/indexer/nft-aggregator/analytics-api)** for aggregated analytics
- Marketplace integration support for new partners

Our API supports two main use cases:

- **Historical Data tracking:** Listings, NFT Token Offers, NFT Collection Offers ‚Äî in real-time.
- **Analytics & Trends:** Aggregate data, market insights, top traders, and more.

## GraphQL API

Query real-time marketplace activity across all integrated marketplaces. Use this for:

- Basic historical data
- Aggregated data (e.g. how many listings are there for a given collection)

You can explore it by hand by viewing the Hasura Explorer below for the network you are interested in.

- Hasura Console: [https://cloud.hasura.io/public/graphiql?endpoint=https://api.mainnet.aptoslabs.com/nft-aggregator/v1/graphql](https://cloud.hasura.io/public/graphiql?endpoint=https://api.mainnet.aptoslabs.com/nft-aggregator/v1/graphql)

For direct GraphQL queries to the Aptos-Labs hosted Indexer API, use these endpoints:

- Mainnet Graphql Endpoint: [https://api.mainnet.aptoslabs.com/nft-aggregator/v1/graphql](https://api.mainnet.aptoslabs.com/nft-aggregator/v1/graphql)

you can find the full API reference [here](/build/indexer/nft-aggregator/graphql-api).

## Analytics REST API

<Aside type="note">
  Analytics API is currently in beta.\
  For custom analytics pipelines, we recommend using our gRPC stream for raw structured events.
</Aside>

Get high-level insights and historical data on the NFT market. Use this analytics API for:

- Total sales volumes
- Top buyers and sellers
- Marketplace trends

You can find the full API reference [here](/build/indexer/nft-aggregator/analytics-api).

## Integrated Marketplaces

See the full list of marketplaces currently integrated with the NFT Aggregator [here](/build/indexer/nft-aggregator/marketplaces).

## Add Your Marketplace

<Aside type="note">
  We handle most integrations directly with your support
</Aside>

If you'd like your marketplace to be included, please reach out to our team. We support both public integrations and private beta partners.

## Next Steps

Ready to dive deeper?

- üëâ [GraphQL API](/build/indexer/nft-aggregator/graphql-api)
- üëâ [Analytics REST API](/build/indexer/nft-aggregator/analytics-api)
- üëâ [Integrated Marketplaces](/build/indexer/nft-aggregator/marketplaces)

# Analytics REST API

> NFT marketplace analytics and insights via REST API with collection performance, volume data, and top trader metrics for Aptos ecosystem

import { Aside } from '@astrojs/starlight/components';

<Aside type="note">
  The REST API provides collection and marketplace-level insights across the Aptos ecosystem.
</Aside>

Use this API to access:

- üìä Marketplace performance metrics
- ü•â Collection-level sales and volume data
- üèÜ Top buyers and sellers
- üìà Historical trends and leaderboard data

> **Base URL:** `https://api.mainnet.aptoslabs.com/v1/analytics/nft`

***

## Marketplace Endpoints

### **Get Marketplace Total Sales Count**

- **GET** `/nft/marketplace/total_sales_count`
- **Parameters:**
  - `marketplace` _(string, required)_ ‚Äî Marketplace identifier (e.g. `topaz`, `wapal`)
- **Description:** Returns the total number of completed sales for a given marketplace.
- **Example:**

```shellscript
curl "https://api.mainnet.aptoslabs.com/v1/analytics/nft/marketplace/total_sales_count?marketplace=topaz"
```

***

## Collection Endpoints

### **Get Collection Total Sales**

- **GET** `/nft/collection/total_sales_count`
- **Parameters:**
  - `collection_id` _(string, required)_
- **Description:** Returns total number of completed sales for the specified collection.
- **Example:**

```shellscript
curl "https://api.mainnet.aptoslabs.com/v1/analytics/nft/collection/total_sales_count?collection_id=123"
```

***

### **Get Collection Top Buyers**

- **GET** `/nft/collection/top_buyer`
- **Parameters:**
  - `collection_id` _(string, required)_
  - `limit` _(integer, optional, default: 10)_
  - `offset` _(integer, optional, default: 0)_
- **Description:** Returns top buyers in the collection, ranked by total amount spent.
- **Example:**

```shellscript
curl "https://api.mainnet.aptoslabs.com/v1/analytics/nft/collection/top_buyer?collection_id=123&limit=5"
```

***

### **Get Collection Top Sellers**

- **GET** `/nft/collection/top_seller`
- **Parameters:**
  - `collection_id` _(string, required)_
  - `limit` _(integer, optional, default: 10)_
  - `offset` _(integer, optional, default: 0)_
- **Description:** Returns top sellers in the collection, ranked by total volume sold.
- **Example:**

```shellscript
curl "https://api.mainnet.aptoslabs.com/v1/analytics/nft/collection/top_seller?collection_id=123&limit=5"
```

***

### **Get Collection Total Sales Volume**

- **GET** `/nft/collection/total_sales_volume`
- **Parameters:**
  - `collection_id` _(string, required)_
- **Description:** Returns total trading volume (in APT) for the collection.
- **Example:**

```shellscript
curl "https://api.mainnet.aptoslabs.com/v1/analytics/nft/collection/total_sales_volume?collection_id=123"
```

***

### **List Collections by Trading Volume**

- **GET** `/nft/collection/list_by_volume`
- **Parameters:**
  - `limit` _(integer, max: 10)_
  - `offset` _(integer)_
  - `time_period` _(string)_ ‚Äî `1h`, `6h`, `24h`, `7d`, `30d`
- **Description:** Returns collections sorted by total sales volume within a selected time period.
- **Example:**

```shellscript
curl "https://api.mainnet.aptoslabs.com/v1/analytics/nft/collection/list_by_volume?limit=10&offset=0&time_period=1d"
```

***

### **List Collections by Number of Sales**

- **GET** `/nft/collection/list_by_sales`
- **Parameters:** Same as above
- **Description:** Returns collections sorted by total number of sales.
- **Example:**

```shellscript
curl "https://api.mainnet.aptoslabs.com/v1/analytics/nft/collection/list_by_sales?limit=10&offset=0&time_period=1d"
```

***

### **List Collections by Floor Price**

- **GET** `/nft/collection/list_by_floor_price`
- **Parameters:** Same as above
- **Description:** Returns collections sorted by floor price within the selected time period.
- **Example:**

```shellscript
curl "https://api.mainnet.aptoslabs.com/v1/analytics/nft/collection/list_by_floor_price?limit=10&offset=0&time_period=1d"
```

***

### **Get Number of Unique Token Holders**

- **GET** `/nft/collection/unique_holders_count`
- **Parameters:**
  - `collection_id` _(string, required)_
- **Description:** Returns the number of unique wallet addresses currently holding at least one token from the specified collection. Only current holders (amount > 0) are counted.
- **Example:**

```shellscript
curl "https://api.mainnet.aptoslabs.com/v1/analytics/nft/collection/unique_holders_count?collection_id=<collection_id>"
```

# GraphQL API

> Real-time NFT marketplace activity data via GraphQL API with queries for listings, offers, and marketplace events across Aptos ecosystem

import { GraphQLEditor } from '~/components/react/GraphQLEditor';

import { Aside } from '@astrojs/starlight/components';

<Aside type="note">
  The GraphQL API provides real-time access to NFT marketplace activity across the Aptos ecosystem.
</Aside>

## Endpoints

- **Hasura Console:** [API Explorer](https://cloud.hasura.io/public/graphiql?endpoint=https://api.mainnet.aptoslabs.com/nft-aggregator/v1/graphql)
- **Mainnet Endpoint:**\
  `https://api.mainnet.aptoslabs.com/nft-aggregator/v1/graphql`

## Schema

The API follows standard GraphQL conventions.

You can explore all available queries and types using the API Explorer linked above.

Some key types:

- `current_nft_marketplace_listings`: Get active listings
- `current_nft_marketplace_token_offers`: See offers made on specific tokens
- `current_nft_marketplace_collection_offers`: Track offers made at the collection level
- `nft_marketplace_activities`: Monitor all marketplace activities

‚û°Ô∏è [Full Schema Reference](/build/indexer/nft-aggregator/nft-aggregator-table)

## Example Queries

### Get Active Listings with Token Metadata

Retrieve **active NFT listings** enriched with token metadata.

<Aside type="note">
  Try it yourself! Adjust filters like `marketplace`, `limit`, and sorting to explore more results.
</Aside>

<GraphQLEditor
  query={`query ActiveListingsWithMetadata {
  current_nft_marketplace_listings(
    limit: 10
    where: { is_deleted: { _eq: false } }
    order_by: { last_transaction_timestamp: desc }
  ) {
    listing_id
    price
    marketplace
    seller
    last_transaction_version
    last_transaction_timestamp
    token_data_id
    current_token_data {
      token_name
      token_uri
      description
      token_properties
      token_standard
      supply
      maximum
      collection_id
    }
  }
}`}
  endpoint="https://api.mainnet.aptoslabs.com/nft-aggregator-staging/v1/graphql"
/>

_No variables are required for this query by default, but you can adjust the `where` filter directly inside the editor._

***

### Get Collection Offers with Collection Metadata

Retrieve **active collection-level offers** along with detailed collection metadata.

<Aside type="note">
  Try it yourself! Adjust marketplace filter and pagination to explore more offers.
</Aside>

<GraphQLEditor
  query={`query CollectionOffersWithMetadata($marketplace: String!) {
  current_nft_marketplace_collection_offers(
    where: { is_deleted: { _eq: false }, marketplace: { _eq: $marketplace } }
    limit: 2
    order_by: { last_transaction_timestamp: desc }
  ) {
    collection_offer_id
    collection_id
    price
    marketplace
    buyer
    last_transaction_timestamp
    token_data_id
    current_collection {
      collection_id
      collection_name
      creator_address
      current_supply
      max_supply
      description
    }
  }
}`}
  variables={`{
  "marketplace": "wapal"
}`}
  endpoint="https://api.mainnet.aptoslabs.com/nft-aggregator-staging/v1/graphql"
/>

### Get Token Offers with Token Metadata

Retrieve **active token-specific offers** along with detailed token metadata.

<Aside type="note">
  Try it yourself! Adjust the token\_data\_id and other filters to explore specific token offers.
</Aside>

<GraphQLEditor
  query={`query TokenOffersWithMetadata($token_data_id: String!) {
  current_nft_marketplace_token_offers(
    where: {
      is_deleted: { _eq: false }
      token_data_id: { _eq: $token_data_id }
    }
    limit: 5
    order_by: { last_transaction_timestamp: desc }
  ) {
    offer_id
    token_data_id
    price
    marketplace
    buyer
    last_transaction_timestamp
    current_token_datas {
      token_name
      token_uri
      description
      collection_id
    }
  }
}`}
  variables={`{
  "token_data_id": "0x8142a7fde5039839509e81615e456413bac1c53a1d6c6447f2daf64e84665948"
}`}
  endpoint="https://api.mainnet.aptoslabs.com/nft-aggregator-staging/v1/graphql"
/>

# Integrated Marketplaces

> Complete list of NFT marketplaces integrated with Aptos NFT Aggregator including event mappings and transaction examples

import { Aside, CardGrid, LinkCard } from '@astrojs/starlight/components';

<Aside type="note">
  Explore all marketplaces currently supported by the NFT Aggregator API.\
  For each marketplace, we provide detailed event type mappings, example transactions, and integration notes.
</Aside>

<CardGrid>
  <LinkCard href="/build/indexer/nft-aggregator/marketplaces/tradeport" title="Tradeport" description="View supported events and example transactions for Tradeport" />

  <LinkCard href="/build/indexer/nft-aggregator/marketplaces/bluemove" title="Bluemove" description="View supported events and example transactions for Bluemove" />

  <LinkCard href="/build/indexer/nft-aggregator/marketplaces/wapal" title="Wapal" description="View supported events and example transactions for Wapal" />

  <LinkCard href="/build/indexer/nft-aggregator/marketplaces/rarible" title="Rarible" description="View supported events and example transactions for Rarible" />
</CardGrid>

## Deprecated Marketplaces

These marketplaces are no longer operational, but their historical data remains available through our API.

<CardGrid>
  <LinkCard href="/build/indexer/nft-aggregator/marketplaces/topaz" title="Topaz (Deprecated)" description="Historical data available for reference" />
</CardGrid>

## Notes

- ‚úÖ All marketplaces share the same core event schema for consistency.
- üìñ Use individual marketplace pages for detailed event-to-type mappings and example transactions.
- üöÄ Add your marketplace: Reach out to our team!

# Bluemove

> Bluemove marketplace integration with supported NFT events, transaction examples, and aggregator API compatibility for Aptos ecosystem

import { Aside } from '@astrojs/starlight/components';

<Aside type="note">
  This page details all supported event types and example transactions for the Bluemove marketplace.
</Aside>

## Contract Address

| Contract Version | Account Address                                                                                                                                                                                                       |
| ---------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Mainnet          | [`0xd1fd99c1944b84d1670a2536417e997864ad12303d19eac725891691b04d614e`](https://explorer.aptoslabs.com/account/0xd1fd99c1944b84d1670a2536417e997864ad12303d19eac725891691b04d614e/modules/code/events?network=mainnet) |

_This address is the on-chain account for Bluemove's contract deployment._

***

## Supported Event Types

| Standard Event Type          | Raw On-Chain Event Type (entry function) | Example Txn Version                                                         |
| ---------------------------- | ---------------------------------------- | --------------------------------------------------------------------------- |
| **Offers**                   |                                          |                                                                             |
| `token_offer_created`        | `offer_lib::OfferEvent`                  | [2299166354](https://explorer.aptoslabs.com/txn/2299166354?network=mainnet) |
| `token_offer_cancelled`      | `offer_lib::CancelOfferEvent`            | [2299053567](https://explorer.aptoslabs.com/txn/2299053567?network=mainnet) |
| `token_offer_filled`         | `offer_lib::AcceptOfferEvent`            | [1809917526](https://explorer.aptoslabs.com/txn/1809917526?network=mainnet) |
| **Collection Offers**        |                                          |                                                                             |
| `collection_offer_created`   | `offer_lib::OfferCollectionEvent`        | [2403214712](https://explorer.aptoslabs.com/txn/2403214712?network=mainnet) |
| `collection_offer_cancelled` | `offer_lib::CancelOfferCollectionEvent`  | [2397017908](https://explorer.aptoslabs.com/txn/2397017908?network=mainnet) |
| `collection_offer_filled`    | `offer_lib::AcceptOfferCollectionEvent`  | [2382717056](https://explorer.aptoslabs.com/txn/2382717056?network=mainnet) |
| **Listings**                 |                                          |                                                                             |
| `listing_created`            | `marketplaceV2::ListEvent`               | [2404863839](https://explorer.aptoslabs.com/txn/2404863839?network=mainnet) |
| `listing_cancelled`          | `marketplaceV2::DeListEvent`             | [2399933805](https://explorer.aptoslabs.com/txn/2399933805?network=mainnet) |
| `listing_filled`             | `listings_v2::BuyEvent`                  | [2396025485](https://explorer.aptoslabs.com/txn/2396025485?network=mainnet) |

***

## Related Docs

- üëâ [NFT Aggregator Table Reference](/build/indexer/nft-aggregator/nft-aggregator-table)
- üëâ [GraphQL API: Real-time Activity](/build/indexer/nft-aggregator/graphql-api)
- üëâ [Integrated Marketplaces Overview](/build/indexer/nft-aggregator/marketplaces)

# Rarible

> Rarible marketplace integration with NFT event types, transaction examples, and compatibility with Aptos aggregator data pipeline

import { Aside } from '@astrojs/starlight/components';

<Aside type="note">
  This page details all supported event types and example transactions for the Rarible marketplace.
</Aside>

## Contract Address

| Contract Version | Account Address                                                                                                                                                                                                       |
| ---------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Mainnet          | [`0x465a0051e8535859d4794f0af24dbf35c5349bedadab26404b20b825035ee790`](https://explorer.aptoslabs.com/account/0x465a0051e8535859d4794f0af24dbf35c5349bedadab26404b20b825035ee790/modules/code/events?network=mainnet) |

_This address is the on-chain account for Rarible's contract deployment._

***

## Supported Event Types

| Standard Event Type          | Raw On-Chain Event Type (entry function) | Example Txn Version                                                         |
| ---------------------------- | ---------------------------------------- | --------------------------------------------------------------------------- |
| **Offers**                   |                                          |                                                                             |
| `token_offer_created`        | `events::TokenOfferPlaced`               | [1647787967](https://explorer.aptoslabs.com/txn/1647787967?network=mainnet) |
| `token_offer_cancelled`      | `events::TokenOfferCancelled`            | _No example provided (optional)_                                            |
| `token_offer_filled`         | `events::TokenOfferFilled`               | [1647790684](https://explorer.aptoslabs.com/txn/1647790684?network=mainnet) |
| **Collection Offers**        |                                          |                                                                             |
| `collection_offer_created`   | `events::CollectionOfferPlaced`          | [2202390104](https://explorer.aptoslabs.com/txn/2202390104?network=mainnet) |
| `collection_offer_cancelled` | `events::CollectionOfferCanceled`        | _No example provided (optional)_                                            |
| `collection_offer_filled`    | `events::CollectionOfferFilled`          | [2205653354](https://explorer.aptoslabs.com/txn/2205653354?network=mainnet) |
| **Listings**                 |                                          |                                                                             |
| `listing_created`            | `events::ListingPlaced`                  | [2417694028](https://explorer.aptoslabs.com/txn/2417694028?network=mainnet) |
| `listing_cancelled`          | `events::ListingCanceled`                | [2403151598](https://explorer.aptoslabs.com/txn/2403151598?network=mainnet) |
| `listing_filled`             | `events::ListingFilled`                  | [2395762995](https://explorer.aptoslabs.com/txn/2395762995?network=mainnet) |

***

## Related Docs

- üëâ [NFT Aggregator Table Reference](/build/indexer/nft-aggregator/nft-aggregator-table)
- üëâ [GraphQL API: Real-time Activity](/build/indexer/nft-aggregator/graphql-api)
- üëâ [Integrated Marketplaces Overview](/build/indexer/nft-aggregator/marketplaces)

# Topaz (Deprecated)

> Historical Topaz marketplace data integration - deprecated marketplace with legacy NFT transaction support in aggregator

import { Aside } from '@astrojs/starlight/components';

<Aside type="caution">
  **Marketplace Deprecated**\
  Topaz is no longer operational as a marketplace. However, we continue to include its historical data in our NFT Aggregator for reference.
</Aside>

## Contract Address

| Contract Version | Account Address                                                                                                                                                                                                       |
| ---------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Mainnet          | [`0x2c7bccf7b31baf770fdbcc768d9e9cb3d87805e255355df5db32ac9a669010a2`](https://explorer.aptoslabs.com/account/0x2c7bccf7b31baf770fdbcc768d9e9cb3d87805e255355df5db32ac9a669010a2/modules/code/events?network=mainnet) |

_This address is the on-chain account for Topaz's contract deployment._

***

## Supported Event Types

| Standard Event Type          | Raw On-Chain Event Type (entry function) | Example Txn Version                                                         |
| ---------------------------- | ---------------------------------------- | --------------------------------------------------------------------------- |
| **Offers**                   |                                          |                                                                             |
| `token_offer_created`        | `events::BidEvent`                       | [1645629583](https://explorer.aptoslabs.com/txn/1645629583?network=mainnet) |
| `token_offer_cancelled`      | `events::CancelBidEvent`                 | [86119627](https://explorer.aptoslabs.com/txn/86119627?network=mainnet)     |
| `token_offer_filled`         | `events::SellEvent`                      | [984827420](https://explorer.aptoslabs.com/txn/984827420?network=mainnet)   |
| **Collection Offers**        |                                          |                                                                             |
| `collection_offer_created`   | `events::CollectionBidEvent`             | [85566357](https://explorer.aptoslabs.com/txn/85566357?network=mainnet)     |
| `collection_offer_cancelled` | `events::CancelCollectionBidEvent`       | [2787969](https://explorer.aptoslabs.com/txn/2787969?network=mainnet)       |
| `collection_offer_filled`    | `events::FillCollectionBidEvent`         | [2367804069](https://explorer.aptoslabs.com/txn/2367804069?network=mainnet) |
| **Listings**                 |                                          |                                                                             |
| `listing_created`            | `events::ListEvent`                      | [1964348978](https://explorer.aptoslabs.com/txn/1964348978?network=mainnet) |
| `listing_cancelled`          | `events::DelistEvent`                    | [2331658551](https://explorer.aptoslabs.com/txn/2331658551?network=mainnet) |
| `listing_filled`             | `events::BuyEvent`                       | [2379182335](https://explorer.aptoslabs.com/txn/2379182335?network=mainnet) |

***

## Historical Data Access

While Topaz is no longer operational, all historical marketplace events remain accessible through the NFT Aggregator API. You can filter specifically for Topaz marketplace activity using the `marketplace` field:

```graphql
query GetTopazHistoricalActivity {
  nft_marketplace_activities(
    where: {marketplace: {_eq: "topaz"}}
  ) {
    txn_version
    standard_event_type
    token_data_id
    }
}
```

***

## Related Docs

- üëâ [NFT Aggregator Table Reference](/build/indexer/nft-aggregator/nft-aggregator-table)
- üëâ [GraphQL API: Real-time Activity](/build/indexer/nft-aggregator/graphql-api)
- üëâ [Integrated Marketplaces Overview](/build/indexer/nft-aggregator/marketplaces)

# Tradeport

> Tradeport marketplace integration details including V1 and V2 contract event types, transaction examples, and NFT aggregator support

import { Aside } from '@astrojs/starlight/components';

<Aside type="note">
  This page details all supported event types and example transactions for the Tradeport marketplace, across both V1 and V2 contracts.
</Aside>

## Contract Address

| Contract Version | Account Address                                                                                                                                                                                                            |
| ---------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Mainnet          | [`0xe11c12ec495f3989c35e1c6a0af414451223305b579291fc8f3d9d0575a23c26`](https://explorer.aptoslabs.com/account/0xe11c12ec495f3989c35e1c6a0af414451223305b579291fc8f3d9d0575a23c26/modules/code/bluemove_v2?network=mainnet) |

_This address is the on-chain account for Tradeport's contract deployment, used across both V1 and V2 versions._

<Aside type="note">
  **Important:**\
  While most marketplaces aim for a single contract supporting both v1 and v2 tokens, Tradeport is an exception.

  - The **V1 contract exclusively handles Aptos v1 tokens**.
  - The **V2 contract exclusively handles Aptos v2 tokens**.
  - Both contracts share the same account but operate independently.

  When building queries, make sure to align your token standard with the correct contract version for accurate results.
</Aside>

***

## Supported Event Types

### V1 Contract

| Standard Event Type          | Raw On-Chain Event Type (i.e. entry function) | Example Txn Version                                                         |
| ---------------------------- | --------------------------------------------- | --------------------------------------------------------------------------- |
| **Offers**                   |                                               |                                                                             |
| `token_offer_created`        | `biddings::InsertTokenBidEvent`               | [2377828353](https://explorer.aptoslabs.com/txn/2377828353?network=mainnet) |
| `token_offer_cancelled`      | `biddings::DeleteTokenBidEvent`               | [2361990811](https://explorer.aptoslabs.com/txn/2361990811?network=mainnet) |
| `token_offer_filled`         | `biddings::AcceptTokenBidEvent`               | [2332332877](https://explorer.aptoslabs.com/txn/2332332877?network=mainnet) |
| **Collection Offers**        |                                               |                                                                             |
| `collection_offer_created`   | `biddings::InsertCollectionBidEvent`          | [2386877471](https://explorer.aptoslabs.com/txn/2386877471?network=mainnet) |
| `collection_offer_cancelled` | `biddings::DeleteCollectionBidEvent`          | [2386876427](https://explorer.aptoslabs.com/txn/2386876427?network=mainnet) |
| `collection_offer_filled`    | `biddings::AcceptCollectionBidEvent`          | [2386481933](https://explorer.aptoslabs.com/txn/2386481933?network=mainnet) |
| **Listings**                 |                                               |                                                                             |
| `listing_created`            | `listings::InsertListingEvent`                | [2386786871](https://explorer.aptoslabs.com/txn/2386786871?network=mainnet) |
| `listing_cancelled`          | `listings::DeleteListingEvent`                | [2386786127](https://explorer.aptoslabs.com/txn/2386786127?network=mainnet) |
| `listing_filled`             | `listings::BuyEvent`                          | [2386133110](https://explorer.aptoslabs.com/txn/2386133110?network=mainnet) |

***

### V2 Contract

| Standard Event Type          | Raw On-Chain Event Type (i.e. entry function) | Example Txn Version                                                         |
| ---------------------------- | --------------------------------------------- | --------------------------------------------------------------------------- |
| **Offers**                   |                                               |                                                                             |
| `token_offer_created`        | `biddings_v2::InsertTokenBidEvent`            | [2386133936](https://explorer.aptoslabs.com/txn/2386133936?network=mainnet) |
| `token_offer_cancelled`      | `biddings_v2::DeleteTokenBidEvent`            | [2386142672](https://explorer.aptoslabs.com/txn/2386142672?network=mainnet) |
| `token_offer_filled`         | `biddings_v2::AcceptTokenBidEvent`            | [2298838662](https://explorer.aptoslabs.com/txn/2298838662?network=mainnet) |
| **Collection Offers**        |                                               |                                                                             |
| `collection_offer_created`   | `biddings_v2::InsertCollectionBidEvent`       | [2386891051](https://explorer.aptoslabs.com/txn/2386891051?network=mainnet) |
| `collection_offer_cancelled` | `biddings_v2::DeleteCollectionBidEvent`       | [2386889884](https://explorer.aptoslabs.com/txn/2386889884?network=mainnet) |
| `collection_offer_filled`    | `biddings_v2::AcceptCollectionBidEvent`       | [2386021136](https://explorer.aptoslabs.com/txn/2386021136?network=mainnet) |
| **Listings**                 |                                               |                                                                             |
| `listing_created`            | `listings_v2::InsertListingEvent`             | [2386809975](https://explorer.aptoslabs.com/txn/2386809975?network=mainnet) |
| `listing_cancelled`          | `listings_v2::DeleteListingEvent`             | [2386716658](https://explorer.aptoslabs.com/txn/2386716658?network=mainnet) |
| `listing_filled`             | `listings_v2::BuyEvent`                       | [2386455218](https://explorer.aptoslabs.com/txn/2386455218?network=mainnet) |

***

## Related Docs

- üëâ [NFT Aggregator Table Reference](/build/indexer/nft-aggregator/nft-aggregator-table)
- üëâ [GraphQL API: Real-time Activity](/build/indexer/nft-aggregator/graphql-api)
- üëâ [Integrated Marketplaces Overview](/build/indexer/nft-aggregator/marketplaces)

# Wapal

> Wapal marketplace integration details with event type mappings, transaction examples, and NFT aggregator data structure support

import { Aside } from '@astrojs/starlight/components';

<Aside type="note">
  This page details all supported event types and example transactions for the Wapal marketplace.
</Aside>

## Contract Address

| Contract Version | Account Address                                                                                                                                                                                                       |
| ---------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Mainnet          | [`0x584b50b999c78ade62f8359c91b5165ff390338d45f8e55969a04e65d76258c9`](https://explorer.aptoslabs.com/account/0x584b50b999c78ade62f8359c91b5165ff390338d45f8e55969a04e65d76258c9/modules/code/events?network=mainnet) |

_This address is the on-chain account for Wapal's contract deployment._

***

## Supported Event Types

| Standard Event Type          | Raw On-Chain Event Type (entry function) | Example Txn Version                                                         |
| ---------------------------- | ---------------------------------------- | --------------------------------------------------------------------------- |
| **Offers**                   |                                          |                                                                             |
| `token_offer_created`        | `TokenOfferPlacedEvent`                  | [2382313982](https://explorer.aptoslabs.com/txn/2382313982?network=mainnet) |
| `token_offer_cancelled`      | `TokenOfferCanceledEvent`                | [2381810159](https://explorer.aptoslabs.com/txn/2381810159?network=mainnet) |
| `token_offer_filled`         | `TokenOfferFilledEvent`                  | [2313248448](https://explorer.aptoslabs.com/txn/2313248448?network=mainnet) |
| **Collection Offers**        |                                          |                                                                             |
| `collection_offer_created`   | `CollectionOfferPlacedEvent`             | [2382373209](https://explorer.aptoslabs.com/txn/2382373209?network=mainnet) |
| `collection_offer_cancelled` | `CollectionOfferCanceledEvent`           | [2382373978](https://explorer.aptoslabs.com/txn/2382373978?network=mainnet) |
| `collection_offer_filled`    | `CollectionOfferFilledEvent`             | [2382219668](https://explorer.aptoslabs.com/txn/2382219668?network=mainnet) |
| **Listings**                 |                                          |                                                                             |
| `listing_created`            | `ListingPlacedEvent`                     | [2382251863](https://explorer.aptoslabs.com/txn/2382251863?network=mainnet) |
| `listing_cancelled`          | `ListingCanceledEvent`                   | [2381742315](https://explorer.aptoslabs.com/txn/2381742315?network=mainnet) |
| `listing_filled`             | `ListingFilledEvent`                     | [2382221134](https://explorer.aptoslabs.com/txn/2382221134?network=mainnet) |

***

## Related Docs

- üëâ [NFT Aggregator Table Reference](/build/indexer/nft-aggregator/nft-aggregator-table)
- üëâ [GraphQL API: Real-time Activity](/build/indexer/nft-aggregator/graphql-api)
- üëâ [Integrated Marketplaces Overview](/build/indexer/nft-aggregator/marketplaces)

# NFT Aggregator Table Reference

> Database schema reference for NFT aggregator PostgreSQL tables with marketplace activity data structure and field documentation

import { Aside } from '@astrojs/starlight/components';

This page documents the PostgreSQL tables generated and updated by the NFT Aggregator.\
These tables power both the **GraphQL API** and **REST API**, and reflect the live state of marketplace activity on Aptos.

For querying, refer to:

- **[NFT Aggregator API GraphQL](/build/indexer/nft-aggregator/graphql-api)**
- **[NFT Aggregator REST API](/build/indexer/nft-aggregator/analytics-api)**

<Aside type="note">
  When exploring the GraphQL API, you can view these tables in the schema explorer. Tables with `_by_pk` suffixes are automatically generated for primary key lookups.
</Aside>

<br />

# NFT Aggregator Table Overview

| Table Name                                 | Description                                   |
| ------------------------------------------ | --------------------------------------------- |
| `nft_marketplace_activities`               | Historical data of all NFT marketplace events |
| `current_nft_marketplace_listing`          | Latest active listings per token              |
| `current_nft_marketplace_token_offer`      | Latest active offers per token and buyer      |
| `current_nft_marketplace_collection_offer` | Latest active offers per collection           |
| `current_collections_v2`                   | Latest active collections                     |
| `current_token_datas_v2`                   | Latest active tokens                          |
| `current_token_ownerships_v2`              | Latest active token ownerships                |
| `current_collection_ownerships_v2_view`    | Latest active collection ownerships           |

## Notes

- Use `is_deleted = false` to query **only active** records in current state tables.
- The `nft_marketplace_activities` table is your **source of truth** for historical marketplace activity.

## `nft_marketplace_activities`

Historical table capturing all NFT marketplace events ‚Äî listings, offers, sales, and more. Has an aggregate view for summary data called `nft_marketplace_activities_aggregate`.

**Primary Key:** `txn_version, index, marketplace`

### Indexes

| Index Name                | Columns                                                      |
| ------------------------- | ------------------------------------------------------------ |
| `idx_collection_event_ts` | collection\_id, standard\_event\_type, block\_timestamp DESC |
| `idx_token_id`            | token\_data\_id                                              |
| `idx_buyer`               | buyer                                                        |
| `idx_seller`              | seller                                                       |
| `idx_listing_id`          | listing\_id                                                  |
| `idx_offer_id`            | offer\_id                                                    |
| `idx_timestamp`           | block\_timestamp DESC                                        |

### Fields

<Aside type="note">
  Many fields use `Option` types because marketplace events may not emit complete data for all fields. The processor captures what's available while maintaining type safety.
</Aside>

| Field                 | Type               | Description                             |
| --------------------- | ------------------ | --------------------------------------- |
| txn\_version          | i64                | Blockchain version of the transaction   |
| index                 | i64                | Event index in the transaction          |
| listing\_id           | Option\<String>    | Listing ID (if applicable)              |
| offer\_id             | Option\<String>    | Offer ID (if applicable)                |
| raw\_event\_type      | String             | Raw marketplace event type              |
| standard\_event\_type | String             | Normalized event type                   |
| creator\_address      | Option\<String>    | Collection creator address              |
| collection\_id        | Option\<String>    | Collection identifier                   |
| collection\_name      | Option\<String>    | Collection name                         |
| token\_data\_id       | Option\<String>    | Token identifier                        |
| token\_name           | Option\<String>    | Token name                              |
| price                 | i64                | Price in Octas                          |
| token\_amount         | Option\<i64>       | Token amount (for bundles etc.)         |
| buyer                 | Option\<String>    | Buyer's address                         |
| seller                | Option\<String>    | Seller's address                        |
| expiration\_time      | Option\<String>    | Listing/offer expiration time           |
| marketplace           | String             | Marketplace name                        |
| contract\_address     | String             | Contract address of the marketplace     |
| json\_data            | serde\_json::Value | Internal raw event payload (not public) |
| block\_timestamp      | NaiveDateTime      | Block timestamp of the event            |

<Aside type="caution">
  `json_data` is internal and not exposed in public APIs.
</Aside>

## `current_nft_marketplace_listing`

Tracks current active listings. Updated in real-time.

**Primary Key:** `token_data_id, marketplace`

### Indexes

| Index Name                                                 | Columns               |
| ---------------------------------------------------------- | --------------------- |
| `idx_current_nft_marketplace_listings_token_data_id`       | token\_data\_id       |
| `idx_current_nft_marketplace_listings_collection_id`       | collection\_id        |
| `idx_current_nft_marketplace_listings_collection_id_price` | collection\_id, price |
| `idx_current_nft_marketplace_listings_seller`              | seller                |

### Fields

| Field                        | Type            | Description                     |
| ---------------------------- | --------------- | ------------------------------- |
| token\_data\_id              | String          | Token identifier                |
| listing\_id                  | Option\<String> | Listing ID                      |
| collection\_id               | Option\<String> | Collection identifier           |
| seller                       | String          | Seller address                  |
| price                        | i64             | Listing price                   |
| token\_amount                | i64             | Number of tokens listed         |
| token\_name                  | Option\<String> | Token name                      |
| standard\_event\_type        | String          | Normalized event type           |
| is\_deleted                  | bool            | True if the listing is inactive |
| marketplace                  | String          | Marketplace name                |
| contract\_address            | String          | Marketplace contract address    |
| last\_transaction\_version   | i64             | Last transaction version        |
| last\_transaction\_timestamp | NaiveDateTime   | Last update timestamp           |

## `current_nft_marketplace_token_offer`

Tracks current active token offers by token and buyer.

**Primary Key:** `token_data_id, buyer, marketplace`

### Indexes

| Index Name                                               | Columns         |
| -------------------------------------------------------- | --------------- |
| `idx_current_nft_marketplace_token_offers_token_data_id` | token\_data\_id |
| `idx_current_nft_marketplace_token_offers_price`         | price           |
| `idx_current_nft_marketplace_token_offers_buyer`         | buyer           |

### Fields

| Field                        | Type            | Description                  |
| ---------------------------- | --------------- | ---------------------------- |
| token\_data\_id              | String          | Token identifier             |
| offer\_id                    | Option\<String> | Offer ID                     |
| buyer                        | String          | Buyer's address              |
| collection\_id               | String          | Collection identifier        |
| price                        | i64             | Offer price                  |
| token\_amount                | Option\<i64>    | Token quantity               |
| token\_name                  | Option\<String> | Token name                   |
| standard\_event\_type        | String          | Normalized event type        |
| bid\_key                     | Option\<i64>    | Unique bid key               |
| is\_deleted                  | bool            | Offer active status          |
| marketplace                  | String          | Marketplace name             |
| contract\_address            | String          | Marketplace contract address |
| last\_transaction\_version   | i64             | Last transaction version     |
| last\_transaction\_timestamp | NaiveDateTime   | Last update timestamp        |

## `current_nft_marketplace_collection_offer`

Tracks current active collection-wide offers.

**Primary Key:** `collection_offer_id`

### Indexes

| Index Name                                                                        | Columns                                |
| --------------------------------------------------------------------------------- | -------------------------------------- |
| `idx_current_nft_marketplace_collection_offers_collection_id`                     | collection\_id                         |
| `idx_current_nft_marketplace_collection_offers_token_data_id`                     | token\_data\_id                        |
| `idx_current_nft_marketplace_collection_offers_collection_offer_id_token_data_id` | collection\_offer\_id, token\_data\_id |

### Fields

| Field                        | Type          | Description                     |
| ---------------------------- | ------------- | ------------------------------- |
| collection\_offer\_id        | String        | Unique collection offer ID      |
| token\_data\_id              | String        | Token identifier                |
| collection\_id               | String        | Collection identifier           |
| buyer                        | String        | Buyer's address                 |
| price                        | i64           | Offer price                     |
| remaining\_token\_amount     | Option\<i64>  | Remaining quantity in the offer |
| standard\_event\_type        | String        | Normalized event type           |
| is\_deleted                  | bool          | Offer active status             |
| marketplace                  | String        | Marketplace name                |
| contract\_address            | String        | Marketplace contract address    |
| last\_transaction\_version   | i64           | Last transaction version        |
| last\_transaction\_timestamp | NaiveDateTime | Last update timestamp           |

## Other Tables

More info on tables (e.g. `current_token_datas_v2`, `current_collections_v2`, `current_token_ownerships_v2`, `current_collection_ownerships_v2_view`) are available [here](/build/indexer/indexer-api/indexer-reference)

# Transaction Stream Service

> Real-time transaction streaming service for Aptos blockchain data, supporting both Aptos-hosted and self-hosted deployment options

{/* <IndexerBetaNotice /> */}

The Transaction Stream Service is a service that listens to the Aptos blockchain and emits transactions as they are processed. These docs explain how this system works, how to use the Labs-Hosted instance of the service, and how to deploy it yourself.

You can get API access to a transaction stream hosted by Aptos Labs [here](/build/indexer/txn-stream/aptos-hosted-txn-stream).

# Hosted Transaction Stream Service

> Access Aptos Labs hosted transaction stream service with gRPC endpoints for mainnet, testnet, and devnet blockchain data streaming

{/* <IndexerBetaNotice /> */}

If you are running your own instance of the [Indexer API](/build/indexer), or an [Indexer SDK](/build/indexer/indexer-sdk) custom processor, you must have access to an instance of the Transaction Stream Service. This page contains information about how to use the Aptos Labs Hosted Transaction Stream Service.

## Endpoints

All endpoints are in GCP us-central1 unless otherwise specified.

- **Mainnet:** grpc.mainnet.aptoslabs.com:443
- **Testnet:** grpc.testnet.aptoslabs.com:443
- **Devnet:** grpc.devnet.aptoslabs.com:443

You can learn about the rate limits for this service by reading the [Geomi docs](https://geomi.dev/docs/admin/billing).

## Authorization via API Key

In order to use the Labs-Hosted Transaction Stream Service you must have an API key. To get an API key, do the following:

1. Go to [https://geomi.dev](https://geomi.dev).
2. Sign in and select "API Resource".
3. Create a new key. You will see the API key secret in the first table.

You can provide the API key by setting the `Authorization` HTTP header ([MDN](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Authorization)). For example, with curl:

```shellscript filename="Terminal"
curl -H 'Authorization: Bearer aptoslabs_yj4donpaKy_Q6RBP4cdBmjA8T51hto1GcVX5ZS9S65dx'
```

Learn more about API keys at the [Geomi docs site](https://geomi.dev/docs/api-keys).

For more comprehensive information about how to use the Transaction Stream Service, see the docs for the downstream systems:

- [Indexer API](/build/indexer/indexer-api)
- [Indexer SDK](/build/indexer/indexer-sdk)

# Running Locally

> Set up local development environment for transaction stream service using Docker compose and Python scripts for custom processor development

import { Aside } from '@astrojs/starlight/components';

{/* <IndexerBetaNotice /> */}

<Aside type="note">
  This has been tested on macOS 13 on ARM and Debian 11 on x86\_64.
</Aside>

When building a custom processor, you might find it helpful to develop against a local development stack. The Transaction Stream Service is a complicated, multi-component system. To assist with local development, we offer a Python script that wraps a Docker compose file to set up the entire system.

This script sets up the following:

- Single node testnet with the indexer GRPC stream enabled.
- A Redis instance.
- Transaction Stream Service, including the following components:
  - [cache-worker](https://github.com/aptos-labs/aptos-core/tree/main/ecosystem/indexer-grpc/indexer-grpc-cache-worker): Pulls transactions from the node and stores them in Redis.
  - [file-store](https://github.com/aptos-labs/aptos-core/tree/main/ecosystem/indexer-grpc/indexer-grpc-file-store): Fetches transactions from Redis and stores them in a filesystem.
  - [data-service](https://github.com/aptos-labs/aptos-core/tree/main/ecosystem/indexer-grpc/indexer-grpc-data-service): Serves transactions via a GRPC stream to downstream clients. It pulls from either the cache or the file store depending on the age of the transaction.
- Shared volumes and networking to hook it all up.

You can learn more about the Transaction Stream Service architecture [here](/build/indexer/txn-stream) and the Docker compose file [here](https://github.com/aptos-labs/aptos-core/blob/main/docker/compose/indexer-grpc/docker-compose.yaml).

## Prerequisites

In order to use the local development script you must have the following installed:

- Python 3.8+: [Installation Guide](https://docs.python-guide.org/starting/installation/#python-3-installation-guides).
- Poetry: [Installation Guide](https://python-poetry.org/docs/#installation).
- Docker: [Installation Guide](https://docs.docker.com/get-docker/).
- Docker Compose v2: This should be installed by default with modern Docker installations, verify with this command:

```shellscript filename="Terminal"
docker-compose version --short
```

- grpcurl: [Installation Guide](https://github.com/fullstorydev/grpcurl#installation)
- OpenSSL

## Preparation

Clone the aptos-core repo:

```shellscript filename="Terminal"
# HTTPS
git clone https://github.com/aptos-labs/aptos-core.git

# SSH
git clone git@github.com:aptos-labs/aptos-core.git
```

Navigate to the `testsuite` directory:

```shellscript filename="Terminal"
cd aptos-core
cd testsuite
```

Install the Python dependencies:

```shellscript filename="Terminal"
poetry install
```

## Running the script

### Starting the service

```shellscript filename="Terminal"
poetry run python indexer_grpc_local.py start
```

You will know this succeeded if the command exits, and you see the following:

```shellscript filename="Terminal"
Attempting to stream from indexer grpc for 10s
Stream finished successfully
```

### Stopping the service

```shellscript filename="Terminal"
poetry run python indexer_grpc_local.py stop
```

### Wiping the data

When you start, stop, and start the service again, it will re-use the same localnet data. If you wish to wipe the locnet and start from scratch you can run the following command:

```shellscript filename="Terminal"
poetry run python indexer_grpc_local.py wipe
```

## Using the local service

You can connect to the local Transaction Stream Service, e.g. from a custom processor, using the following configuration values:

```shellscript filename="Terminal"
indexer_grpc_data_service_address: 127.0.0.1:50052
auth_token: dummy_token
```

You can connect to the node at the following address:

```shellscript filename="Terminal"
http://127.0.0.1:8080/v1
```

## Debugging

### Usage on ARM systems

If you have a machine with an ARM processor, e.g. an M1/M2 Mac, the script should detect that and set the appropriate environment variables to ensure that the correct images will be used. If you have issues with this, try setting the following environment variable:

```shellscript filename="Terminal"
export DOCKER_DEFAULT_PLATFORM=linux/amd64
```

Additionally, make sure the following settings are correct in Docker Desktop:

- Enabled: Preferences > General > Use Virtualization framework
- Enabled: Preferences > General > Use Docker Compose V2
- Disabled: Features in development -> Use Rosetta for x86/amd64 emulation on Apple Silicon

This script has not been tested on Linux ARM systems.

### Redis fails to start

Try setting the following environment variable before running the script:

```shellscript filename="Terminal"
export REDIS_IMAGE_REPO=arm64v8/redis
```

### Cache worker is crash-looping or `Redis latest version update failed.` in log

Wipe the data:

```shellscript filename="Terminal"
poetry run python indexer_grpc_local.py wipe
```

This means historical data will be lost.

# Self-Hosted Transaction Stream Service

> Deploy your own transaction stream service with indexer fullnode, gRPC manager, and data service components for private blockchain data access

{/* <IndexerBetaNotice /> */}

In order to run Self-Hosted Transaction Stream Service, you will need to run the following components.

Indexer FN \[[https://github.com/aptos-labs/aptos-core/tree/main/ecosystem/indexer-grpc/indexer-grpc-fullnode](https://github.com/aptos-labs/aptos-core/tree/main/ecosystem/indexer-grpc/indexer-grpc-fullnode)]: A FN with indexer grpc functionality enabled. Typically your data service will need to access all historical data, therefore your FN need to sync from genesis in order to bootstrap the whole stack. The pruner can be deleted (through pruner) later on once the data is persisted into file store.

GrpcManager \[[https://github.com/aptos-labs/aptos-core/tree/main/ecosystem/indexer-grpc/indexer-grpc-manager](https://github.com/aptos-labs/aptos-core/tree/main/ecosystem/indexer-grpc/indexer-grpc-manager)]: A centrilized component that manages all the components in the stack. It can run in two mode (master and non-master), only 1 master is allowed. When it is running as master mode, it will also pull data from the upstream FN, and persistent the data into file store (which can be a local file system or Gooogle Cloud Storage).

DataService \[[https://github.com/aptos-labs/aptos-core/tree/main/ecosystem/indexer-grpc/indexer-grpc-data-service-v2](https://github.com/aptos-labs/aptos-core/tree/main/ecosystem/indexer-grpc/indexer-grpc-data-service-v2)]: Provides the client facing streaming Grpc service. It can run in 2 modes. The live mode serves data from its local cache, the historical mode serves data from the file store.

## Example Configs

- FN

```
indexer_grpc:
  enabled: true
  address: 0.0.0.0:50051 # The address to service Grpc request.
  processor_task_count: 32
  processor_batch_size: 100
  output_batch_size: 100

indexer_table_info:
  table_info_service_mode: IndexingOnly
  parser_task_count: 10
  parser_batch_size: 100
```

- GrpcManager

```
health_check_port: 8081 # The port for monitoring purpose.
server_config:
  is_master: true # Whether running in master mode.
  service_config:
    listen_address: 0.0.0.0:50052 # The port that serves Grpc requests.
  self_advertised_address: 0.0.0.0:50052
  grpc_manager_addresses: # All GrpcManager addresses in the stack, need to point to the server_config.self_advertised_address in GrpcManager config.
    - >-
      http://0.0.0.0:50052
  fullnode_addresses: # All upstream FN addresses in the stack, need to point to the indexer_grpc.address in FN config.
    - >-
      http://0.0.0.0:50051
    - >-
      http://other-fullnode.xyz:50051
  file_store_config:
    file_store_type: GcsFileStore
    gcs_file_store_bucket_name: indexer
    gcs_file_store_service_account_key_path: /secrets/indexer-sa-key
  chain_id: 1
```

- DataService

```
health_check_port: 8081 # The port for monitoring purpose.
server_config:
  chain_id: 1
  self_advertised_address: 0.0.0.0:50053
  grpc_manager_addresses: # All GrpcManager addresses in the stack, need to point to the server_config.self_advertised_address in GrpcManager config.
    - >-
      http://0.0.0.0:50052
  service_config:
    listen_address: 0.0.0.0:50053
  live_data_service_config: # For live data service.
    enabled: true
    num_slots: 5000000 # Max number of transactions to cache.
    size_limit_bytes: 10000000000 # Cache size in bytes.
  historical_data_service_config: # For historical data service.
    enabled: true
    file_store_config:
      file_store_type: GcsFileStore
      gcs_file_store_bucket_name: indexer
      gcs_file_store_service_account_key_path: /secrets/indexer-sa-key
```

## Usage

- Use GrpcManager for routing / load balancing

Call GrpcManager.GetDataServiceForRequest first, it will return the address of a data service instance.

Then Call DataService.GetTransactions.

- Use DataService directly

Call DataService.GetTransactions directly. In this case you might want to run both live data service and historical data service together.

## Advanced Usage

- Do not keep full history
  If your stream never needs to serve old data and you don't want to keep the full history, for example you want to start a stream now and only care about data in the future, you can choose to not sync from genesis.

In order to do that, first you can start your FN and do a fast sync. Then download the most recent table info database from [https://console.cloud.google.com/storage/browser/aptos-indexer-grpc-mainnet-table-info-backup](https://console.cloud.google.com/storage/browser/aptos-indexer-grpc-mainnet-table-info-backup) (for testnet, replace `mainnet` with `testnet`), unzip to the db folder in your FN.

Then start your GrpcManager, it will generate the `metadata.json` in your file store (it could be your local file stream or GCS based on your config). Manually update the version to the next version you want to start processing. (the version must be a multiple of 100000 plus 1, e.g. 1000000001, and your FN must have data at this version).

Then restart all your binaries, it should start working.

# Transaction Filtering

> Filter transactions in the Transaction Stream Service using our custom DSL

## Overview

With the release of Indexer gRPC v2, we introduce the feature of transaction filtering.
Transaction filtering enables you to selectively process transactions from the Aptos blockchain based on specific criteria.
This is particularly useful when building indexers or services that only need to process a subset of all transactions, such as:

- Tracking specific smart contract interactions
- Monitoring wallet activity for certain addresses
- Indexing events from particular modules
- Processing only successful transactions

The source code can be found in [aptos-core](https://github.com/aptos-labs/aptos-core/tree/main/ecosystem/indexer-grpc/transaction-filter).

## Protocol Buffers (Proto) Definitions

Transaction filters are applied by including them in the gRPC request to the transaction stream.

### Filter Proto Structure

The filtering system is defined in [`aptos/indexer/v1/filter.proto`](https://github.com/aptos-labs/aptos-core/blob/main/protos/proto/aptos/indexer/v1/filter.proto):

```protobuf
message BooleanTransactionFilter {
  oneof filter {
    APIFilter api_filter = 1;
    LogicalAndFilters logical_and = 2;
    LogicalOrFilters logical_or = 3;
    BooleanTransactionFilter logical_not = 4;
  }
}

message APIFilter {
  oneof filter {
    TransactionRootFilter transaction_root_filter = 1;
    UserTransactionFilter user_transaction_filter = 2;
    EventFilter event_filter = 3;
  }
}
```

### gRPC Request Integration

Filters are supplied as an **optional** parameter in the `GetTransactionsRequest` message:

```protobuf
message GetTransactionsRequest {
  // Required; start version of current stream.
  optional uint64 starting_version = 1;

  // Optional; number of transactions to return in current stream.
  optional uint64 transactions_count = 2;

  // Optional; number of transactions in each response batch.
  optional uint64 batch_size = 3;

  // Optional; if provided, only transactions matching the filter are included.
  optional BooleanTransactionFilter transaction_filter = 4;
}
```

**Example:**

We can utilize the transaction filter to get all user transactions from [Geomi](https://geomi.dev/)'s gRPC endpoint:

```bash
grpcurl \
  -d '{"transaction_filter":{"api_filter":{"transaction_root_filter":{"transaction_type":"TRANSACTION_TYPE_USER"}}}}' \
  -max-msg-sz 30000000 \
  -H "authorization:Bearer <api_key>" \
  grpc.mainnet.aptoslabs.com:443 \
  aptos.indexer.v1.RawData/GetTransactions
```

**Key Points:**
- The `transaction_filter` field is **optional** - you can stream all transactions by omitting it
- When supplied, only transactions matching the filter criteria will be returned
- The filter is applied server-side, reducing bandwidth and processing overhead for clients
- Filters are validated before being applied; invalid filters will result in an error response

## How It Works

The transaction filter system uses a declarative approach where you specify what you want to match using filters, and then combine them using boolean logic (AND, OR, NOT). 
Filters can be defined in:

- **Rust code** using builder patterns
- **JSON** for API-based configuration
- **YAML** for configuration files

## Filter Types

There are three main types of filters you can use:

### 1. Transaction Root Filter

Filters transactions based on top-level transaction properties.

**Available Fields:**
- `success` (boolean): Whether the transaction succeeded or failed
- `txn_type` (enum): The type of transaction (User, Genesis, BlockMetadata, StateCheckpoint, Validator, BlockEpilogue)

**Example:**

```json
{
  "type": "TransactionRootFilter",
  "txn_type": "User",
  "success": true
}
```

### 2. User Transaction Filter

Filters user-submitted transactions based on sender and entry function details.

**Available Fields:**
- `sender` (string): The account address that submitted the transaction
- `payload`: Filter on the entry function being called
  - `function`: Entry function details
    - `address` (string): Contract address
    - `module` (string): Module name
    - `function` (string): Function name

**Example:**

```json
{
  "type": "UserTransactionFilter",
  "sender": "0x1",
  "payload": {
    "function": {
      "address": "0x1",
      "module": "coin",
      "function": "transfer"
    }
  }
}
```

### 3. Event Filter

Filters transactions based on events they emit.

**Available Fields:**
- `struct_type`: Filter on the event's Move struct type
  - `address` (string): Contract address
  - `module` (string): Module name
  - `name` (string): Struct name
- `data_substring_filter` (string): Filter events by a substring in their data

**Example 1 - Filter by struct type:**

```json
{
  "type": "EventFilter",
  "struct_type": {
    "address": "0x1",
    "module": "coin",
    "name": "CoinDeposit"
  }
}
```

**Example 2 - Filter by data substring:**

```json
{
  "type": "EventFilter",
  "data_substring_filter": "transfer"
}
```

**Example 3 - Combine struct type and data substring:**

```json
{
  "type": "EventFilter",
  "struct_type": {
    "address": "0x1",
    "module": "coin"
  },
  "data_substring_filter": "0xabc123"
}
```

## Combining Filters with Boolean Logic

Filters can be combined using logical operators to create complex queries:

### AND Operator

Matches transactions that satisfy **all** of the specified filters.

```json
{
  "and": [
    {
      "type": "TransactionRootFilter",
      "success": true
    },
    {
      "type": "EventFilter",
      "struct_type": {
        "address": "0x1",
        "module": "coin",
        "name": "CoinDeposit"
      }
    }
  ]
}
```

### OR Operator

Matches transactions that satisfy **any** of the specified filters.

```json
{
  "or": [
    {
      "type": "UserTransactionFilter",
      "sender": "0xabc..."
    },
    {
      "type": "UserTransactionFilter",
      "sender": "0xdef..."
    }
  ]
}
```

### NOT Operator

Matches transactions that **do not** satisfy the specified filter.

```json
{
  "not": {
    "type": "TransactionRootFilter",
    "success": false
  }
}
```

## Common Use Cases

### Filter Coin Transfer Transactions

Match all successful coin transfer transactions:

```json
{
  "and": [
    {
      "type": "TransactionRootFilter",
      "success": true
    },
    {
      "type": "UserTransactionFilter",
      "payload": {
        "function": {
          "address": "0x1",
          "module": "coin",
          "function": "transfer"
        }
      }
    }
  ]
}
```

### Filter by Specific Sender

Track all transactions from a specific wallet:

```json
{
  "type": "UserTransactionFilter",
  "sender": "0x806b27f3d7824a1d78c4291b6d0371aa693437f9eb3393c6440519c0ffaa627f"
}
```

### Filter by Multiple Senders

Track transactions from multiple wallets:

```json
{
  "or": [
    {
      "type": "UserTransactionFilter",
      "sender": "0xabc..."
    },
    {
      "type": "UserTransactionFilter",
      "sender": "0xdef..."
    }
  ]
}
```

### Filter NFT Events

Track NFT minting events from a specific collection:

```json
{
  "type": "EventFilter",
  "struct_type": {
    "address": "0x4",
    "module": "aptos_token",
    "name": "MintTokenEvent"
  }
}
```

### Filter Smart Contract Interactions

Track all interactions with a specific smart contract module:

```json
{
  "type": "EventFilter",
  "struct_type": {
    "address": "0x123abc...",
    "module": "my_defi_module"
  }
}
```

### Complex Filter: DEX Trading

Track successful swap events from multiple DEX protocols:

```json
{
  "and": [
    {
      "type": "TransactionRootFilter",
      "success": true
    },
    {
      "or": [
        {
          "type": "EventFilter",
          "struct_type": {
            "address": "0xdex1",
            "module": "swap",
            "name": "SwapEvent"
          }
        },
        {
          "type": "EventFilter",
          "struct_type": {
            "address": "0xdex2",
            "module": "pool",
            "name": "TradeEvent"
          }
        }
      ]
    }
  ]
}
```

### Exclude Failed Transactions

Get all user transactions except failed ones:

```json
{
  "and": [
    {
      "type": "UserTransactionFilter",
      "sender": "0xabc..."
    },
    {
      "type": "TransactionRootFilter",
      "success": true
    }
  ]
}
```

## YAML Format

Filters can also be expressed in YAML format, which is often more readable for configuration files:

```yaml
and:
  - or:
      - type: TransactionRootFilter
        success: true
      - type: UserTransactionFilter
        sender: '0x1'
  - type: EventFilter
    struct_type:
      address: '0x1'
      module: coin
      name: CoinDeposit
```

## Using Filters in Rust

If you're building with Rust, you can use the `aptos-transaction-filter` crate with builder patterns:

### Basic Filter

```rust
use aptos_transaction_filter::{TransactionRootFilterBuilder, BooleanTransactionFilter};

// Create a filter for successful transactions
let filter = TransactionRootFilterBuilder::default()
    .success(true)
    .build()
    .unwrap();

let boolean_filter = BooleanTransactionFilter::from(filter);
```

### Event Filter

```rust
use aptos_transaction_filter::{EventFilterBuilder, MoveStructTagFilterBuilder};

let filter = EventFilterBuilder::default()
    .struct_type(
        MoveStructTagFilterBuilder::default()
            .address("0x1")
            .module("coin")
            .name("CoinDeposit")
            .build()
            .unwrap()
    )
    .build()
    .unwrap();
```

### User Transaction Filter

```rust
use aptos_transaction_filter::{UserTransactionFilterBuilder, EntryFunctionFilterBuilder, UserTransactionPayloadFilterBuilder};

let filter = UserTransactionFilterBuilder::default()
    .sender("0x1")
    .payload(
        UserTransactionPayloadFilterBuilder::default()
            .function(
                EntryFunctionFilterBuilder::default()
                    .address("0x1")
                    .module("coin")
                    .function("transfer")
                    .build()
                    .unwrap()
            )
            .build()
            .unwrap()
    )
    .build()
    .unwrap();
```

### Combining Filters

```rust
use aptos_transaction_filter::BooleanTransactionFilter;

// Create individual filters
let success_filter = TransactionRootFilterBuilder::default()
    .success(true)
    .build()
    .unwrap();

let sender_filter = UserTransactionFilterBuilder::default()
    .sender("0x1")
    .build()
    .unwrap();

let event_filter = EventFilterBuilder::default()
    .struct_type(
        MoveStructTagFilterBuilder::default()
            .address("0x1")
            .module("coin")
            .build()
            .unwrap()
    )
    .build()
    .unwrap();

// Combine with logical operators
let combined = BooleanTransactionFilter::from(success_filter)
    .or(sender_filter)
    .and(event_filter);

// Use the filter
if combined.matches(&transaction) {
    // Process transaction
}
```

### Serialization

```rust
// Serialize to JSON
let json = serde_json::to_string_pretty(&filter).unwrap();

// Serialize to YAML
let yaml = serde_yaml::to_string(&filter).unwrap();

// Deserialize from JSON
let filter: BooleanTransactionFilter = serde_json::from_str(&json).unwrap();
```

## Performance Considerations

The transaction filter system is optimized for high-throughput processing:

1. **Single Pass**: Filters process each transaction only once
2. **Minimal Allocations**: Filters avoid clones and unnecessary copies
3. **Early Exit**: Filters short-circuit as soon as a non-match is found
4. **Address Caching**: Address standardization is cached for performance

For best performance:
- Use specific filters when possible (e.g., filter by address rather than all transactions)
- Place more restrictive filters first in AND operations
- Consider the transaction volume on mainnet when designing filters

# SDKs Overview

> Comprehensive software development kits for building on Aptos blockchain in TypeScript, Python, Go, Rust, C#, C++, Unity and more languages

import { CardGrid, LinkCard } from '@astrojs/starlight/components';

## Official SDKs

Use these Aptos software development kits (SDKs), in combination with the [Aptos CLI](/build/cli) for your development on the Aptos blockchain.

<CardGrid>
  <LinkCard href="/build/sdks/ts-sdk" title="Typescript SDK" description="Aptos Typescript SDK (recommended)" />

  <LinkCard href="/build/sdks/python-sdk" title="Python SDK" description="Aptos Python SDK" />

  <LinkCard href="/build/sdks/go-sdk" title="Go SDK" description="Aptos Go SDK" />

  <LinkCard href="/build/sdks/dotnet-sdk" title="C#/.NET SDK" description="Aptos .NET SDK" />

  <LinkCard href="/build/sdks/rust-sdk" title="Rust SDK" description="Aptos Rust SDK" />

  <LinkCard href="/build/sdks/cpp-sdk" title="C++ / Unreal SDK" description="Aptos C++ / Unreal SDK" />

  <LinkCard href="/build/sdks/unity-sdk" title="Unity SDK" description="Aptos Unity SDK" />

  <LinkCard href="/build/sdks/wallet-adapter" title="Wallet Adapter" description="Aptos Wallet Adapter" />
</CardGrid>

## [Community SDKs](/build/sdks/community-sdks)

SDKs provided by the community for Aptos.  These may not be fully vetted by the
Aptos team, and may still be in development. They are still provided as a
resource for all developers.

<CardGrid>
  <LinkCard href="/build/sdks/community-sdks/kotlin-sdk" title="Kotlin SDK" description="Aptos Kotlin Multiplatform SDK by Kaptos" />

  <LinkCard href="/build/sdks/community-sdks/swift-sdk" title="Swift SDK" description="Aptos Swift SDK by Alcove" />
</CardGrid>

# Community SDKs

> Community-built SDKs for Aptos including Swift, Kotlin, and other programming languages

import { CardGrid, LinkCard } from '@astrojs/starlight/components';

Here is a list of community-built SDKs for Aptos.  These may not be fully vetted by the Aptos team, and may still be in development.
They are still provided as a resource for all developers.

## SDKs

<CardGrid>
  <LinkCard href="/build/sdks/community-sdks/kotlin-sdk" title="Kotlin SDK" description="Aptos Kotlin Multiplatform SDK by Kaptos" />

  <LinkCard href="/build/sdks/community-sdks/swift-sdk" title="Swift SDK" description="Aptos Swift SDK by Alcove" />
</CardGrid>

# Kaptos - Kotlin SDK

> Kaptos - A Kotlin Multiplatform SDK for building cross-platform applications on the Aptos blockchain

import { Aside, CardGrid, LinkCard, TabItem, Tabs } from '@astrojs/starlight/components';

import { RemoteCodeblock } from '~/components/RemoteCodeblock';

Kaptos is a Kotlin **Multiplatform** SDK for interacting with the Aptos blockchain
across various platforms. It offers a **consistent** API for data requests,
transaction submissions, and more, facilitating cross-platform app development
with shared business logic. The SDK includes **asynchronous** Aptos clients for
smooth blockchain interactions.

Kaptos also provides **platform-specific** SDKs for JVM, Android, iOS, JS, Linux,
macOS, and Windows.

<div className="flex gap-2 mt-6 flex-wrap">
  <img src="http://img.shields.io/badge/Platform-Android-brightgreen.svg?logo=android" alt="Android Badge" />

  <img src="http://img.shields.io/badge/Platform-iOS-orange.svg?logo=apple" alt="iOS Badge" />

  <img src="http://img.shields.io/badge/Platform-tvOS-lightgrey.svg?logo=apple" alt="tvOS Badge" />

  <img src="http://img.shields.io/badge/Platform-watchOS-lightgrey.svg?logo=apple" alt="watchOS Badge" />

  <img src="http://img.shields.io/badge/Platform-NodeJS-yellow.svg?logo=javascript" alt="NodeJS Badge" />

  <img src="http://img.shields.io/badge/Platform-JVM-red.svg?logo=openjdk" alt="JVM Badge" />

  <img src="http://img.shields.io/badge/Platform-Linux-lightgrey.svg?logo=linux" alt="Linux Badge" />

  <img src="http://img.shields.io/badge/Platform-macOS-orange.svg?logo=apple" alt="macOS Badge" />

  <img src="http://img.shields.io/badge/Platform-Windows-blue.svg?logo=windows" alt="Windows Badge" />
</div>

<div className="flex gap-2 mt-6 flex-wrap">
  <img src="https://img.shields.io/maven-central/v/xyz.mcxross.kaptos/kaptos.svg?label=Maven%20Central" alt="Maven Central" />

  <a target="_blank" href="https://mcxross.github.io/kaptos/">
    ![Static Badge](https://img.shields.io/badge/SDK_Reference-Docs)
  </a>
</div>

## Features

- **Type-safe**: The SDK is fully type-safe and provides a rich set of types for all operations.
- **Expressive**: Kaptos provides a simple and expressive DSL-style API for building transactions.
- **Multiplatform**: Write cross-platform applications with shared business logic.
- **Consistent API**: All operations bare a uniform and consistent API across all platforms.
- **BCS Support**: The SDK defaults to BCS for serialization and deserialization of transactions.
- **Asynchronous**: All blockchain operations are asynchronous.
- **Configurable**: The SDK provides highly configurable clients for all platforms.

<Aside type="note">
  Kaptos is currently under development, please give feedback [here](https://github.com/mcxross/kaptos/issues)
</Aside>

## Installation

<Tabs>
  <TabItem label="Multiplatform">
    ```kotlin
    commonMain.dependencies {
      implementation("xyz.mcxross.kaptos:kaptos:<version>")
    }
    ```
  </TabItem>

  <TabItem label="JVM">
    ```kotlin
    jvmMain.dependencies {
      implementation("xyz.mcxross.kaptos:kaptos-jvm:<version>")
    }
    ```
  </TabItem>

  <TabItem label="Android">
    ```kotlin
    androidMain.dependencies {
      implementation("xyz.mcxross.kaptos:kaptos-android:<version>")
    }
    ```

    <Aside type="note" emoji="‚ÑπÔ∏è">
      The Android SDK provides flavors for both release and debug builds.
      To use the debug flavor, add the following to your `build.gradle`:

      ```kotlin
      androidMain.dependencies {
        implementation("xyz.mcxross.kaptos:kaptos-android-debug:<version>")
      }
      ```
    </Aside>
  </TabItem>

  <TabItem label="iOS">
    The SDK is compatible with iosArm64, iosX64, and iosSimulatorArm64. Depending
    on how your project is configured, you can add the following dependencies:

    For iosArm64:

    ```kotlin
    iosMain.dependencies {
      implementation("xyz.mcxross.kaptos:kaptos-iosArm64:<version>")
    }
    ```

    For iosX64:

    ```kotlin
    iosMain.dependencies {
      implementation("xyz.mcxross.kaptos:kaptos-iosX64:<version>")
    }
    ```
  </TabItem>

  <TabItem label="JS">
    ```kotlin
    jsMain.dependencies {
      implementation("xyz.mcxross.kaptos:kaptos-js:<version>")
    }
    ```
  </TabItem>

  <TabItem label="Linux">
    The SDK only supports Linux x64. To add the dependency, use the following:

    ```kotlin
    linuxMain.dependencies {
      implementation("xyz.mcxross.kaptos:kaptos-linux:<version>")
    }
    ```
  </TabItem>

  <TabItem label="macOS">
    The SDK only supports macOS x64, macOS arm64, and macOS arm64 simulator.
    To add the dependency, use the following:

    For macOS x64:

    ```kotlin
    macosMain.dependencies {
      implementation("xyz.mcxross.kaptos:kaptos-macosX64:<version>")
    }
    ```

    For macOS arm64:

    ```kotlin
    macosMain.dependencies {
      implementation("xyz.mcxross.kaptos:kaptos-macosArm64:<version>")
    }
    ```
  </TabItem>

  <TabItem label="Windows">
    The SDK only supports Windows x64. To add the dependency, use the following:

    ```kotlin
    mingwMain.dependencies {
      implementation("xyz.mcxross.kaptos:kaptos-mingwX64:<version>")
    }
    ```
  </TabItem>
</Tabs>

## Perform a Transaction

Below is an example of how you can perform a transaction using the Kotlin SDK.
The snippet demonstrates how to build a transaction to transfer APT. We then
sign and submit the transaction to the blockchain in a single step.

<RemoteCodeblock permalink="https://github.com/mcxross/kaptos/blob/64731d7085bfa64e93941aad78ba5ac429787552/sample/jvmApp/src/main/kotlin/APTTransfer.kt#L59-L71" />

The SDK also provides pre-built methods for common transaction operations. For
example, you can use the `transferCoinTransaction` method to generate a transfer
transaction between two accounts as shown below:

```kotlin
val txn = aptos.transferCoinTransaction(
     alice.accountAddress,
     bob.accountAddress,
     SEND_AMOUNT
   )
```

You can then [sign](/build/sdks/community-sdks/kotlin-sdk/building-transactions#sign-the-transaction) and
[submit](/build/sdks/community-sdks/kotlin-sdk/building-transactions#submit-the-transaction) this transaction.

## Examples

For more examples on how and what you can do with the Kotlin SDK, check out the
following:

<CardGrid>
  <LinkCard href="/build/sdks/community-sdks/kotlin-sdk/quickstart" title="Quickstart" description="Integrate Aptos in < 5 minutes" />

  <LinkCard href="https://github.com/mcxross/kaptos/tree/master/sample" title="Single and Multiplatform Projects" description="Explore various demo apps, single and multiplatform projects, on how using the SDK" target="_blank" />
</CardGrid>

# Creating and Managing Accounts

> Learn how to create and manage both legacy and SingleKey accounts using the Kaptos Kotlin SDK

**Kaptos** provides a few ways to generate account credentials, both _legacy_ and
`SingleKeyAccount`s. You can either generate a new account or derive
an account from a private key.

## Legacy Account

**Kaptos** offers a straightforward method to generate a legacy account using the
`Account` class. By invoking the static method `generate()`, you can create a new
legacy account either by passing no arguments or by explicitly setting
the `scheme` to `SigningSchemeInput.Ed25519` and the `legacy` property to `true` as
shown below.

### Generate a New Account

To create a new legacy account, you can generate a new account credential using the
`Account.generate()` method. This method will create a new account with a new
key pair.

```kotlin
val account = Account.generate()
```

You can also use the `Ed25519Account` class that provides a **nullary** method,
`generate()`, to create a new account:

```kotlin
val account = Ed25519Account.generate()
```

### Derive an Account from a Private Key

If you have a private key, you can use it to create an `Account` object to manage
those credentials.

```kotlin
val privateKey = Ed25519PrivateKey("myEd25519privatekeystring")

val account = Account.fromPrivateKey(privateKey)
```

## Single Key Account

The SDK offers two ways to generate a single key account: using either the
`SingleKeyAccount` or the `Account` class. In both cases, you can create a
new account by calling the static `generate()` method. You‚Äôll need to specify
the `scheme`, and for the `Account` class, you can optionally set the `legacy`
property to `false`.

```kotlin
val secp256k1SKAccount = SingleKeyAccount.generate(SigningSchemeInput.Secp256k1)
val ed25519SKAccount = SingleKeyAccount.generate(SigningSchemeInput.Ed25519)
```

Using the `Account` class, you can create a new single key account by setting
the `scheme` to `SigningSchemeInput.Secp256k1` and optionally setting the
`legacy` property to `false`. Alternatively, you can set the `scheme` to
`SigningSchemeInput.Ed25519` and ensure the `legacy` property is also
set to `false`.

```kotlin
val secp256k1SKAccount = Account.generate(scheme = SigningSchemeInput.Secp256k1)
val ed25519SKAccount = Account.generate(scheme = SigningSchemeInput.Ed25519, legacy = false)
```

## On-chain Account Creation

It is also worth noting that Account generation does not create the account
on-chain. You must fund the account on-chain to use it for transactions.
On test networks, you can fund an account programmatically by asking a
"faucet" for test tokens. You can do this as shown below:

```kotlin
val fundedAccount = aptos.fundAccount(aliceAccount.accountAddress, FUNDING_AMOUNT)
```

This only works on devnet. On testnet you can mint at the [mint page](/network/faucet).

# Building and Sending Transactions

> Build and submit transactions on Aptos using Kaptos' expressive and type-safe DSL-style API

import { Aside, Steps } from '@astrojs/starlight/components';

Kaptos boasts an expressive and type-safe DSL-style API for building and sending
transactions on-chain. This guide will walk you through the process of building
and sending transactions using Kaptos.

The typical flow for sending a transaction is as follows:

1. Create an account (if you don't already have one).
2. Build the transaction.
3. Sign the transaction.
4. Submit the transaction.

<Steps>
  1) Create an Account

     To create a new account, you first generate new credentials then fund the
     account. On devnet, you can fund an account programmatically by asking
     a "faucet".

     ```kotlin
     val aliceAccount = Account.generate()
     val bobAccount = Account.generate()
     ```

     OR

     If you have a private key, you can use it to create an `Account` object to manage
     those credentials.

     ```kotlin
     val privateKey = Ed25519PrivateKey("myEd25519privatekeystring")
     val account = Account.fromPrivateKey(privateKey)
     ```

     On testnet you can mint at the [mint page](/network/faucet).

  2) Build the Transaction

     Kaptos provides a `buildTransaction.simple` method to build a transaction. You can specify
     the sender, entry function data like the function name, type arguments, and function arguments.
     You can also configure the transaction with the gas price and maximum gas amount. However, reasonable
     defaults are provided for these values in case you don't specify them.

     ```kotlin
     val txn = aptos.buildTransaction.simple(
         sender = aliceAccount.accountAddress,
         data = entryFunctionData {
             function = "0x1::coin::transfer"
             typeArguments = typeArguments {
                 +TypeTagStruct("0x1::aptos_coin::AptosCoin")
             }
             functionArguments = functionArguments {
                 +bobAccount.accountAddress
                 +U64(SEND_AMOUNT)
             }
         },
     )
     ```

  3) Sign the Transaction

     Once you have built a transaction, you can sign it using the `sign` method.

     ```kotlin
       val aliceAuthenticator = aptos.sign(
           sender = aliceAccount,
           transaction = txn,
       )
     ```

  4) Submit the Transaction

     Finally, you can submit the transaction to the network using the `submit` method.

     ```kotlin
     val committedTransaction = aptos.submitTransaction.simple(
         transaction = signedTransaction,
         senderAuthenticator = aliceAuthenticator,
     )
     ```

     <Aside type="note" emoji="‚ÑπÔ∏è">
       You can collapse the signing and submitting steps into one by using the `signAndSubmitTransaction` method.

       ```kotlin
       val executedTransaction = aptos.signAndSubmitTransaction(
           signer = aliceAccount,
           transaction = signedTransaction,
       )
       ```
     </Aside>

  5) Wait for the Transaction to Execute

     Then you can wait for the transaction to be executed by using the `waitForTransaction` method.

     ```kotlin
     val executedTransaction = aptos.waitForTransaction(HexInput.fromString(committedTransaction.expect("Transaction failed").hash))
     ```
</Steps>

### Full Kotlin Example

The following is a complete example of how to build and send a transaction to transfer APT:

```kotlin filename="transaction.kt"

const val FUNDING_AMOUNT = 100_000_000L
const val SEND_AMOUNT_APT = 0.5f
const val UNIT_CONVERSION = 100_000_000
const val SEND_AMOUNT_UNITS = (SEND_AMOUNT_APT * UNIT_CONVERSION)
const val SEND_AMOUNT = 1_000_000UL

/**
 * This example demonstrates how to transfer APT from one account to another.
 *
 * Each run generates and creates new accounts on-chain using faucet funding. After funding, the APT
 * balance of each account is printed; if funding fails, an error is thrown.
 *
 * Next, a transaction is constructed to send 0.5 APT from Alice to Bob. The transaction is then
 * signed and submitted using the one-step `signAndSubmitTransaction` method. We wait for the
 * transaction to complete and print the updated balances of Alice and Bob. If the transaction
 * fails, an error is thrown.
 */
fun main() = runBlocking {
  val aptos = Aptos(AptosConfig(AptosSettings(network = Network.DEVNET)))

  println("Generating Alice and Bob's accounts")

  val alice = Account.generate()
  val bob = Account.generate()

  aptos.fundAccount(alice.accountAddress, FUNDING_AMOUNT).expect("Failed to fund Alice's account")
  aptos.fundAccount(bob.accountAddress, FUNDING_AMOUNT).expect("Failed to fund Bob's account")

  println("Created accounts on chain")
  println("Alice's balance: ${aptos.getAccountAPTAmount(alice.accountAddress)}")
  println("Bob's balance: ${aptos.getAccountAPTAmount(bob.accountAddress)}")
  println("=============================================")
  println(
    "Building transaction to send ${SEND_AMOUNT / 100_000_000u} APT to Bob: ${bob.accountAddress}"
  )

  val txn =
    aptos.buildTransaction.simple(
      sender = alice.accountAddress,
      data =
        entryFunctionData {
          function = "0x1::coin::transfer"
          typeArguments = typeArguments { +TypeTagStruct("0x1::aptos_coin::AptosCoin") }
          functionArguments = functionArguments {
            +bob.accountAddress
            +U64(SEND_AMOUNT_UNITS.toULong())
          }
        },
    )

  // Sign and submit the transaction
  val committedTransaction = aptos.signAndSubmitTransaction(alice, txn)

  val executedTransaction =
    aptos.waitForTransaction(
      HexInput.fromString(committedTransaction.expect("Transaction failed").hash)
    )

  println(
    "Transaction wait response: $executedTransaction\n============================================="
  )

  val aliceNewBalance =
    aptos.getAccountAPTAmount(alice.accountAddress).expect("Alice's account does not exist")
  val bobNewBalance =
    aptos.getAccountAPTAmount(bob.accountAddress).expect("Bob's account does not exist")

  println("Alice's new balance: $aliceNewBalance")
  println("Bob's new balance: $bobNewBalance")
}

```

# Client Configuration

> Configure Kaptos clients with shared and platform-specific options to customize behavior across different platforms

Whilst **Kaptos** offers a **consistent interface** for interacting with Aptos
across all supported platforms, it also features both shared and
platform-specific configuration options for its various clients.

These configuration options allow you to customize the behavior of the client to
suit your needs. They can be set by creating a `ClientConfig` object and passing
it to the `AptosSettings` object when creating an `Aptos` client as shown below:

```kotlin
val clientConfig = ClientConfig(followRedirects = false, retryOnServerErrors = 3)
val client = Aptos(AptosConfig(AptosSettings(clientConfig = clientConfig)))
```

This page will guide you through the available configuration options for
each platform.

### Shared Configuration

`followRedirects` ‚Äî A boolean value that determines whether the client should
follow redirects. The default value is `true`.

`retryOnServerErrors` ‚Äî The number of times to retry the request if a server error
occurs. The default value is `‚Äî1`, which means no retries.

`requestTimeout` ‚Äî The timeout in milliseconds for the request. The default value
is `10_000`.

`maxRetries` ‚Äî The maximum number of times to retry the request. The default value
is `-1`, which means no retries.

`agent` ‚Äî A `String` that specifies the user agent to use for the connection.
Defaults to `Kaptos/{PLATFORM}`.

`likeAgent` ‚Äî A `UserAgent` enum value that specifies the user agent to use for the
connection.

`proxy` ‚Äî A `String` that specifies the proxy server to use for the connection.

`cache` ‚Äî A boolean value that determines whether to cache the response. The default
value is `false`.

### JVM Configuration

`pipelining` ‚Äî A boolean value that determines whether the client should use
pipelining. The default value is `false`.

`pipelineMaxSize` ‚Äî The maximum number of requests to pipeline. The default value
is `20`.

`maxConnectionsPerRoute` ‚Äî The maximum number of connections per route. The default
value is `100`.

`maxConnectionsCount` ‚Äî The maximum number of connections. The default value is
`100`.

`connectTimeoutMillis` ‚Äî The timeout in milliseconds for establishing a connection
to the server. The default value is `10_000`.

`keepAliveTime` ‚Äî The time in milliseconds to keep a connection alive. The default
value is `5_000`.

`connectAttempts` ‚Äî The number of times to attempt to connect to the server. The
default value is `5`.

`connectTimeout` ‚Äî The timeout in milliseconds for establishing a connection to the
server. The default value is `10_000`.

### Android Configuration

`followSslRedirects` ‚Äî A boolean value that determines whether the client should
follow SSL redirects. The default value is `true`.

`connectTimeoutMillis` ‚Äî The timeout in milliseconds for establishing a connection
to the server. The default value is `10_000`.

`readTimeoutMillis` ‚Äî The timeout in milliseconds for reading data from the server.
The default value is `10_000`.

`writeTimeoutMillis` ‚Äî The timeout in milliseconds for writing data to the server.
The default value is `10_000`.

`maxRetries` ‚Äî The maximum number of times to retry the request. The default value
is `-1`, which means no retries.

`connectTimeout` ‚Äî The timeout in milliseconds for establishing a connection to the
server. The default value is `10_000`.

### Apple (iOS, macOS) Configuration

Apple platforms currently do not have any platform-specific configuration options.

### Web Configuration

Web platforms currently do not have any platform-specific configuration options.

### Linux Configuration

`connectTimeout` ‚Äî The timeout in milliseconds for establishing a connection to the
server. The default value is `10_000`.

### Windows Configuration

`connectTimeout` ‚Äî The timeout in milliseconds for establishing a connection to the
server. The default value is `10_000`.

# Fetch Data via the Kotlin SDK

> Retrieve on-chain data and network information using the Kaptos client with idiomatic Option-based error handling

You can use the Aptos client to fetch all sorts of data from on-chain such as
information about the network itself or account-specific information.

```kotlin
val modules = aptos.getAccountModules("0x123").expect("Failed to fetch account modules")
val option = aptos.getChainTopUserTransactions(10)
```

Kaptos returns an `Option` type for all network requests. This allows you to handle
both successful and failed requests in a more idiomatic way.

```kotlin
val ledgerInfo = aptos.getLedgerInfo()
when (ledgerInfo) {
    is Some -> println("Ledger Info: ${ledgerInfo.value}")
    is None -> println("Failed to fetch ledger info")
}
```

If you trust the result exists, you can use the `.expect` function to unwrap the value.

```kotlin
val ledgerInfo = aptos.getLedgerInfo().expect("Failed to fetch ledger info")
```

### Using Move View Functions

You can call view functions which return custom data from on-chain by using the
`.view` method on the `Aptos` object.
The user specifies the return type of the view function as a type parameter.

For example, you can look up the supply of tokens as follows:

```kotlin
val inputViewFunctionData = InputViewFunctionData(
      "0x1::coin::supply",
      listOf(TypeTagStruct("0x1::aptos_coin::AptosCoin")),
      emptyList(),)

  val view = aptos
      .view<List<MoveValue.MoveListType<MoveValue.String>>>(inputViewFunctionData)
      .expect("Failed to fetch view")
```

# Swift SDK

> AptosKit - A Swift SDK for iOS developers to interact with the Aptos blockchain, built on Kaptos

import { Aside, CardGrid, LinkCard } from '@astrojs/starlight/components';

**AptosKit** is a Swift SDK for interacting with the Aptos blockchain.
It provides a simple and easy-to-use interface for interacting with the Aptos
blockchain.

The SDK is a Swift package export for [Kaptos](/build/sdks/community-sdks/kotlin-sdk), a Kotlin SDK for
the Aptos blockchain. It is build by making its iOS binary available as a
dependency to iOS developers working on native Swift projects.

<Aside type="note">
  **AptosKit** is currently under development, please give feedback [here](https://github.com/mcxross/swift-aptos/issues)
</Aside>

## Installation

To install **AptosKit**, add the following to your `Package.swift` file:

```swift filename="Package.swift"
dependencies: [
    .package(url: "https://github.com/mcxross/swift-aptos.git", .upToNextMajor(from: <version>))
]
```

## Example

<CardGrid>
  <LinkCard href="/build/sdks/community-sdks/kotlin-sdk/for-ios-devs/getting-started" title="Quickstart" description="Integrate Aptos in < 5 minutes" />

  <LinkCard href="https://github.com/mcxross/swift-aptos/tree/main/iOSDemo/iOSDemo" title="iOS Demo" description="Sample iOS app using AptosKit" target="_blank" />
</CardGrid>

# Getting Started with Kaptos For iOS Developers

> Get started with AptosKit for iOS development - a Swift SDK for interacting with the Aptos blockchain

import { Steps } from '@astrojs/starlight/components';

This guide will walk you through the process of setting up **AptosKit**, and
fetching data on the Aptos blockchain.

<Steps>
  1. Install the SDK

     **AptosKit** is available as a Swift package. To add it to your project,
     add the following to your `Package.swift` file:

     ```swift filename="Package.swift"
     dependencies: [
       .package(url: "https://github.com/mcxross/swift-aptos.git", .upToNextMajor(from: <version>))
     ]
     ```

  2. Import the SDK

     Import the SDK in your Swift file:

     ```swift filename="Main.swift"
     import AptosKit
     ```

  3. Create the ClientConfig object

     This object is used to configure the client behavior. You can set `maxRetries`,
     `requestTimeout`, and `retryOnServerErrors` properties.

     ```swift filename="Main.swift"
     let config = ClientConfig(
         followRedirects: true,
         agent: "AptosClient",
         likeAgent: nil,
         requestTimeout: 5000,
         retryOnServerErrors: 3,
         maxRetries: 5,
         cache: false,
         proxy: nil
     )
     ```

  4. Create the AptosSettings object

     This object is used to configure the Aptos network connection. You can set `network`,
     `fullnode`, and `faucet` properties.

     ```swift filename="Main.swift"
     let aptosSettings = AptosSettings(
         network: .devnet,
         fullNode: nil,
         faucet: nil,
         indexer: nil,
         client: nil,
         clientConfig: config,
         fullNodeConfig: nil,
         indexerConfig: nil,
         faucetConfig: nil
     )
     ```

  5. Create the AptosConfig object

     ```swift filename="Main.swift"
     let aptosConfig = AptosConfig(settings: aptosSettings)
     ```

  6. Create the Aptos object

     This object is used to interact with the Aptos blockchain. It serves as the
     entry point for all interactions with the blockchain.

     ```swift filename="Main.swift"
     let aptos = Aptos(config: aptosConfig, graceFull: false)
     ```

  7. Fetch the chain ID

     ```swift filename="Main.swift"
     let chainId = try await aptos.getChainId()
     ```

     Congratulations! You have successfully set up the **AptosKit** SDK and fetched the chain ID from the Aptos blockchain.
</Steps>

## Complete Example

```swift filename="Main.swift"

import SwiftUI
import AptosKit

struct ContentView: View {
@State private var chainId: String? = nil

var body: some View {
  VStack {
    if let chainId = chainId {
      Text("Chain ID: \(chainId)")
    } else {
      Text("Fetching Chain ID...")
    }
  }
.padding()
    .onAppear {
    fetchChainId()
  }
}

private func fetchChainId() {
  DispatchQueue.main.async {
    Task {
      do {

        let clientConfig = ClientConfig(
            followRedirects: true,
            agent: "AptosClient",
            likeAgent: nil,
            requestTimeout: 5000,
            retryOnServerErrors: 3,
            maxRetries: 5,
            cache: false,
            proxy: nil
        )

        let aptosSettings = AptosSettings(
            network: .devnet,
            fullNode: nil,
            faucet: nil,
            indexer: nil,
            client: nil,
            clientConfig: clientConfig,
            fullNodeConfig: nil,
            indexerConfig: nil,
            faucetConfig: nil
        )

        let aptosConfig = AptosConfig(settings: aptosSettings)
        let aptos = Aptos(config: aptosConfig, graceFull: false)

        let chainId = try await aptos.getChainId()
        self.chainId = chainId.expect(message: "Failed...")?.stringValue ?? "null"
      } catch {
        print("Failed to get chain ID: \(error)")
        self.chainId = "Error"
        }
      }
    }
  }
}
```

# Kotlin SDK Quickstart

> Get started with Kaptos by setting up the SDK, fetching blockchain data, and sending transactions on Aptos

import { Aside, Steps } from '@astrojs/starlight/components';

This guide will walk you through the process of setting up Kaptos,
fetching data, and sending a transaction on the Aptos blockchain.

<Steps>
  1. Install the SDK

     Kaptos is available for both multiplatform and single-platform development.
     Artifacts are published at Sonatype Maven Central and can be added to your
     project using Gradle as shown below:

     #### Multiplatform Development

     In your `build.gradle.kts` file, and in your `commonMain` source set block, add as follows:

     ```kotlin
     kotlin {
         sourceSets {
             commonMain.dependencies {
                 implementation("xyz.mcxross.kaptos:kaptos:<version>")
             }
         }
     }
     ```

     #### Single-platform Development

     Depending on your target platform, Kaptos provides different artifacts in the
     form of `kaptos-jvm`, `kaptos-android`, `kaptos-iosArm64`, and `kaptos-js`.
     For example, to add the JVM artifact to your project, add the following dependency:

     ```kotlin
     dependencies {
         implementation("xyz.mcxross.kaptos:kaptos-jvm:<version>")
     }
     ```

     To add the Android artifact, use:

     ```kotlin
     dependencies {
         implementation("xyz.mcxross.kaptos:kaptos-android:<version>")
     }
     ```

  2. Set up the Aptos client

     You can use the `Aptos` object to handle everything that requires a connection
     to the Aptos network.

     ```kotlin
     val aptos = Aptos()
     ```

     If you want to pass in a custom configuration, you can do so by passing in a
     AptosConfig object that takes in an AptosSettings object. The AptosSettings object
     allows you to specify the network you want to connect to, the fullnode URL, and
     other settings.

     ```kotlin
     val settings = AptosSettings(network = Network.MAINNET, clientConfig = ClientConfig(maxRetries = 10))
     val aptosConfig = AptosConfig(settings = settings)
     val aptos = Aptos(aptosConfig)
     ```

     <Aside type="note" emoji="‚ÑπÔ∏è">
       Kaptos offers common configurations for all platforms while also providing
       platform-specific settings. For instance, you can configure both connection
       and request timeouts on Linux, whereas on iOS, you can only set request timeouts.
     </Aside>

  3. Fetch data from on-chain

     Once you have an `Aptos` object, you can use it to fetch data from the Aptos blockchain.
     For example, you can fetch the ledger information like so:

     ```kotlin
     val ledgerInfo = aptos.getLedgerInfo()
     ```

  4. Send Transactions

     To interact with the ledger and change its state, you must send transactions.
     To do this, you need an existing account. You can create an account by
     generating a new account key pair and funding the account on-chain.
     Once you have an account, you can sign transactions to demonstrate authority,
     allowing you to perform actions such as transferring tokens, triggering Move
     modules, or trading NFTs.

     Here's how you can build a transaction to transfer APT:

     <Steps>
       1. Create an Account

          To create a new account, you first generate new credentials then fund the account.
          On devnet networks, you can fund an account programmatically by asking a "faucet"

          ```kotlin
          val aliceAccount = Account.generate()
          val bobAccount = Account.generate()
          ```

          On testnet you can mint at the [mint page](/network/faucet).

       2. Build the Transaction

          ```kotlin
          val txn = aptos.buildTransaction.simple(
              sender = aliceAccount.accountAddress,
              data = entryFunctionData {
                  function = "0x1::coin::transfer"
                  typeArguments = typeArguments {
                      +TypeTagStruct("0x1::aptos_coin::AptosCoin")
                  }
                  functionArguments = functionArguments {
                      +bobAccount.accountAddress
                      +U64(SEND_AMOUNT)
                  }
          },)
          ```

       3. Sign the Transaction

          Once you have built a transaction, you can sign it using the `sign` method.

          ```kotlin
            val aliceAuthenticator = aptos.sign(
                sender = aliceAccount,
                transaction = txn,
            )
          ```

       4. Submit the Transaction

          Finally, you can submit the transaction to the network using the `submitTransaction.simple` method.

          ```kotlin
          val committedTransaction = aptos.submitTransaction.simple(
                transaction = signedTransaction,
                senderAuthenticator = aliceAuthenticator,
          )
          ```

       5. Wait for the Transaction to Execute

          Then you can wait for the transaction to be executed by using the `waitForTransaction` method.

          ```kotlin
          val executedTransaction = aptos.waitForTransaction(HexInput.fromString(committedTransaction.expect("Transaction failed").hash))
          ```
     </Steps>
</Steps>

# Sponsored Transactions (Fee Payer)

> Implement sponsored transactions with Kaptos where one account pays gas fees for another account's transactions

import { Aside } from '@astrojs/starlight/components';

The Kotlin SDK provides support for sponsored transactions also known as fee
payer transactions.

The standard flow for sending a sponsored transaction is as follows:

1. Determine upon **operation** by creating a **Transaction**
2. The **sender signs** the transaction
3. The **fee payer** signs the transaction
4. **Submit** the transaction

## Determine Upon Operation

As we'd already seen in the previous section, you can build a transaction by yourself
using the `buildTransaction.simple` method or use the pre-built transaction builders
like `transferCoinTransaction`. However, in the case of sponsored transactions, you
need to specify the optional `withFeePayer` parameter as `true` in all cases.

```kotlin
val txn = aptos.buildTransaction.simple(
      sender = alice.accountAddress,
      data =
        entryFunctionData {
          function = "0x1::coin::transfer"
          typeArguments = typeArguments { +TypeTagStruct("0x1::aptos_coin::AptosCoin") }
          functionArguments = functionArguments {
            +bob.accountAddress
            +U64(SEND_AMOUNT_UNITS.toULong())
          }
        },
      withFeePayer = true,
    )
```

OR

```kotlin
val txn = aptos.transferCoinTransaction(
      sender = alice,
      receiver = bob.accountAddress,
      amount = SEND_AMOUNT_UNITS,
      withFeePayer = true,
    )
```

## Sign the Transaction

Once you have built a transaction, you (the sender) can sign it using the `sign`
method.

```kotlin
val aliceAuthenticator = aptos.sign(
    sender = alice,
    transaction = txn,
)
```

## Sign the Transaction as Fee Payer

To sign the transaction as a fee payer, you can use the `signAsFeePayer` method.

```kotlin
val signerAuthenticator = aptos.signAsFeePayer(
    feePayer = sponsor,
    transaction = txn,
)
```

## Submit the Transaction

Finally, you can submit the transaction to the network using the `submit` method.

```kotlin
val committedTxn = aptos.submitTransaction.simple(
      transaction = txn,
      senderAuthenticator = aliceAuthenticator,
      feePayerAuthenticator = signerAuthenticator,
    )
```

<Aside type="note" emoji="‚ÑπÔ∏è">
  You can collapse the fee payer signing and submitting steps into one by using the `signAndSubmitAsFeePayer` method.

  ```kotlin
    val committedTxn = aptos.signAndSubmitAsFeePayer(sponsor, aliceAuthenticator, txn)
  ```
</Aside>

# Swift SDK

> Community-built Swift SDK for iOS development on the Aptos blockchain, created by Alcove Labs

There is a Swift SDK for Aptos, built by Alcove [here](https://github.com/ALCOVE-LAB/aptos-swift-sdk)

## Installing the Swift SDk

```swift
.package(url: "https://github.com/ALCOVE-LAB/aptos-swift-sdk.git", branch: "main")
```

## Using the Swift SDk

### Creating a client

You can create a client by importing the aptos-swift-sdk, and createing a `Client`

```swift
import Aptos

let client = Aptos(aptosConfig: .devnet)

```

You can configure the network with the AptosConfig.Network, or use a preexisting AptosConfig.devnet, AptosConfig.testnet, or AptosConfig.mainnet

### Creating a private key

You can create a new Ed25519 account‚Äôs private key by calling Account.generate().

```swift
let account = Account.generate()
```

Derive from private key

```swift

let privateKey = try Ed25519PrivateKey("myEd25519privatekeystring")
// or
let singleKeyPrivateKey = try Secp256k1PrivateKey(Secp256k1.privateKey)

let newAccount: Account.Ed25519Account = try Account.fromPrivateKey(privateKey)
let singleKeyAccount: Account.SingleKeyAccount = try Account.fromPrivateKey(singleKeyPrivateKey)
```

Derive from path

```swift
let path = "m/44'/637'/0'/0'/1"
let mnemonic = "various float stumble..."
let newAccount = try Account.fromDerivationPath(Wallet.path, mnemonic: Wallet.mnemonic)
```

### Funding accounts

You can create and fund an account with a faucet on devnet

```swift
let account = Account.generate()
let txn = try await client.faucet.fundAccount(accountAddress: account.accountAddress, amount: 100_000_000)
```

On testnet you can mint at the [mint page](/network/faucet).

### Sending a transaction

You can send a AptosCoin via a transaction

```swift
let txn: TransactionResponse
let senderAccount = Account.generate()
_ = try await aptos.faucet.fundAccount(accountAddress: senderAccount.accountAddress, amount: 100_000_000)
let bob = Account.generate()
// Build transaction
let rawTxn = try await aptos.transaction.build.simple(
    sender: senderAccount.accountAddress,
    data: InputEntryFunctionData(
        function: "0x1::aptos_account::transfer",
        functionArguments: [bob.accountAddress, 100]
    )
)
// Sign
let authenticator = try await aptos.transaction.sign.transaction(
    signer: senderAccount,
    transaction: rawTxn
)
// Submit
let response = try await aptos.transaction.submit.simple(
    transaction: rawTxn,
    senderAuthenticator: authenticator
)
// Wait
txn = try await aptos.transaction.waitForTransaction(transactionHash: response.hash)
// Read
let transaction = try await aptos.transaction.getTransactionByHash(txn.hash)

```

### Testing

To run the SDK tests, simply run from the root of this repository:

> Note: for a better experience, make sure there is no aptos local node process up and running (can check if there is a ?process running on port 8080).

```swift
swift test
```

# Unity SDK (Legacy)

> Legacy Unity SDK for multi-platform game development on Aptos - now superseded by the official Unity SDK

import { Aside } from '@astrojs/starlight/components';

<Aside type="caution" emoji="‚ùó">
  This SDK is currently unmaintained. You can use the official [Unity
  SDK](/build/sdks/unity-sdk) for the latest features.
</Aside>

The [Aptos Unity SDK](https://github.com/aptos-labs/Aptos-Unity-SDK) is a .NET implementation of the [Aptos SDK](/build/sdks), compatible with .NET Standard 2.0 and .NET 4.x for Unity. The goal of this SDK is to provide a set of tools for developers to build multi-platform applications (mobile, desktop, web, VR) using the Unity game engine and the Aptos blockchain infrastructure.

See the post [Aptos Labs brings Web3 to Gaming with its new SDK for Unity developers](https://medium.com/aptoslabs/aptos-labs-brings-web3-to-gaming-with-its-new-sdk-for-unity-developers-e6544bdf9ba9) and the [Technical details](https://github.com/aptos-labs/Aptos-Unity-SDK#technical-details) section of the Unity SDK README for all the features offered to game developers by the Aptos Unity SDK.

## User flows

The Aptos Unity SDK supports these use cases:

- _Progressive onboarding flow_ in which users can log into a game by email. In this flow, transactions are proxied, and Aptos uses a distributed key system. The users can then onboard to a full custodial wallet if desired.
- _In-game non-custodial wallet integration_ in which game developers have the option to allow users to create full non-custodial wallets in the games.
- _Off-game non-custodial wallet integration_ in which game developers may allow users to connect to a desktop wallet or a mobile wallet within the game or create burner wallets from the parent wallet seamlessly.

## Prerequisites

### Supported Unity versions

| Supported Version: | Tested |
| ------------------ | ------ |
| 2021.3.x           | ‚úÖ      |
| 2022.2.x           | ‚úÖ      |

| Windows | macOS | iOS | Android | WebGL |
| ------- | ----- | --- | ------- | ----- |
| ‚úÖ       | ‚úÖ     | ‚úÖ   | ‚úÖ       | ‚úÖ     |

### Dependencies

> As of Unity 2021.x.x, Newtonsoft Json is a common dependency. Prior versions of Unity require installing Newtonsoft.

- [Chaos.NaCl.Standard](https://www.nuget.org/packages/Chaos.NaCl.Standard/)
- Microsoft.Extensions.Logging.Abstractions.1.0.0 ‚Äî required by NBitcoin.7.0.22
- Newtonsoft.Json
- NBitcoin.7.0.22
- [Portable.BouncyCastle](https://www.nuget.org/packages/Portable.BouncyCastle)
- Zxing

## Install the Unity SDK

You may install the Unity SDK either through our `unitypackage` or the [Unity Package Manager](https://docs.unity3d.com/Manual/Packages.html).

### Install by `unitypackage`

1. Start Unity.
2. Download the latest `Aptos.Unity.unitypackage` file from the [Unity Asset Store](https://assetstore.unity.com/packages/decentralization/aptos-sdk-244713).
3. Click **Assets** ‚Üí **Import Packages** ‚Üí **Custom Package** and select the downloaded file.

### Install by Unity Package Manager

1. Open the [Unity Package Manager](https://docs.unity3d.com/Manual/upm-ui.html) window.
2. Click the add **+** button in the top status bar.
3. Select _Add package from git URL_ from the dropdown menu.
4. Enter the URL _[https://github.com/aptos-labs/Aptos-Unity-SDK.git](https://github.com/aptos-labs/Aptos-Unity-SDK.git)_ and click **Add**.

# C++ / Unreal SDK

> Community-built C++ SDK for Aptos blockchain development with Unreal Engine integration

There is a C++ / Unreal SDK for Aptos, built by Var Meta [here](https://github.com/VAR-META-Tech/Aptos-Cpp-SDK/)

## Installing the SDK

There are installation instructions, as well as usage instructions [here](https://github.com/VAR-META-Tech/Aptos-Cpp-SDK/?tab=readme-ov-file#installation-guide)

# .NET SDK

> Official .NET SDK for Aptos blockchain development with Unity and Godot integration support

import { Aside, CardGrid, LinkCard } from '@astrojs/starlight/components';

<Aside type="caution" emoji="‚ùó">
  This SDK is currently in beta. Please report any issues you encounter by
  creating an issue in the
  [aptos-labs/aptos-dotnet-sdk](https://github.com/aptos-labs/aptos-dotnet-sdk)
  repository.
</Aside>

Integrate Aptos Web3 capabilities within your .NET applications. The goal of this SDK is to provide a set of tools
for developers to build multi-platform applications across compatible game engines and platforms.

**Supported Features**

- Binary Canonical Serialization (BCS) encoding and decoding
- Ed25519, SingleKey, MultiKey, and Keyless signer support
- Utilities for transaction building, signing, and submission
- Abstractions over the Aptos Fullnode and Indexer APIs
- Aptos Names (ANS) support for resolution and lookup

## Installation

The .NET SDK is available on [NuGet](https://www.nuget.org/packages/Aptos).

You can install the .NET SDK using the following command:

```shellscript
dotnet add package Aptos
```

## Gaming Integrations

Begin using the Aptos .NET SDK in your game engine of choice.

<CardGrid>
  <LinkCard href="/build/sdks/dotnet-sdk/godot-integration" title="Godot Integration" description="Begin integrating into Godot projects." />

  <LinkCard href="/build/sdks/dotnet-sdk/unity-integration" title="Unity Integration" description="Begin integrating into Unity projects." />
</CardGrid>

### Compatibility

| .NET Version      | Supported | Target Game Engines |
| ----------------- | --------- | ------------------- |
| .NET Standard 2.1 | ‚úÖ         | Unity               |
| .NET 6.0          | ‚úÖ         | Godot               |
| .NET 7.0          | ‚úÖ         | Godot (Android)     |
| .NET 8.0          | ‚úÖ         | Godot (iOS)         |

## Resources

<CardGrid>
  <LinkCard href="/build/sdks/dotnet-sdk/getting-started" title="Getting Started" description="Begin developing using the Aptos .NET SDK." />

  <LinkCard href="https://aptos-labs.github.io/aptos-dotnet-sdk/" title="Full API Reference" description="The full API reference for the Aptos .NET SDK." target="_blank" />
</CardGrid>

# Ed25519 Accounts

> Learn how to create and manage Ed25519 accounts for signing transactions with the Aptos .NET SDK

import { Aside, CardGrid, LinkCard } from '@astrojs/starlight/components';

<Aside type="caution" emoji="‚ùó">
  This SDK is currently in beta. Please report any issues you encounter by
  creating an issue in the
  [aptos-labs/aptos-dotnet-sdk](https://github.com/aptos-labs/aptos-dotnet-sdk)
  repository.
</Aside>

The Aptos .NET SDK provides a simple way to create and manage Ed25519 accounts. In this guide we
will provide snippets of creating or importing existing accounts.

## Creating Ed25519Accounts

Ed25519Accounts are created to sign transactions and interact with the blockchain.

### Using a Private Key

To generate an account from a private key, you will need to create the `Ed25519PrivateKey` object and pass into the
`Ed25519Account` constructor. The private key can be given a `string` or `byte[]` representation.

```csharp
var privateKey = new Ed25519PrivateKey("0x1234...abcdef");
var account = new Ed25519Account(privateKey);
```

### Using a Mneomonic Phrase

To generate an account from a phrase, you can use `Ed25519Account.FromDerivationPath` and pass in the phrase and the derivation path.
The derivation path that is typically used throughout the Aptos ecosystem is `m/44'/637'/0'/0'/0'`.

```csharp
var account = Ed25519Account.FromDerivationPath(
    "m/44'/637'/0'/0'/0'",
    "apple banana cat dog elephant fox ..."
);
```

### Generating a Random Account

To create a random account, you can use the `Account.Generate()` method.

```csharp
var account = Account.Generate();
```

## Additional Resources

<CardGrid>
  <LinkCard href="https://aptos-labs.github.io/aptos-dotnet-sdk/docs/Aptos.Ed25519Account.html" title="Ed25519Account Reference" description="The full API reference for the Ed25519Account class." target="_blank" />
</CardGrid>

# Keyless Accounts

> Create and manage Keyless accounts using social provider logins for seamless user authentication with the Aptos .NET SDK

import { Aside, CardGrid, LinkCard, Steps } from '@astrojs/starlight/components';

<Aside type="caution" emoji="‚ùó">
  This SDK is currently in beta. Please report any issues you encounter by
  creating an issue in the
  [aptos-labs/aptos-dotnet-sdk](https://github.com/aptos-labs/aptos-dotnet-sdk)
  repository.
</Aside>

The Aptos .NET SDK provides an implementation of Keyless accounts to derive accounts from social provider logins. In this guide,
we will provide snippets of creating accounts.

## Creating KeylessAccounts

KeylessAccounts are created to sign transactions and interact with the blockchain using social provider logins. To create a Keyless account,
you will need to follow a few steps to obtain the necessary components of a Keyless account.

<Aside type="note" emoji="‚ÑπÔ∏è">
  We plan on creating end-to-end guides on integrating Keyless with Unity and
  Godot. They are currently in development.
</Aside>

<Steps>
  1. Create a Ephemeral Key Pair

     The first step to creating a Keyless account is to create an ephemeral key pair. This is an ephemeral key used to sign transactions. It's important
     to store this key pair in a secure location in the application as it will be used to sign transactions.

     ```csharp
     var ephemeralKeyPair = EphemeralKeyPair.Generate();
     ```

  2. Obtaining an OpenID Connect (OIDC) Identity Token

     To obtain an `id_token` (OIDC Identity Token), you will need to authenticate with a social provider. At the end of the authorization flow, the user should be redirected
     to your application with an `id_token`. You will need to store this `id_token` in a secure location in the application. **It's important that the `id_token` has a nonce field that matches the `nonce` field inside the `EphemeralKeyPair`.**

     **Example:**

     ```csharp
     var nonce = ephemeralKeyPair.Nonce;
     var authorizationUrl = "https://accounts.google.com/o/oauth2/v2/auth&nonce=" + nonce;
     ```

  3. Deriving a Keyless Account

     Once the user has the following components, they should be able to derive a Keyless account.

     - `id_token`: Obtained from the authorization flow.
     - `EphemeralKeyPair`: Created in the previous steps.

     **It's important that the `nonce` field inside the `EphemeralKeyPair` matches the `nonce` field inside the `id_token` to ensure that the user can sign transactions.**

     ```csharp
     var client = new AptosClient(Networks.Mainnet);
     var keylessAccount = await client.Keyless.DeriveAccount(idToken, ephemeralKeyPair);
     ```

  4. Sign and Submit transactions

     After deriving a Keyless account, you can sign and submit transactions using the `AptosClient`.

     ```csharp
     // 1. Build the transaction
     var transaction = await client.Transaction.Build(
         sender: keylessAccount,
         data: new GenerateEntryFunctionPayloadData(
             function: "0x1::aptos_account::transfer_coins",
             typeArguments: ["0x1::aptos_coin::AptosCoin"],
             functionArguments: [account.Address, "100000"]
         )
     );

     // 2. Sign and submit the transaction
     var submittedTransaction = await client.Transaction.SignAndSubmitTransaction(keylessAccount, transaction);

     // 3. (Optional) Wait for the transaction to be committed
     var committedTransaction = await client.Transaction.WaitForTransaction(submittedTransaction.Hash);
     ```
</Steps>

## Additional Resources

<CardGrid>
  <LinkCard href="https://aptos-labs.github.io/aptos-dotnet-sdk/docs/Aptos.KeylessAccount.html" title="KeylessAccount Reference" description="The full API reference for the KeylessAccount class." target="_blank" />
</CardGrid>

# Multikey Accounts

> Create and manage Multikey accounts for multisig functionality using multiple key pairs with the Aptos .NET SDK

import { Aside, CardGrid, LinkCard, Steps } from '@astrojs/starlight/components';

<Aside type="caution" emoji="‚ùó">
  This SDK is currently in beta. Please report any issues you encounter by
  creating an issue in the
  [aptos-labs/aptos-dotnet-sdk](https://github.com/aptos-labs/aptos-dotnet-sdk)
  repository.
</Aside>

The Aptos .NET SDK provides an implementation of Multikey accounts to create accounts from a combination of multiple key pairs. This is useful for
Multisig accounts. In this guide, we will provide snippets of creating accounts.

## Creating a MultiKeyAccount

MultiKeyAccount's are created to sign transactions where the account is controlled by multiple private keys.

### Create a MultiKeyAccount

To create a MultiKey account, you will need the following components:

- `PublicKeys`: The public keys of the accounts that control the MultiKey account.
- `SignaturesRequired`: The minimum number of signers required to sign transactions.
- `Signers`: The account signers that will be used to sign transactions. The number of signers should be equal to or greater than the `SignaturesRequired`.

<Steps>
  1. Create your Accounts

     Create your accounts, they can be different types of accounts.

     ```csharp
     var account1 = Ed25519Account.Generate();
     var account2 = SingleKeyAccount.Generate(PublicKeyVariant.Secp256k1Ecdsa);
     ```

  2. Create a MultiKey Verifying Key

     Create a MultiKey verifying key using the `PublicKeys` and `SignaturesRequired`. In this example,
     we have two accounts controlling the MultiKey and we require 2 signers to sign transactions.

     ```csharp
     var multiKey = new MultiKey(
         publicKeys: [account1.PublicKey, account2.PublicKey],
         signaturesRequired: 2,
     );
     ```

  3. Create the MultiKey Account

     Create the MultiKey account using the `PublicKeys`, `SignaturesRequired`, and `Signers`.

     ```csharp
     var multikeyAccount = new MultiKeyAccount(
         multiKey: multiKey,
         signers: [account1, account2]
     );
     ```

  4. Sign and Submit transactions

     After creating a MultiKey account, you can sign and submit transactions using the `AptosClient`.

     ```csharp
     // 1. Build the transaction
     var transaction = await client.Transaction.Build(
         sender: multikeyAccount,
         data: new GenerateEntryFunctionPayloadData(
             function: "0x1::aptos_account::transfer_coins",
             typeArguments: ["0x1::aptos_coin::AptosCoin"],
             functionArguments: [account.Address, "100000"]
         )
     );

     // 2. Sign and submit the transaction
     var submittedTransaction = await client.Transaction.SignAndSubmitTransaction(multikeyAccount, transaction);

     // 3. (Optional) Wait for the transaction to be committed
     var committedTransaction = await client.Transaction.WaitForTransaction(submittedTransaction.Hash);
     ```
</Steps>

## Additional Resources

<CardGrid>
  <LinkCard href="https://aptos-labs.github.io/aptos-dotnet-sdk/docs/Aptos.MultiKeyAccount.html" title="MultiKeyAccount Reference" description="The full API reference for the MultiKeyAccount class." target="_blank" />
</CardGrid>

# Examples

> Comprehensive collection of example applications and code samples for the Aptos .NET SDK

import { Aside, CardGrid, LinkCard, Steps } from '@astrojs/starlight/components';

<Aside type="caution" emoji="‚ùó">
  This SDK is currently in beta. Please report any issues you encounter by
  creating an issue in the
  [aptos-labs/aptos-dotnet-sdk](https://github.com/aptos-labs/aptos-dotnet-sdk)
  repository.
</Aside>

The Aptos .NET SDK provides a number of examples to help you get started with the SDK. You can find the examples in the
[aptos-labs/aptos-dotnet-sdk](https://github.com/aptos-labs/aptos-dotnet-sdk) repository.

<br />

<LinkCard href="https://github.com/aptos-labs/aptos-dotnet-sdk/tree/main/Aptos.Examples" title="Aptos .NET SDK Examples" description="Example applications for the .NET SDK." target="_blank" />

<Steps>
  1. Install .NET

     To run the examples, you will need to install the .NET SDK. You can download the .NET SDK from the
     [dotnet.microsoft.com](https://dotnet.microsoft.com/en-us/download) website.

  2. Clone the Repository

     Clone the repository by running the following command:

     ```shellscript
     git clone https://github.com/aptos-labs/aptos-dotnet-sdk.git
     ```

  3. Running the Examples

     You can run the examples by navigating to the `Aptos.Examples` directory and running the
     `dotnet run --framework net8.0` command.

     ```shellscript
     cd Aptos.Examples
     dotnet run --framework net8.0
     ```

  4. Selecting an Example

     When running the examples, you will be prompted to select an example. You can select the example by
     entering the number of the example you want to run or navigating with the arrow keys.

     ![examples-demonstration](~/images/dotnet-examples/select-example.png)
</Steps>

## Additional Resources

<CardGrid>
  <LinkCard href="/build/sdks/dotnet-sdk/getting-started" title="Getting Started" description="Begin developing using the Aptos .NET SDK." />

  <LinkCard href="https://aptos-labs.github.io/aptos-dotnet-sdk/" title="Full API Reference" description="The full API reference for the Aptos .NET SDK." target="_blank" />
</CardGrid>

# Quickstart

> Get started with the Aptos .NET SDK by installing and setting up the SDK for your game development projects

import { Aside, CardGrid, LinkCard, Steps } from '@astrojs/starlight/components';

<Aside type="caution" emoji="‚ùó">
  This SDK is currently in beta. Please report any issues you encounter by
  creating an issue in the
  [aptos-labs/aptos-dotnet-sdk](https://github.com/aptos-labs/aptos-dotnet-sdk)
  repository.
</Aside>

If you have not already installed the Aptos .NET SDK, follow one of the guides below to get started.

<CardGrid>
  <LinkCard href="/build/sdks/dotnet-sdk/godot-integration" title="Godot Integration" description="Integrate the Aptos .NET SDK with a Godot project." />

  <LinkCard href="/build/sdks/dotnet-sdk/unity-integration" title="Unity SDK" description="Integrate the Aptos .NET SDK with a Unity project." />
</CardGrid>

<Steps>
  1. Set up your AptosClient

     Set up your Aptos client by adding the `Aptos` namespace and instantiating an `AptosClient`. You can use a predefined
     configuration from `Networks` or configuring your own.

     ```csharp filename="Program.cs"  {1-1, 7-8}
     using Aptos;

     class Program
     {
         static void Main(string[] args)
         {
             var config = new AptosConfig(Aptos.Networks.Mainnet);
             var client = new AptosClient(config);
         }
     }
     ```

  2. Query the Blockchain

     Now that you have the client setup, you can query the blockchain!

     ```csharp filename="Program.cs" {10-11}
     using Aptos;

     class Program
     {
         static void Main(string[] args)
         {
             var config = new AptosConfig(Aptos.Networks.Mainnet);
             var client = new AptosClient(config);

             var ledgerInfo = client.Block.GetLedgerInfo();
             Console.WriteLine(ledgerInfo.BlockHeight);
         }
     }
     ```

  3. Sign and Submit Transactions

     To interact with the blockchain, you will need to create a signer and build a transaction.

     ```csharp filename="Program.cs" {10-11,13-21,23-24,26-27}
     using Aptos;

     class Program
     {
         static void Main(string[] args)
         {
             var config = new AptosConfig(Aptos.Networks.Mainnet);
             var client = new AptosClient(config);

             // 1. Create a signer
             var signer = Account.Generate();

             // 2. Build the transaction
             var transaction = await client.Transaction.Build(
                 sender: account,
                 data: new GenerateEntryFunctionPayloadData(
                     function: "0x1::aptos_account::transfer_coins",
                     typeArguments: ["0x1::aptos_coin::AptosCoin"],
                     functionArguments: [account.Address, "100000"]
                 )
             );

             // 3. Sign and submit the transaction
             var pendingTransaction = client.Transaction.SignAndSubmitTransaction(account, transaction);

             // 4. (Optional) Wait for the transaction to be committed
             var committedTransaction = await client.Transaction.WaitForTransaction(pendingTransaction);
         }
     }
     ```

  4. Smart Contract View Functions

     Call view functions to query smart contracts.

     ```csharp filename="Program.cs" {10-17,19-20}
     using Aptos;

     class Program
     {
         static void Main(string[] args)
         {
             var config = new AptosConfig(Aptos.Networks.Mainnet);
             var client = new AptosClient(config);

             // Call the view function by specifying the function name, arguments, and type arguments
             var values = await client.Contract.View(
                 new GenerateViewFunctionPayloadData(
                     function: "0x1::coin::name",
                     functionArguments: [],
                     typeArguments: ["0x1::aptos_coin::AptosCoin"]
                 )
             );

             // Returns a list of return values: ["Aptos Coin"]
             Console.WriteLine("APT Name: " + values[0]);
         }
     }
     ```
</Steps>

## Additional Resources

<CardGrid>
  <LinkCard href="https://aptos-labs.github.io/aptos-dotnet-sdk" title="Full API Reference" description="The full API reference for the Aptos .NET SDK." target="_blank" />
</CardGrid>

# Godot Integration

> Complete guide to integrate the Aptos .NET SDK into your Godot game development projects

import { Aside, CardGrid, LinkCard, Steps } from '@astrojs/starlight/components';

<Aside type="caution" emoji="‚ùó">
  This integration is currently in beta. Please report any issues you encounter
  by creating an issue in the
  [aptos-labs/aptos-dotnet-sdk](https://github.com/aptos-labs/aptos-dotnet-sdk)
  repository.
</Aside>

This guide will walk you through the process of integrating the Aptos .NET SDK. To install the Aptos SDK into your Godot project,
you will need to add the Aptos SDK into your Godot project's `.csproj` file.

<Steps>
  1. Find the .csproj

     In the root of your Godot project, find the `.csproj` file. This file is used to
     configure your Godot project and is used by the Godot build system. You can find
     this file by clicking on `res://` in the Godot editor and selecting `Open in File Manager`.

     > If you can't find the `.csproj` file, you can create a `.cs` file and build the application one time and it should be generated.

     <br />

     <div className="border dark:border-white/30 w-fit rounded-md overflow-clip shadow-md max-w-lg">
       ![Open in File Manager](~/images/dotnet-sdk/open-in-file-manager.png)
     </div>

  2. Add the Aptos NuGet package

     Add the following line to the `<ItemGroup>` section of the `.csproj` file. If it doesn't exist, create it the `<ItemGroup>` section.

     ```xml filename=".csproj"
     <ItemGroup>
       <PackageReference Include="Aptos" Version="0.0.2-beta" />
     </ItemGroup>
     ```

     It should look something like this:

     ```xml filename=".csproj" {10-14}
     <Project Sdk="Godot.NET.Sdk/4.3.0">
       <PropertyGroup>
         <TargetFramework>net6.0</TargetFramework>
         <TargetFramework Condition=" '$(GodotTargetPlatform)' == 'android' ">net7.0</TargetFramework>
         <TargetFramework Condition=" '$(GodotTargetPlatform)' == 'ios' ">net8.0</TargetFramework>
         <EnableDynamicLoading>true</EnableDynamicLoading>
         <RootNamespace>AptosSDKExample</RootNamespace>
       </PropertyGroup>

       <!-- START: Add these lines -->
       <ItemGroup>
         <PackageReference Include="Aptos" Version="0.0.1-beta" />
       </ItemGroup>
       <!-- END -->

     </Project>
     ```

  3. Use the Aptos SDK

     Import the `Aptos` namespace in your C# script and use the SDK.

     ```csharp filename="Example.cs" {3-3,9-9,12-16}
     using Godot;
     using System;
     using Aptos;

     public partial class Example : Node
     {
     	public override void _Ready()
     	{
             PrintLedgerInfo();
     	}

     	async void PrintLedgerInfo() {
             var client = new AptosClient(Networks.Mainnet);
             var ledgerInfo = await client.Block.GetLedgerInfo();
             GD.Print(ledgerInfo.BlockHeight);
     	}

     }
     ```
</Steps>

## Next Steps

You've successfully integrated the Aptos .NET SDK into your Godot project. Now
you can start building your game and interacting with the Aptos blockchain. Below
are some resources to help you get started.

<CardGrid>
  <LinkCard href="/build/sdks/dotnet-sdk/getting-started" title="Getting Started" description="Begin developing using the Aptos .NET SDK." />
</CardGrid>

# View Functions

> Query smart contracts on the blockchain using view functions with dynamic and strongly-typed approaches in the .NET SDK

import { Aside } from '@astrojs/starlight/components';

<Aside type="caution" emoji="‚ùó">
  This SDK is currently in beta. Please report any issues you encounter by
  creating an issue in the
  [aptos-labs/aptos-dotnet-sdk](https://github.com/aptos-labs/aptos-dotnet-sdk)
  repository.
</Aside>

View functions allow you to query smart contracts on the blockchain. They are defined in smart contracts as entry functions with the `view` modifier.
In this guide, we will provide snippets of view functions and how they are typed and used.

## Dynamically Typed View Functions

When you don't care about the return type of a view function, you can use the `View` function without any type arguments.

The Move function we will be calling:

```move
public fun balance<CoinType>(owner: address): u64
```

And to call the view function, we will use the `View` function from the `ContractClient`.

```csharp {9-16}
using Aptos;

class Program
{
    static void Main(string[] args)
    {
        var client = new AptosClient(Networks.Mainnet);

        // Call the view function by specifying the function name, arguments, and type arguments
        var values = await client.Contract.View(
            new GenerateViewFunctionPayloadData(
                function: "0x1::coin::balance",
                functionArguments: ["0x1"],
                typeArguments: ["0x1::aptos_coin::AptosCoin"]
            )
        );

        // Returns a list of return values: ["100"]
        ulong balance = ulong.Parse(values[0]);
    }
}
```

## Simple Typed View Functions

For view functions with common return types, you can type the return values by passing in a type argument.

The Move function we will be calling:

```move
public fun get_current_epoch_proposal_counts(validator_index: u64): (u64, u64)
```

And to call the view function, we will use the `View` function from the `ContractClient` with the type arguments.

```csharp {9-16}
using Aptos;

class Program
{
    static void Main(string[] args)
    {
        var client = new AptosClient(Networks.Mainnet);

        // Call the view function by specifying the function name, arguments, and type arguments
        var values = await client.Contract.View<List<ulong>>(
            new GenerateViewFunctionPayloadData(
                function: "0x1::stake::get_current_epoch_proposal_counts",
                functionArguments: [(ulong)0],
                typeArguments: []
            )
        );

        // Returns a list of return values: ["100", "100"]
        ulong successfulProposals = values[0];
        ulong failedProposals = values[1];
    }
}
```

## Complex Typed View Functions

For view functions with complex return types, you can leverage `Newtonson.Json` to deserialize the return values. By default,
all types passed into the View function leverage `JsonConvert.DeserializeObject<T>()` from `Newtonson.Json` to deserialize
the return values. You can override the deserialization behavior by creating a custom `JsonConverter`.

The Move function we will be calling:

```move
public fun supply<CoinType>(): Option<u128>
```

Create your own `JsonConverter` to deserialize the return values.

```csharp {9-26}
using Aptos;
using Newtonsoft.Json;

[JsonConverter(typeof(CoinSupplyConverter))]
class CoinSupply(ulong value) {
    public ulong Value;
}

class CoinSupplyConverter : JsonConverter<CoinSupply> {
    public override CoinSupply ReadJson(JsonReader reader, Type objectType, CoinSupply existingValue, bool hasExistingValue, JsonSerializer serializer) {
        // The return type of the view function is an Option<u128> -> [{ "vec": [] }] or [{ "vec": ["100"] }]
        JArray array = JArray.Load(reader);
        var option = array[0];

        // If the Option is None
        if (option["vec"].Count == 0) return null;

        // If the Option is Some
        ulong value = ulong.Parse(option["vec"][0]);
        return new CoinSupply(value);
    }
}
```

And to call the view function, we will use the `View` function from the `ContractClient` with the type arguments.

```csharp {10-17}
using Aptos;
using Newtonsoft.Json;

class Program
{
    static void Main(string[] args)
    {
        var client = new AptosClient(Networks.Mainnet);

        // Call the view function by specifying the function name, arguments, and type arguments
        CoinSupply coinSupply = await client.Contract.View<CoinSupply>(
            new GenerateViewFunctionPayloadData(
                function: "0x1::coin::supply",
                functionArguments: [],
                typeArguments: ["0x1::aptos_coin::AptosCoin"]
            )
        );

        ulong coinSupply = coinSupply.Value;
    }
}
```

# Basic Transactions

> Learn how to build and submit basic transaction types to the Aptos blockchain using the .NET SDK

import { Aside, Steps } from '@astrojs/starlight/components';

<Aside type="caution" emoji="‚ùó">
  This SDK is currently in beta. Please report any issues you encounter by
  creating an issue in the
  [aptos-labs/aptos-dotnet-sdk](https://github.com/aptos-labs/aptos-dotnet-sdk)
  repository.
</Aside>

This section covers the basic transaction types that can be built and submitted to the Aptos blockchain.

<Steps>
  1. Set up your AptosClient

     Set up your Aptos client by adding the `Aptos` namespace and instantiating an `AptosClient`. You can use a predefined
     configuration from `Networks` or configuring your own.

     ```csharp filename="Program.cs"  {1-1, 7-8}
     using Aptos;

     class Program
     {
         static void Main(string[] args)
         {
             var config = new AptosConfig(Aptos.Networks.Mainnet);
             var client = new AptosClient(config);
         }
     }
     ```

  2. Set up an Account

     To create a transaction, you will need an account to sign the transaction. This can be done using a private key,
     mnemonic, or a combination of both. In this example, we will generate a random new account.

     ```csharp filename="Program.cs" {10-12}
     using Aptos;

     class Program
     {
         static void Main(string[] args)
         {
             var config = new AptosConfig(Aptos.Networks.Devnet);
             var client = new AptosClient(config);

             // 1. Create an account and fund it.
             var account = Account.Generate();
             await client.Faucet.FundAccount(account.Address, 100_000_000);
         }
     }
     ```

  3. Build the Transaction

     To interact with the blockchain, you will need to build a transaction. The `AptosClient` can be
     used to build a transaction payload that can be signed and submitted to chain. In the transaction,
     we can specify the sender, entry function, and arguments.

     ```csharp filename="Program.cs" {12-20}
     using Aptos;

     class Program
     {
         static void Main(string[] args)
         {
             var config = new AptosConfig(Aptos.Networks.Devnet);
             var client = new AptosClient(config);

             var account = Account.Generate();

             // 2. Build the transaction
             var transaction = await client.Transaction.Build(
                 sender: account,
                 data: new GenerateEntryFunctionPayloadData(
                     function: "0x1::aptos_account::transfer_coins",
                     typeArguments: ["0x1::aptos_coin::AptosCoin"],
                     functionArguments: [account.Address, "100000"]
                 )
             );
         }
     }
     ```

  4. Sign and Submit Transactions

     Once the transaction is built, it can be signed and submitted to the blockchain. The `AptosClient` can be
     used to sign and submit the transaction.

     ```csharp filename="Program.cs" {21-22}
     using Aptos;

     class Program
     {
         static void Main(string[] args)
         {
             var config = new AptosConfig(Aptos.Networks.Devnet);
             var client = new AptosClient(config);

             var account = Account.Generate();

             var transaction = await client.Transaction.Build(
                 sender: account,
                 data: new GenerateEntryFunctionPayloadData(
                     function: "0x1::aptos_account::transfer_coins",
                     typeArguments: ["0x1::aptos_coin::AptosCoin"],
                     functionArguments: [account.Address, "100000"]
                 )
             );

             // 3. Sign the transaction
             var submittedTransaction = await client.Transaction.SignAndSubmitTransaction(signer, transaction);
         }
     }
     ```

  5. (Optional) Wait for the Transaction to Execute

     After the transaction has been submitted, it will have to process before its committed to the blockchain. The `AptosClient` can be
     used to wait for the transaction to be processed and executed.

     ```csharp filename="Program.cs" {23-24}
     using Aptos;

     class Program
     {
         static void Main(string[] args)
         {
             var config = new AptosConfig(Aptos.Networks.Devnet);
             var client = new AptosClient(config);

             var account = Account.Generate();

             var transaction = await client.Transaction.Build(
                 sender: account,
                 data: new GenerateEntryFunctionPayloadData(
                     function: "0x1::aptos_account::transfer_coins",
                     typeArguments: ["0x1::aptos_coin::AptosCoin"],
                     functionArguments: [account.Address, "100000"]
                 )
             );

             var submittedTransaction = await client.Transaction.SignAndSubmitTransaction(account, transaction);

             // 4. Wait for the transaction to be processed
             var transactionResult = await client.Transaction.WaitForTransaction(submittedTransaction.Hash);
         }
     }
     ```
</Steps>

# Sponsored Transactions

> Learn how to implement sponsored transactions where one account pays gas fees for another account using the Aptos .NET SDK

import { Aside, LinkCard, Steps } from '@astrojs/starlight/components';

<Aside type="caution" emoji="‚ùó">
  This SDK is currently in beta. Please report any issues you encounter by
  creating an issue in the
  [aptos-labs/aptos-dotnet-sdk](https://github.com/aptos-labs/aptos-dotnet-sdk)
  repository.
</Aside>

This section covers how to do sponsored transactions with the Aptos .NET SDK.

**It's important that you understand the basics of building transactions. If not, refer to the guide below for more information.**

<br />

<LinkCard href="/build/sdks/dotnet-sdk/transactions/basic-transactions" title="Basic Transactions" description="Learn how to build basic transactions with the Aptos .NET SDK." />

## Create a Sponsored Transaction

<Steps>
  1. Set up your AptosClient

     Set up your Aptos client by adding the `Aptos` namespace and instantiating an `AptosClient`. You can use a predefined
     configuration from `Networks` or configuring your own.

     ```csharp filename="Program.cs"  {1-1, 7-8}
     using Aptos;

     class Program
     {
         static void Main(string[] args)
         {
             var config = new AptosConfig(Aptos.Networks.Mainnet);
             var client = new AptosClient(config);
         }
     }
     ```

  2. Set up the Accounts

     To create a sponsored transaction, it's important that there is a sponsor and a user. In this example:

     - **The user:** Will be the account that is sending APT to the recipient.
     - **The sponsor:** Will be the account that pays for **gas fees** of the transaction.

     ```csharp filename="Program.cs" {10-16}
     using Aptos;

     class Program
     {
         static void Main(string[] args)
         {
             var config = new AptosConfig(Aptos.Networks.Devnet);
             var client = new AptosClient(config);

             // 1. Create accounts and fund it them.
             var user = Account.Generate();
             var recipient = Account.Generate();
             var sponsor = Account.Generate();

             await client.Faucet.FundAccount(user.Address, 100_000_000);
             await client.Faucet.FundAccount(sponsor.Address, 100_000_000);
         }
     }
     ```

  3. Build the Transaction

     You can now build the transaction using the `AptosClient`. In the transaction, its important that you
     enable the `withFeePayer` flag to enable the sponsored transactions.

     ```csharp filename="Program.cs" {9-19}
     using Aptos;

     class Program
     {
         static void Main(string[] args)
         {
             ...

             // 2. Build the transaction
             var transaction = await client.Transaction.Build(
                 sender: account,
                 data: new GenerateEntryFunctionPayloadData(
                     function: "0x1::aptos_account::transfer_coins",
                     typeArguments: ["0x1::aptos_coin::AptosCoin"],
                     functionArguments: [account.Address, "100000"]
                 ),
                 // It's important to set this flag to true to enable sponsored transactions
                 withFeePayer: true
             );
         }
     }
     ```

  4. Sign the Transaction using both accounts

     Have both the user and the sponsor sign the transaction. This ensures that the sponsor has agreed
     to pay for the transaction and the user has agreed to execute the transaction. When signing with
     the sponsor, the `SignAsFeePayer` method is used instead.

     ```csharp filename="Program.cs" {9-13}
     using Aptos;

     class Program
     {
         static void Main(string[] args)
         {
             ...

             // 3. Sign the transaction with the user
             var userSignature = client.Transaction.SignTransaction(transaction);

             // 4. Sign the transaction with the sponsor
             var feePayerSignature = client.Transaction.SignAsFeePayer(feePayer, transaction);
         }
     }
     ```

  5. Submit the Transaction

     Once the transaction is signed by both the user and the sponsor, it can be submitted to the blockchain. The `AptosClient` can be
     used to submit the transaction.

     ```csharp filename="Program.cs" {9-11}
     using Aptos;

     class Program
     {
         static void Main(string[] args)
         {
             ...

             // 5. Submit the transaction
             var submitTransactionData = new SubmitTransactionData(transaction, userSignature, feePayerSignature);
             var submittedTransaction = await client.Transaction.SubmitTransaction(submitTransactionData);
         }
     }
     ```

  6. Wait for the Transaction to Execute

     After the transaction has been submitted, it will have to process before its committed to the blockchain. The `AptosClient` can be
     used to wait for the transaction to be processed and executed.

     ```csharp filename="Program.cs" {8-9}
     using Aptos;

     class Program
     {
         static void Main(string[] args)
         {
             ...

             // 6. Wait for the transaction to be processed
             var transactionResult = await client.Transaction.WaitForTransaction(submittedTransaction.Hash);
         }
     }
     ```

  7. Print Balances

     After the transaction has committed to the blockchain, you can print the balances of the user and the recipient.

     ```csharp filename="Program.cs" {9-15}
     using Aptos;

     class Program
     {
         static void Main(string[] args)
         {
             ...

             // 7. Print balances
             var userBalance = await client.Account.GetCoinBalance(user.Address);
             var feePayerBalance = await client.Account.GetCoinBalance(feePayer.Address);
             var recipientBalance = await client.Account.GetCoinBalance(recipient.Address);
             Console.WriteLine($"User {user.Address} has {userBalance?.Amount ?? 0} APT");
             Console.WriteLine($"FeePayer {feePayer.Address} has {feePayerBalance?.Amount ?? 0} APT");
             Console.WriteLine($"Recipient {recipient.Address} has {recipientBalance?.Amount ?? 0} APT");
         }
     }
     ```

     The result should look like this:

     ```shellscript
     User 0xffd89f1e2fef8c67cfb1b99d58ea799281f1d1a0a178db49c3eacab2fe7c0735 has 99900000 APT
     FeePayer 0x842ca7d995255ee73186a6793d6bde7c983c528be7b1a25e1614f4eddb744d4c has 99900100 APT
     Recipient 0x823010a52a589ef528d14ebee4a4af56a00f0ae8afba135c9268581a960e21d7 has 100000 APT
     ```

     The user sent 0.001 APT to the recipient leaving the user with 0.999 APT. The sponsor paid
     for the gas fees of the transaction leaving the sponsor with 0.999001 APT.
</Steps>

# Unity Integration

> Step-by-step guide to integrate the Aptos .NET SDK into your Unity game development projects

import { Aside, CardGrid, LinkCard, Steps } from '@astrojs/starlight/components';

<Aside type="caution" emoji="‚ùó">
  This integration is currently in beta. Please report any issues you encounter
  by creating an issue in the
  [aptos-labs/aptos-dotnet-sdk](https://github.com/aptos-labs/aptos-dotnet-sdk)
  repository.
</Aside>

This guide will walk you through the process of integrating the Aptos .NET SDK.

<Steps>
  1. Install the Aptos Unity SDK

     #### Option 1: Import via Unity Package Manager (UPM)

     1. Open Package Manager window (Window | Package Manager)
     2. Click + button on the upper-left of a window, and select _Add package from git URL..._
     3. Enter the following URL and click Add button

     ```shellscript
     https://github.com/aptos-labs/unity-sdk.git?path=/Packages/com.aptoslabs.aptos-unity-sdk
     ```

     #### Option 2: Import via `unitypackage`

     1. Go to the [`aptos-labs/unity-sdk Releases`](https://github.com/aptos-labs/unity-sdk/releases) and download the latest release.
     2. Drag and drop the `.unitypackage` file into your Unity project.

  2. Use the Aptos SDK

     Import the `Aptos` namespace in your C# script and use the SDK.

     ```csharp {2-2,8-8,11-15}
     using UnityEngine;
     using Aptos;

     class Example : MonoBehaviour
     {
         public void Start()
         {
             PrintLedgerInfo();
         }

         async void PrintLedgerInfo() {
             var client = new AptosUnityClient(Networks.Mainnet);
             var ledgerInfo = await client.Block.GetLedgerInfo();
             Debug.Log(ledgerInfo.BlockHeight);
         }

     }
     ```
</Steps>

## Next Steps

You've successfully integrated the Aptos .NET SDK into your Unity project. Now
you can start building your game and interacting with the Aptos blockchain. Below
are some resources to help you get started.

<CardGrid>
  <LinkCard href="/build/sdks/dotnet-sdk/getting-started" title="Getting Started" description="Begin developing using the Aptos .NET SDK." />

  <LinkCard href="/build/sdks/unity-sdk" title="Unity SDK" description="Overview of the Unity SDK." />

  <LinkCard href="https://github.com/aptos-labs/aptos-unity-starter" title="Aptos Wallet Starter" description="Example Unity project with an integration of the Aptos Unity SDK." target="_blank" />
</CardGrid>

# Go SDK

> Official Go SDK for Aptos blockchain development with comprehensive examples and transaction building capabilities

import { CardGrid, LinkCard } from '@astrojs/starlight/components';

## Installing the Go SDK

Aptos provides an official Go SDK in
the [aptos-go-sdk GitHub](https://github.com/aptos-labs/aptos-go-sdk) repository.
To use the Go SDK, get the main package here:

```shellscript
go get github.com/aptos-labs/aptos-go-sdk
```

## Usage

<CardGrid>
  <LinkCard href="/build/sdks/go-sdk/fetch-data-via-sdk" title="Fetching Data" description="Learn how to fetch data with the Go SDK" />

  <LinkCard href="/build/sdks/go-sdk/building-transactions" title="Submitting Transactions" description="Learn how to submit transactions with the Go SDK" />

  <LinkCard href="/build/sdks/go-sdk/go-examples" title="Examples" description="Explore Go examples provided in the SDK" />
</CardGrid>

# Go SDK - Creating and Managing Accounts

> Learn how to generate, fund, and manage Aptos accounts using the Go SDK with different signing schemes

There are several ways to generate account credentials using the Go SDK. You can
use:

- `aptos.NewEd25519Account()`
- `aptos.NewSecp256k1Account()`
- `aptos.NewEd25519SingleSenderAccount()`
- `aptos.NewAccountFromSigner()`

`Account.NewEd25519Account()` is the most commonly used method to create keys
for a new account. It defaults to `ED25519` key types, but you can also specify
which signing scheme you would prefer like so:

```go
// To derive an ed25519 account
account1 := aptos.NewEd25519Account()

// To derive a secp256k1 account
account2 := aptos.NewSecp256k1Account()
```

Once you have generated credentials, you **must** fund it for the network to know it exists.

In devnet environments this can be done with a faucet by running the following command:

```go filename="fund.go"
client, err = aptos.NewClient(aptos.DevnetConfig)
if err != nil {
  panic("Failed to create client:" + err.Error())
}

// Fund an account with 1 Devnet APT
client.Fund(account1.Address, 100_000_000)
```

On testnet you can mint at the [mint page](/network/faucet).

## Other Ways To Represent Accounts

If you have a private key, or equivalent representation, you can use that to
create an `Account` struct to manage those credentials while using the Go SDK.

Here are several examples that show how to do so with specific encoding schemes.

### Derive an account from private key

The SDK supports deriving an account from a private key with `NewAccountFromSigner()` method.
In addition, this method supports deriving an account from a private key and account address.
This method uses a local calculation and therefore is used to derive an `Account` that has not had its authentication key rotated.

```go
// to derive an account with a Ed25519 key scheme
privateKey := &aptos.Ed25519PrivateKey{}
err := privateKey.FromHex(privateKeyHex)
if err != nil {
  panic("Failed to parse private key:" + err.Error())
}
account := aptos.NewAccountFromSigner(privateKey)

// to derive an account with a Single Sender Ed25519 key scheme
privateKey := &aptos.Ed25519PrivateKey{}
err := privateKey.FromHex(privateKeyHex)
if err != nil {
  panic("Failed to parse private key:" + err.Error())
}
singleSigner := &crypto.SingleSigner{Signer: privateKey}
account := aptos.NewAccountFromSigner(singleSigner)

// to derive an account with a Single Sender Secp256k1 key scheme
privateKey := &aptos.Secp256k1PrivateKey{}
err := privateKey.FromHex(privateKeyHex)
if err != nil {
  panic("Failed to parse private key:" + err.Error())
}
singleSigner := &crypto.SingleSigner{Signer: privateKey}
account := aptos.NewAccountFromSigner(singleSigner)

// to derive an account with a private key and account address
address := &aptos.AccountAddress{}
err := address.ParseStringRelaxed(addressHex)
if err != nil {
  panic("Failed to parse address:" + err.Error())
}
privateKey := &aptos.Ed25519PrivateKey{}
err := privateKey.FromHex(privateKeyHex)
if err != nil {
  panic("Failed to parse private key:" + err.Error())
}
account := aptos.NewAccountFromSigner(privateKey, address.AuthKey())
```

{/* TODO: Once derivation path is supported ### Derive an account from derivation path */}

# Go SDK - Building Transactions

> Comprehensive guide to building, simulating, signing, submitting, and executing transactions on Aptos using the Go SDK

import { Aside, Steps } from '@astrojs/starlight/components';

Transactions allow you to change on-chain data or trigger events. Generally,
transactions follow 5 steps from building to executing on chain: building,
simulating, signing, submitting, and waiting.

<Aside type="note">
  For these examples, `client` is an instance of the
  [`Client`](https://pkg.go.dev/github.com/aptos-labs/aptos-go-sdk#Client)
  object.
</Aside>

<Steps>
  1. Build

     Building a transaction is how you specify:

     1. **The `Sender` account.** <br />This account normally pays the gas fees for
        this transaction. See [Sponsoring Transactions](/build/sdks/go-sdk/building-transactions/sponsoring-transactions)
        to learn how to  have another account pay for transaction fees.
     2. **The `Function` being called on-chain.** <br />This is the identifier for
        the smart contract entry function on-chain that will trigger when you execute
        this transaction.
     3. **The `ArgTypes` and `Args`.** <br />This is any data the function needs to
        run.

     This can be made for a single account like so:

     ```go filename="build_a_transaction.go"
     // 1. Build transaction
     accountBytes, err := bcs.Serialize(&bob.Address)
     if err != nil {
         panic("Failed to serialize bob's address:" + err.Error())
     }

     amountBytes, err := bcs.SerializeU64(TransferAmount)
     if err != nil {
         panic("Failed to serialize transfer amount:" + err.Error())
     }
     rawTxn, err := client.BuildTransaction(alice.AccountAddress(), aptos.TransactionPayload{
         Payload: &aptos.EntryFunction{
             Module: aptos.ModuleId{
                 Address: aptos.AccountOne,
                 Name:    "aptos_account",
             },
             Function: "transfer",
             ArgTypes: []aptos.TypeTag{},
             Args: [][]byte{
                 accountBytes,
                 amountBytes,
             },
         }},
     )
     ```

     <Aside type="note">
       All arguments `Args` must be serialized to bytes before being passed in. They
       must be serialized with [Binary Canonical Serialization (BCS)](/build/sdks/go-sdk/building-transactions/bcs-format)
     </Aside>

     #### Building Options

     You can customize the way your transaction executes by passing in
     `options` when building. Some of the most commonly used options are:

     1. `MaxGasAmount` - This caps the amount of gas you are willing to pay for to
        execute this transaction.
     2. `GasUnitPrice` - You can specify a higher than minimum price per gas to be
        executed with higher priority by the Aptos network.
     3. `ExpirationSeconds` - This gives a concrete time the transaction must execute
        by or it will be canceled.

     The SDK provides sensible defaults for these values if they are not specified
     explicitly.

  2. Simulate (Optional)

     Every transaction on the Aptos chain has a gas fee associated with how much
     work the network machines have to do when executing the transaction. In order
     to estimate the cost associated with that, you can simulate transactions
     before committing them.

     <Aside type="note">
       This simulation only requires the `PublicKey` of an account since it will
       not impact the actual state of the ledger.
     </Aside>

     You can execute the simulation by using
     `aptos.SimulateTransaction` like so:

     ```go filename="build_a_transaction.go"
     // 2. Simulate transaction (optional)
     // This is useful for understanding how much the transaction will cost
     // and to ensure that the transaction is valid before sending it to the network
     // This is optional, but recommended
     simulationResult, err := client.SimulateTransaction(rawTxn, alice)

     // If the fee looks ok, continue to signing!
     ```

  3. Sign

     Once the transaction is built and the fees seem reasonable, you can sign the
     transaction with `rawTransaction.SignedTransaction()`. The signature must come
     from the `sender` account.

     ```go filename="build_a_transaction.go"
     // 3. Sign transaction
     signedTxn, err := rawTxn.SignedTransaction(alice)
     ```

  4. Submit

     Now that the transaction is signed, you can submit it to the network using
     `client.SubmitTransaction()` like so:

     ```go filename="build_a_transaction.go"
     // 4. Submit transaction
     submitResult, err := client.SubmitTransaction(signedTxn)
     ```

  5. Wait

     Finally, you can wait for the result of the transaction by using
     `client.WaitForTransaction()` and specifying the hash of the transaction you
     just submitted like so:

     ```go filename="build_a_transaction.go"
     // 5. Wait for the transaction to complete
     txnHash := submitResult.Hash
     _, err = client.WaitForTransaction(txnHash)
     ```
</Steps>

## Full Go Example

```go filename="build_a_transaction.go"
// transfer_coin is an example of how to make a coin transfer transaction in the simplest possible way
package main

import (
	"fmt"

	"github.com/aptos-labs/aptos-go-sdk"
	"github.com/aptos-labs/aptos-go-sdk/bcs"
)

const FundAmount = 100_000_000
const TransferAmount = 1_000

// example This example shows you how to make an APT transfer transaction in the simplest possible way
func example(networkConfig aptos.NetworkConfig) {
	// Create a client for Aptos
	client, err := aptos.NewClient(networkConfig)
	if err != nil {
		panic("Failed to create client:" + err.Error())
	}

	// Create accounts locally for alice and bob
	alice, err := aptos.NewEd25519Account()
	if err != nil {
		panic("Failed to create alice:" + err.Error())
	}
	bob, err := aptos.NewEd25519Account()
	if err != nil {
		panic("Failed to create bob:" + err.Error())
	}

	fmt.Printf("\n=== Addresses ===\n")
	fmt.Printf("Alice: %s\n", alice.Address.String())
	fmt.Printf("Bob:%s\n", bob.Address.String())

	// Fund the sender with the faucet to create it on-chain
	err = client.Fund(alice.Address, FundAmount)
	if err != nil {
		panic("Failed to fund alice:" + err.Error())
	}

	aliceBalance, err := client.AccountAPTBalance(alice.Address)
	if err != nil {
		panic("Failed to retrieve alice balance:" + err.Error())
	}
	bobBalance, err := client.AccountAPTBalance(bob.Address)
	if err != nil {
		panic("Failed to retrieve bob balance:" + err.Error())
	}
	fmt.Printf("\n=== Initial Balances ===\n")
	fmt.Printf("Alice: %d\n", aliceBalance)
	fmt.Printf("Bob:%d\n", bobBalance)

	// 1. Build transaction
	accountBytes, err := bcs.Serialize(&bob.Address)
	if err != nil {
		panic("Failed to serialize bob's address:" + err.Error())
	}

	amountBytes, err := bcs.SerializeU64(TransferAmount)
	if err != nil {
		panic("Failed to serialize transfer amount:" + err.Error())
	}
	rawTxn, err := client.BuildTransaction(alice.AccountAddress(), aptos.TransactionPayload{
		Payload: &aptos.EntryFunction{
			Module: aptos.ModuleId{
				Address: aptos.AccountOne,
				Name:    "aptos_account",
			},
			Function: "transfer",
			ArgTypes: []aptos.TypeTag{},
			Args: [][]byte{
				accountBytes,
				amountBytes,
			},
		}},
	)

	if err != nil {
		panic("Failed to build transaction:" + err.Error())
	}

	// 2. Simulate transaction (optional)
	// This is useful for understanding how much the transaction will cost
	// and to ensure that the transaction is valid before sending it to the network
	// This is optional, but recommended
	simulationResult, err := client.SimulateTransaction(rawTxn, alice)
	if err != nil {
		panic("Failed to simulate transaction:" + err.Error())
	}
	fmt.Printf("\n=== Simulation ===\n")
	fmt.Printf("Gas unit price: %d\n", simulationResult[0].GasUnitPrice)
	fmt.Printf("Gas used: %d\n", simulationResult[0].GasUsed)
	fmt.Printf("Total gas fee: %d\n", simulationResult[0].GasUsed*simulationResult[0].GasUnitPrice)
	fmt.Printf("Status: %s\n", simulationResult[0].VmStatus)

	// 3. Sign transaction
	signedTxn, err := rawTxn.SignedTransaction(alice)
	if err != nil {
		panic("Failed to sign transaction:" + err.Error())
	}

	// 4. Submit transaction
	submitResult, err := client.SubmitTransaction(signedTxn)
	if err != nil {
		panic("Failed to submit transaction:" + err.Error())
	}
	txnHash := submitResult.Hash

	// 5. Wait for the transaction to complete
	_, err = client.WaitForTransaction(txnHash)
	if err != nil {
		panic("Failed to wait for transaction:" + err.Error())
	}

	// Check balances
	aliceBalance, err = client.AccountAPTBalance(alice.Address)
	if err != nil {
		panic("Failed to retrieve alice balance:" + err.Error())
	}
	bobBalance, err = client.AccountAPTBalance(bob.Address)
	if err != nil {
		panic("Failed to retrieve bob balance:" + err.Error())
	}
	fmt.Printf("\n=== Intermediate Balances ===\n")
	fmt.Printf("Alice: %d\n", aliceBalance)
	fmt.Printf("Bob:%d\n", bobBalance)

	// Now do it again, but with a different method
	resp, err := client.BuildSignAndSubmitTransaction(alice, aptos.TransactionPayload{
		Payload: &aptos.EntryFunction{
			Module: aptos.ModuleId{
				Address: aptos.AccountOne,
				Name:    "aptos_account",
			},
			Function: "transfer",
			ArgTypes: []aptos.TypeTag{},
			Args: [][]byte{
				accountBytes,
				amountBytes,
			},
		}},
	)
	if err != nil {
		panic("Failed to sign transaction:" + err.Error())
	}

	_, err = client.WaitForTransaction(resp.Hash)
	if err != nil {
		panic("Failed to wait for transaction:" + err.Error())
	}

	aliceBalance, err = client.AccountAPTBalance(alice.Address)
	if err != nil {
		panic("Failed to retrieve alice balance:" + err.Error())
	}
	bobBalance, err = client.AccountAPTBalance(bob.Address)
	if err != nil {
		panic("Failed to retrieve bob balance:" + err.Error())
	}
	fmt.Printf("\n=== Final Balances ===\n")
	fmt.Printf("Alice: %d\n", aliceBalance)
	fmt.Printf("Bob:%d\n", bobBalance)
}

func main() {
	example(aptos.DevnetConfig)
}
```

## Summary

Building and sending transactions on-chain involves the following 5 steps:

1. **Build** the transaction.
2. **Simulate** the cost. (Optional)
3. **Sign** the transaction (if the simulated cost seems ok).
4. **Submit** the transaction to the network.
5. **Wait** for the chain to validate and update.

## Explore Advanced Transaction Features

Transactions have a couple of additional features which let them adapt to your needs which you can learn about here:

1. [Multi-Agent Signatures](/build/sdks/go-sdk/building-transactions/multi-agent-transactions) - Allowing multiple accounts to be used for a single contract.
2. [Sponsoring Transactions](/build/sdks/go-sdk/building-transactions/sponsoring-transactions) - Have another account pay gas fees for this transaction.
3. [Batch Submit Transactions](/build/sdks/go-sdk/building-transactions/batching-transactions) - How to send multiple transactions quickly from a single account.
4. [Binary Canonical Serialization (BCS)](/build/sdks/go-sdk/building-transactions/bcs-format) - The format used to serialize data for Aptos transactions.

# Go SDK - Batching Transactions

> Execute multiple transactions concurrently from a single account using the Go SDK's built-in batching capabilities

The Go SDK has a built-in way to send many transactions concurrently, and order
them. This can be a convenient tool when trying to execute multiple transactions
quickly from the same account.

This can be done with `client.BuildSignAndSubmitTransactions` as can be seen in the below example.

## Full Go Example

```go filename="batch.go"
// sending_concurrent_transactions shows how to submit transactions serially or concurrently on a single account
package main

import (
	"github.com/aptos-labs/aptos-go-sdk"
	"github.com/aptos-labs/aptos-go-sdk/api"
	"time"
)

func setup(networkConfig aptos.NetworkConfig) (*aptos.Client, aptos.TransactionSigner) {
	client, err := aptos.NewClient(networkConfig)
	if err != nil {
		panic("Failed to create client:" + err.Error())
	}

	sender, err := aptos.NewEd25519Account()
	if err != nil {
		panic("Failed to create sender:" + err.Error())
	}

	err = client.Fund(sender.Address, 100_000_000)
	if err != nil {
		panic("Failed to fund sender:" + err.Error())
	}

	return client, sender
}

func payload() aptos.TransactionPayload {
	receiver := aptos.AccountAddress{}
	err := receiver.ParseStringRelaxed("0xBEEF")
	if err != nil {
		panic("Failed to parse address:" + err.Error())
	}
	amount := uint64(100)
	p, err := aptos.CoinTransferPayload(nil, receiver, amount)
	if err != nil {
		panic("Failed to serialize arguments:" + err.Error())
	}
	return aptos.TransactionPayload{Payload: p}
}

func sendManyTransactionsSerially(networkConfig aptos.NetworkConfig, numTransactions uint64) {
	client, sender := setup(networkConfig)

	responses := make([]*api.SubmitTransactionResponse, numTransactions)
	payload := payload()

	senderAddress := sender.AccountAddress()
	sequenceNumber := uint64(0)
	for i := uint64(0); i < numTransactions; i++ {
		rawTxn, err := client.BuildTransaction(senderAddress, payload, aptos.SequenceNumber(sequenceNumber))
		if err != nil {
			panic("Failed to build transaction:" + err.Error())
		}

		signedTxn, err := rawTxn.SignedTransaction(sender)
		if err != nil {
			panic("Failed to sign transaction:" + err.Error())
		}

		submitResult, err := client.SubmitTransaction(signedTxn)
		if err != nil {
			panic("Failed to submit transaction:" + err.Error())
		}
		responses[i] = submitResult
		sequenceNumber++
	}

	// Wait on last transaction
	response, err := client.WaitForTransaction(responses[numTransactions-1].Hash)
	if err != nil {
		panic("Failed to wait for transaction:" + err.Error())
	}
	if response.Success == false {
		panic("Transaction failed due to " + response.VmStatus)
	}
}

func sendManyTransactionsConcurrently(networkConfig aptos.NetworkConfig, numTransactions uint64) {
	client, sender := setup(networkConfig)
	payload := payload()

	// start submission goroutine
	payloads := make(chan aptos.TransactionBuildPayload, 50)
	results := make(chan aptos.TransactionSubmissionResponse, 50)
	go client.BuildSignAndSubmitTransactions(sender, payloads, results)

	// Submit transactions to goroutine
	go func() {
		for i := uint64(0); i < numTransactions; i++ {
			payloads <- aptos.TransactionBuildPayload{
				Id:    i,
				Type:  aptos.TransactionSubmissionTypeSingle,
				Inner: payload,
			}
		}
		close(payloads)
	}()

	// Wait for all transactions to be processed
	for result := range results {
		if result.Err != nil {
			panic("Failed to submit and wait for transaction:" + result.Err.Error())
		}
	}
}

// example This example shows you how to improve performance of the transaction submission
//
// Speed can be improved by locally handling the sequence number, gas price, and other factors
func example(networkConfig aptos.NetworkConfig, numTransactions uint64) {
	println("Sending", numTransactions, "transactions Serially")
	startSerial := time.Now()
	sendManyTransactionsSerially(networkConfig, numTransactions)
	endSerial := time.Now()
	println("Serial:", time.Duration.Milliseconds(endSerial.Sub(startSerial)), "ms")

	println("Sending", numTransactions, "transactions Concurrently")
	startConcurrent := time.Now()
	sendManyTransactionsConcurrently(networkConfig, numTransactions)
	endConcurrent := time.Now()
	println("Concurrent:", time.Duration.Milliseconds(endConcurrent.Sub(startConcurrent)), "ms")

	println("Concurrent is", time.Duration.Milliseconds(endSerial.Sub(startSerial)-endConcurrent.Sub(startConcurrent)), "ms faster than Serial")
}

func main() {
	example(aptos.DevnetConfig, 100)
}
```

# Go SDK - Binary Canonical Serialization (BCS) Format

> Learn how to use Binary Canonical Serialization (BCS) format for transaction parameters with the Go SDK

All transaction arguments for the Aptos Go SDK are encoded as bytes in Binary
Canonical Serialization (BCS) format. This is the format the Aptos chain
recognizes, with specific types (ex. Instead of an uint64 or big.Int, it uses
types like `u64` or `u128`)

You can directly use the BCS format to build transactions by specifying argument types explicitly like so:

```go filename="example.go"
	accountBytes, err := bcs.Serialize(&bob.Address)
	if err != nil {
		panic("Failed to serialize bob's address:" + err.Error())
	}

	amountBytes, err := bcs.SerializeU64(TransferAmount)
	if err != nil {
		panic("Failed to serialize transfer amount:" + err.Error())
	}
	rawTxn, err := client.BuildTransaction(alice.AccountAddress(), aptos.TransactionPayload{
		Payload: &aptos.EntryFunction{
			Module: aptos.ModuleId{
				Address: aptos.AccountOne,
				Name:    "aptos_account",
			},
			Function: "transfer",
			ArgTypes: []aptos.TypeTag{},
			Args: [][]byte{
				accountBytes,
				amountBytes,
			},
		}},
	)
```

You can learn more about BCS by exploring the [BCS GitHub repo](https://github.com/aptos-labs/bcs).

# Go SDK - Multi-Agent Transactions

> Enable multiple accounts to participate in a single transaction with coordinated signatures using the Go SDK

import { Aside, Steps } from '@astrojs/starlight/components';

Multi-agent transactions allow multiple accounts to participate in the logic of
a Move contract.

This can be used to require multiple parties agree to a transaction before
executing or to use resources from multiple accounts.

## Writing Multi-Agent Transactions

Creating and executing a multi-agent transaction follows a similar flow to the
[regular transaction flow](/build/sdks/go-sdk/building-transactions), but with several
notable differences.

<Aside type="note">
  Instead of `client.BuildTransaction`, multi-agent and sponsored transactions
  use `client.BuildTransactionMultiAgent`.
</Aside>

<Steps>
  1. Build the transaction by including aptos.AdditionalSigners with a list of each additional signers.

     <Aside type="note">
       Make sure to replace the `Function` field below with your entry function
       that requires multiple agents to sign.
     </Aside>

     ```go filename="multi_agent.go"
     transaction, err := client.BuildTransactionMultiAgent(alice.AccountAddress(), aptos.TransactionPayload{
       Payload: &aptos.EntryFunction{
         // Replace module and function with your multi-agent function
         Module: aptos.ModuleId{
           Address: aptos.AccountOne,
           Name:    "aptos_account",
         },
         Function: "transfer",
         ArgTypes: []aptos.TypeTag{},
         Args: [][]byte{
           accountBytes,
           amountBytes,
         },
       },
       AdditionalSigners: []aptos.AccountAddress{bob.AccountAddress()},
     })
     ```

     {/* TODO Support simulation of multiagent */}

  2. Sign once for each signer.

     You will combine these signatures in the next step.

     ```go filename="multi_agent.go"
     aliceAuth, err := rawTxn.Sign(alice)
     if err != nil {
         panic("Failed to sign transaction as sender:" + err.Error())
     }
     bobAuth, err := rawTxn.Sign(bob)
     if err != nil {
         panic("Failed to sign transaction as second signer:" + err.Error())
     }
     ```

  3. Combine the signatures with the raw transaction to create a multi-agent signed transaction.

     ```go filename="multi_agent.go"
     signedTxn, ok := rawTxn.ToMultiAgentSignedTransaction(aliceAuth, []crypto.AccountAuthenticator{bobAuth})
     ```

  4. Submit the transaction by combining all agent signatures via the aptos.AdditionalSigners parameter.

     ```go filename="multi_agent.go"
     submitResponse, err := client.SubmitTransaction(signedTxn)
     ```

  5. Lastly, wait for the transaction to resolve.

     ```go filename="multi_agent.go"
     txnResult, err := client.WaitForTransaction(submitResponse.Hash)
     ```
</Steps>

{/* TODO: Add full code snippet for Go */}

## Common Errors

`NUMBER_OF_SIGNER_ARGUMENTS_MISMATCH` - This happens when you are attempting to
do multi-agent signing for a function which does not require that number of
accounts. For example, if you try using multiple signatures for a
`0x1::aptos_account::transfer` function - it only expects one address, and so
produces an error when more than one is provided.

# Go SDK - Simulating Transactions

> Preview transaction costs and effects before submission using transaction simulation with the Go SDK

Simulating transactions allows you to preview the cost and effect of submitting
a transaction without paying fees. You can use this to estimate fees, test a
transaction, or to check what the output might be.

To simulate a transaction, you must pass in a transaction and which account
would be the signer:

```go filename="simulate_a_transaction.go"
// transfer_coin is an example of how to make a coin transfer transaction in the simplest possible way
package main

import (
	"fmt"

	"github.com/aptos-labs/aptos-go-sdk"
	"github.com/aptos-labs/aptos-go-sdk/bcs"
)

const FundAmount = 100_000_000
const TransferAmount = 1_000

// example This example shows you how to make an APT transfer transaction in the simplest possible way
func example(networkConfig aptos.NetworkConfig) {
	// Create a client for Aptos
	client, err := aptos.NewClient(networkConfig)
	if err != nil {
		panic("Failed to create client:" + err.Error())
	}

	// Create accounts locally for alice and bob
	alice, err := aptos.NewEd25519Account()
	if err != nil {
		panic("Failed to create alice:" + err.Error())
	}
	bob, err := aptos.NewEd25519Account()
	if err != nil {
		panic("Failed to create bob:" + err.Error())
	}

	fmt.Printf("\n=== Addresses ===\n")
	fmt.Printf("Alice: %s\n", alice.Address.String())
	fmt.Printf("Bob:%s\n", bob.Address.String())

	// Fund the sender with the faucet to create it on-chain
	err = client.Fund(alice.Address, FundAmount)
	if err != nil {
		panic("Failed to fund alice:" + err.Error())
	}

	aliceBalance, err := client.AccountAPTBalance(alice.Address)
	if err != nil {
		panic("Failed to retrieve alice balance:" + err.Error())
	}
	bobBalance, err := client.AccountAPTBalance(bob.Address)
	if err != nil {
		panic("Failed to retrieve bob balance:" + err.Error())
	}
	fmt.Printf("\n=== Initial Balances ===\n")
	fmt.Printf("Alice: %d\n", aliceBalance)
	fmt.Printf("Bob:%d\n", bobBalance)

	// 1. Build transaction
	accountBytes, err := bcs.Serialize(&bob.Address)
	if err != nil {
		panic("Failed to serialize bob's address:" + err.Error())
	}

	amountBytes, err := bcs.SerializeU64(TransferAmount)
	if err != nil {
		panic("Failed to serialize transfer amount:" + err.Error())
	}
	rawTxn, err := client.BuildTransaction(alice.AccountAddress(), aptos.TransactionPayload{
		Payload: &aptos.EntryFunction{
			Module: aptos.ModuleId{
				Address: aptos.AccountOne,
				Name:    "aptos_account",
			},
			Function: "transfer",
			ArgTypes: []aptos.TypeTag{},
			Args: [][]byte{
				accountBytes,
				amountBytes,
			},
		}},
	)

	if err != nil {
		panic("Failed to build transaction:" + err.Error())
	}

	// 2. Simulate transaction
	// This is useful for understanding how much the transaction will cost
	// and to ensure that the transaction is valid before sending it to the network
	// This is optional, but recommended
	simulationResult, err := client.SimulateTransaction(rawTxn, alice)
	if err != nil {
		panic("Failed to simulate transaction:" + err.Error())
	}
	fmt.Printf("\n=== Simulation ===\n")
	fmt.Printf("Gas unit price: %d\n", simulationResult[0].GasUnitPrice)
	fmt.Printf("Gas used: %d\n", simulationResult[0].GasUsed)
	fmt.Printf("Total gas fee: %d\n", simulationResult[0].GasUsed*simulationResult[0].GasUnitPrice)
	fmt.Printf("Status: %s\n", simulationResult[0].VmStatus)
}

func main() {
	example(aptos.DevnetConfig)
}
```

{ /* TODO: Details on the simulation result */ }

Look [here](/build/sdks/go-sdk/building-transactions) to see the full example of how to build, simulate, and submit a transaction.

You can also learn how to simulate more advanced transactions by looking at the following guides:

- [Sponsored Transactions](/build/sdks/go-sdk/building-transactions/sponsoring-transactions)
- [Multi-Agent Transactions](/build/sdks/go-sdk/building-transactions/multi-agent-transactions)

# Go SDK - Sponsoring Transactions

> Learn how to sponsor transactions on Aptos using the Go SDK, allowing one account to pay gas fees for another account's transactions

import { Aside, Steps } from '@astrojs/starlight/components';

Normally, the account that is executing a transaction pays for the gas fees. You
can allow another account to cover those charges by sponsoring a transaction.

This can be used to help manage fees from a central account when working with
complicated smart contracts.

## How To Sponsor a Transaction

<Steps>
  1. Build the transaction with the parameter FeePayer().

     ```go filename="sponsor.go"
       rawTxn, err := client.BuildTransactionMultiAgent(
       alice.Address,
       aptos.TransactionPayload{
       Payload: transferPayload,
       },
       aptos.FeePayer(&sponsor.Address),
       )
     ```

     <Aside type="note">
       The `FeePayer()` function is used to specify the account that will pay the
       gas fees for the transaction. You can use `AccountZero` to indicate that the
       fee payer is not known ahead of time.
     </Aside>

  2. Sign the transaction with BOTH the sender and the feePayer.

     1. Sign with the sender account using `rawTxn.Sign()`.
     2. Sign with the sponsor account using `rawTxn.Sign()`.

     ```go filename="sponsor.go"
       aliceAuth, err := rawTxn.Sign(alice)
       if err != nil {
         panic("Failed to sign transaction as sender:" + err.Error())
       }
       sponsorAuth, err := rawTxn.Sign(sponsor)
       if err != nil {
         panic("Failed to sign transaction as sponsor:" + err.Error())
       }
     ```

     {/* TODO: Support simulation for fee payer
       ### (Optional) When simulating the transaction, include the parameter `feePayerPublicKey: account.publicKey`

       <Callout type="warning">
       Currently, simulating a sponsor transaction must happen AFTER signing with the sponsor or it will fail to recognize this transaction has a sponsor.
       </Callout>

       ```ts filename="sponsor.ts"
       const [userTransactionResponse] = await aptos.transaction.simulate.simple({
         signerPublicKey: sender.publicKey,
         feePayerPublicKey: feePayer.publicKey,
         transaction,
       });
       ```
       */}

  3. Submit the transaction by combining both signatures.

     ```go filename="sponsor.go"
       signedFeePayerTxn, ok = rawTxn.ToFeePayerSignedTransaction(
           aliceAuth,
           sponsorAuth,
           []crypto.AccountAuthenticator{},
       )
       if !ok {
           panic("Failed to build fee payer signed transaction")
       }

       // Submit and wait for it to complete
       submitResult, err = client.SubmitTransaction(signedFeePayerTxn)
       if err != nil {
           panic("Failed to submit transaction:" + err.Error())
       }
     ```

  4. Wait for the transaction to execute.

     ```go filename="sponsor.go"
       // Wait for the transaction
       _, err = client.WaitForTransaction(txnHash)
     ```
</Steps>

## Go Sponsored Transaction Code Sample

```go filename="sponsor.go"
// sponsored_transaction is an example of how to make a sponsored transaction in Aptos.
package main

import (
	"fmt"

	"github.com/aptos-labs/aptos-go-sdk"
	"github.com/aptos-labs/aptos-go-sdk/crypto"
)

const FundAmount = 100_000_000
const TransferAmount = 1_000

// example This example shows you how to make an APT transfer transaction in the simplest possible way
func example(networkConfig aptos.NetworkConfig) {
	// Create a client for Aptos
	client, err := aptos.NewClient(networkConfig)
	if err != nil {
		panic("Failed to create client:" + err.Error())
	}

	// Create accounts locally for alice and bob
	alice, err := aptos.NewEd25519Account()
	if err != nil {
		panic("Failed to create alice:" + err.Error())
	}
	bob, err := aptos.NewEd25519Account()
	if err != nil {
		panic("Failed to create bob:" + err.Error())
	}
	sponsor, err := aptos.NewEd25519Account()
	if err != nil {
		panic("Failed to create sponsor:" + err.Error())
	}

	fmt.Printf("\n=== Addresses ===\n")
	fmt.Printf("Alice: %s\n", alice.Address.String())
	fmt.Printf("Bob:%s\n", bob.Address.String())
	fmt.Printf("Sponsor:%s\n", sponsor.Address.String())

	// Fund the alice with the faucet to create it on-chain
	err = client.Fund(alice.Address, FundAmount)
	if err != nil {
		panic("Failed to fund alice:" + err.Error())
	}

	// And the sponsor
	err = client.Fund(sponsor.Address, FundAmount)
	if err != nil {
		panic("Failed to fund sponsor:" + err.Error())
	}

	aliceBalance, err := client.AccountAPTBalance(alice.Address)
	if err != nil {
		panic("Failed to retrieve alice balance:" + err.Error())
	}
	bobBalance, err := client.AccountAPTBalance(bob.Address)
	if err != nil {
		panic("Failed to retrieve bob balance:" + err.Error())
	}
	sponsorBalance, err := client.AccountAPTBalance(sponsor.Address)
	if err != nil {
		panic("Failed to retrieve sponsor balance:" + err.Error())
	}
	fmt.Printf("\n=== Initial Balances ===\n")
	fmt.Printf("Alice: %d\n", aliceBalance)
	fmt.Printf("Bob: %d\n", bobBalance)
	fmt.Printf("Sponsor: %d\n", sponsorBalance)

	// Build transaction
	transferPayload, err := aptos.CoinTransferPayload(&aptos.AptosCoinTypeTag, bob.Address, TransferAmount)
	if err != nil {
		panic("Failed to build transfer payload:" + err.Error())
	}
	rawTxn, err := client.BuildTransactionMultiAgent(
		alice.Address,
		aptos.TransactionPayload{
			Payload: transferPayload,
		},
		aptos.FeePayer(&sponsor.Address),

	)
	if err != nil {
		panic("Failed to build transaction:" + err.Error())
	}

	// Sign transaction
	aliceAuth, err := rawTxn.Sign(alice)
	if err != nil {
		panic("Failed to sign transaction as sender:" + err.Error())
	}
	sponsorAuth, err := rawTxn.Sign(sponsor)
	if err != nil {
		panic("Failed to sign transaction as sponsor:" + err.Error())
	}

	signedFeePayerTxn, ok := rawTxn.ToFeePayerSignedTransaction(
		aliceAuth,
		sponsorAuth,
		[]crypto.AccountAuthenticator{},
	)
	if !ok {
		panic("Failed to build fee payer signed transaction")
	}

	// Submit and wait for it to complete
	submitResult, err := client.SubmitTransaction(signedFeePayerTxn)
	if err != nil {
		panic("Failed to submit transaction:" + err.Error())
	}
	txnHash := submitResult.Hash
	println("Submitted transaction hash:", txnHash)

	// Wait for the transaction
	_, err = client.WaitForTransaction(txnHash)
	if err != nil {
		panic("Failed to wait for transaction:" + err.Error())
	}
	aliceBalance, err = client.AccountAPTBalance(alice.Address)
	if err != nil {
		panic("Failed to retrieve alice balance:" + err.Error())
	}
	bobBalance, err = client.AccountAPTBalance(bob.Address)
	if err != nil {
		panic("Failed to retrieve bob balance:" + err.Error())
	}
	sponsorBalance, err = client.AccountAPTBalance(sponsor.Address)
	if err != nil {
		panic("Failed to retrieve sponsor balance:" + err.Error())
	}
	fmt.Printf("\n=== Intermediate Balances ===\n")
	fmt.Printf("Alice: %d\n", aliceBalance)
	fmt.Printf("Bob: %d\n", bobBalance)
	fmt.Printf("Sponsor: %d\n", sponsorBalance)

	fmt.Printf("\n=== Now do it without knowing the signer ahead of time ===\n")

	rawTxn, err = client.BuildTransactionMultiAgent(
		alice.Address,
		aptos.TransactionPayload{
			Payload: transferPayload,
		},
		aptos.FeePayer(&aptos.AccountZero), // Note that the Address is 0x0, because we don't know the signer
	)
	if err != nil {
		panic("Failed to build transaction:" + err.Error())
	}

	// Alice signs the transaction, without knowing the sponsor
	aliceAuth, err = rawTxn.Sign(alice)
	if err != nil {
		panic("Failed to sign transaction as sender:" + err.Error())
	}

	// The sponsor has to add themselves to the transaction to sign, note that this would likely be on a different
	// server
	ok = rawTxn.SetFeePayer(sponsor.Address)
	if !ok {
		panic("Failed to set fee payer")
	}

	sponsorAuth, err = rawTxn.Sign(sponsor)
	if err != nil {
		panic("Failed to sign transaction as sponsor:" + err.Error())
	}

	signedFeePayerTxn, ok = rawTxn.ToFeePayerSignedTransaction(
		aliceAuth,
		sponsorAuth,
		[]crypto.AccountAuthenticator{},
	)
	if !ok {
		panic("Failed to build fee payer signed transaction")
	}

	// Submit and wait for it to complete
	submitResult, err = client.SubmitTransaction(signedFeePayerTxn)
	if err != nil {
		panic("Failed to submit transaction:" + err.Error())
	}
	txnHash = submitResult.Hash
	println("Submitted transaction hash:", txnHash)

	// Wait for the transaction
	_, err = client.WaitForTransaction(txnHash)
	if err != nil {
		panic("Failed to wait for transaction:" + err.Error())
	}
	aliceBalance, err = client.AccountAPTBalance(alice.Address)
	if err != nil {
		panic("Failed to retrieve alice balance:" + err.Error())
	}
	bobBalance, err = client.AccountAPTBalance(bob.Address)
	if err != nil {
		panic("Failed to retrieve bob balance:" + err.Error())
	}
	sponsorBalance, err = client.AccountAPTBalance(sponsor.Address)
	if err != nil {
		panic("Failed to retrieve sponsor balance:" + err.Error())
	}
	fmt.Printf("\n=== Final Balances ===\n")
	fmt.Printf("Alice: %d\n", aliceBalance)
	fmt.Printf("Bob: %d\n", bobBalance)
	fmt.Printf("Sponsor: %d\n", sponsorBalance)
}

func main() {
	example(aptos.DevnetConfig)
}
```

# Go SDK - Fetch Data

> Learn how to retrieve on-chain data, account information, and resources using the Aptos Go SDK

import { Aside } from '@astrojs/starlight/components';

You can use the `Aptos` client to get on-chain data using a variety of helper
functions. Specifically, many of the functions listed in the [reference docs](https://pkg.go.dev/github.com/aptos-labs/aptos-go-sdk)
will retrieve data from on-chain e.g. `Account`, `AccountResources`, `Transactions`.

Here‚Äôs an example showing how to fetch common data you may need in your application:

```go filename="fetch_data.go"
client, err := aptos.NewClient(aptos.DevnetConfig)
if err != nil {
  panic("Failed to create client:" + err.Error())
}

address := aptos.AccountAddress{}
err := address.ParseStringRelaxed("0x123")
if err != nil {
  panic("Failed to parse address:" + err.Error())
}

accountInfo, err := client.Account(address)
resources, err := client.AccountResources(address)
transactions, err := client.Transactions()
```

<Aside type="note">
  Many have optional inputs such as `ledgerVersion` to specify which ledger
  version to query state.
</Aside>

The `Aptos` client can out of the box query both network data from
[fullnodes](https://api.mainnet.aptoslabs.com/v1/spec#/) and the
[Indexer](https://cloud.hasura.io/public/graphiql?endpoint=https://api.mainnet.aptoslabs.com/v1/graphql)
API which contains aggregated and enriched data. If you want to use a custom
query for Indexer API data, you can use `client.QueryIndexer()` like so:

```go filename="fetch_data.go"
	var out []CoinBalance
	var q struct {
		Current_coin_balances []struct {
			CoinType     string `graphql:"coin_type"`
			Amount       uint64
			OwnerAddress string `graphql:"owner_address"`
		} `graphql:"current_coin_balances(where: {owner_address: {_eq: $address}})"`
	}

	variables := map[string]any{
		"address": address.StringLong(),
	}
	err := ic.Query(&q, variables)

	if err != nil {
		return nil, err
	}

	for _, coin := range q.Current_coin_balances {
		out = append(out, CoinBalance{
			CoinType: coin.CoinType,
			Amount:   coin.Amount,
		})
	}
```

<Aside type="note">
  Note that all values in the GraphQL must be capitalized and CamelCased. To
  convert to direct database field names, use the `graphql` tag.
</Aside>

## Using Move View Functions

You can call view functions which return custom data from on-chain by using `client.View`.

For example, you can look up the network you are using with the `chain_id` view function:

```go filename="fetch_data.go"
viewResponse, err := client.View(&aptos.ViewPayload {
  Module: aptos.ModuleId{Address: aptos.AccountAddress{}, Name: "chain_id"},
  Function: "get",
  ArgTypes: []aptos.TypeTag{},
  Args: [][]byte{},
)

chainId := viewResponse[0]
```

## Ensuring Fresh Indexer Data

Behind the scenes, some requests use the [Indexer API](/build/indexer) to
access data which has been processed or aggregated. That extra parsing can take
a bit of time, so the data may lag slightly behind the latest ledger.

If you want to ensure that the data is fresh, you can wait on a specific version
from the indexer.

```go filename="fetch_data.go"
// Wait on processorName to reach version 12345
err := client.WaitOnIndexer("processorName", 12345)
```

# Go SDK - Examples

> Comprehensive collection of example code and reference implementations for the Aptos Go SDK

import { Steps } from '@astrojs/starlight/components';

For sample code which explains the core concepts of how to use the SDK, see:

- [Fetching Data](/build/sdks/go-sdk/fetch-data-via-sdk)
- [Building, Simulating, and Submitting Transactions](/build/sdks/go-sdk/building-transactions)

Below are additional resources which may be more suited for your individual use case.

## Code Snippets

The [`examples` folder](https://github.com/aptos-labs/aptos-go-sdk/tree/main/examples)
in the SDK repo has many code snippets you can customize to your needs.

### How to run examples

To run one of the example scripts:

<Steps>
  1. Clone the

     ```shellscript filename="Terminal"
     git clone https://github.com/aptos-labs/aptos-go-sdk.git
     ```

  2. From the top-level of the package, install all dependencies.

     ```shellscript filename="Terminal"
     go install
     ```

  3. Build the package.

     ```shellscript filename="Terminal"
     go build ./...
     ```

  4. Run an example

     ```shellscript filename="Terminal"
     go run examples/transfer_coin/main.go
     ```
</Steps>

## Helpful Reference Code

- [SDK source code](https://github.com/aptos-labs/aptos-go-sdk/tree/main) - This has in-line comments explaining what each function does.
- [SDK reference docs](https://pkg.go.dev/github.com/aptos-labs/aptos-go-sdk) - These are another way to view the in-line documentation with built-in search.

# Python SDK

> Official Python SDK for Aptos - perfect for getting started with blockchain development and tutorials

Aptos provides a lightly maintained official Python SDK. It is available on
[PyPi](https://pypi.org/project/aptos-sdk/) with the source code in the
[aptos-python-sdk GitHub repository](https://github.com/aptos-labs/aptos-python-sdk).
Much of the functionality of the Python SDK mirrors the [Typescript SDK](/build/sdks/ts-sdk).
The primary purpose of the Python SDK is to help Python developers to quickly
become familiar with Aptos and as an accompaniment to Aptos tutorials.

## Installing Python SDK

The Python SDK can either be installed via `pip`, from source, or embedded:

### Install with pip

To install via `pip`:

```shellscript filename="Terminal"
pip3 install aptos-sdk
```

The `aptos-sdk` will be installed in the local site packages directory. For
example, on macOS, you will find the `aptos-sdk` in the
`~/Library/Python/3.8/lib/python/site-packages/aptos_sdk` directory.

### Install from the source code

To install from source:

```shellscript filename="Terminal"
git clone https://github.com/aptos-labs/aptos-python-sdk
pip3 install . --user
```

### Install by embedding

To embed the Python SDK into your existing Python project:

```shellscript filename="Terminal"
cd /path/to/python/project
cp -r /path/to/aptos-python-sdk aptos-sdk
```

## Using the Python SDK

See the [Developer Tutorials](/build/guides) for code examples showing how to
use the Python SDK.

# Rust SDK

> Official Rust SDK for Aptos blockchain development - lightweight and efficient for Rust applications

## Installation

Aptos provides an official lightly supported Rust SDK in the
[Aptos-core GitHub](https://github.com/aptos-labs/aptos-core/tree/main/sdk)
repository. To use the Rust SDK, add the following dependency and patches on the
git repo directly in your `Cargo.toml`, like this:

```toml filename="Cargo.toml"
[dependencies]
aptos-sdk = { git = "https://github.com/aptos-labs/aptos-core", branch = "devnet" }

[patch.crates-io]
merlin = { git = "https://github.com/aptos-labs/merlin" }
x25519-dalek = { git = "https://github.com/aptos-labs/x25519-dalek", branch = "zeroize_v1" }
```

You must also create a `.cargo/config.toml` file with this content:

```toml filename=".cargo/config.toml"
[build]
rustflags = ["--cfg", "tokio_unstable"]
```

The source code for the official Rust SDK is available in the
[aptos-core GitHub repository](https://github.com/aptos-labs/aptos-core/tree/main/sdk).

## Using Rust SDK

See the [Developer Tutorials](/build/guides) for code examples showing how to
use the Rust SDK.

# TypeScript SDK

> Official TypeScript SDK for building applications on Aptos - the most comprehensive and up-to-date SDK

import { CardGrid, LinkCard } from '@astrojs/starlight/components';

import { RemoteCodeblock } from '~/components/RemoteCodeblock';

<div className="flex gap-2 mt-6 flex-wrap">
  <a target="_blank" href="https://github.com/aptos-labs/aptos-ts-sdk">
    ![Github Repo Stars](https://img.shields.io/github/stars/aptos-labs/aptos-ts-sdk)
  </a>

  <a target="_blank" href="https://www.npmjs.com/package/@aptos-labs/ts-sdk">
    ![NPM Version](https://img.shields.io/npm/v/%40aptos-labs%2Fts-sdk)
  </a>

  <a target="_blank" href="https://www.npmjs.com/package/@aptos-labs/ts-sdk">
    ![Node Version](https://img.shields.io/node/v/%40aptos-labs%2Fts-sdk)
  </a>

  <a target="_blank" href="https://www.npmjs.com/package/@aptos-labs/ts-sdk">
    ![NPM bundle size](https://img.shields.io/bundlephobia/min/%40aptos-labs/ts-sdk)
  </a>

  <a target="_blank" href="https://aptos-labs.github.io/aptos-ts-sdk/@aptos-labs/ts-sdk-latest">
    ![Static Badge](https://img.shields.io/badge/SDK_Reference-Docs)
  </a>
</div>

The TypeScript SDK allows you to connect, explore, and interact on the Aptos blockchain. You can use it to request data, send transactions, set up test environments, and more!

```shellscript npm2yarn
npm i @aptos-labs/ts-sdk
```

## Examples

<CardGrid>
  <LinkCard href="/build/sdks/ts-sdk/quickstart" title="Quickstart" description="See the quickstart to get a working demo in < 5 minutes" />

  <LinkCard href="https://github.com/aptos-labs/aptos-ts-sdk/tree/main/examples/typescript" title="20+ Examples" description="Explore all of the TypeScript examples provided in the SDK repository" target="_blank" />

  <LinkCard href="https://github.com/aptos-labs/aptos-ts-sdk/tree/main/tests/e2e" title="Comprehensive Tests" description="See end to end tests which demonstrate how to use each feature of the SDK" target="_blank" />
</CardGrid>

### Transfer APT in 10 lines or less

<RemoteCodeblock permalink="https://github.com/aptos-labs/aptos-ts-sdk/blob/bcde1e3af2f09615015c774fb0c2f5206377346e/examples/typescript/simple_transfer.ts#L77-L91" />

# Creating and Managing Accounts

> Learn how to generate, fund, and manage Aptos accounts using the TypeScript SDK with different signing schemes

import { Aside } from '@astrojs/starlight/components';

There are several ways to generate account credentials using the TypeScript SDK. You can use:

- `Account.generate()`
- `Account.fromPrivateKey()`
- `Account.fromDerivationPath()`

`Account.generate()` is the most commonly used method to create keys for a new account.
It defaults to `ED25519` key encodings, but you can also manually specify which signing scheme you would prefer like so:

```typescript
const account = Account.generate(); // defaults to Legacy Ed25519
const account = Account.generate({ scheme: SigningSchemeInput.Secp256k1Ecdsa }); // Single Sender Secp256k1
const account = Account.generate({
  scheme: SigningSchemeInput.Ed25519,
  legacy: false,
}); // Single Sender Ed25519
```

<Aside type="note">
  Following [AIP-55](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-55.md) the SDK supports `Legacy` and `Unified` authentications. `Legacy` includes `ED25519` and `MultiED25519` and `Unified` includes `SingleSender` and `MultiSender` authenticators.
</Aside>

Once you have generated credentials, you **must** fund it for the network to know it exists.

In localnet / devnet this can be done with a faucet by running the following command:

```typescript filename="fund.ts"
const transaction = await aptos.fundAccount({
  accountAddress: account.accountAddress,
  amount: 100,
});
```

For testnet you can use the mint page [here](/network/faucet).

## Other Ways To Represent Accounts

If you have a private key, or equivalent representation, you can use that to create an `Account` object to manage those credentials while using the TypeScript SDK.

Here are several examples that show how to do so with specific encoding schemes.

### Derive an account from private key

The SDK supports deriving an account from a private key with `fromPrivateKey()` static method.
In addition, this method supports deriving an account from a private key and account address.
This method uses a local calculation and therefore is used to derive an `Account` that has not had its authentication key rotated.

```typescript
// to derive an account with a legacy Ed25519 key scheme
const privateKey = new Ed25519PrivateKey(privateKeyBytes);
const account = Account.fromPrivateKey({ privateKey });

// to derive an account with a Single Sender Ed25519 key scheme
const privateKey = new Ed25519PrivateKey(privateKeyBytes);
const account = Account.fromPrivateKey({ privateKey, legacy: false });

// to derive an account with a Single Sender Secp256k1 key scheme
const privateKey = new Secp256k1PrivateKey(privateKeyBytes);
const account = Account.fromPrivateKey({ privateKey });

// to derive an account with a private key and account address
const privateKey = new Ed25519PrivateKey(privateKeyBytes);
const address = AccountAddress.from(address);
const account = Account.fromPrivateKey({ privateKey, address });
```

### Derive an account from derivation path

The SDK supports deriving an account from derivation path with `fromDerivationPath()` static method.

```typescript
// to derive an account with a legacy Ed25519 key scheme
const { mnemonic, address, path } = wallet;
const account = Account.fromDerivationPath({
  path,
  mnemonic,
  scheme: SigningSchemeInput.Ed25519,
});

// to derive an account with a Single Sender Ed25519 key scheme
const { mnemonic, address, path } = wallet;
const account = Account.fromDerivationPath({
  path,
  mnemonic,
  scheme: SigningSchemeInput.Ed25519,
  legacy: false,
});

// to derive an account with a Single Sender Secp256k1 key scheme
const { mnemonic, address, path } = wallet;
const account = Account.fromDerivationPath({
  path,
  mnemonic,
  scheme: SigningSchemeInput.Secp256k1Ecdsa,
});
```

# Account Abstraction

> Implement custom transaction authentication logic through Move modules with Aptos Account Abstraction

import { Aside, Steps } from '@astrojs/starlight/components';

Account Abstraction (AA) on Aptos **enables custom transaction authentication logic through Move modules**, allowing accounts to define their own rules beyond native cryptographic schemes. **Note:** This is currently only live on testnet as of July 17, 2025.

## Core Concepts

### `FunctionInfo`

A struct defining the authentication function to be invoked.

```move
struct FunctionInfo has copy, drop, store {
    module_address: address,
    module_name: String,
    function_name: String
}
```

The authentication function is responsible for defining the authentication logic using Move. It should return a signer if authentication is successful, otherwise it aborts the transaction.
The only accepted authentication function signature that can be added onto an account is the following:

```move
// The function can return a signer if authentication is successful, otherwise it aborts the transaction.
public fun authenticate(account: signer, auth_data: AbstractionAuthData): signer;
```

**Example (Move)**

```move
module deployer::authenticator {
    use aptos_framework::auth_data::{AbstractionAuthData};

    public fun authenticate(account: signer, auth_data: AbstractionAuthData): signer {
        // ... authentication logic ...
        account
    }
}
```

**Example (Typescript)**

```typescript
const authenticationFunction = `${deployer}::authenticator::authenticate`;
```

### `AbstractionAuthData`

An enum variant defining the authentication data to be passed to the authentication function. It contains:

- `digest`: The sha256 hash of the signing message.
- `authenticator`: Abstract bytes that will be passed to the authentication function that will be used to verify the transaction.

```move
enum AbstractionAuthData has copy, drop {
    V1 { 
        digest: vector<u8>,       // SHA3-256 hash of the signing message
        authenticator: vector<u8> // Custom auth data (e.g., signatures)
    },
}
```

**Why is the `digest` important?**

The `digest` is checked by the MoveVM to ensure that the signing message of the transaction being submitted is the same as the one presented in the `AbstractionAuthData`. This
is important because it allows the authentication function to verify signatures with respect to the correct transaction.

For example, if you want to permit a public key to sign transactions on behalf of the user, you can permit the public key to sign a transaction with a specific payload.
However, if a malicious user sends a signature for the correct public key but a different payload from the `digest`, the signature will not be valid.

**Example (Move)**

This example demonstrates a simple authentication logic that checks if the authenticator is equal to `"hello world"`.

```move
module deployer::hello_world_authenticator {
    use aptos_framework::auth_data::{Self, AbstractionAuthData};

    public fun authenticate(
        account: signer,
        auth_data: AbstractionAuthData
    ): signer {
        let authenticator = *auth_data::authenticator(&auth_data);
        assert!(authenticator == b"hello world", 1);
        account
    }
}
```

**Example (Typescript)**

```typescript
const abstractedAccount = new AbstractedAccount({
  /**
   * The result of the signer function will be available as the `authenticator` field in the `AbstractionAuthData` enum variant.
   */
  signer: () => new TextEncoder().encode("hello world"),
  /**
   * The authentication function to be invoked.
   */
  authenticationFunction: `${deployer}::hello_world_authenticator::authenticate`,
});
```

## Minimal Step-by-Step Guide

<Steps>
  1. 1. Deploy Authentication Module

     In this example, we will deploy the `hello_world_authenticator` module. The `authenticate` function takes an `AbstractionAuthData` and returns a `signer`
     if the authentication is successful, otherwise it aborts the transaction. The authentication logic will only allow transactions that have an authenticator equal to `"hello world"`.

     ```move
     module deployer::hello_world_authenticator {
         use aptos_framework::auth_data::{Self, AbstractionAuthData};
         use std::bcs;

         public fun authenticate(
             account: signer,
             auth_data: AbstractionAuthData
         ): signer {
             let authenticator = *auth_data::authenticator(&auth_data);
             assert!(authenticator == b"hello world", 1);
             account
         }
     }
     ```

     To deploy the module, you can use the following commands from the [Aptos CLI](/build/cli). We assume that you already have set up a workspace with `aptos init` and
     declared the named addresses in your `Move.toml` file.

     ```shellscript
     aptos move publish --named-addresses deployer=0x1234567890123456789012345678901234567890
     ```

  2. 2. Setup your Environment

     Once deployed, you can setup your environment. In this example, we will use Devnet and create an account named `alice` which will act as our user.

     ```typescript
     const DEPLOYER = "0x<hello_world_authenticator_deployer>"

     const aptos = new Aptos(new AptosConfig({ network: Network.DEVNET }));

     const alice = Account.generate();

     const authenticationFunctionInfo = `${deployer}::hello_world_authenticator::authenticate`;
     ```

  3. 3. (Optional) Check if Account Abstraction is Enabled

     Before you ask them to enable account abstraction, you can check if the account has account abstraction enabled by calling the `isAccountAbstractionEnabled` function.
     This will return a boolean value indicating if the account has account abstraction enabled.

     ```typescript
     const accountAbstractionStatus = await aptos.abstraction.isAccountAbstractionEnabled({
         accountAddress: alice.accountAddress,
         authenticationFunction,
     });

     console.log("Account Abstraction status: ", accountAbstractionStatus);
     ```

  4. 4. Enable the Authentication Function

     Assuming that the account does not have account abstraction enabled, you need to enable the authentication function for the account. This can be done by calling
     the `enableAccountAbstractionTransaction` function. This creates a raw transaction that needs to be signed and submitted to the network. In this example, `alice`
     will be the account that will be enabled.

     ```typescript
     const transaction = aptos.abstraction.enableAccountAbstractionTransaction({
       accountAddress: alice.accountAddress,
       authenticationFunction: `${deployer}::hello_world_authenticator::authenticate`,
     });

     const pendingTransaction = await aptos.signAndSubmitTransaction({
       transaction,
       signer: alice.signer,
     });

     await aptos.waitForTransaction({ hash: pendingTransaction.hash });

     console.log("Account Abstraction enabled for account: ", alice.accountAddress);
     ```

     <details>
       <summary>
         <b>Wallet Adapter Example</b>
       </summary>

       <Aside type="note">
         If you are using the wallet adapter, you can use the `signTransaction` function to sign the transaction before submitting it to the network.
       </Aside>

       ```tsx
       export default function useEnableAbstraction() {
         const { account, signTransaction } = useWallet();

         return {
           enableAbstraction: async () => {
             if (!account) return;

             // Note: The Aptos client must be defined somewhere in the application.
             const transaction = aptos.abstraction.enableAccountAbstractionTransaction({
               accountAddress: account.address,
               authenticationFunction: `${deployer}::hello_world_authenticator::authenticate`,
             });

             const senderAuthenticator = await signTransaction(txn);

             const pendingTxn = await aptos.transaction.submit.simple({
               transaction: txn,
               senderAuthenticator,
             });

             return await aptos.waitForTransaction({ hash: pendingTxn.hash });
           }
         }
       }
       ```
     </details>

  5. 5. Create an Abstracted Account

     Once the authentication function is enabled, you can create an abstracted account object for signing transactions. You must provide the authentication function that will be used to verify the transaction
     and a `signer` function that will be used to sign the transaction. The `signer` function is responsible for generating the authenticator that will be passed to the authentication function.

     ```typescript
     const abstractedAccount = new AbstractedAccount({
       accountAddress: alice.accountAddress,
       signer: () => new TextEncoder().encode("hello world"),
       authenticationFunction: `${deployer}::hello_world_authenticator::authenticate`,
     });
     ```

  6. 6. Sign and Submit a Transaction using the Abstracted Account

     Once you have created the abstracted account, you can use it to sign transactions normally. It is important that the `sender` field in the transaction
     is the same as the abstracted account's address.

     ```typescript
     const coinTransferTransaction = await aptos.transaction.build.simple({
       sender: abstractedAccount.accountAddress,
       data: {
         function: "0x1::coin::transfer",
         typeArguments: ["0x1::aptos_coin::AptosCoin"],
         functionArguments: [alice.accountAddress, 100],
       },
     });

     const pendingCoinTransferTransaction = await aptos.transaction.signAndSubmitTransaction({
       transaction: coinTransferTransaction,
       signer: abstractedAccount,
     });

     await aptos.waitForTransaction({ transactionHash: pendingCoinTransferTransaction.hash });

     console.log("Coin transfer transaction submitted! ", pendingCoinTransferTransaction.hash);
     ```

  7. 7. Conclusion

     To verify that you have successfully sign and submitted the transaction using the abstracted account, you can use the explorer to check the transaction. If the
     transaction signature contains a `function_info` and `auth_data` field, it means you successfully used account abstraction! The full E2E demo can be found [here](https://github.com/aptos-labs/aptos-ts-sdk/blob/main/examples/typescript/public_key_authenticator_account_abstraction.ts).

     ![Transaction Signature](~/images/account-abstraction/minimal-guide-transaction-signature.png)
</Steps>

## Complex Step-by-Step Guide

Now that you have a basic understanding of how account abstraction works, let's dive into a more complex example.

In this example, we will create an authenticator that allows users to permit certain public keys to sign transactions on behalf of the abstracted account.

<Steps>
  1. 1. Create an Authenticator module

     We will deploy the `public_key_authenticator` module that does two things:

     - Allow users to permit and/or revoke public keys from signing on behalf of the user.
     - Allow users to authenticate on behalf of somebody else using account abstraction.

     ```move
     module deployer::public_key_authenticator {
         use std::signer;
         use aptos_std::smart_table::{Self, SmartTable};
         use aptos_std::ed25519::{
             Self,
             new_signature_from_bytes,
             new_unvalidated_public_key_from_bytes,
             unvalidated_public_key_to_bytes
         };
         use aptos_framework::bcs_stream::{Self, deserialize_u8};
         use aptos_framework::auth_data::{Self, AbstractionAuthData};

         // ====== Error Codes ====== //

         const EINVALID_PUBLIC_KEY: u64 = 0x20000;
         const EPUBLIC_KEY_NOT_PERMITTED: u64 = 0x20001;
         const EENTRY_ALREADY_EXISTS: u64 = 0x20002;
         const ENO_PERMISSIONS: u64 = 0x20003;
         const EINVALID_SIGNATURE: u64 = 0x20004;

         // ====== Data Structures ====== //

         struct PublicKeyPermissions has key {
             public_key_table: SmartTable<vector<u8>, bool>,
         }

         // ====== Authenticator ====== //

         public fun authenticate(
             account: signer,
             auth_data: AbstractionAuthData
         ): signer acquires PublicKeyPermissions {
             let account_addr = signer::address_of(&account);
             assert!(exists<PublicKeyPermissions>(account_addr), ENO_PERMISSIONS);
             let permissions = borrow_global<PublicKeyPermissions>(account_addr);

             // Extract the public key and signature from the authenticator
             let authenticator = *auth_data::authenticator(&auth_data);
             let stream = bcs_stream::new(authenticator);
             let public_key = new_unvalidated_public_key_from_bytes(
                 bcs_stream::deserialize_vector<u8>(&mut stream, |x| deserialize_u8(x))
             );
             let signature = new_signature_from_bytes(
                 bcs_stream::deserialize_vector<u8>(&mut stream, |x| deserialize_u8(x))
             );

             // Check if the public key is permitted
             assert!(smart_table::contains(&permissions.public_key_table, unvalidated_public_key_to_bytes(&public_key)), EPUBLIC_KEY_NOT_PERMITTED);

             // Verify the signature
             let digest = *auth_data::digest(&auth_data);
             assert!(ed25519::signature_verify_strict(&signature, &public_key, digest), EINVALID_SIGNATURE);

             account
         }

         // ====== Core Functionality ====== //

         public entry fun permit_public_key(
             signer: &signer,
             public_key: vector<u8>
         ) acquires PublicKeyPermissions {
             let account_addr = signer::address_of(signer);
             assert!(std::vector::length(&public_key) == 32, EINVALID_PUBLIC_KEY);
             
             if (!exists<PublicKeyPermissions>(account_addr)) {
                 move_to(signer, PublicKeyPermissions {
                     public_key_table: smart_table::new(),
                 });
             };

             let permissions = borrow_global_mut<PublicKeyPermissions>(account_addr);
             assert!(
                 !smart_table::contains(&permissions.public_key_table, public_key), 
                 EENTRY_ALREADY_EXISTS
             );

             smart_table::add(&mut permissions.public_key_table, public_key, true);
         
         }

         public entry fun revoke_public_key(
             signer: &signer,
             public_key: vector<u8>
         ) acquires PublicKeyPermissions {
             let account_addr = signer::address_of(signer);
             
             assert!(exists<PublicKeyPermissions>(account_addr), ENO_PERMISSIONS);

             let permissions = borrow_global_mut<PublicKeyPermissions>(account_addr);
             smart_table::remove(&mut permissions.public_key_table, public_key);
         }

     }
     ```

     Let's break down the module...

     **Storing Public Keys**

     The `PublicKeyPermissions` struct is a key that contains a `SmartTable` of public keys that determines
     whether a public key is permitted to sign transactions on behalf of the user.

     ```move
     module deployer::public_key_authenticator {
       // ...
      
       struct PublicKeyPermissions has key {
           public_key_table: SmartTable<vector<u8>, bool>,
       } 
       
     }
     ```

     **Permitting and Revoking Public Keys**

     We define two entry functions to permit and revoke public keys. These functions are used to add and remove public keys from the `PublicKeyPermissions` struct.

     ```move
     module deployer::public_key_authenticator {
       // ...

           public entry fun permit_public_key(
             signer: &signer,
             public_key: vector<u8>
         ) acquires PublicKeyPermissions {
             let account_addr = signer::address_of(signer);
             assert!(std::vector::length(&public_key) == 32, EINVALID_PUBLIC_KEY);
             
             if (!exists<PublicKeyPermissions>(account_addr)) {
                 move_to(signer, PublicKeyPermissions {
                     public_key_table: smart_table::new(),
                 });
             };

             let permissions = borrow_global_mut<PublicKeyPermissions>(account_addr);
             assert!(
                 !smart_table::contains(&permissions.public_key_table, public_key), 
                 EENTRY_ALREADY_EXISTS
             );

             smart_table::add(&mut permissions.public_key_table, public_key, true);
         
         }

         public entry fun revoke_public_key(
             signer: &signer,
             public_key: vector<u8>
         ) acquires PublicKeyPermissions {
             let account_addr = signer::address_of(signer);
             
             assert!(exists<PublicKeyPermissions>(account_addr), ENO_PERMISSIONS);

             let permissions = borrow_global_mut<PublicKeyPermissions>(account_addr);
             smart_table::remove(&mut permissions.public_key_table, public_key);
         }
     }
     ```

     **Authenticating on behalf of somebody else**

     The `authenticate` function is the main function that allows users to authenticate on behalf of somebody else using account abstraction. The `authenticator`
     will contain the **public key** and a **signature** of the user. We will verify that the public key is permitted and that the signature is valid.

     The signature is the result of signing the `digest`. The `digest` is the sha256 hash of the **signing message** which contains information about the transaction.
     By signing the `digest`, we confirm that the user has approved the specific transaction that was submitted.

     ```move
     module deployer::public_key_authenticator {
         // ...

         public fun authenticate(
             account: signer,
             auth_data: AbstractionAuthData
         ): signer acquires PublicKeyPermissions {
             let account_addr = signer::address_of(&account);
             assert!(exists<PublicKeyPermissions>(account_addr), ENO_PERMISSIONS);
             let permissions = borrow_global<PublicKeyPermissions>(account_addr);

             // Extract the public key and signature from the authenticator
             let authenticator = *auth_data::authenticator(&auth_data);
             let stream = bcs_stream::new(authenticator);
             let public_key = new_unvalidated_public_key_from_bytes(
                 bcs_stream::deserialize_vector<u8>(&mut stream, |x| deserialize_u8(x))
             );
             let signature = new_signature_from_bytes(
                 bcs_stream::deserialize_vector<u8>(&mut stream, |x| deserialize_u8(x))
             );

             // Check if the public key is permitted
             assert!(smart_table::contains(&permissions.public_key_table, unvalidated_public_key_to_bytes(&public_key)), EPUBLIC_KEY_NOT_PERMITTED);

             // Verify the signature
             let digest = *auth_data::digest(&auth_data);
             assert!(ed25519::signature_verify_strict(&signature, &public_key, digest), EINVALID_SIGNATURE);

             account
         }
     }
     ```

     To deploy the module, you can use the following commands from the [Aptos CLI](/build/cli). We assume that you already have set up a workspace with `aptos init` and
     declared the named addresses in your `Move.toml` file.

     ```shellscript
     aptos move publish --named-addresses deployer=0x1234567890123456789012345678901234567890
     ```

  2. 2. Setup your Environment

     Once deployed, you can setup your environment. In this example, we will use Devnet and create an account named `alice` as the user that will be authenticated on behalf of
     and `bob` as the user that will be permitted to sign transactions on behalf of `alice`.

     ```typescript
     const DEPLOYER = "0x<public_key_authenticator_deployer>"

     const aptos = new Aptos(new AptosConfig({ network: Network.DEVNET }));

     const alice = Account.generate();
     const bob = Account.generate();

     const authenticationFunctionInfo = `${deployer}::public_key_authenticator::authenticate`;
     ```

  3. 3. (Optional) Check if Account Abstraction is Enabled

     Before we enable the authentication function, we can check if the account has account abstraction enabled by calling the `isAccountAbstractionEnabled` function.
     This will return a boolean value indicating if the account has account abstraction enabled.

     ```typescript
     const accountAbstractionStatus = await aptos.abstraction.isAccountAbstractionEnabled({
         accountAddress: alice.accountAddress,
         authenticationFunction,
     });

     console.log("Account Abstraction status: ", accountAbstractionStatus);
     ```

  4. 4. Enable the Authentication Function

     Assuming that the account does not have account abstraction enabled, we need to enable the authentication function for the account. This can be done by calling
     the `enableAccountAbstractionTransaction` function. This creates a raw transaction that needs to be signed and submitted to the network. In this example, `alice`
     will be the account that will be enabled.

     ```typescript
     const transaction = await aptos.abstraction.enableAccountAbstractionTransaction({
       accountAddress: alice.accountAddress,
       authenticationFunction,
     });

     const pendingTransaction = await aptos.signAndSubmitTransaction({
       transaction,
       signer: alice.signer,
     });

     await aptos.waitForTransaction({ hash: pendingTransaction.hash });

     console.log("Account Abstraction enabled for account: ", alice.accountAddress);
     ```

  5. 5. Permit Bob's Public Key

     Now that we have enabled the authentication function, we can permit `bob`'s public key to sign transactions on behalf of `alice`.

     ```typescript
     const enableBobPublicKeyTransaction = await aptos.transaction.build.simple({
         sender: alice.accountAddress,
         data: {
           function: `${alice.accountAddress}::public_key_authenticator::permit_public_key`,
           typeArguments: [],
           functionArguments: [bob.publicKey.toUint8Array()],
         },
       });

     const pendingEnableBobPublicKeyTransaction = await aptos.signAndSubmitTransaction({
       signer: alice,
       transaction: enableBobPublicKeyTransaction,
     });

     await aptos.waitForTransaction({ hash: pendingEnableBobPublicKeyTransaction.hash });

     console.log(`Enable Bob's public key transaction hash: ${pendingEnableBobPublicKeyTransaction.hash}`);
     ```

  6. 6. Create an Abstracted Account

     Now that we have permitted `bob`'s public key, we can create an abstracted account that will be used to sign transactions on behalf of `alice`.
     **Notice that the `signer` function uses `bob`'s signer.**

     ```typescript
     const abstractedAccount = new AbstractedAccount({
       accountAddress: alice.accountAddress,
       signer: (digest) => {
           const serializer = new Serializer();
           bob.publicKey.serialize(serializer);
           bob.sign(digest).serialize(serializer);
           return serializer.toUint8Array();
       },
       authenticationFunction,
     });
     ```

  7. 7. Sign and Submit a Transaction using the Abstracted Account

     Now that we have created the abstracted account, we can use it to sign transactions normally. It is important that the `sender` field in the transaction
     is the same as the abstracted account's address.

     ```typescript
     const coinTransferTransaction = new aptos.transaction.build.simple({
       sender: abstractedAccount.accountAddress,
       data: {
         function: "0x1::coin::transfer",
         typeArguments: ["0x1::aptos_coin::AptosCoin"],
         functionArguments: [alice.accountAddress, 100],
       },
     });

     const pendingCoinTransferTransaction = await aptos.transaction.signAndSubmitTransaction({
       transaction: coinTransferTransaction,
       signer: abstractedAccount,
     });

     await aptos.waitForTransaction({ hash: pendingCoinTransferTransaction.hash });

     console.log("Coin transfer transaction submitted! ", pendingCoinTransferTransaction.hash);
     ```

  8. 8. Conclusion

     To verify that you have successfully sign and submitted the transaction using the abstracted account, you can use the explorer to check the transaction. If the
     transaction signature contains a `function_info` and `auth_data` field, it means you successfully used account abstraction! The full E2E demo can be found [here](https://github.com/aptos-labs/aptos-ts-sdk/blob/main/examples/typescript/public_key_authenticator_account_abstraction.ts)

     ![Transaction Signature](~/images/account-abstraction/complex-guide-transaction-signature.png)
</Steps>

## Management Operations

If you want to disable account abstraction for an account, you can use the `disableAccountAbstractionTransaction`. If you do not specify an authentication function,
the transaction will disable all authentication functions for the account.

```typescript
const transaction = aptos.abstraction.disableAccountAbstractionTransaction({
  accountAddress: alice.accountAddress,
  /**
   * The authentication function to be disabled. If left `undefined`, all authentication functions will be disabled.
  */
  authenticationFunction,
});
```

## Application User Experience

Applications that want to leverage account abstraction will want to provide a user experience that allows users to check if the account has account abstraction enabled,
and to enable it, if it is not enabled.

Below is a diagram of the UX flow for enabling account abstraction.

![Account Abstraction UX](~/images/account-abstraction/account-abstraction-ux.png)

# Derivable Account Abstraction

> Enable deterministic account address derivation with custom authentication schemes using Derivable Account Abstraction

import { Steps } from '@astrojs/starlight/components';

[Derivable Account Abstraction (DAA)](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-113.md)
is a standard for account abstraction that enables custom authentication schemes by registering a `derivable_authentication_function`.

DAA differs from vanilla [Account Abstraction (AA)](/build/sdks/ts-sdk/account/account-abstraction) in that, for a given `derivable_authentication_function`,
it defines how to deterministically derive the account address from an `abstract_public_key`, which can be done off-chain.

In contrast, vanilla AA is enabled for a specific pre-existing account by explicitly registering an on-chain `authentication_function`
and submitting a transaction, which involves extra steps and costs gas for each account.

This allows registering secondary authentication schemes with identical user experience to the native ones.
More specifically, this provides a flexible and secure way to manage cross-chain signatures. (see [x-chain accounts](/build/sdks/wallet-adapter/x-chain-accounts))

## Core Concepts

### Authentication function

DAA works by defining an custom authentication scheme and registering a valid authentication function to perform on-chain authentication.

Each abstract account should have an associated `abstract_public_key` and should be able to produce `abstract_signature`s
whose formats depend on the authentication scheme.

Simply put, the `derivable_authentication_function` needs to check that:

- the `abstract_signature` is valid for the given `abstract_public_key`
- the `abstract_signature` depends on the transaction's digest

```move
// The function should return a signer if authentication is successful, otherwise it aborts the execution
public fun authenticate(account: signer, auth_data: AbstractionAuthData): signer;
```

The DAA framework automatically checks whether the address derived from `abstract_public_key` matches with the signer's address.

### Authentication data

`AbstractionAuthData` is an enum that represent the authentication data to be passed to custom authentication functions.
It's used in all flavors of AA, but the `DerivableV1` variant defines the following fields:

- `digest`: The SHA3-256 hash of the signing message.
- `abstract_signature`: Abstract signature bytes that need to be verified against `abstract_public_key`.
- `abstract_public_key`: Abstract public key bytes associated to the abstract account

Here's what the Move enum looks like:

```move
enum AbstractionAuthData has copy, drop {
  V1 { ... }, // Only applicable to vanilla AA
  DerivableV1 {
      digest: vector<u8>, // SHA3-256 hash of the signing message
      abstract_signature: vector<u8>,
      abstract_public_key: vector<u8>,
  }
}
```

**Why is the `digest` important?**

The `digest` is checked by the MoveVM to ensure that the signing message of the transaction being submitted is the same as the one presented in the `AbstractionAuthData`. This
is important because it allows the authentication function to verify signatures with respect to the correct transaction.

For example, if you want to permit a public key to sign transactions on behalf of the user, you can permit the public key to sign a transaction with a specific payload.
However, if a malicious user sends a signature for the correct public key but a different payload from the `digest`, the signature will not be valid.

### Account address derivation

With DAA, a given `derivable_authentication_function` defines a space of account addresses that can be deterministically derived from their associated `abstract_public_key`.

The on-chain function looks like the following:

```move
public fun derive_account_address(derivable_func_info: FunctionInfo, abstract_public_key: &vector<u8>): address {
  let bytes = bcs::to_bytes(&derivable_func_info);
  bytes.append(bcs::to_bytes(abstract_public_key));
  bytes.push_back(DERIVABLE_ABSTRACTION_DERIVED_SCHEME);
  from_bcs::to_address(hash::sha3_256(bytes))
}
```

where `FunctionInfo` is a fully qualified identifier for a on-chain function:

```move
struct FunctionInfo has copy, drop, store {
    module_address: address,
    module_name: String,
    function_name: String
}
```

The address derivation depends on the authentication function's identifier and on a DAA-specific domain separator.
Because of this, each address space is isolated from the others and it's not possible for the same account to have multiple
authentication functions.

**Example (Move)**

This example demonstrates domain account abstraction using ed25519 hex for signing.

```move
module aptos_experimental::test_derivable_account_abstraction_ed25519_hex {
    use std::error;
    use aptos_std::string_utils;
    use aptos_std::ed25519::{
        Self,
        new_signature_from_bytes,
        new_unvalidated_public_key_from_bytes,
    };
    use aptos_framework::auth_data::AbstractionAuthData;

    const EINVALID_SIGNATURE: u64 = 1;

    /// Authorization function for derivable account abstraction.
    public fun authenticate(account: signer, aa_auth_data: AbstractionAuthData): signer {
    let hex_digest = string_utils::to_string(aa_auth_data.digest());

    let public_key = new_unvalidated_public_key_from_bytes(*aa_auth_data.derivable_abstract_public_key());
    let signature = new_signature_from_bytes(*aa_auth_data.derivable_abstract_signature());
    assert!(
        ed25519::signature_verify_strict(
            &signature,
            &public_key,
            *hex_digest.bytes(),
        ),
        error::permission_denied(EINVALID_SIGNATURE)
    );

    account
    }
}
```

**Example (Typescript)**

```typescript
const derivableAbstractedAccount = new DerivableAbstractedAccount({
  /**
   * The result of the signer function will be available as the `abstract_signature` field in the `AbstractionAuthData` enum variant.
   */
  signer: (digest) => {
    const hexDigest = new TextEncoder().encode(Hex.fromHexInput(digest).toString());
    return solanaAccount.sign(hexDigest).toUint8Array();
  },
  /**
   * The authentication function to be invoked.
   */
  authenticationFunction: `0x7::test_derivable_account_abstraction_ed25519_hex::authenticate`,
  /**
  * The abstract public key (i.e the account identity)
  */
  abstractPublicKey: account.publicKey.toUint8Array(),
});
```

## Minimal Step-by-Step Guide

<Steps>
  1. 1. Generate a ED25519 key pair

     ```typescript
     const ed25519Account = Account.generate();
     ```

  2. 2. Create a DAA

     ```typescript
     const daa = new DerivableAbstractedAccount({
       signer: (digest) => {
         const hexDigest = new TextEncoder().encode(Hex.fromHexInput(digest).toString());
         return ed25519Account.sign(hexDigest).toUint8Array();
       },
       authenticationFunction: `0x7::test_derivable_account_abstraction_ed25519_hex::authenticate`,
       abstractPublicKey: ed25519Account.publicKey.toUint8Array(),
     });
     ```

  3. 3. Fund the DAA to create it on chain

     ```typescript
     await aptos.fundAccount({ accountAddress: daa.accountAddress, amount: 1000000 });
     ```

  4. 4. Create a recipient account and transfer APT to it

     ```typescript
     const recipient = Account.generate();

     const pendingTxn = await aptos.transaction.signAndSubmitTransaction({
       signer: daa,
       transaction: await aptos.transferCoinTransaction({
         sender: daa.accountAddress,
         recipient: recipient.accountAddress,
         amount: 100,
       }),
     });

     const response = await aptos.waitForTransaction({ transactionHash: pendingTxn.hash });
     ```
</Steps>

# Building Transactions

> Comprehensive guide to building, simulating, signing, submitting, and executing transactions on Aptos using the TypeScript SDK

import { Aside, Steps } from '@astrojs/starlight/components';

Transactions allow you to change on-chain data or trigger events. Generally, transactions follow 5 steps from building to executing on chain: building, simulating, signing, submitting, and waiting.

<Aside type="note">
  For these examples, `aptos` is an instance of the [`Aptos`](https://aptos-labs.github.io/aptos-ts-sdk/@aptos-labs/ts-sdk-1.35.0/classes/Aptos.html) client object.
</Aside>

<Steps>
  1. Build

     Building a transaction is how you specify:

     1. **The `sender` account.** <br />This account normally pays the gas fees for this transaction. See [Transaction Sponsoring](/build/sdks/ts-sdk/building-transactions/sponsoring-transactions) to learn how to have another account pay for fees.
     2. **The `function` being called on-chain.** <br />This is the identifier for the smart contract entry function on-chain that will trigger when you execute this transaction.
     3. **The `functionArguments`.** <br />This is any data the function needs to run.

     This can be packaged into a `SimpleTransaction` using `aptos.transaction.build.simple(...)` like so:

     ```typescript filename="build-a-transaction.ts"
     const transaction = await aptos.transaction.build.simple({
       sender: sender.accountAddress,
       data: {
     	  // All transactions on Aptos are implemented via smart contracts.
     	  function: "0x1::aptos_account::transfer",
     	  functionArguments: [destination.accountAddress, 100],
       },
     });
     ```

     <Aside type="note">
       There is a more advanced format to pass in `functionArguments` called [Binary Canonical Serialization (BCS)](/build/sdks/ts-sdk/building-transactions/bcs-format) format which is how the Aptos chain parses function arguments. The SDK converts TypeScript primitives to BCS format behind the scenes via an API call.
     </Aside>

     #### Building Options

     You can customize the way your transaction executes by passing in `options: {...}` when building. Some of the most commonly used options are:

     1. `maxGasAmount` - This caps the amount of gas you are willing to pay for to execute this transaction.
     2. `gasUnitPrice` - You can specify a higher than minimum price per gas to be executed with higher priority by the Aptos network.
     3. `expireTimestamp` - This gives a concrete time the transaction must execute by or it will be canceled.

     The SDK provides sensible defaults for these values if they are not specified explicitly.

  2. Simulate (Optional)

     Every transaction on the Aptos chain has a gas fee associated with how much work the network machines have to do when executing the transaction. In order to estimate the cost associated with that, you can simulate transactions before committing them.

     <Aside type="note">
       This simulation only requires the `publicKey` of an account since it will not impact the actual state of the ledger.
     </Aside>

     You can execute the simulation by using `aptos.transaction.simulate.simple(...)` like so:

     ```typescript filename="build-a-transaction.ts"
     const [userTransactionResponse] = await aptos.transaction.simulate.simple({
       signerPublicKey: signer.publicKey,
       transaction,
     });
     // If the fee looks ok, continue to signing!
     ```

  3. Sign

     Once the transaction is built and the fees seem reasonable, you can sign the transaction with `aptos.transaction.sign`. The signature must come from the `sender` account.

     ```typescript filename="build-a-transaction.ts"
     // 3. Sign
     const senderAuthenticator = aptos.transaction.sign({
       signer: sender,
       transaction,
     });
     ```

  4. Submit

     Now that the transaction is signed, you can submit it to the network using `aptos.transaction.submit.simple` like so:

     ```typescript filename="build-a-transaction.ts"
     // 4. Submit
     const committedTransaction = await aptos.transaction.submit.simple({
       transaction,
       senderAuthenticator,
     });
     ```

  5. Wait

     Finally, you can wait for the result of the transaction by using [`aptos.waitForTransaction`](https://aptos-labs.github.io/aptos-ts-sdk/@aptos-labs/ts-sdk-1.35.0/classes/Aptos.html#waitForTransaction) and specifying the hash of the transaction you just submitted like so:

     ```typescript filename="build-a-transaction.ts"
     // 5. Wait
     const executedTransaction = await aptos.waitForTransaction({ transactionHash: committedTransaction.hash });
     ```
</Steps>

## Full TypeScript Example

```typescript filename="build-a-transaction.ts"
/**
 * This example shows how to use the Aptos SDK to send a transaction.
 * Don't forget to install @aptos-labs/ts-sdk before running this example!
 */

import {
    Account,
    Aptos,
    AptosConfig,
    Network,
} from "@aptos-labs/ts-sdk";

async function example() {
    console.log("This example will create two accounts (Alice and Bob) and send a transaction transfering APT to Bob's account.");

    // 0. Setup the client and test accounts
    const config = new AptosConfig({ network: Network.DEVNET });
    const aptos = new Aptos(config);

    let alice = Account.generate();
    let bob = Account.generate();

    console.log("=== Addresses ===\n");
    console.log(`Alice's address is: ${alice.accountAddress}`);
    console.log(`Bob's address is: ${bob.accountAddress}`);

    console.log("\n=== Funding accounts ===\n");
    await aptos.fundAccount({
        accountAddress: alice.accountAddress,
        amount: 100_000_000,
    });
    await aptos.fundAccount({
        accountAddress: bob.accountAddress,
        amount: 100,
    });
    console.log("Funded Alice and Bob's accounts!")

    // 1. Build
    console.log("\n=== 1. Building the transaction ===\n");
    const transaction = await aptos.transaction.build.simple({
        sender: alice.accountAddress,
        data: {
        // All transactions on Aptos are implemented via smart contracts.
        function: "0x1::aptos_account::transfer",
        functionArguments: [bob.accountAddress, 100],
        },
    });
    console.log("Built the transaction!")

    // 2. Simulate (Optional)
    console.log("\n === 2. Simulating Response (Optional) === \n")
    const [userTransactionResponse] = await aptos.transaction.simulate.simple({
        signerPublicKey: alice.publicKey,
        transaction,
    });
    console.log(userTransactionResponse)

    // 3. Sign
    console.log("\n=== 3. Signing transaction ===\n");
    const senderAuthenticator = aptos.transaction.sign({
        signer: alice,
        transaction,
    });
    console.log("Signed the transaction!")

    // 4. Submit
    console.log("\n=== 4. Submitting transaction ===\n");
    const submittedTransaction = await aptos.transaction.submit.simple({
        transaction,
        senderAuthenticator,
    });

    console.log(`Submitted transaction hash: ${submittedTransaction.hash}`);

    // 5. Wait for results
    console.log("\n=== 5. Waiting for result of transaction ===\n");
    const executedTransaction = await aptos.waitForTransaction({ transactionHash: submittedTransaction.hash });
    console.log(executedTransaction)
};

example();
```

## Summary

Building and sending transactions on-chain involves the following 5 steps:

1. **Build** the transaction.
2. **Simulate** the cost. (Optional)
3. **Sign** the transaction (if the simulated cost seems ok).
4. **Submit** the transaction to the network.
5. **Wait** for the chain to validate and update.

## Explore Advanced Transaction Features

Transactions have a couple of additional features which let them adapt to your needs which you can learn about here:

1. [Multi-Agent Transactions](/build/sdks/ts-sdk/building-transactions/multi-agent-transactions) - Allowing multiple accounts to interact with a single transaction.
2. [Orderless Transactions](/build/sdks/ts-sdk/building-transactions/orderless-transactions) - Allowing for transactions to be executed out of order for easier management.
3. [Sponsoring Transactions](/build/sdks/ts-sdk/building-transactions/sponsoring-transactions) - Have another account pay gas fees for this transaction.
4. [Batch Submit Transactions](/build/sdks/ts-sdk/building-transactions/batching-transactions) - How to send multiple transactions quickly from a single account.
5. [Binary Canonical Serialization (BCS)](/build/sdks/ts-sdk/building-transactions/bcs-format) - The format used to serialize data for Aptos transactions.
6. [Composing multiple Move calls with ScriptComposer](/build/sdks/ts-sdk/building-transactions/script-composer) - (Experimental) Building more complex transaction payload that calls into multiple Move functions dynamically.

# Batching Transactions

> Execute multiple independent transactions simultaneously from a single account using batch transaction processing

The TypeScript SDK has a built-in way to send several independent transactions together in a batch. This can be a convenient tool when trying to execute multiple transactions quickly from the same account.

This can be done with `aptos.transaction.batch.forSingleAccount` as can be seen in the below example.

## Full TypeScript Example

```typescript filename="batch.ts"
/**
 * This example shows how to use the Aptos SDK to send several transactions in a batch.
 */

import {
    Account,
    Aptos,
    AptosConfig,
    Network,
    InputGenerateTransactionPayloadData,
} from "@aptos-labs/ts-sdk";

async function example() {
    console.log("This example will send several transactions in a batch.");

    // Setup the client and test accounts
    const config = new AptosConfig({ network: Network.DEVNET });
    const aptos = new Aptos(config);

    let sender = Account.generate();

    console.log("=== Addresses ===\n");
    console.log(`Sender's address is: ${sender.accountAddress}`);

    console.log("\n=== Funding sender ===\n");
    await aptos.fundAccount({
        accountAddress: sender.accountAddress,
        amount: 100_000_000,
    });  
    console.log("Funded the sender account!")

    // Generate several recipients to send APT to
    const recipients = [Account.generate(), Account.generate(), Account.generate()];

    // Create transactions to send APT to each account
    const transactions: InputGenerateTransactionPayloadData[] = [];

    for (let i = 0; i < recipients.length; i += 1) {
        const transaction: InputGenerateTransactionPayloadData = {
            function: "0x1::aptos_account::transfer",
            functionArguments: [recipients[i].accountAddress, 10],
        };
        transactions.push(transaction);
    }

    // Sign and submit all transactions as fast as possible (throws if any error)
    await aptos.transaction.batch.forSingleAccount({ sender: sender, data: transactions });
};

example();
```

## Checking The Status of Batched Transactions

In order to tell when transaction submitted in a batch have executed on chain, you must listen to events while the process runs.

```typescript filename="transaction-worker-events.ts"
export enum TransactionWorkerEventsEnum {
  // Fired after a transaction gets sent to the chain
  TransactionSent = "transactionSent",
  // Fired if there is an error sending the transaction to the chain
  TransactionSendFailed = "transactionSendFailed",
  // Fired when a single transaction has executed successfully
  TransactionExecuted = "transactionExecuted",
  // Fired if a single transaction fails in execution
  TransactionExecutionFailed = "transactionExecutionFailed",
  // Fired when the worker has finished its job / when the queue has been emptied
  ExecutionFinish = "executionFinish",
}
```

You can find an example of how to listen to these events [here](https://github.com/aptos-labs/aptos-ts-sdk/blob/main/examples/typescript/batch_funds.ts#L108).

# BCS Format

> Learn how to use Binary Canonical Serialization (BCS) format for advanced transaction parameter handling and performance optimization

Behind the scenes, the Aptos SDK has two formats for transaction parameters:

1. **Simple** - This represents transaction parameters using primitive types like strings, integers, etc.
2. **Binary Canonical Serialization (BCS)** - This is the format the Aptos chain recognizes, with specific types (ex. Instead of an integer, it uses types like `U64` or `U128`)

Normally, the TypeScript SDK will automatically convert simple types in function parameters into BCS in order to communicate with the network. For some contracts though, you will have to use BCS directly to specify complicated types.

Using BCS directly can have a light performance advantage as the SDK can skip an API call to transform the TypeScript primitive parameter format into BCS format.

You can directly use the BCS format to build transactions by specifying argument types explicitly like so:

```typescript filename="example.ts"
const transaction = await aptos.transaction.build.simple({
    sender: alice.accountAddress,
    data: {
      function: "0x1::aptos_account::transfer",
      functionArguments: [AccountAddress.fromString("0x123"), new U64(1_000_000)],
    },
  });
```

You can learn more about BCS by exploring the [BCS GitHub repo](https://github.com/aptos-labs/bcs).

# Multi-Agent Transactions

> Enable multiple accounts to participate in a single transaction with coordinated signatures and shared resources

import { Aside, Steps } from '@astrojs/starlight/components';

Multi-agent transactions allow multiple accounts to participate in the logic of a Move contract.

This can be used to require multiple parties agree to a transaction before executing or to use resources from multiple accounts.

## Writing Multi-Agent Transactions

Creating and executing a multi-agent transaction follows a similar flow to the [simple transaction flow](/build/sdks/ts-sdk/building-transactions), but with several notable differences.

<Aside type="note">
  Instead of `.simple`, multi-agent transaction functions use `.multiAgent`.
</Aside>

<Steps>
  1. Build the transaction by including secondarySignerAddresses with a list of each additional agent.

     <Aside type="note">
       Make sure to replace the `function` field below with your entry function that requires multiple agents to sign.
     </Aside>

     ```typescript filename="multi-agent.ts"
     const transaction = await aptos.transaction.build.multiAgent({
       sender: alice.accountAddress,
       secondarySignerAddresses: [bob.accountAddress],
       data: {
         // REPLACE WITH YOUR MULTI-AGENT FUNCTION HERE
         function:
           "<REPLACE WITH YOUR MULTI AGENT MOVE ENTRY FUNCTION> (Syntax {address}::{module}::{function})",
         // Pass in arguments for the function you specify above
         functionArguments: [],
       },
     });
     ```

  2. (Optional) Simulate the transaction.

     You can simulate the multi-agent transaction to preview the result before submitting it as follows:

     ```typescript filename="multi-agent.ts"
     const [userTransactionResponse] = await aptos.transaction.simulate.multiAgent(
       {
         signerPublicKey: alice.publicKey,
         secondarySignersPublicKeys: [bob.publicKey],
         transaction,
       },
     );
     ```

     The `signerPublicKey` and `secondarySignersPublicKeys` inputs are optional and can be omitted to skip authentication key checks for the signers during simulation. If you want to skip the authentication key check for only some of the secondary signers, you can provide `secondarySignersPublicKeys` with the public keys of the specific signers you want to check, using `undefined` as a placeholder for the others.

     For example, if `bob` and `carol` are secondary signers and you only want to check `carol`‚Äôs authentication key, you can set `secondarySignersPublicKeys: [undefined, carol.publicKey]`, leaving `undefined` as a placeholder for `bob`.

  3. Sign once for each agent.

     You will combine these signatures in the next step.

     ```typescript filename="multi-agent.ts"
     const aliceSenderAuthenticator = aptos.transaction.sign({
       signer: alice,
       transaction,
     });
     // Bob is a secondary signer for this transaction
     const bobSenderAuthenticator = aptos.transaction.sign({
       signer: bob,
       transaction,
     });
     ```

  4. Submit the transaction by combining all agent signatures via the additionalSignerAuthenticators parameter.

     ```typescript filename="multi-agent.ts"
     const committedTransaction = await aptos.transaction.submit.multiAgent({
       transaction,
       senderAuthenticator: aliceSenderAuthenticator,
       additionalSignersAuthenticators: [bobSenderAuthenticator],
     });
     ```

  5. Lastly, wait for the transaction to resolve.

     ```typescript filename="multi-agent.ts"
     const executedTransaction = await aptos.waitForTransaction({
       transactionHash: committedTransaction.hash,
     });
     ```
</Steps>

## Full TypeScript Multi-Agent Code Snippet

<Aside type="caution">
  The below snippet needs light editing to work properly! (See below steps)
</Aside>

1. Install `@aptos-labs/ts-sdk` by running `pnpm i @aptos-labs/ts-sdk` or using whichever package manager is most comfortable for you.
2. Update the below snippet to build a transaction that requires multi-agent signing.
   1. Replace the function and parameters below this comment: `// REPLACE WITH YOUR MULTI-AGENT FUNCTION HERE`
   2. This customization is needed as there are no pre-made Aptos contracts which need multi-agent signatures. If you want to deploy your own example multi-agent contract, you can deploy the ["transfer two by two" example Move contract](https://github.com/aptos-labs/aptos-ts-sdk/blob/main/tests/move/transfer/sources/script_two_by_two.move#L5).

```typescript filename="multi-agent.ts"
/**
 * This example shows how to use the Aptos SDK to send a transaction.
 */

import { Account, Aptos, AptosConfig, Network } from "@aptos-labs/ts-sdk";

async function example() {
  console.log(
    "This example will create two accounts (Alice and Bob) and send a transaction transfering APT to Bob's account.",
  );

  // 0. Setup the client and test accounts
  const config = new AptosConfig({ network: Network.DEVNET });
  const aptos = new Aptos(config);

  let alice = Account.generate();
  let bob = Account.generate();
  let carol = Account.generate();

  console.log("=== Addresses ===\n");
  console.log(`Alice's address is: ${alice.accountAddress}`);
  console.log(`Bob's address is: ${bob.accountAddress}`);
  console.log(`Carol's address is: ${carol.accountAddress}`);

  console.log("\n=== Funding accounts ===\n");
  await aptos.fundAccount({
    accountAddress: alice.accountAddress,
    amount: 100_000_000,
  });
  await aptos.fundAccount({
    accountAddress: bob.accountAddress,
    amount: 100_000_000,
  });
  await aptos.fundAccount({
    accountAddress: carol.accountAddress,
    amount: 100_000_000,
  });
  console.log("Done funding Alice, Bob, and Carol's accounts.");

  // 1. Build
  console.log("\n=== 1. Building the transaction ===\n");
  const transaction = await aptos.transaction.build.multiAgent({
    sender: alice.accountAddress,
    secondarySignerAddresses: [bob.accountAddress],
    data: {
      // REPLACE WITH YOUR MULTI-AGENT FUNCTION HERE
      function:
        "<REPLACE WITH YOUR MULTI AGENT MOVE ENTRY FUNCTION> (Syntax {address}::{module}::{function})",
      functionArguments: [],
    },
  });
  console.log("Transaction:", transaction);

  // 2. Simulate (Optional)
  console.log("\n === 2. Simulating Response (Optional) === \n");
  const [userTransactionResponse] = await aptos.transaction.simulate.multiAgent(
    {
      signerPublicKey: alice.publicKey,
      secondarySignersPublicKeys: [bob.publicKey],
      transaction,
    },
  );
  console.log(userTransactionResponse);

  // 3. Sign
  console.log("\n=== 3. Signing transaction ===\n");
  const aliceSenderAuthenticator = aptos.transaction.sign({
    signer: alice,
    transaction,
  });
  const bobSenderAuthenticator = aptos.transaction.sign({
    signer: bob,
    transaction,
  });
  console.log(aliceSenderAuthenticator);
  console.log(bobSenderAuthenticator);

  // 4. Submit
  console.log("\n=== 4. Submitting transaction ===\n");
  const committedTransaction = await aptos.transaction.submit.multiAgent({
    transaction,
    senderAuthenticator: aliceSenderAuthenticator,
    additionalSignersAuthenticators: [bobSenderAuthenticator],
  });
  console.log("Submitted transaction hash:", committedTransaction.hash);

  // 5. Wait for results
  console.log("\n=== 5. Waiting for result of transaction ===\n");
  const executedTransaction = await aptos.waitForTransaction({
    transactionHash: committedTransaction.hash,
  });
  console.log(executedTransaction);
}

example();
```

## Common Errors

`NUMBER_OF_SIGNER_ARGUMENTS_MISMATCH` - This happens when you are attempting to do multi-agent signing for a function which does not require that number of accounts. For example, if you try using multiple signatures for a `0x1::aptos_account::transfer` function - it only expects one address, and so produces an error when more than one is provided.

# Orderless Transactions

> Create transactions that can be executed in any order, enabling flexible multi-machine signing scenarios

import { Aside } from '@astrojs/starlight/components';

Orderless transactions allow you to create transactions that do not specify a
order of execution between them. This is particularly useful
in scenarios where multiple machines need to sign a transaction, but the order
in which they sign does not affect the outcome of the transaction or matter to
the creator.

## Building Orderless Transactions

Creating and executing a multi-agent transaction follows a similar flow to the
[simple transaction flow](/build/sdks/ts-sdk/building-transactions), and the
[multi-agent transaction flow](/build/sdks/ts-sdk/building-transactions/multi-agent-transactions).

<Aside type="note">
  Instead of providing a `sequenceNumber` (or no sequence number at all), a
  `Replay Protection Nonce` is used to ensure that the transaction is unique and
  cannot be replayed (i.e., executed multiple times with the same nonce).
</Aside>

For example, to create a single signer transaction that uses orderless transactions,
specify the `nonce` in the `build.simple` method like so:

```typescript filename="build-a-transaction.ts"
const transaction = await aptos.transaction.build.simple({
  sender: sender.accountAddress,
  data: {
	  // All transactions on Aptos are implemented via smart contracts.
	  function: "0x1::aptos_account::transfer",
	  functionArguments: [destination.accountAddress, 100],
  },
  options: {
    replayProtectionNonce: 12345, // This is the nonce that will be used to ensure the transaction is unique.
  }
});
```

Similarly, if you are building a multi-agent transaction, you can specify the
`replayProtectionNonce` in the `build.multiAgent` method:

```typescript filename="build-a-transaction.ts"
const transaction = await aptos.transaction.build.multiAgent({
  sender: sender.accountAddress,
  secondarySignerAddresses: [bob.accountAddress], // List of secondary signers
  data: {
	  // All transactions on Aptos are implemented via smart contracts.
	  function: "0x1::aptos_account::transfer",
	  functionArguments: [destination.accountAddress, 100],
  },
  options: {
    replayProtectionNonce: 12345, // This is the nonce that will be used to ensure the transaction is unique.
  }
});
```

And the same if you are building a sponsored transaction, you can specify the
`replayProtectionNonce` in the `build.multiAgent` method:

```typescript filename="build-a-transaction.ts"
const transaction = await aptos.transaction.build.multiAgent({
  sender: sender.accountAddress,
  withFeePayer: true, // This indicates that the transaction will be sponsored.
  data: {
	  // All transactions on Aptos are implemented via smart contracts.
	  function: "0x1::aptos_account::transfer",
	  functionArguments: [destination.accountAddress, 100],
  },
  options: {
    replayProtectionNonce: 12345, // This is the nonce that will be used to ensure the transaction is unique.
  }
});
```

<Aside type="note">
  For orderless transactions, the `replayProtectionNonce` must be unique for
  each transaction. Additionally, the expiration time of the transaction is
  maximum 60 seconds from the time it is submitted. If the transaction is not
  executed within that time, it will be considered expired and will not be
  executed.
</Aside>

After that, simply follow the same steps as you would for a simple transaction:

1. [**Simulate** the transaction (optional)](/build/sdks/ts-sdk/building-transactions/simulating-transactions).
2. **Sign** the transaction.
3. **Submit** the transaction to the network.
4. **Wait** for the transaction to be executed.

### Examples

- [TS SDK Example](https://github.com/aptos-labs/aptos-ts-sdk/blob/main/examples/typescript/simple_orderless_transfer.ts)

# Invoke chains of Move calls with Dynamic Script Composer

> Build complex transaction payloads that call multiple Move functions dynamically using the Script Composer SDK

import { Aside } from '@astrojs/starlight/components';

<Aside type="tip">
  We are pleased to announce that we now have an independent package for the Script Composer functionality, which can be found in the following repository:

  [https://github.com/aptos-labs/script-composer-sdk](https://github.com/aptos-labs/script-composer-sdk)

  Of course! You can use it as an npm package! Please install this package:

  [https://www.npmjs.com/package/@aptos-labs/script-composer-sdk](https://www.npmjs.com/package/@aptos-labs/script-composer-sdk)
</Aside>

<Aside type="caution">
  If you are still using the Script Composer in the 1.39.0 version of the ts-sdk, you can switch to the independent package version as soon as possible:
  [https://www.npmjs.com/package/@aptos-labs/ts-sdk/v/1.39.0](https://www.npmjs.com/package/@aptos-labs/ts-sdk/v/1.39.0)
</Aside>

## Overview

In the basic API, you can only specify one entry function call for a single transaction. Advanced builders might want to invoke multiple **public** Move functions in one transaction. This is now enabled by the new `scriptComposer` API provided in the transaction builder.

## Basic Usage

Here's an example of how to invoke the API:

> Please note that the current example is only for reference on how to use Script Composer to combine transactions, receive return values from public functions, and pass them to the next function

```typescript filename="example.ts"
const tx = await BuildScriptComposerTransaction({
    // You need to fill in the sender's address here
    sender: singleSignerED25519SenderAccount.accountAddress,
    builder: async (composer) => {
        // Start by withdrawing some Coin
        const coin = await composer.addBatchedCalls({
            function: "0x1::coin::withdraw",
            functionArguments: [CallArgument.newSigner(0), 1],
            typeArguments: ["0x1::aptos_coin::AptosCoin"],
        });

        // Pass the coin value to 0x1::coin::coin_to_fungible_asset to convert the token
        // into a fungible asset
        const fungibleAsset = await composer.addBatchedCalls({
            function: "0x1::coin::coin_to_fungible_asset",
            // coin[0] represents the first return value from the first call you added
            functionArguments: [coin[0]],
            typeArguments: ["0x1::aptos_coin::AptosCoin"],
        });

        // Deposit the fungibleAsset converted from the second call
        await composer.addBatchedCalls({
            function: "0x1::primary_fungible_store::deposit",
            // You need to fill in the sender's address here
            functionArguments: [singleSignerED25519SenderAccount.accountAddress, fungibleAsset[0]],
            typeArguments: [],
        });
        return composer
    },
    // You need to pass Aptos Config here because the combined transaction needs to read on-chain state
    aptosConfig: new AptosConfig({
        network: Network.TESTNET,
    }),
});
```

## Transaction Processing

After combining the transaction, we can use interfaces like sign transaction / simulate transaction / submit transaction from `@aptos-labs/ts-sdk`:

We'll use the simulate transaction interface to show how to use it:

```typescript filename="example.ts"

...

    const aptos = new Aptos(new AptosConfig({
        network: Network.TESTNET,
    }));

    const simulate_result = await aptos.transaction.simulate.simple({
        transaction: tx,
    })
    
    console.log('simulate_result: ', simulate_result)
...

```

## Examples

If you need some practical examples, we have also prepared usage examples for three common environments:

In the examples, you will see a combined transaction and the return value of the simulated transaction (the simulated transaction uses the 0x1 address as the sender. Although it can be simulated successfully by default,
if you want to actually use this feature to initiate a simulated transaction, please replace it with your account address and set up the corresponding network)

1. nodejs: [https://github.com/aptos-labs/script-composer-sdk/tree/main/examples/nodejs](https://github.com/aptos-labs/script-composer-sdk/tree/main/examples/nodejs)
2. nextjs: [https://github.com/aptos-labs/script-composer-sdk/tree/main/examples/nextjs-project](https://github.com/aptos-labs/script-composer-sdk/tree/main/examples/nextjs-project)
3. react: [https://github.com/aptos-labs/script-composer-sdk/tree/main/examples/react-project](https://github.com/aptos-labs/script-composer-sdk/tree/main/examples/react-project)

## Technical Principles

Under the hood, the SDK will invoke a WASM binary to compile the series of Move calls into a `CompiledScript`. This will guarantee that the type and ability safety of Move is still being honored during the construction process. For the SDK users, this means:

1. Ability safety:
   a. If the returned value does not have the Drop ability, the returned value needs to be consumed by subsequent calls.
   b. If the returned value does not have the Copy ability, the returned value can only be passed to subsequent calls once.
2. The caller will need to make sure they pass the right values as arguments to subsequent calls. In the previous example, the `0x1::coin::coin_to_fungible_asset` function will expect an argument of `Coin<AptosCoin>`.

This implements [AIP-102](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-102.md)

# Simulating Transactions

> Preview transaction costs and effects before submission using transaction simulation with the TypeScript SDK

Simulating transactions allows you to preview the cost and effect of submitting a transaction without paying fees.
You can use this to estimate fees, test a transaction, or to check what the output might be.

To simulate a transaction, you must pass in a transaction and which account would be the signer:

```typescript filename="simulate-a-transaction.ts"
import {
    Account,
    Aptos,
    AptosConfig,
    Network,
} from "@aptos-labs/ts-sdk";

async function example() {
    let sender = Account.generate();
    let receiver = Account.generate();

    // 0. Setup the client and test accounts
    const config = new AptosConfig({ network: Network.DEVNET });
    const aptos = new Aptos(config);

    await aptos.fundAccount({
        accountAddress: sender.accountAddress,
        amount: 100_000_000,
    });

    // 1. Build the transaction to preview the impact of it
    const transaction = await aptos.transaction.build.simple({
        sender: sender.accountAddress,
        data: {
        // All transactions on Aptos are implemented via smart contracts.
        function: "0x1::aptos_account::transfer",
        functionArguments: [receiver.accountAddress, 100],
        },
    });

    // 2. Simulate to see what would happen if we execute this transaction
    const [userTransactionResponse] = await aptos.transaction.simulate.simple({
        signerPublicKey: sender.publicKey,
        transaction,
    });
    console.log(userTransactionResponse)

    // If the fee looks ok, continue to signing!
    // ...
}

example();
```

This will produce the same output as if the transaction was submitted.

The `signerPublicKey` parameter in `aptos.transaction.simulate.simple` is used to verify the signer‚Äôs authentication key during transaction simulation. This parameter is optional, and simulation will bypass checking the authentication key if omitted. For example below:

```typescript
// 2. Simulate to see what would happen if we execute this transaction, skipping the authentication key check
const [userTransactionResponse] = await aptos.transaction.simulate.simple({
    transaction,
});
```

<details>
  <summary>Example Output</summary>

  ```shellscript filename="Terminal"
  {
    version: '9534925',
    hash: '0xea50b6fbea39ad1ba015d11cda0e7478334669c34830bc3df067a260d680893c',
    state_change_hash: '0x0000000000000000000000000000000000000000000000000000000000000000',
    event_root_hash: '0x0000000000000000000000000000000000000000000000000000000000000000',
    state_checkpoint_hash: null,
    gas_used: '9',
    success: true,
    vm_status: 'Executed successfully',
    accumulator_root_hash: '0x0000000000000000000000000000000000000000000000000000000000000000',
    changes: [
      {
        address: '0x811d5a94ccb597fa2a4f7872a3c678867cff94130d9378c39304c1354ef54abe',
        state_key_hash: '0x09adecee8779b64d05847488e2dbec6679c0c9e2fe618caf0793472ba3a7e4ab',
        data: [Object],
        type: 'write_resource'
      },
      {
        address: '0x811d5a94ccb597fa2a4f7872a3c678867cff94130d9378c39304c1354ef54abe',
        state_key_hash: '0x0c70ede5412277b81d9f8d99369930ed5d56ad65862e3e878ad22dd5500833d0',
        data: [Object],
        type: 'write_resource'
      },
      {
        address: '0xf40c314051890d16ba0a2ba427e003a83e730956fdeccf6c8eebc893a229ddc1',
        state_key_hash: '0x503f9cffb248036da24e18875f3dce72bb33d1d3ef5cfdbdb2fb3411cd718f4f',
        data: [Object],
        type: 'write_resource'
      },
      {
        state_key_hash: '0x6e4b28d40f98a106a65163530924c0dcb40c1349d3aa915d108b4d6cfc1ddb19',
        handle: '0x1b854694ae746cdbd8d44186ca4929b2b337df21d1c74633be19b2710552fdca',
        key: '0x0619dc29a0aac8fa146714058e8dd6d2d0f3bdf5f6331907bf91f3acd81e6935',
        value: '0x708f579f62cb01000100000000000000',
        data: null,
        type: 'write_table_item'
      }
    ],
    sender: '0x811d5a94ccb597fa2a4f7872a3c678867cff94130d9378c39304c1354ef54abe',
    sequence_number: '0',
    max_gas_amount: '200000',
    gas_unit_price: '100',
    expiration_timestamp_secs: '1718983701',
    payload: {
      function: '0x1::aptos_account::transfer',
      type_arguments: [],
      arguments: [
        '0xf40c314051890d16ba0a2ba427e003a83e730956fdeccf6c8eebc893a229ddc1',
        '100'
      ],
      type: 'entry_function_payload'
    },
    signature: {
      public_key: '0x966b6b9aa8feb58ee1b911235dea1f185b9169de56303d18bb59937066881e44',
      signature: '0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000',
      type: 'ed25519_signature'
    },
    events: [
      {
        guid: [Object],
        sequence_number: '0',
        type: '0x1::coin::CoinWithdraw',
        data: [Object]
      },
      {
        guid: [Object],
        sequence_number: '0',
        type: '0x1::coin::WithdrawEvent',
        data: [Object]
      },
      {
        guid: [Object],
        sequence_number: '0',
        type: '0x1::coin::CoinDeposit',
        data: [Object]
      },
      {
        guid: [Object],
        sequence_number: '1',
        type: '0x1::coin::DepositEvent',
        data: [Object]
      },
      {
        guid: [Object],
        sequence_number: '0',
        type: '0x1::transaction_fee::FeeStatement',
        data: [Object]
      }
    ],
    timestamp: '1718983681460047'
  }
  ```
</details>

Look [here](/build/sdks/ts-sdk/building-transactions) to see the full example of how to build, simulate, and submit a transaction.

# Simulating more advanced Transactions

You can also learn how to simulate more advanced transactions by looking at the following guides:

- [Sponsored Transactions](/build/sdks/ts-sdk/building-transactions/sponsoring-transactions)
- [Multi-Agent Transactions](/build/sdks/ts-sdk/building-transactions/multi-agent-transactions)
- Multisig V2 Transactions: See the next section for details.

## Simulating On-Chain Multisig (v2) Transactions

For multisig transactions, there are two types of simulation:

1. Simulation of the target payload before it‚Äôs submitted on-chain, ignoring the voting status.
2. Simulation of the approved on-chain multisig transaction before execution to verify output and gas estimation.

To perform the first type, you can simulate the target payload as a sponsored transaction with the multisig account as the sender, and set the fee payer to `0x0` to bypass gas fee payment during simulation. For example:

```typescript
// Generate a raw transaction with the multisig address as the sender,
// the provided entry function payload, and 0x0 as the fee payer address.
const transactionToSimulate = await aptos.transaction.build.simple({
  sender: multisigAddress,
  data: {
    function: "0x1::aptos_account::transfer",
    functionArguments: [recipient.accountAddress, 1_000_000],
  },
  withFeePayer: true,
});

// Simulate the transaction, skipping the public/auth key check for both the sender and the fee payer.
const [simulateMultisigTx] = await aptos.transaction.simulate.simple({
  transaction: transactionToSimulate,
});
```

This setup allows you to preview the target payload's result before submitting it on-chain. Here, `signerPublicKey` is omitted to skip the authentication key check for the sender, as the multisig account does not have a public key. Additionally, `feePayerAddress` defaults to `0x0`, and `feePayerPublicKey` is omitted to bypass the gas fee payment during simulation. When this payload is later executed after submission and approval, the owner executing the transaction will cover the gas fee.

For the second type of simulation, where the on-chain multisig payload transaction is simulated for final validation and gas estimation, use the following approach:

```typescript
const transactionPayload: TransactionPayloadMultiSig = await generateTransactionPayload({
  multisigAddress,
  function: "0x1::aptos_account::transfer",
  functionArguments: [recipient.accountAddress, 1_000_000],
  aptosConfig: config,
});

const rawTransaction = await generateRawTransaction({
  aptosConfig: config,
  sender: owner.accountAddress,
  payload: transactionPayload,
});

const [simulateMultisigTx] = await aptos.transaction.simulate.simple({
  signerPublicKey: owner.publicKey,
  transaction: new SimpleTransaction(rawTransaction),
});
```

Note that `signerPublicKey` is optional and can be omitted if you wish to skip the authentication key check for the sender during simulation.

For the complete source code, see the [Multisig V2 Example](https://github.com/aptos-labs/aptos-ts-sdk/blob/main/examples/typescript-esm/multisig_v2.ts).

# Sponsoring Transactions

> Learn how to sponsor transactions on Aptos, allowing one account to pay gas fees for another account's transactions

import { Aside, Steps } from '@astrojs/starlight/components';

Normally, the account that is executing a transaction pays for the gas fees. You can allow another account to cover those charges by sponsoring a transaction.

This can be used to help manage fees from a central account when working with complicated smart contracts.

## How To Sponsor a Transaction

<Steps>
  1. Build the transaction with the parameter withFeePayer: true.

     ```typescript filename="sponsor.ts"
     const transaction = await aptos.transaction.build.simple({
         sender: sender.accountAddress,
         withFeePayer: true,
         data: {
             // All transactions on Aptos are implemented via smart contracts.
             function: "0x1::aptos_account::transfer",
             functionArguments: [destination.accountAddress, 100],
         },
     });
     ```

  2. Sign the transaction with BOTH the sender and the feePayer.

     1. Sign with the sender account using `.sign`.
     2. Sign with the sponsor account using `.signAsFeePayer`.

     <Aside type="caution">
       The sponsor uses a different function (`.signAsFeePayer`) than the sender to sign!
     </Aside>

     ```typescript filename="sponsor.ts"
     const senderAuthenticator = aptos.transaction.sign({
         signer: sender,
         transaction,
     });
     const feePayerAuthenticator = aptos.transaction.signAsFeePayer({
         signer: feePayer,
         transaction
     })
     ```

  3. (Optional) Simulate the sponsoring transaction

     You can simulate the sponsoring transaction to preview the result before submitting it as follows:

     ```typescript filename="sponsor.ts"
     const [userTransactionResponse] = await aptos.transaction.simulate.simple({
         signerPublicKey: sender.publicKey,
         transaction,
     });
     ```

     By default, the `transaction`‚Äôs `feePayerAddress` is set to `0x0`, which directs the transaction simulation to skip the gas fee payment. This allows you to simulate the transaction without specifying a fee payer. Note that `signerPublicKey` is optional and can be omitted if you want to skip the authentication key check for the sender.

     You can also simulate the transaction with a specific fee payer by setting the `feePayerAddress` in the `transaction` object as follows:

     ```typescript filename="sponsor.ts"
     transaction.feePayerAddress = feePayer.accountAddress;
     const [userTransactionResponse] = await aptos.transaction.simulate.simple({
         signerPublicKey: sender.publicKey,
         feePayerPublicKey: feePayer.publicKey,
         transaction,
     });
     ```

     This setup will verify that `feePayer` has sufficient balance to cover the gas fee for the transaction. Similarly, `feePayerPublicKey` is optional and can be omitted if you wish to bypass the authentication key check for the fee payer.

  4. Submit the transaction by combining both signatures.

     ```typescript filename="sponsor.ts"
     // 4. Submit
     const committedTransaction = await aptos.transaction.submit.simple({
         transaction,
         senderAuthenticator: senderAuthenticator,
         feePayerAuthenticator: feePayerAuthenticator,
     });
     ```

  5. Wait for the transaction to execute.

     ```typescript filename="sponsor.ts"
     // 5. Wait for results
     const executedTransaction = await aptos.waitForTransaction({ transactionHash: committedTransaction.hash });
     ```
</Steps>

## TypeScript Sponsor Transaction Code Sample

```typescript filename="sponsor.ts"
/**
 * This example shows how to use the Aptos SDK to send a transaction with a sponsor.
 */

import {
    Account,
    Aptos,
    AptosConfig,
    Network,
} from "@aptos-labs/ts-sdk";

async function example() {
    console.log("This example will send a sponsored transaction from Alice to Carol.");

    // 0. Setup the client and test accounts
    const config = new AptosConfig({ network: Network.DEVNET });
    const aptos = new Aptos(config);

    let alice = Account.generate();
    let bob = Account.generate();
    let carol = Account.generate();

    console.log("=== Addresses ===\n");
    console.log(`Alice's address is: ${alice.accountAddress}`);
    console.log(`Bob's address is: ${bob.accountAddress}`);
    console.log(`Carol's address is: ${carol.accountAddress}`);

    console.log("\n=== Funding accounts ===\n");
    await aptos.fundAccount({
        accountAddress: alice.accountAddress,
        amount: 500_000_000,
    });
    await aptos.fundAccount({
        accountAddress: bob.accountAddress,
        amount: 500_000_000,
    });
    await aptos.fundAccount({
        accountAddress: carol.accountAddress,
        amount: 100,
    });
    console.log("Funded the accounts!")

    // 1. Build
    console.log("\n=== 1. Building the transaction ===\n");
    const transaction = await aptos.transaction.build.simple({
        sender: alice.accountAddress,
        withFeePayer: true,
        data: {
            // All transactions on Aptos are implemented via smart contracts.
            function: "0x1::aptos_account::transfer",
            functionArguments: [carol.accountAddress, 100],
        },
    });
    console.log("Built the transaction!")

    // 2. Sign
    console.log("\n=== 2. Signing transaction ===\n");
    const aliceSenderAuthenticator = aptos.transaction.sign({
        signer: alice,
        transaction,
    });
    const bobSenderAuthenticator = aptos.transaction.signAsFeePayer({
        signer: bob,
        transaction
    })
    console.log("Signed the transaction!")

    // 3. Simulate (Optional)
    console.log("\n === 3. Simulating Response (Optional) === \n")
    const [userTransactionResponse] = await aptos.transaction.simulate.simple({
        signerPublicKey: alice.publicKey,
        feePayerPublicKey: bob.publicKey,
        transaction,
    });
    console.log(userTransactionResponse)

    // 4. Submit
    console.log("\n=== 4. Submitting transaction ===\n");
    const committedTransaction = await aptos.transaction.submit.simple({
        transaction,
        senderAuthenticator: aliceSenderAuthenticator,
        feePayerAuthenticator: bobSenderAuthenticator,
    });
    console.log("Submitted transaction hash:", committedTransaction.hash);

    // 5. Wait for results
    console.log("\n=== 5. Waiting for result of transaction ===\n");
    const executedTransaction = await aptos.waitForTransaction({ transactionHash: committedTransaction.hash });
    console.log(executedTransaction)
};

example();
```

## Common Errors

`INSUFFICIENT_BALANCE_FOR_TRANSACTION_FEE` :

1. This may be caused by accidentally using `.sign` instead of `.signAsFeePayer` when signing the transaction before submitting on-chain.
2. Sponsoring a transaction requires that the sponsoring account have enough funds to cover the max possible gas fee. This is often orders of magnitude larger than the expected or actual gas fees required for a transaction to execute. In this case, increase the funds in the account above the `max_gas_amount` **multiplied** by the `gas_unit_price` in the simulated transaction. These must be multiplied because gas is unitless, and so must be multiplied by the conversion rate from gas to  [octas](/network/glossary#Octa). You can learn more about gas [here](/network/blockchain/gas-txn-fee).

# Confidential Asset (CA)

> Complete guide to working with confidential assets on Aptos, including ZK-proofs, encryption, transfers, and key rotation

import { Aside } from '@astrojs/starlight/components';

You can use `confidentialCoin` property of `Aptos` client to interact with `CA`

### Initialization

Operations in CA require generating zk-proofs (ZKPs), and depending on your environment, you need to define a `Range Proof` calculation.

For the web, you could use `confidential-asset-wasm-bindings/confidential-asset-wasm-bindings`:

Let's prepare range-proof generation and configure SDK to use it:

```typescript
import initWasm, {
  batch_range_proof as batchRangeProof,
  batch_verify_proof as batchVerifyProof,
  range_proof as rangeProof,
  verify_proof as verifyProof,
} from '@aptos-labs/confidential-asset-wasm-bindings/range-proofs'
import {
  BatchRangeProofInputs,
  BatchVerifyRangeProofInputs,
  RangeProofInputs,
  VerifyRangeProofInputs,
} from '@lukachi/aptos-labs-ts-sdk'

const RANGE_PROOF_WASM_URL =
  'https://unpkg.com/@aptos-labs/confidential-asset-wasm-bindings@0.3.16/range-proofs/aptos_rp_wasm_bg.wasm'

export async function genBatchRangeZKP(
  opts: BatchRangeProofInputs,
): Promise<{ proof: Uint8Array; commitments: Uint8Array[] }> {
  await initWasm({ module_or_path: RANGE_PROOF_WASM_URL })

  const proof = batchRangeProof(
    new BigUint64Array(opts.v),
    opts.rs,
    opts.val_base,
    opts.rand_base,
    opts.num_bits,
  )

  return {
    proof: proof.proof(),
    commitments: proof.comms(),
  }
}

export async function verifyBatchRangeZKP(
  opts: BatchVerifyRangeProofInputs,
): Promise<boolean> {
  await initWasm({ module_or_path: RANGE_PROOF_WASM_URL })

  return batchVerifyProof(
    opts.proof,
    opts.comm,
    opts.val_base,
    opts.rand_base,
    opts.num_bits,
  )
}
```

And then, just place this at the very top of your app:

```typescript
import { RangeProofExecutor } from '@aptos-labs/ts-sdk'

RangeProofExecutor.setGenBatchRangeZKP(genBatchRangeZKP);
RangeProofExecutor.setVerifyBatchRangeZKP(verifyBatchRangeZKP);
RangeProofExecutor.setGenerateRangeZKP(generateRangeZKP);
RangeProofExecutor.setVerifyRangeZKP(verifyRangeZKP);
```

For the native apps:

Generate `android` and `ios` bindings [here](https://github.com/aptos-labs/confidential-asset-wasm-bindings) and integrate in your app as you please.

And the last, but not the least important part:

To get a "numeric" value of the confidential balance, you also need to solve a Discrete Logarithm Problem (DLP).
CA implements the Pollard's Kangaroo method for solving DLPs on the Ristretto curve.
[Source](https://cr.yp.to/dlog/cuberoot-20120919.pdf)

So we also need to initialize a decryption function for that:

```typescript
// Copyright ¬© Aptos Foundation
// SPDX-License-Identifier: Apache-2.0

import initWasm, {
  create_kangaroo,
  WASMKangaroo,
} from '@aptos-labs/confidential-asset-wasm-bindings/pollard-kangaroo'
import {
  ConfidentialAmount,
  TwistedEd25519PrivateKey,
  TwistedElGamal,
  TwistedElGamalCiphertext,
} from '@lukachi/aptos-labs-ts-sdk'
import { bytesToNumberLE } from '@noble/curves/abstract/utils'

const POLLARD_KANGAROO_WASM_URL =
  'https://unpkg.com/@aptos-labs/confidential-asset-wasm-bindings@0.3.15/pollard-kangaroo/aptos_pollard_kangaroo_wasm_bg.wasm'

export async function createKangaroo(secret_size: number) {
  await initWasm({ module_or_path: POLLARD_KANGAROO_WASM_URL })

  return create_kangaroo(secret_size)
}

export const preloadTables = async () => {
  const kangaroo16 = await createKangaroo(16)
  const kangaroo32 = await createKangaroo(32)
  const kangaroo48 = await createKangaroo(48)

  TwistedElGamal.setDecryptionFn(async pk => {
    if (bytesToNumberLE(pk) === 0n) return 0n

    let result = kangaroo16.solve_dlp(pk, 500n)

    if (!result) {
      result = kangaroo32.solve_dlp(pk, 1500n)
    }

    if (!result) {
      result = kangaroo48.solve_dlp(pk)
    }

    if (!result) throw new TypeError('Decryption failed')

    return result
  })
}
```

[//]: # "TODO: update to 16->32->48 usage"

Now, place this at the top of your app:

```typescript
const init = async () => {
  await preloadTables();
}
```

For the native apps, you could generate `android` and `ios` bindings [here](https://github.com/aptos-labs/confidential-asset-wasm-bindings) to use instead of WASM.

***

Now we are ready to go. Let's define Aptos client:

```typescript
const APTOS_NETWORK: Network = NetworkToNetworkName[Network.TESTNET];
const config = new AptosConfig({ network: APTOS_NETWORK });
export const aptos = new Aptos(config);
```

### Create Decryption Key (DK)

To interact with the confidential asset, create a [unique key pair](/build/sdks/ts-sdk/confidential-asset#confidential-asset-store) first.

Generate new:

```typescript
const dk = TwistedEd25519PrivateKey.generate();
```

Or import existed one:

```typescript
const dk = new TwistedEd25519PrivateKey("0x...");
```

Also, you could derive it using your `signature` (for testing purposes, don't use at production):

```typescript
const user = Account.generate()

const signature = user.sign(TwistedEd25519PrivateKey.decryptionKeyDerivationMessage);

const dk = TwistedEd25519PrivateKey.fromSignature(signature);
```

Or use [`pepper`](/build/guides/aptos-keyless/how-keyless-works) from [Keyless Account](/build/guides/aptos-keyless)

### Register

Next, you need to [register](/build/sdks/ts-sdk/confidential-asset#register) a previously generated encryption key (EK) in contracts:

```typescript
export const registerConfidentialBalance = async (
  account: Account,
  publicKeyHex: string,
  tokenAddress = "0x...",
) => {
  const txBody = await aptos.confidentialAsset.deposit({
    sender: account.accountAddress,
    to: AccountAddress.from(to),
    tokenAddress: tokenAddress,
    amount: amount,
  })

  const txResponse = await aptos.signAndSubmitTransaction({ signer: user, transaction: userRegisterCBTxBody });

  const txReceipt = await aptos.waitForTransaction({ transactionHash: txResponse.hash });

  return txReceipt;
}
```

Check if a user has already registered a specific token:

```typescript
export const getIsAccountRegisteredWithToken = async (
  account: Account,
  tokenAddress = "0x...",
) => {
  const isRegistered = await aptos.confidentialAsset.hasUserRegistered({
    accountAddress: account.accountAddress,
    tokenAddress: tokenAddress,
  })

  return isRegistered
}
```

### Deposit

Let's say you already have tokens.

This will deposit them to your confidential balance

```typescript
export const depositConfidentialBalance = async (
  account: Account,
  amount: bigint,
  to: string,
  tokenAddress = "0x...",
) => {
  const txBody = await aptos.confidentialAsset.deposit({
    sender: account.accountAddress,
    to: AccountAddress.from(to),
    tokenAddress: tokenAddress,
    amount: amount,
  })
  // Sign and send transaction
}
```

### Get user's balance

Let's check the user's balance after the deposit.

```typescript
const userConfidentialBalance = await aptos.confidentialAsset.getBalance({ accountAddress: user.accountAddress, tokenAddress: TOKEN_ADDRESS });
```

This method returns you the user's [`pending` and `actual`](/build/sdks/ts-sdk/confidential-asset#confidential-asset-store) confidential balances, and to [decrypt](/build/sdks/ts-sdk/confidential-asset#encryption-and-decryption) them, you can use `ConfidentialAmount` class

```typescript
export const getConfidentialBalances = async (
  account: Account,
  decryptionKeyHex: string,
  tokenAddress = "0x...",
) => {
  const decryptionKey = new TwistedEd25519PrivateKey(decryptionKeyHex)

  const { pending, actual } = await aptos.confidentialAsset.getBalance({
    accountAddress: account.accountAddress,
    tokenAddress,
  })

  try {
    const [confidentialAmountPending, confidentialAmountActual] =
      await Promise.all([
        ConfidentialAmount.fromEncrypted(pending, decryptionKey),
        ConfidentialAmount.fromEncrypted(actual, decryptionKey),
      ])

    return {
      pending: confidentialAmountPending,
      actual: confidentialAmountActual,
    }
  } catch (error) {
    return {
      pending: ConfidentialAmount.fromAmount(0n),
      actual: ConfidentialAmount.fromAmount(0n),
    }
  }
}
```

### Rollover

After you deposited to user's confidential balance, you can see, that he has, for instance `5n` at his `pending` balance, and `0n` at his `actual` balance.

User can't operate with `pending` balance, so you could [rollover](/build/sdks/ts-sdk/confidential-asset#rollover-pending-balance) it to `actual` one.

And to do so - use `aptos.confidentialAsset.rolloverPendingBalance`.

<Aside type="caution">
  Important note, that user's actual balance need to be [normalized](/build/sdks/ts-sdk/confidential-asset#normalize) before `rollover` operation.
</Aside>

To cover [normalization](#normalization) & `rollover` simultaneously, you could use `aptos.confidentialAsset.safeRolloverPendingCB`.

```typescript
export const safelyRolloverConfidentialBalance = async (
  account: Account,
  decryptionKeyHex: string,
  tokenAddress = "0x...",
) => {
  const rolloverTxPayloads = await aptos.confidentialAsset.safeRolloverPendingCB({
    sender: account.accountAddress,
    tokenAddress,
    decryptionKey: new TwistedEd25519PrivateKey(decryptionKeyHex),
  })

  // Sign and send batch txs
}
```

***

### Normalization

Usually you don't need to explicitly call [normalization](/build/sdks/ts-sdk/confidential-asset#normalize)

In case you want to:

<Aside type="caution">
  Firstly, check a confidential balance is normalized, because trying to normalize an already normalized balance will return you an exception
</Aside>

```typescript
export const getIsBalanceNormalized = async (
  account: Account,
  tokenAddress = "0x...",
) => {
  const isNormalized = await aptos.confidentialAsset.isUserBalanceNormalized({
    accountAddress: account.accountAddress,
    tokenAddress: tokenAddress,
  })

  return isNormalized
}
```

Get your balance and finally call the `aptos.confidentialAsset.normalizeUserBalance` method:

```typescript
export const normalizeConfidentialBalance = async (
  account: Account,
  decryptionKeyHex: string,
  encryptedPendingBalance: TwistedElGamalCiphertext[],
  amount: bigint,
  tokenAddress = "0x...",
) => {
  const normalizeTx = await aptos.confidentialAsset.normalizeUserBalance({
    tokenAddress,
    decryptionKey: new TwistedEd25519PrivateKey(decryptionKeyHex),
    unnormalizedEncryptedBalance: encryptedPendingBalance,
    balanceAmount: amount,

    sender: account.accountAddress,
  })

  // Sign and send transaction
}
```

### Withdraw

To [withdraw](/build/sdks/ts-sdk/confidential-asset#withdraw) your assets out from confidential balance:

```typescript
export const withdrawConfidentialBalance = async (
  account: Account,
  receiver: string,
  decryptionKeyHex: string,
  withdrawAmount: bigint,
  encryptedActualBalance: TwistedElGamalCiphertext[],
  tokenAddress = '0x...',
) => {
  const withdrawTx = await aptos.confidentialAsset.withdraw({
    sender: account.accountAddress,
    to: receiver,
    tokenAddress,
    decryptionKey: decryptionKey,
    encryptedActualBalance,
    amountToWithdraw: withdrawAmount,
  })

  // Sign and send transaction
}
```

### Transfer

For [transfer](/build/sdks/ts-sdk/confidential-asset#confidential-transfer) you need to know the recipient's encryption key and `aptos` account address

Let's say you have a recipient's account address, let's get their encryption key.

```typescript
export const getEkByAddr = async (addrHex: string, tokenAddress: string) => {
  return aptos.confidentialAsset.getEncryptionByAddr({
    accountAddress: AccountAddress.from(addrHex),
    tokenAddress,
  })
}
```

Now, wrap it all together and transfer:

```typescript
export const transferConfidentialCoin = async (
  account: Account,
  decryptionKeyHex: string,
  encryptedActualBalance: TwistedElGamalCiphertext[],
  amountToTransfer: bigint,
  recipientAddressHex: string,
  auditorsEncryptionKeyHexList: string[],
  tokenAddress = "0x...",
) => {
  const decryptionKey = new TwistedEd25519PrivateKey(decryptionKeyHex)

  const recipientEncryptionKeyHex = await getEkByAddr(
    recipientAddressHex,
    tokenAddress,
  )

  const transferTx = await aptos.confidentialAsset.transferCoin({
    senderDecryptionKey: decryptionKey,
    recipientEncryptionKey: new TwistedEd25519PublicKey(
      recipientEncryptionKeyHex,
    ),
    encryptedActualBalance: encryptedActualBalance,
    amountToTransfer,
    sender: account.accountAddress,
    tokenAddress,
    recipientAddress: recipientAddressHex,
    auditorEncryptionKeys: auditorsEncryptionKeyHexList.map(
      hex => new TwistedEd25519PublicKey(hex),
    ),
  })

  // Sign and send transaction
}
```

### Key Rotation

To do [key rotation](/build/sdks/ts-sdk/confidential-asset#rotate-encryption-key), you need to create a new decryption key and use `aptos.confidentialAsset.rotateCBKey`

<Aside type="caution">
  But keep in mind, that `key-rotation` checks that pending balance equals 0.
  In that case, we could do a `rollover` with `freeze` option, to move assets from the pending balance to the actual one and lock our balance.

  ```typescript
  aptos.confidentialAsset.safeRolloverPendingCB({
    ...,
    withFreezeBalance: false,
  })
  ```
</Aside>

Now let's create a new decryption key and rotate our encryption key:

```typescript
const balances = await getBalances(user.accountAddress.toString(), myDecryptionKey, TOKEN_ADDRESS);

const NEW_DECRYPTION_KEY = TwistedEd25519PrivateKey.generate();
const keyRotationAndUnfreezeTxResponse = await ConfidentialCoin.safeRotateCBKey(aptos, user, {
  sender: user.accountAddress,

  currDecryptionKey: currentDecryptionKey,
  newDecryptionKey: NEW_DECRYPTION_KEY,

  currEncryptedBalance: balances.actual.amountEncrypted,

  withUnfreezeBalance: true, // if you want to unfreeze balance after
  tokenAddress: TOKEN_ADDRESS,
});

// save: new decryption key
console.log(NEW_DECRYPTION_KEY.toString());

// check new balances
const newBalance = await getBalances(user.accountAddress.toString(), NEW_DECRYPTION_KEY, TOKEN_ADDRESS);

console.log(newBalance.pending.amount);
console.log(newBalance.actual.amount);
```

# Fetch Data via SDK

> Learn how to retrieve on-chain data, query the Indexer API, and use view functions with the Aptos TypeScript SDK

import { Aside } from '@astrojs/starlight/components';

You can use the `Aptos` client to get on-chain data using a variety of helper functions. Specifically, many of the functions listed in the reference docs [here](https://aptos-labs.github.io/aptos-ts-sdk/@aptos-labs/ts-sdk-1.35.0/classes/Aptos.html) that start with `get...` will retrieve data from on-chain.

Here‚Äôs an example showing how to fetch common data you may need in your application:

```typescript filename="fetch-data.ts"
const aptosConfig = new AptosConfig({ network: Network.DEVNET });
const aptos = new Aptos(aptosConfig);

const fund = await aptos.getAccountInfo({ accountAddress: "0x123" });
const modules = await aptos.getAccountModules({ accountAddress: "0x123" });
const tokens = await aptos.getAccountOwnedTokens({ accountAddress: "0x123" });
```

<Aside type="note">
  Many queries have a parameter named `options` to customize the results, use it to get specifically what you are looking for.
</Aside>

The `Aptos` client can out of the box query both network data from [fullnodes](https://api.mainnet.aptoslabs.com/v1/spec#/) and the [Indexer](https://cloud.hasura.io/public/graphiql?endpoint=https://api.mainnet.aptoslabs.com/v1/graphql) API which contains aggregated and enriched data. If you want to use a custom query for Indexer API data, you can use `aptos.queryIndexer` like so:

```typescript filename="fetch-data.ts"
  const ledgerInfo = await aptos.queryIndexer({
    query: {
      query: `
        query MyQuery {
          ledger_infos {
            chain_id
          }
        }
      `
    }
  })
```

## Using Generic Queries

Some queries are intentionally broad, but this can make inferring the proper return type difficult. To accommodate that, these broad requests like `getAccountResources` allow you to specify what the expected response type should be.

```typescript filename="fetch-data.ts"
type Coin = { coin: { value: string } };

const resource = await aptos.getAccountResource<Coin>({
  accountAddress: testAccount.accountAddress,
  resourceType: "0x1::coin::CoinStore<0x1::aptos_coin::AptosCoin>",
});

// Now you have access to the response type property
const value = resource.coin.value;
```

## Using Move View Functions

You can call view functions which return custom data from on-chain by using `aptos.view`.

For example, you can look up the network you are using with the `chain_id` view function:

```typescript filename="fetch-data.ts"
const payload: InputViewFunctionData = {
  function: "0x1::chain_id::get",
};

const chainId = (await aptos.view({ payload }))[0];
```

## Ensuring Fresh Indexer Data

Behind the scenes, some requests use the [Indexer API](/build/indexer) to access data which has been processed or aggregated. That extra parsing can take a bit of time, so the data may lag slightly behind the latest ledger.

If you want to ensure that the data is fresh, you can specify the `minimumLedgerVersion` in any request which uses the Indexer API.

```typescript filename="fetch-data.ts"
// Get the latest ledger version number
const ledgerVersion = await aptos.getLedgerInfo().ledger_version;

const tokens = await aptos.getAccountOwnedTokens({
  accountAddress: alice.accountAddress,
  minimumLedgerVersion: BigInt(response.version),
});
```

You can also ensure that your request has the data from a transaction you submitted by getting the ledger version from the transaction validation itself.

```typescript filename="fetch-data.ts"
// Wait for a transaction you just submitted
const response = await aptos.waitForTransaction({
  transactionHash: pendingTransaction.hash,
});

// Then look up how that transaction affected alice's account
const tokens = await aptos.getAccountOwnedTokens({
  accountAddress: alice.accountAddress,
  minimumLedgerVersion: BigInt(response.version),
});
```

# Legacy TypeScript SDK

> Information about the deprecated TypeScript SDK package and migration instructions to the new SDK

import { Aside } from '@astrojs/starlight/components';

<Aside emoji="üö®" type="danger">
  The Legacy TypeScript SDK package `aptos` is deprecated and will be replaced by the new TypeScript SDK. Please refer to the [new TypeScript SDK](/build/sdks/ts-sdk) for the latest features and updates.  Take a look at the [migration guide](/build/sdks/ts-sdk/legacy-ts-sdk/migration-guide).
</Aside>

# Migration Guide

> Complete guide for migrating from the legacy TypeScript SDK (v1.x.x) to the new @aptos-labs/ts-sdk package

import { Aside } from '@astrojs/starlight/components';

<Aside emoji="üö®" type="danger">
  The Legacy TypeScript SDK package `aptos` is deprecated and will be replaced by the new TypeScript SDK. Please refer to the [new TypeScript SDK](/build/sdks/ts-sdk) for the latest features and updates.
</Aside>

If you are coming from an earlier version `1.x.x` of `aptos`, you will need to make the following updates.

<Aside type="note">
  This guide only contains API differences and updates required for deprecated features. New features of the v2 SDK are not included.
</Aside>

## Install the SDK

The TypeScript SDK V2 is under a new [GitHub repo](https://github.com/aptos-labs/aptos-ts-sdk) and with a new package name - `@aptos-labs/ts-sdk`

```shellscript npm2yarn
npm i @aptos-labs/ts-sdk
```

## SDK usage and query the Aptos chain

Remove all `<*>Client` modules (i.e `AptosClient`, `FaucetClient`, `CoinClient`, etc.) and replace with an `Aptos` entry point class

**V1**

```typescript filename="v1.ts"
const faucetClient = new FaucetClient(NODE_URL, FAUCET_URL);
const aptosClient = new AptosClient(NODE_URL);
const indexerClient = new IndexerClient(INDEXER_URL);
const tokenClient = new TokenClient(aptosClient);
```

**V2**

<Aside type="note">
  Read more about it [here](/build/sdks/ts-sdk).
</Aside>

```typescript filename="v2.ts"
const aptos = new Aptos();

// make queries
const fund = await aptos.fundAccount({ accountAddress: "0x123", amount: 100 });
const modules = await aptos.getAccountModules({ accountAddress: "0x123" });
const tokens = await aptos.getAccountOwnedTokens({ accountAddress: "0x123" });
```

## Configuration class

To configure your `Aptos` client, you can use an `AptosConfig` object.

```typescript filename="v2.ts"
const aptosConfig = new AptosConfig({ network: Network.DEVNET }); // default to devnet
const aptos = new Aptos(config);
```

## Transaction Builder Flow

Removed all separate transaction functions in favor of a more simplified and friendlier transaction builder flow

**V1**

```typescript filename="v1.ts"
const aptosClient = new AptosClient(NODE_URL);

// bcs serialized arguments payload
const entryFunctionPayload =
  new TxnBuilderTypes.TransactionPayloadEntryFunction(
    TxnBuilderTypes.EntryFunction.natural(
      "0x1::aptos_account",
      "transfer",
      [],
      [bcsToBytes(TxnBuilderTypes.AccountAddress.fromHex(receiver.address()))],
    ),
  );
// generate a raw transaction
const transaction = await client.generateRawTransaction(
  sender.address(),
  entryFunctionPayload,
);

// non-serialized arguments payload
const payload: Gen.TransactionPayload = {
  type: "entry_function_payload",
  function: "0x1::aptos_account::transfer",
  type_arguments: [],
  arguments: [account2.address().hex(), 100000],
};
// generate a raw transaction
const transaction = await client.generateTransaction(
  account1.address(),
  payload,
);

// sign transaction
const signedTransaction = AptosClient.generateBCSTransaction(
  sender,
  transaction,
);
// submit transaction
const txn = await client.submitSignedBCSTransaction(signedTransaction);
```

**V2**

<Aside type="note">
  Read more about it [here](/build/sdks/ts-sdk/building-transactions).
</Aside>

```typescript filename="v2.ts"
const aptos = new Aptos();

// non-serialized arguments transaction
const transaction = await aptos.build.transaction({
  sender: alice.accountAddress,
  data: {
    function: "0x1::coin::transfer",
    typeArguments: ["0x1::aptos_coin::AptosCoin"],
    functionArguments: [bobAddress, 100],
  },
});

// bcs serialized arguments transaction
const transaction = await aptos.build.transaction({
  sender: alice.accountAddress,
  data: {
    function: "0x1::coin::transfer",
    typeArguments: [parseTypeTag("0x1::aptos_coin::AptosCoin")],
    functionArguments: [bobAddress, new U64(100)],
  },
});
// sign transaction
const senderAuthenticator = aptos.sign.transaction({
  signer: alice,
  transaction,
});
// submit transaction
const committedTransaction = await aptos.submit.transaction({
  transaction,
  senderAuthenticator,
});
```

## Account

Rename `AptosAccount` to `Account` and use static methods to generate / derive an account

**V1**

```typescript filename="v1.ts"
// generate a new account (or key pair) OR derive from private key OR derive from private key and address
const account = new AptosAccount(); // supports only Legacy Ed25519

// derive account from derivation path
const account = AptosAccount.fromDerivePath(..)
```

**V2**

<Aside type="note">
  Read more about it [here](/build/sdks/ts-sdk/account).
</Aside>

```typescript filename="v2.ts"
// generate a new account (or key pair)
const account = Account.generate(); // defaults to Legacy Ed25519
const account = Account.generate({ scheme: SigningSchemeInput.Secp256k1Ecdsa }); // Single Sender Secp256k1
const account = Account.generate({
  scheme: SigningSchemeInput.Ed25519,
  legacy: false,
}); // Single Sender Ed25519

// derive account from private key
const account = Account.fromPrivateKey({ privateKey });

// derive account from private key and address
const account = Account.fromPrivateKeyAndAddress({
  privateKey,
  address: accountAddress,
});

// derive account from derivation path
const account = Account.fromDerivationPath({
  path,
  mnemonic,
  scheme: SigningSchemeInput.Ed25519,
});
```

# TypeScript SDK Quickstart

> Get started with the Aptos TypeScript SDK by creating accounts, funding them, and transferring APT tokens between accounts

import { Aside, Steps, TabItem, Tabs } from '@astrojs/starlight/components';

<Aside type="note">
  The complete example code can be found at [Full Quickstart Code](#full-quickstart-code) at the bottom of the page.
</Aside>

<Steps>
  1. Initialize A Project

     This will initialize a typescript package with `quickstart.ts`

     <Tabs>
       <TabItem label="npm">
         ```shellscript
         npm init && npm add -D typescript @types/node ts-node && npx tsc --init && mkdir src && echo 'async function example() { console.log("Running example!")}; example()' > src/quickstart.ts
         ```
       </TabItem>

       <TabItem label="pnpm">
         ```shellscript
         pnpm init && pnpm add -D typescript @types/node ts-node && pnpx tsc --init && mkdir src && echo 'async function example() { console.log("Running example!")}; example()' > src/quickstart.ts
         ```
       </TabItem>

       <TabItem label="yarn">
         ```shellscript
         yarn init -y && yarn add -D typescript @types/node ts-node && npx tsc --init && mkdir src && echo 'async function example() { console.log("Running example!")}; example()' > src/quickstart.ts
         ```
       </TabItem>
     </Tabs>

  2. Test Initialization

     To test if you have initialized the package correctly run:

     <Tabs>
       <TabItem label="npm">
         ```shellscript
         npx ts-node src/quickstart.ts
         ```
       </TabItem>

       <TabItem label="pnpm">
         ```shellscript
         pnpx ts-node src/quickstart.ts
         ```
       </TabItem>

       <TabItem label="yarn">
         ```shellscript
         yarn ts-node src/quickstart.ts
         ```
       </TabItem>
     </Tabs>

  3. Install the TypeScript SDK using the package manager of your choice:

     ```shellscript npm2yarn
     npm i @aptos-labs/ts-sdk
     ```

  4. Set up the Aptos client

     You can use the `Aptos` object to handle everything that requires a connection to the Aptos network. A connection is established as soon as you create the object.

     ```typescript filename="quickstart.ts"
     import { Account, Aptos, AptosConfig, Network } from "@aptos-labs/ts-sdk";

     // Specify which network to connect to via AptosConfig
     async function example() {
       console.log(
         "This example will create two accounts (Alice and Bob), fund them, and transfer between them.",
       );

       // Setup the client
       const config = new AptosConfig({ network: Network.DEVNET });
       const aptos = new Aptos(config);
     }

     example()
     ```

     <Aside type="note">
       (Advanced) If you need to connect to a specific node, you can set that in the `AptosConfig` by specifying the `fullnode` url. Ex. `fullnode: http://localhost:8080/v1`.
     </Aside>

  5. Fetch data from on-chain

     You can use the `Aptos` client to fetch all sorts of data from on-chain such as information about the network itself or account-specific information.

     ```typescript filename="quickstart.ts"
     ...
     const ledgerInfo = await aptos.getLedgerInfo();
     const modules = await aptos.getAccountModules({ accountAddress: "0x123" });
     const tokens = await aptos.getAccountOwnedTokens({ accountAddress: "0x123" });
     ...
     ```

  6. Send Transactions

     You can send transactions to change the state of the ledger. Transactions let you send tokens like APT, trigger Move modules, trade NFTs, and more. You can find an in-depth tutorial on transactions [here](/build/sdks/ts-sdk/building-transactions).

     To begin with though, here‚Äôs how you can send a basic transaction to transfer APT.

     #### 1. Create an Account

     To create a new account, you first generate new credentials then fund the account. On localnet / devnet you can fund an account programmatically by asking a "faucet" which has a lot of test APT to send some to your new account.

     ```typescript filename="quickstart.ts"
     ...
     // Generate a new account key pair
     const alice: Account = Account.generate();

     // Fund the account on chain. Funding an account creates it on-chain.
     await aptos.fundAccount({
       accountAddress: alice.accountAddress,
       amount: 100000000,
     });

     // Also create a second account to transfer tokens to
     const bob: Account = Account.generate();

     // Fund the account on chain
     await aptos.fundAccount({
       accountAddress: bob.accountAddress,
       amount: 100000000,
     });
     ...
     ```

     #### 2. Build the Transaction

     You can build transactions with `aptos.transaction.build.simple({...})` by specifying:

     1. `sender` - The account that‚Äôs sending the transaction. This account will pay the gas fees.
     2. `data` - The information needed for Aptos to identify what transaction to execute.
        1. `function` - Which smart contract on chain to call. This has the format `<account_address>::<move_module>::<function>`.
        2. `functionArguments` - These are specific to the function being called. You can look up what parameters a function needs by searching for the account and module on chain with an explorer [like this](https://explorer.aptoslabs.com/account/0x0000000000000000000000000000000000000000000000000000000000000001/modules/code/aptos_account?network=mainnet).

     For example:

     ```typescript filename="quickstart.ts"
     ...
     const transaction = await aptos.transaction.build.simple({
       sender: alice.accountAddress,
       data: {
     	  // The Move entry-function
         function: "0x1::aptos_account::transfer",
         functionArguments: [bob.accountAddress, 100],
       },
     });
     ...
     ```

     <Aside type="note">
       For some situations, you can also use simplified functions in the SDK such as [`transferCoinTransaction`](https://explorer.aptoslabs.com/account/0x0000000000000000000000000000000000000000000000000000000000000001/modules/code/aptos_account?network=mainnet).
     </Aside>

     #### 3. Sign and Submit

     Signing proves that you own or manage the account that is executing the transaction. This is important since the sender must pay gas fees for the work the network does to execute the transaction.

     Once signed, you can submit to the network for on chain verification and execution.

     You can use `aptos.signAndSubmitTransaction` which combines those two steps into one:

     ```typescript filename="quickstart.ts"
     ...
     // Both signs and submits (although these can be done separately too)
     const pendingTransaction = await aptos.signAndSubmitTransaction({
       signer: alice,
       transaction,
     });
     ...
     ```

     #### 4. Wait for completion

     You can run `aptos.waitForTransaction` to guarantee your code executes after the transaction has been processed and applied.

     This also helps you get any errors that may occur after submitting, such as the transaction being rejected.

     ```typescript filename="quickstart.ts"
     ...
     const executedTransaction = await aptos.waitForTransaction({ transactionHash: pendingTransaction.hash });
     ...
     ```
</Steps>

## Full Quickstart Code

### Run Quickstart

<Tabs>
  <TabItem label="npm">
    ```shellscript
    npx ts-node src/quickstart.ts
    ```
  </TabItem>

  <TabItem label="pnpm">
    ```shellscript
    pnpx ts-node src/quickstart.ts
    ```
  </TabItem>

  <TabItem label="yarn">
    ```shellscript
    yarn ts-node src/quickstart.ts
    ```
  </TabItem>
</Tabs>

```typescript filename="quickstart.ts"
/**
 * This example shows how to use the Aptos client to create accounts, fund them, and transfer between them.
 */

import { Account, Aptos, AptosConfig, Network } from "@aptos-labs/ts-sdk";

const APTOS_COIN = "0x1::aptos_coin::AptosCoin";
const COIN_STORE = `0x1::coin::CoinStore<${APTOS_COIN}>`;
const ALICE_INITIAL_BALANCE = 100_000_000;
const BOB_INITIAL_BALANCE = 100;
const TRANSFER_AMOUNT = 100;

async function example() {
  console.log(
    "This example will create two accounts (Alice and Bob), fund them, and transfer between them.",
  );

  // Setup the client
  const config = new AptosConfig({ network: Network.DEVNET });
  const aptos = new Aptos(config);

  // Generate two account credentials
  // Each account has a private key, a public key, and an address
  const alice = Account.generate();
  const bob = Account.generate();

  console.log("=== Addresses ===\n");
  console.log(`Alice's address is: ${alice.accountAddress}`);
  console.log(`Bob's address is: ${bob.accountAddress}`);

  // Fund the accounts using a faucet
  console.log("\n=== Funding accounts ===\n");

  await aptos.fundAccount({
    accountAddress: alice.accountAddress,
    amount: ALICE_INITIAL_BALANCE,
  });

  await aptos.fundAccount({
    accountAddress: bob.accountAddress,
    amount: BOB_INITIAL_BALANCE,
  });
  console.log("Alice and Bob's accounts have been funded!");

  // Look up the newly funded account's balances
  console.log("\n=== Balances ===\n");
  const aliceAccountBalance = await aptos.getAccountResource({
    accountAddress: alice.accountAddress,
    resourceType: COIN_STORE,
  });
  const aliceBalance = Number(aliceAccountBalance.coin.value);
  console.log(`Alice's balance is: ${aliceBalance}`);

  const bobAccountBalance = await aptos.getAccountResource({
    accountAddress: bob.accountAddress,
    resourceType: COIN_STORE,
  });
  const bobBalance = Number(bobAccountBalance.coin.value);
  console.log(`Bob's balance is: ${bobBalance}`);

  // Send a transaction from Alice's account to Bob's account
  const txn = await aptos.transaction.build.simple({
    sender: alice.accountAddress,
    data: {
      // All transactions on Aptos are implemented via smart contracts.
      function: "0x1::aptos_account::transfer",
      functionArguments: [bob.accountAddress, 100],
    },
  });

  console.log("\n=== Transfer transaction ===\n");
  // Both signs and submits
  const committedTxn = await aptos.signAndSubmitTransaction({
    signer: alice,
    transaction: txn,
  });
  // Waits for Aptos to verify and execute the transaction
  const executedTransaction = await aptos.waitForTransaction({
    transactionHash: committedTxn.hash,
  });
  console.log("Transaction hash:", executedTransaction.hash);

  console.log("\n=== Balances after transfer ===\n");
  const newAliceAccountBalance = await aptos.getAccountResource({
    accountAddress: alice.accountAddress,
    resourceType: COIN_STORE,
  });
  const newAliceBalance = Number(newAliceAccountBalance.coin.value);
  console.log(`Alice's balance is: ${newAliceBalance}`);

  const newBobAccountBalance = await aptos.getAccountResource({
    accountAddress: bob.accountAddress,
    resourceType: COIN_STORE,
  });
  const newBobBalance = Number(newBobAccountBalance.coin.value);
  console.log(`Bob's balance is: ${newBobBalance}`);

  // Bob should have the transfer amount
  if (newBobBalance !== TRANSFER_AMOUNT + BOB_INITIAL_BALANCE)
    throw new Error("Bob's balance after transfer is incorrect");

  // Alice should have the remainder minus gas
  if (newAliceBalance >= ALICE_INITIAL_BALANCE - TRANSFER_AMOUNT)
    throw new Error("Alice's balance after transfer is incorrect");
}

example();
```

## Summary

All told, you just learned how to transfer APT via a transaction by:

1. Connecting to the network using the `Aptos` client.
2. Creating an account.
3. Looking up data from on-chain using client helper functions like [`aptos.getAccountModules`](https://aptos-labs.github.io/aptos-ts-sdk/@aptos-labs/ts-sdk-1.35.0/classes/Aptos.html#getAccountModules).
4. Signing and submitting a transaction to the network.
5. Waiting for Aptos to execute the transaction.

To see all this in action, you can copy and run the full working code snippet for this quickstart above.

<Aside type="note">
  For future development, make sure to bookmark the [reference docs](https://aptos-labs.github.io/aptos-ts-sdk/) to look up specific function signatures.

  Note that most helper functions are listed on the [`Aptos` client object](https://aptos-labs.github.io/aptos-ts-sdk/@aptos-labs/ts-sdk-1.35.0/classes/Aptos.html).
</Aside>

# TypeScript SDK Example Code

> Comprehensive collection of example code and reference implementations for the Aptos TypeScript SDK

import { Steps } from '@astrojs/starlight/components';

For sample code which explains the core concepts of how to use the SDK, see:

- [Fetching Data](/build/sdks/ts-sdk/fetch-data-via-sdk)
- [Building, Simulating, and Submitting Transactions](/build/sdks/ts-sdk/building-transactions)

Below are additional resources which may be more suited for your individual use case.

## Code Snippets

The [`examples` folder](https://github.com/aptos-labs/aptos-ts-sdk/tree/main/examples) in the SDK repo has dozens of code snippets you can customize to your needs.

### How to run examples

To run one of the example scripts:

<Steps>
  1. Clone the

     ```shellscript filename="Terminal"
     git clone https://github.com/aptos-labs/aptos-ts-sdk.git
     ```

  2. From the top-level of the package, install all dependencies.

     ```shellscript filename="Terminal"
     pnpm install
     ```

  3. Build the package.

     ```shellscript filename="Terminal"
     pnpm build
     ```

  4. Go to the folder of an example you would like to run.

     ```shellscript filename="Terminal"
     cd examples/typescript
     ```

  5. Install local dependencies.

     ```shellscript filename="Terminal"
     pnpm install
     ```

  6. Run the example.

     ```shellscript filename="Terminal"
     pnpm run simple_transfer
     ```
</Steps>

## Helpful Reference Code

- [The SDK's end-to-end tests](https://github.com/aptos-labs/aptos-ts-sdk/tree/main/tests/e2e) - This has the most comprehensive set of code that uses the SDK.
- [SDK source code](https://github.com/aptos-labs/aptos-ts-sdk/tree/main) - This has in-line comments explaining what each function does.
- [SDK reference docs](https://aptos-labs.github.io/aptos-ts-sdk/) - These are another way to view the in-line documentation with built-in search.

# Surf: TypeScript Type Safety for Move Contracts

> Learn how to use Surf for static type safety when interacting with Move contracts, including ABI extraction and type inference

import { Steps, TabItem, Tabs } from '@astrojs/starlight/components';

## What is Surf

Surf is a TypeScript library built on top of the Aptos TypeScript SDK and the wallet adapter that provides static type safety for your Move contracts by inferring type from contract ABI (Application Binary Interface). It allows you to catch type errors at compile time rather than at runtime. Most existing TypeScript IDEs will automatically provide warnings if you try to access fields that don't exist, or provide wrong input types.

## Usage

<Steps>
  1. Step 1

     First, download the ABI of the Move contract and save it to a TypeScript file. In this case, we're naming the file `abi.ts` in the `src/utils` folder.

     <Tabs>
       <TabItem label="macOS & Linux">
         ```shellscript filename="get_abi.sh"
         #! /bin/bash

         # replace it with the network your contract lives on
         NETWORK=testnet
         # replace it with your contract address
         CONTRACT_ADDRESS=0x12345
         # replace it with your module name, every .move file except move script has module_address::module_name {}
         MODULE_NAME=fungible_asset_launchpad

         # save the ABI to a TypeScript file
         echo "export const ABI = $(curl https://fullnode.$NETWORK.aptoslabs.com/v1/accounts/$CONTRACT_ADDRESS/module/$MODULE_NAME | sed -n 's/.*"abi":\({.*}\).*}$/\1/p') as const" > abi.ts
         ```
       </TabItem>

       <TabItem label="Windows">
         ```powershell filename="get_abi.ps1"
         # replace it with the network your contract lives on
         $NETWORK = "testnet"
         # replace it with your contract address
         $CONTRACT_ADDRESS = "0x1"
         # replace it with your module name, every .move file except move script has module_address::module_name {}
         $MODULE_NAME = "fungible_asset_launchpad"

         # save the ABI to a TypeScript file
         Invoke-RestMethod -Uri "https://fullnode.$NETWORK.aptoslabs.com/v1/accounts/$CONTRACT_ADDRESS/module/$MODULE_NAME" |
             Select-Object -ExpandProperty abi | ConvertTo-Json -Compress |
             Foreach-Object { "export const ABI = $_ as const" } |
             Out-File -FilePath "abi.ts"
         ```
       </TabItem>
     </Tabs>

  2. Step 2

     With the ABI, you can use Surf as a layer on top of the Aptos TypeScript SDK client `Aptos`, when interacting with Move contracts. For non-contract related operations, the `Aptos` will still need to be used.

     ```typescript filename="src/utils/aptos.ts"
     import { createSurfClient } from '@thalalabs/surf';
     import { Aptos, AptosConfig, NETWORK } from "@aptos-labs/ts-sdk";
     import { ABI } from "./abi";

     // First, create an Aptos client, make sure the network is the one that contract lives on
     export const aptos = new Aptos(new AptosConfig({ network: Network.DEVNET }));
     // Second, create a SurfClient with the Aptos client and the ABI
     export const surfClient = createSurfClient(aptos).useABI(ABI);

     // Use Surf to executes an entry function
     const result = await surfClient.entry.transfer({
       functionArguments: ['0x1', 1],
       typeArguments: ['0x1::aptos_coin::AptosCoin'],
       account: Account.fromPrivateKey(...),
     });

     // Use Surf to query a view function
     const [balance] = await surfClient.view.balance({
       functionArguments: ['0x1'],
       typeArguments: ['0x1::aptos_coin::AptosCoin'],
     });
     ```
</Steps>

## Resources

- [Surf GitHub](https://github.com/ThalaLabs/surf)
- [A simple Next.js example demonstrating Surf](https://github.com/ThalaLabs/surf/tree/main/example)
- [An example of a fungible asset launchpad using Surf](https://github.com/aptos-labs/move-by-examples/tree/main/fungible-asset-launchpad): This example is part of the Solana to Aptos guide on Aptos Learn, you can try it [here](https://fungible-asset-launchpad.vercel.app/) and read the complete tutorial [here](https://learn.aptoslabs.com/en/tutorials/aptogotchi-intermediate/fungible-assets?workshop=solana-to-aptos).

## Credits

Surf is built by [Thala Labs](https://thala.fi/), an Aptos ecosystem project, and maintained together by the Aptos community.

## Feedback

If you have any feedback or questions, please open an issue on [Surf's GitHub](https://github.com/ThalaLabs/surf/issues).

# Unity SDK

> Official Unity SDK for Aptos blockchain development - build games and applications with Unity

import { Aside, CardGrid, LinkCard } from '@astrojs/starlight/components';

<Aside type="caution" emoji="‚ùó">
  This SDK is currently in beta. Please report any issues you encounter by
  creating an issue in the
  [aptos-labs/unity-sdk](https://github.com/aptos-labs/unity-sdk) repository.
</Aside>

Integrate Aptos Web3 capabilities within your Unity applications. The goal of this SDK is to provide a set of tools
for developers to build Web3 games using the Unity game engine.

**Supported Features**

- Support for the [Aptos .NET SDK](/build/sdks/dotnet-sdk)

  > - Binary Canonical Serialization (BCS) encoding and decoding
  > - Ed25519, SingleKey, MultiKey, and Keyless signer support
  > - Utilities for transaction building, signing, and submission
  > - Abstractions over the Aptos Fullnode and Indexer APIs
  > - Aptos Names (ANS) support for resolution and lookup

**Compatibility**

| .NET Version      | Supported |
| ----------------- | --------- |
| .NET Standard 2.1 | ‚úÖ         |

## Installation

### Install via Unity Package Manager (UPM)

1. Open the Unity Package Manager (`Window` > `Package Manager`).
2. Click on the `+` button and select `Add package from git URL...`.
3. Enter the URL of the Aptos Unity SDK path in this repository:

```shellscript
https://github.com/aptos-labs/unity-sdk.git?path=/Packages/com.aptoslabs.aptos-unity-sdk
```

### Install via `unitypackage`

1. Go to the [`aptos-labs/unity-sdk Releases`](https://github.com/aptos-labs/unity-sdk/releases) and download the latest release.
2. Drag and drop the `.unitypackage` file into your Unity project.

## Usage

Set up your Aptos client by adding the `Aptos` namespace and instantiating an `AptosUnityClient`. You can use a predefined
configuration from `Networks` or configuring your own.

```csharp {2-2,8-8,11-15}
using UnityEngine;
using Aptos;

class Example : MonoBehaviour
{
    public void Start()
    {
        PrintLedgerInfo();
    }

    async void PrintLedgerInfo() {
        var client = new AptosUnityClient(Networks.Mainnet);
        var ledgerInfo = await client.Block.GetLedgerInfo();
        Debug.Log(ledgerInfo.BlockHeight);
    }

}
```

To interact with the blockchain, you will need to create a signer and build a transaction.

```csharp filename="Program.cs" {10-11,13-21,23-24,26-27}
using UnityEngine;
using Aptos;

class Example : MonoBehaviour
{
    public async void Start()
    {
        var client = new AptosUnityClient(Networks.Mainnet);

        // 1. Create a signer
        var signer = Account.Generate();

        // 2. Build the transaction
        var transaction = await client.Transaction.Build(
            sender: account,
            data: new GenerateEntryFunctionPayloadData(
                function: "0x1::aptos_account::transfer_coins",
                typeArguments: ["0x1::aptos_coin::AptosCoin"],
                functionArguments: [account.Address, "100000"]
            )
        );

        // 3. Sign and submit the transaction
        var pendingTransaction = client.Transaction.SignAndSubmitTransaction(account, transaction);

        // 4. (Optional) Wait for the transaction to be committed
        var committedTransaction = await client.Transaction.WaitForTransaction(pendingTransaction);
    }
}
```

## Resources

<CardGrid>
  <LinkCard href="https://github.com/aptos-labs/aptos-unity-starter" title="Aptos Wallet Starter" description="Example Unity project with an integration of the Aptos Unity SDK." target="_blank" />
</CardGrid>

# Wallet Adapter

> Connect your dApps to Aptos wallets using the official wallet adapter standards and integration guides

There are two wallet adapter standards in the Aptos ecosystem:

1. [Aptos Wallet Adapter](#aptos-wallet-adapter) by Aptos Labs
2. [OKX Connect](#okx-connect) by OKX

## Aptos Wallet Adapter

The Aptos Wallet Adapter by Aptos Labs provides a single interface for Aptos
dapps and Aptos wallets to communicate with each other.

For dapp developers, this means that you can connect to any Aptos wallet that is
integrated with the Wallet Adapter without needing to write custom code for each
wallet.  This is described in [AIP-62](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-62.md),
which defines the Modern Wallet Standard and autodetection of wallets.

For Aptos wallet providers, integrating with AIP-62 means that your wallet will
be compatible with any dapp that uses the Wallet Adapter.

### For Aptos Dapps

Follow the [Wallet Adapter for Dapp Builders Guide](/build/sdks/wallet-adapter/dapp) on how to use the
Wallet Adapter (via the [Wallet Adapter React package](https://github.com/aptos-labs/aptos-wallet-adapter/tree/main/packages/wallet-adapter-react)).

### For Aptos Wallet Providers

Follow one of these guides for how to implement a Wallet Adapter plugin that
dapps can connect to:

1. For [Browser Extension Wallets](/build/sdks/wallet-adapter/browser-extension-wallets) (ex. [Petra](https://chromewebstore.google.com/detail/petra-aptos-wallet/ejjladinnckdgjemekebdpeokbikhfci?hl=en))
2. For [SDK Wallets](/build/sdks/wallet-adapter/wallets) (ex. [AptosConnect](https://aptosconnect.app))

## OKX Connect

The OKX Connect adapter provides an interface for Aptos dapps to connect to OKX
wallet and other wallets that support the OKX Connect standard.  You can find
more information about OKX Connect for Aptos dapps in the [OKX Connect documentation](https://web3.okx.com/build/dev-docs/sdks/app-connect-aptos)

## Other Resources

- [Dapp Builder Guide](/build/sdks/wallet-adapter/dapp)
- [Wallet Browser Extension Guide](/build/sdks/wallet-adapter/browser-extension-wallets)
- [SDK Wallet Builder Guide](/build/sdks/wallet-adapter/wallets)
- [Modern Wallet Standard (AIP-62)](https://github.com/aptos-foundation/AIPs/blob/1bd0c41971701e54cf35da86c2877e58be61ee38/aips/aip-62.md)
- [Wallet Adapter React Package](https://github.com/aptos-labs/aptos-wallet-adapter/tree/main/packages/wallet-adapter-react)
- [Wallet Standard](https://github.com/aptos-labs/wallet-standard/tree/main) repo (with an example template for creating an AIP-62 Wallet plugin)
- Core logic and react components for the [aptos-wallet-adapter](https://github.com/aptos-labs/aptos-wallet-adapter).

# Wallet Adapter Plugin for Browser Extension Wallet Builders

> Implement wallet adapter plugins for browser extension wallets to enable automatic dapp recognition through AIP-62 standard

import { Aside, Steps } from '@astrojs/starlight/components';

A wallet adapter plugin allows dapps to use your wallet. With the AIP-62 Wallet standard, dapps can simply update their version of `aptos-wallet-adapter` to connect to newly added Wallet plugins.

Implementing a wallet plugin for a browser extension wallet has two main steps:

1. Implement a wallet adapter plugin for your browser extension.
2. Update the `aptos-wallet-adapter` package to let dapps know about your wallet.

## 1. Implement the Wallet Adapter Plugin.

You can use the [`wallet-standard`](https://github.com/aptos-labs/wallet-standard) repo‚Äôs example to implement an [AIP-62](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-62.md) compatible wallet adapter plugin that dapps can automatically recognize.

<Aside type="note">
  For an example of how to implement the Wallet Adapter plugin (and how to register it), see the [Wallet Adapter Demo dapp](https://github.com/aptos-labs/aptos-wallet-adapter/tree/main/apps/nextjs-example). Specifically, [`standardWallet.ts`](https://github.com/aptos-labs/aptos-wallet-adapter/blob/main/apps/nextjs-example/src/utils/standardWallet.ts) contains the plugin implementation, and [`page.tsx`](https://github.com/aptos-labs/aptos-wallet-adapter/blob/main/apps/nextjs-example/src/app/page.tsx) has the `registerWallet` logic.
</Aside>

<Steps>
  1. Copy the  into your browser extension codebase.

  2. Follow the instructions in that example to make it use your wallet to execute the AIP-62 functions.

     <Aside type="note">
       The full list of required functions for AIP-62 compatible wallets can be found [here](https://github.com/aptos-labs/wallet-standard/blob/38defe159b8641ff1763c4db61827c78ab448dab/src/detect.ts#L16).
     </Aside>

  3. Add a call to registerWallet with your plugin implementation so that it gets called on page load.

     This is what will notify dapps that your wallet is available.

     ```tsx filename="Example.tsx"
     // Put this function with your "MyWallet" implementation so it gets called on page load.
     (function () {
         if (typeof window === "undefined") return;
         const myWallet = new MyWallet();
         registerWallet(myWallet);
     })();
     ```

  4. Test your changes by going to the  and trying to connect your wallet.

     1. After your extension calls `registerWallet`, you should be able to click **‚ÄúConnect a Wallet‚Äù** and see your wallet as an option.
        1. You can then use the demo dapp features to verify your other wallet features work as expected.
        2. **This simulates how a real dapp will interact with your browser extension.**
     2. You can also test your implementations by updating [`standardWallet.ts`](https://github.com/aptos-labs/aptos-wallet-adapter/blob/main/apps/nextjs-example/src/utils/standardWallet.ts) from `MyWallet` to your wallet‚Äôs implementation, then running the [Wallet Adapter Demo dapp](https://github.com/aptos-labs/aptos-wallet-adapter/tree/main/apps/nextjs-example) locally.
        1. See the Wallet Adapter Demo dapp [README.md](https://github.com/aptos-labs/aptos-wallet-adapter/tree/main/apps/nextjs-example) for instructions on how to run the demo locally.
        2. In the demo, `registerWallet` is called from [`page.tsx`](https://github.com/aptos-labs/aptos-wallet-adapter/blob/main/apps/nextjs-example/src/app/page.tsx). _This is less realistic, as in practice your browser extension should be calling `registerWallet`._

  5. Publish the new version of your browser extension.
</Steps>

## 2. Update [`wallet-adapter-core`](https://github.com/aptos-labs/aptos-wallet-adapter/tree/main/packages/wallet-adapter-core) to know about your extension.

In order for dapp users who are not already using your wallet to get the option to create an account with your wallet, you need to update [`wallet-adapter-core`](https://github.com/aptos-labs/aptos-wallet-adapter/tree/main/packages/wallet-adapter-core) with your browser extension‚Äôs download link.

<Steps>
  1. Fork the  monorepo. ()

  2. Open your fork in a local editor such as VSCode.

  3. Create a new branch for your changes.

     ```shellscript filename="Terminal"
     git checkout -b your-wallet
     ```

  4. Navigate to .

  5. Add your wallet‚Äôs details to  by following the AptosStandardSupportedWallet interface.

     ```tsx filename="registry.ts"
     export interface AptosStandardSupportedWallet<Name extends string = string> {
       // The name of your wallet cast to WalletName (Ex. "Petra" as WalletName<"Petra">)
       name: WalletName<Name>;
       // The link to your chrome extension or main website where new users can create an account with your wallet.
       url: string;
       // An icon for your wallet. Can be one of 4 data types. Be sure to follow the below format exactly (including the "," after base64).
       icon: `data:image/${"svg+xml" | "webp" | "png" | "gif"};base64,${string}`;
       // Copy this exactly
       readyState: WalletReadyState.NotDetected;
       // Copy this exactly
       isAIP62Standard: true;
     }
     ```

     For example:

     ```tsx filename="Example.tsx"
     {
       name: "Petra" as WalletName<"Petra">,
       url: "https://chromewebstore.google.com/detail/petra-aptos-wallet/ejjladinnckdgjemekebdpeokbikhfci?hl=en",
       icon: "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAWbSURBVHgB7Z09c9NYFIaPlFSpUqQNK6rQhbSkWJghLZP9BesxfwAqytg1xe7+AY+3go5ACzObBkpwSqrVQkuRCiqkva8UZW1je22wpHPveZ8ZRU6wwwznueee+6FLJCuSdzrb7nZTNjaOJc9/ctdNiaJESPPkeeq+phLH5/L162k0HJ7JikTLvtEFPnFBf+D+0l/dt9tCNJK6xnjmZOg7GdJlPvC/AhQtPo5P3MsHQvwhiobLiLBQABf82y74z4Qt3ldSybKHToLTeW+I5/1B3u2euOD/JQy+zyRowEUs5zAzA1x+oCckJHrRYNCf/uE3AjD4QfONBBMC5PfvY2j3TEi4ZNmd8eHilQDFMK/s8xMhIXPhJLjuJLjAN/8VgRsbPWHwLbAtm5tXRWGRAS5b/99C7FBmgbTMAGXrJ5aIomJir8wA3S5afyLEEkUtEBezfQy+RYpFvdilgmMhNnGxRw2wL8QqScy1fMNE0T4yQCLEKkksxDQUwDj2BNjbK69pdndn/zxwNsUCCOyNGyJ374psbYkMBiLv30++59o1kW5X5NMnkdFI5OXL8nXghCsAAn10NL/Fz2NnpxQFFyR5/bq8BypDWAIg6AcHIoeH60nn4/K8e1deECIgwhAAQULQEXxIUAf43bju3ZvMDJ7jrwDT/XpToIvABeECqBf8EuB7+/W6CKBe0C/Auvv1uv

     C0XtArQBP9el14VC/oEqCtfr0uPKgX2hdAW79eF0rrhfYFQPCRKi1RyY4ZyZYF4GKQcSiAcSiAcSiAcSiAcSiAcSiAcSiAcSiAcSiAcSiAcSiAcSiAcShAm3z+LG1DAdqEAhjn40dpGwrQFtgIwgxgGAWtH1CAtsC2cQVQgLZQsk2cArSBoqeHKEAbKHpiiAI0DVq+kv4fUICmQetXMPyroABNgtb/5o1oggI0icJzBChAUyDwr16JNihAUzx+LBqhAE3w5InaU0MoQN08f64y9VdQgDrBkO/FC9EMBagLBB/P/yvHxlGxTYPh3tOn4gMUYN2g4FPc509DAdYFqvxZh1ArhwKsg6rSVzTHvywU4EeoqnyPTxKnAKuCVo4iD4s6ARwhTwGWoTrk8e3bIE4IH4cCVCDI1U6dL1/K73Eh4B727ctCASoQ6MBa9zJwJtA4FMA4FMA4FMA4FMA4FMA4FMA4FMA47Qtg4P/n1Uz7AgQ8zeoD7Qug5KQMq+joApgFWkNHEWhwEUYLFMA4OgRQdGCCNXQIUG28II2jZyKIWaAV9Aig7OgUK+gRAMH36ImaUNC1FoDt1swCjaJLAAQfT9mQxtC3GohugCOCxtC5HIyHLNkVNIJOATAv4Mnz9b6jd0MIhoWsB2pH944gPHmLkQGpDf1bwtAVUILa8GNPICRgd1AL/mwKRXfA0cHa8WtXMArDfp8bSdeIf9vCEfxHj8psQBF+GH/PB0A2wIzhrVsih4ciOztCVsfvAyKQAVAbYPr44EDk6Ehkd1fI8oRxQggKQ2QEXMgEe3ulELhvbQmZT3hHxFRn+1Tn/UAAZAWIUXUTHz4IKQn/jCBkB6Pn/ywDHw41DgUwDgRIhVgljSWKzoXYJM+dAFmWCrHKeewsOBViExd71AAjd10IsUYaDYdnsfty4Uz4U4g1zvClHAbm+e9CbJFlfdwKAVwWSJ0EfwixwrCIuYxPBOV5T1gLWCCtWj+4EqCoBbLsFyFhk2UPq9YPJqaCURW6W19IqPRdjCeG/dGsd+Xdbs/dToSERD8aDHrTP4zmvZsSBMXM4INo0afyTudY4vg39zIR4iNFXXfZtc9k4XJw0V9k2R1OFHkIhvVZdn1R8MHCDDDx+zqdxK0c9tz1szAjaKWc1XUTe+OV/iKWFmAcJ8NtJ8Kxe7kvkCGKEiHN45Zz3b/9yN3/uVzUGxXD+RX4F56985hsqA6SAAAAAElFTkSuQmCC",
       readyState: WalletReadyState.NotDetected,
       isAIP62Standard: true,
     }
     ```

  6. In type.ts, update the type AvailableWallets to include your wallet‚Äôs name.

     ```tsx filename="type.ts"
     export type AvailableWallets = "Nightly" | "Petra" | "T wallet" | "Your Wallet's Name";
     ```

  7. Update the [README file](https://github.com/aptos-labs/aptos-wallet-adapter/blob/main/README.md) at the top-level of the aptos-wallet-adapter to include your wallet in the list of AIP-62 compatible wallets.

  8. Commit and push your changes to your fork.

     <Aside type="note">
       If you‚Äôve pushed your changes to your fork, a green button should appear at the top of the [`aptos-wallet-adapter`](https://github.com/aptos-labs/aptos-wallet-adapter) repo asking if you would like to create a pull request.
     </Aside>

  9. Follow the [CONTRIBUTING guide](https://github.com/aptos-labs/aptos-wallet-adapter/blob/main/CONTRIBUTING.md#creating-a-pull-request) to open a pull request for the  repo.
</Steps>

## Resources

- Wallet Adapter Demo App
  - [Live site](https://aptos-labs.github.io/aptos-wallet-adapter)
  - [Source code](https://github.com/aptos-labs/aptos-wallet-adapter/tree/main/apps/nextjs-example)
  - See [`standardWallet.ts`](https://github.com/aptos-labs/aptos-wallet-adapter/blob/main/apps/nextjs-example/src/utils/standardWallet.ts) for an example implementation of an AIP-62 compatible wallet-adapter plugin.
- [`wallet-standard`](https://github.com/aptos-labs/wallet-standard) source code.
- [`wallet-adapter-core`](https://github.com/aptos-labs/aptos-wallet-adapter/tree/main/packages/wallet-adapter-core) source code.
- [AIP-62 standard](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-62.md).

# Wallet Adapter for Dapp Builders

> Integrate Aptos wallets into your dapp using the React Provider and Context for seamless wallet connectivity

import { Aside, Steps } from '@astrojs/starlight/components';

Aptos provides a React `Provider` and `Context` for connecting Aptos wallets to your dapp. This `Provider` allows you to specify which Wallets you want to allow connections to. Then you can use the `Provider` to look up account information and sign transactions / messages.

This provides a standard interface for using all Aptos wallets, and allows new wallets to easily be supported just by updating your React Wallet Adapter dependency version.

## Using the React `Provider` and `Context`

<Steps>
  1. Install @aptos-labs/wallet-adapter-react.

     ```shellscript filename="Terminal"
     npm install @aptos-labs/wallet-adapter-react
     ```

     <details>
       <summary>
         <b>For versions prior to v4.0.0</b>
       </summary>

       ### (Optional) Install the plugins for any ‚ÄúLegacy Standard Compatible‚Äù Wallets you want to support from [this list](https://github.com/aptos-labs/aptos-wallet-adapter/blob/main/README.md#supported-wallet-packages).

       <Aside type="note">
         The more modern [AIP-62](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-62.md) wallets do NOT require installing a package - they work by default!
         The legacy standard required installing plugins manually.
       </Aside>

       For wallets that have not updated to using the AIP-62 standard, their plugins must be installed and passed in to the `Provider` manually.

       For example:

       ```shellscript filename="Terminal"
       npm i @okwallet/aptos-wallet-adapter
       ```

       ### In `App.tsx` or it‚Äôs equivalent, import the Aptos Wallet Adapter and any legacy Wallet plugins.

       ```tsx filename="App.tsx"
       import { AptosWalletAdapterProvider } from "@aptos-labs/wallet-adapter-react";
       // Import any additional wallet plugins. Ex.
       import { OKXWallet } from "@okwallet/aptos-wallet-adapter";
       // ...
       ```
     </details>

  2. Initialize the AptosWalletAdapterProvider.

     You can use any of the following optional fields.

     It is recommended to:

     1. Set `autoConnect` to `true`.
     2. Set the `dappConfig` with:

     - The `network` property set to the network your dapp works with
     - The `aptosApiKeys` property set to the generated Api Key for the specified network

     | Field         | Description                                                                                                                                                                                                                               | Example                                                                  |
     | ------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------ |
     | `autoConnect` | A prop indicates whether the dapp should auto connect with the most recently connected wallet on page reload.                                                                                                                             | `true`                                                                   |
     | `dappConfig`  | Specify an alternate network to work on. This prop only works for wallets which are NOT chrome extensions. If set, this object must include the name of the network the app is connected to. The object may include a aptosConnectDappId. | `{ network: 'mainnet', aptosApiKeys:{}, aptosConnectDappId: undefined }` |
     | `onError`     | A callback function to fire when the adapter throws an error.                                                                                                                                                                             | `(error) => { console.log("error", error); }`                            |

     #### Full Example

     ```tsx filename="App.tsx"
     import { AptosWalletAdapterProvider } from "@aptos-labs/wallet-adapter-react";
     import { PropsWithChildren } from "react";
     import { Network } from "@aptos-labs/ts-sdk";

     export const WalletProvider = ({ children }: PropsWithChildren) => {

       return (
         <AptosWalletAdapterProvider
           autoConnect={true}
           dappConfig={{ 
             network: Network.MAINNET, 
             aptosApiKeys: {
               mainnet: process.env.APTOS_API_KEY_MAINNET,
             } 
           }}
           onError={(error) => {
             console.log("error", error);
           }}
         >
           {children}
         </AptosWalletAdapterProvider>
       );
     };
     ```

  3. Import useWallet in files where you want to access data from the Provider.

     ```tsx filename="Example.tsx"
     import { useWallet } from "@aptos-labs/wallet-adapter-react";

     // Access fields / functions from the adapter
     const { account, connected, wallet, changeNetwork } = useWallet();
     ```
</Steps>

# Choose a UI Package

The [Wallet Adapter repository](https://github.com/aptos-labs/aptos-wallet-adapter) provides several UI packages to simplify allowing users to connect and select a wallet.

For UI components that work out of the box, but are less customizable, choose one of:

- [Ant Design](https://github.com/aptos-labs/aptos-wallet-adapter/tree/main/packages/wallet-adapter-ant-design)
- [MUI](https://github.com/aptos-labs/aptos-wallet-adapter/tree/main/packages/wallet-adapter-mui-design) (Material UI)

Otherwise, you should use the [shadcn/ui wallet selector](https://github.com/aptos-labs/aptos-wallet-adapter/blob/main/apps/nextjs-example/README.md#use-shadcnui-wallet-selector-for-your-own-app), as it has the most customization options. For more details on how to customize this wallet selector or build your own wallet selector, see [this guide](https://github.com/aptos-labs/aptos-wallet-adapter/blob/main/packages/wallet-adapter-react/docs/BYO-wallet-selector.md).

<Aside type="note">
  For an example that shows how these UI options work in practice, see the [live demo app](https://aptos-labs.github.io/aptos-wallet-adapter/) (you can find its reference code [here](https://github.com/aptos-labs/aptos-wallet-adapter/tree/main/apps/nextjs-example)).
</Aside>

## `useWallet` Fields and Functions

### Fields

| Field       | Type                                                                                                                               | Description                                                                                                                                         |
| ----------- | ---------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------- |
| `connected` | `boolean`                                                                                                                          | Indicates if the wallet is currently connected.                                                                                                     |
| `isLoading` | `boolean`                                                                                                                          | Indicates if a wallet operation is currently loading.                                                                                               |
| `account`   | `{ address: string; publicKey: string \| string[]; minKeysRequired?: number; ansName?: string \| null; } \| null`                  | Current account info or null if no account is connected.                                                                                            |
| `network`   | `{ name: Network; chainId?: string; url?: string; } \| null`                                                                       | Current network info or null if no network is selected.                                                                                             |
| `wallet`    | `{ name: WalletName; icon: string; url: string; } \| null`                                                                         | Current wallet info or null if no wallet is selected. Includes wallet name, icon, and URL.                                                          |
| `wallets`   | `ReadonlyArray<{ name: WalletName; url: string; icon: string; readyState: WalletReadyState.NotDetected; isAIP62Standard: true; }>` | List of available wallets, including standard supported ones, each with name, URL, icon, readiness state, and AIP62 standard compliance indication. |

### Functions

_See [`WalletCore.ts`](https://github.com/aptos-labs/aptos-wallet-adapter/blob/main/packages/wallet-adapter-core/src/WalletCore.ts) in [`wallet-adapter-core`](https://github.com/aptos-labs/aptos-wallet-adapter/tree/main/packages/wallet-adapter-core) for where these functions are implemented._

| Function                   | Signature                                                                                                                                                                              | Description                                                                       |
| -------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------- |
| `connect`                  | `connect(walletName: WalletName): void`                                                                                                                                                | Connects to the specified wallet by its name.                                     |
| `disconnect`               | `disconnect(): void`                                                                                                                                                                   | Disconnects the currently connected wallet.                                       |
| `signTransaction`          | `signTransaction(transactionOrPayload: AnyRawTransaction \| Types.TransactionPayload, asFeePayer?: boolean, options?: InputGenerateTransactionOptions): Promise<AccountAuthenticator>` | Signs a transaction with optional parameters for fee payment.                     |
| `submitTransaction`        | `submitTransaction(transaction: InputSubmitTransactionData): Promise<PendingTransactionResponse>`                                                                                      | Submits a transaction with the provided transaction data.                         |
| `signAndSubmitTransaction` | `signAndSubmitTransaction(transaction: InputTransactionData): Promise<any>`                                                                                                            | Signs and submits a transaction with the given input data.                        |
| `signMessage`              | `signMessage(message: SignMessagePayload): Promise<SignMessageResponse>`                                                                                                               | Signs a message and returns the signature and other response info.                |
| `signMessageAndVerify`     | `signMessageAndVerify(message: SignMessagePayload): Promise<boolean>`                                                                                                                  | Signs a message and verifies the signer.                                          |
| `changeNetwork`            | `changeNetwork(network: Network): Promise<AptosChangeNetworkOutput>`                                                                                                                   | Requests a change in the connected network. This is not supported by all wallets. |

## Code Examples

See the next.js example dapp for a demonstration of how these components are used in practice:

- [Live site](https://aptos-labs.github.io/aptos-wallet-adapter/)
- [Source code](https://github.com/aptos-labs/aptos-wallet-adapter/tree/main/apps/nextjs-example)

### `wallets`

`wallets` is a list of available wallets, including standard supported ones, each with name, URL, icon, readiness state, and AIP62 standard compliance indication.

```tsx filename="WalletDisplayDemo.tsx"
import { useWallet } from '@aptos-labs/wallet-adapter-react';

const displayInstalledWalletsDemo = () => {

  const { wallets } = useWallet();
  
  return (
    <div>
      {wallets.map(wallet => {
        return <p>{wallet.name}</p>
      })}
    </div>
  )
}
```

#### Support for Uninstalled Wallets

Following AIP-62, the adapter uses an event-based communication model between a wallet and a dapp. This means only wallets installed in the user's browser are detected automatically and available for use.
To support the full Aptos wallet ecosystem, the adapter maintains a registry of supported wallets‚Äîallowing dapps to also display uninstalled wallets. It also exposes a utility function to easily manage all wallets.

```tsx filename="WalletDisplayDemo.tsx"
import { useWallet, groupAndSortWallets } from '@aptos-labs/wallet-adapter-react';

const displayAllWalletsDemo = () => {

  const { wallets = [], notDetectedWallets = [] } = useWallet();

  const { aptosConnectWallets, availableWallets, installableWallets } =
    groupAndSortWallets(
      [...wallets, ...notDetectedWallets] 
    );
  
  return (
    <div>
      /** Wallets that use social login to create an account on the blockchain */
      {aptosConnectWallets.map((aptosConnectwallet) => (
        return <p>{aptosConnectwallet.name}</p>
      ))}
      /** Wallets that are currently installed or loadable. */
      {availableWallets.map((availableWallet) => (
        return <p>{availableWallet.name}</p>
      ))}
      /** Wallets that are NOT currently installed or loadable. */
      {installableWallets.map((installableWallet) => (
        return <p>{installableWallet.name}</p>
      ))}
    </div>
  )
}
```

### `connect()` and `disconnect()`

`connect()` establishes a connection between the dapp and a Wallet. You can then use `disconnect()` to

```tsx filename="WalletConnectDemo.tsx"
import React from 'react';
import { WalletName, useWallet } from '@aptos-labs/wallet-adapter-react';

const WalletConnectDemo = () => {
  const { connect, disconnect, account, connected } = useWallet();

  const handleConnect = async () => {
    try {
      // Change below to the desired wallet name instead of "Petra"
      await connect("Petra" as WalletName<"Petra">); 
      console.log('Connected to wallet:', account);
    } catch (error) {
      console.error('Failed to connect to wallet:', error);
    }
  };

  const handleDisconnect = async () => {
    try {
      await disconnect();
      console.log('Disconnected from wallet');
    } catch (error) {
      console.error('Failed to disconnect from wallet:', error);
    }
  };

  return (
    <div>
      <h1>Aptos Wallet Connection</h1>
      <div>
        {connected ? (
          <div>
            <p>Connected to: {account?.address}</p>
            <button onClick={handleDisconnect}>Disconnect</button>
          </div>
        ) : (
          <button onClick={handleConnect}>Connect Wallet</button>
        )}
      </div>
    </div>
  );
};

export default WalletConnectDemo;
```

### `signAndSubmitTransaction`

If you would like to separate out these steps, you can use `signTransaction` and `submitTransaction` separately instead.

```tsx filename="SignAndSubmitDemo.tsx"
import React from 'react';
import { useWallet } from '@aptos-labs/wallet-adapter-react'; 
import { Aptos, AptosConfig, Network } from '@aptos-labs/ts-sdk';

const config = new AptosConfig({ network: Network.MAINNET });
const aptos = new Aptos(config);

const SignAndSubmit = () => {
  const { account, signAndSubmitTransaction } = useWallet();

  const onSignAndSubmitTransaction = async () => {
    if(account == null) {
        throw new Error("Unable to find account to sign transaction")
    }
    const response = await signAndSubmitTransaction({
      sender: account.address,
      data: {
        function: "0x1::aptos_account::transfer",
        functionArguments: [account.address, 1],
      },
    });
    // if you want to wait for transaction
    try {
      await aptos.waitForTransaction({ transactionHash: response.hash });
    } catch (error) {
      console.error(error);
    }
  };

  return (
    <button onClick={onSignAndSubmitTransaction}>
      Sign and submit transaction
    </button>
  );
};

export default SignAndSubmit;
```

`signMessage` and `verifyMessage`

You can also use the shorthand `signAndVerifyMessage` to create a message which can be verifiably from the connected wallet.

```tsx filename="SignMessageDemo.tsx"
import React, { useState } from 'react';
import { useWallet } from '@aptos-labs/wallet-adapter-react';

const SignMessageDemo = () => {
  const { signMessage, signMessageAndVerify, connected, account } = useWallet();
  const [message, setMessage] = useState<string>('');
  const [nonce, setNonce] = useState<string>('');
  const [signedMessage, setSignedMessage] = useState<any>(null);
  const [verificationResult, setVerificationResult] = useState<boolean | null>(null);
  const [error, setError] = useState<string | null>(null);

  const handleSignMessage = async () => {
    setError(null);
    try {
      const response = await signMessage({ message, nonce });
      setSignedMessage(response);
    } catch (err: any) {
      setError(`Failed to sign message: ${err.message}`);
    }
  };

  const handleVerifyMessage = async () => {
    setError(null);
    try {
      const result = await signMessageAndVerify({ message, nonce });
      setVerificationResult(result);
    } catch (err: any) {
      setError(`Failed to verify message: ${err.message}`);
    }
  };

  return (
    <div>
      <h1>Aptos Sign and Verify Message</h1>
      <div>
        {connected ? (
          <div>
            <p>Connected to: {account?.address}</p>
            <div className="flex flex-col gap-4">
              <textarea
                value={message}
                onChange={(e) => setMessage(e.target.value)}
                placeholder="Enter your message here"
                className="border rounded p-2"
              />
              <input
                type="text"
                value={nonce}
                onChange={(e) => setNonce(e.target.value)}
                placeholder="Enter nonce (random string) here"
                className="border rounded p-2 mt-2"
              />
              <button onClick={handleSignMessage} className="bg-blue-500 text-white rounded p-2 mt-2">
                Sign Message
              </button>
              {signedMessage && (
                <div>
                  <h4>Signed Message</h4>
                  <pre>{JSON.stringify(signedMessage, null, 2)}</pre>
                  <button onClick={handleVerifyMessage} className="bg-green-500 text-white rounded p-2 mt-2">
                    Verify Message
                  </button>
                </div>
              )}
              {verificationResult !== null && (
                <div>
                  <h4>Verification Result</h4>
                  <p>{verificationResult ? 'Message is verified!' : 'Failed to verify message.'}</p>
                </div>
              )}
              {error && (
                <div className="text-red-600">
                  <p>{error}</p>
                </div>
              )}
            </div>
          </div>
        ) : (
          <p>Please connect your wallet to sign and verify messages.</p>
        )}
      </div>
    </div>
  );
};

export default SignMessageDemo;
```

### `changeNetwork` (Not supported by all wallets)

Some wallets only support mainnet, so they will not support `changeNetwork`. If you are relying on this feature, ensure that you implement error handling for if a wallet that does not support `changeNetwork`. [Nightly](https://chromewebstore.google.com/detail/nightly/fiikommddbeccaoicoejoniammnalkfa?hl=en) is an example of a wallet which **does** support `changeNetwork`.

```tsx filename="ChangeNetworkDemo.tsx"
import React from 'react';
import { useWallet } from '@aptos-labs/wallet-adapter-react';
import { Network } from '@aptos-labs/ts-sdk';

const ChangeNetworkDemo = () => {
  const { network, changeNetwork, wallet } = useWallet();
  const isNetworkChangeSupported = wallet?.name === "Nightly";

  const isValidNetworkName = () => {
    return network && Object.values<string>(Network).includes(network.name);
  };

  return (
    <div>
      <h4>Network Info</h4>
      <div>
        <div><strong>Network name</strong></div>
        <div>
          <span style={{ color: isValidNetworkName() ? 'green' : 'red' }}>
            {network?.name ?? 'Not Present'}
          </span>
          {` (Expected: ${Object.values<string>(Network).join(', ')})`}
        </div>
        <div><strong>URL</strong></div>
        <div>
          {network?.url ? (
            <a href={network.url} target="_blank" rel="noreferrer">
              {network.url}
            </a>
          ) : (
            'Not Present'
          )}
        </div>
        <div><strong>Chain ID</strong></div>
        <div>{network?.chainId ?? 'Not Present'}</div>
      </div>
      <div>
        <h4>Change Network</h4>
        <div>
          <label>
            <input
              type="radio"
              name="network"
              value={Network.DEVNET}
              checked={network?.name === Network.DEVNET}
              onChange={() => changeNetwork(Network.DEVNET)}
              disabled={!isNetworkChangeSupported}
            />
            Devnet
          </label>
          <label>
            <input
              type="radio"
              name="network"
              value={Network.TESTNET}
              checked={network?.name === Network.TESTNET}
              onChange={() => changeNetwork(Network.TESTNET)}
              disabled={!isNetworkChangeSupported}
            />
            Testnet
          </label>
          <label>
            <input
              type="radio"
              name="network"
              value={Network.MAINNET}
              checked={network?.name === Network.MAINNET}
              onChange={() => changeNetwork(Network.MAINNET)}
              disabled={!isNetworkChangeSupported}
            />
            Mainnet
          </label>
        </div>
        {!isNetworkChangeSupported && (
          <div>
            * {wallet?.name ?? 'This wallet'} does not support network change requests
          </div>
        )}
      </div>
    </div>
  );
};

export default ChangeNetworkDemo;
```

### `signAndSubmitBCSTransaction(payload)` (Not supported by all wallets)

<Aside type="caution">
  This feature is not part of the AIP-62 standard, so it will not be supported by all Wallets. Verify with error handling before calling it.
</Aside>

This is similar to the `signAndSubmit` logic, but uses a BCS format for the transaction `data`.

```tsx filename="SignAndSubmitBCSTransactionDemo.tsx"
const onSignAndSubmitBCSTransaction = async () => {
  const response = await signAndSubmitTransaction({
    sender: account.address,
    data: {
      function: "0x1::aptos_account::transfer",
      functionArguments: [AccountAddress.from(account.address), new U64(1)],
    },
  });
  // if you want to wait for transaction
  try {
    await aptos.waitForTransaction({ transactionHash: response.hash });
  } catch (error) {
    console.error(error);
  }
};

<button onClick={onSignAndSubmitTransaction}>
  Sign and submit BCS transaction
</button>;
```

## Mobile support

Since Chrome extensions are not supported in mobile browsers by default, the adapter maintains a `registry` of undetected wallets, including a `deeplinkProvider` property for wallets that support deep linking.
This allows the dapp to display wallets that aren‚Äôt detectable in a mobile browser view but can still be connected to by redirecting the user to an in-app browser view.

```tsx filename="registry.tsx"
{
  name: "Petra",
  url: "https://chromewebstore.google.com/detail/petra-aptos-wallet/ejjladinnckdgjemekebdpeokbikhfci?hl=en",
  icon: "data:image/png;base64,iVBOR...QmCC",
  readyState: WalletReadyState.NotDetected,
  isAIP62Standard: true,
  deeplinkProvider: "https://petra.app/explore?link=",
}
```

To render wallets with `deeplinkProvider` support in your dapp‚Äîassuming you're not using the official adapter wallet selector UI‚Äîfollow these steps:

<Steps>
  1. Retrieve all compatible wallets and group them by wallet type

     ```tsx filename="WalletDisplayDemo.tsx"
     import { useWallet, groupAndSortWallets } from '@aptos-labs/wallet-adapter-react';

     const displayAllWalletsDemo = () => {

       const { wallets = [], notDetectedWallets = [] } = useWallet();

       const { aptosConnectWallets, availableWallets, installableWallets } =
         groupAndSortWallets(
           [...wallets, ...notDetectedWallets] 
         );
       
       return (
         <div>
           /** Wallets that use social login to create an account on the blockchain */
           {aptosConnectWallets.map((aptosConnectwallet) => (
             <WalletItemComponent wallet={aptosConnectwallet}/>
           ))}
           /** Wallets that are currently installed or loadable. */
           {availableWallets.map((availableWallet) => (
             <WalletItemComponent wallet={availableWallets}/>
           ))}
           /** Wallets that are NOT currently installed or loadable. */
           {installableWallets.map((installableWallet) => (
             <WalletItemComponent wallet={installableWallets}/>
           ))}
         </div>
       )
     }
     ```

     This code snippet retrieves all wallets in the Aptos ecosystem that are supported by the wallet adapter.

  2. Display uninstalled wallets with deep link support in mobile view.

     To ensure we display only wallets that support deep linking on mobile, we can check both for `deepLinkProvider` support and the current view type.

     In the component that renders each wallet:

     ```tsx filename="WalletItemComponent.tsx"
     import { useWallet, WalletReadyState } from '@aptos-labs/wallet-adapter-react';

     const WalletItemComponent = (wallet) => {

       const { connect } = useWallet();

       // On mobile, extension wallets will never have a state of `Installed`
       const isWalletReady = wallet.readyState === WalletReadyState.Installed;

       // Check if the wallet supports mobile deep linking.
       const mobileSupport =
         "deeplinkProvider" in wallet && wallet.deeplinkProvider;

       // If the wallet is not installed, the user is in a redirectable view (i.e., mobile browser but not an in-app browser), 
       // and the wallet does not support deep linking‚Äîdo not display the wallet.
       if (!isWalletReady && isRedirectable() && !mobileSupport) return null;

       // Otherwise, display the wallet
       return (
         <Button onClick={connect(wallet)}>{wallet.name}</Button>
       )
     }
     ```

     This code snippet ensures that the correct `wallet` object is displayed in the appropriate view.
</Steps>

# Aptos Wallet Standard

> Guidelines for wallet interoperability ensuring consistent dapp integration across all Aptos wallet types

import { Aside } from '@astrojs/starlight/components';

{/* TODO: Consolidate with wallet adapter */}

The wallet standard provides guidelines for interoperability between wallet
types. This ensures dapp developers do not need to change their applications to
handle different wallets. This standard offers a single interface for all dapp
developers, allowing easy additions of new wallets and more users to each
application. This interoperability allows users to choose which wallet they want
without worrying about whether apps support their use cases.

In order to ensure interoperability across Aptos wallets, the following is
required:

1. Mnemonics - a set of words that can be used to derive account private keys
2. dapp API - entry points into the wallet to support access to identity managed
   by the wallet
3. Key rotation - the feature handling both the relationship around mnemonics
   and the recovery of accounts in different wallets

## Mnemonics phrases

A mnemonic phrase is a multiple word phrase that can be used to generate account
addresses. We recommend one mnemonic per account in order to handle key rotation
better. However, some wallets may want to support one mnemonic to many accounts
coming from other chains. To support both of these use cases, the Aptos wallet
standard uses a [Bitcoin Improvement Proposal (BIP44)](https://github.com/bitcoin/bips/blob/master/bip-0044.mediawiki) to derive path for
mnemonics to accounts.

### Creating an Aptos account

Aptos account creation can be supported across wallets in the following manner:

1. Generate a mnemonic phrase, for example with BIP39.
2. Get the master seed from that mnemonic phrase.
3. Use the BIP44-derived path to retrieve an account address (e.g. `m/44'/637'/0'/0'/0'`)

- See the [Aptos TypeScript SDK's implementation for the derive path](https://github.com/aptos-labs/aptos-ts-sdk/blob/main/src/account/Account.ts#L181-L202)
- For example, Petra Wallet always uses the path `m/44'/637'/0'/0'/0'` since
  there is one mnemonic per one account.

```typescript
/**
  * Creates new account with bip44 path and mnemonics,
  * @param path. (e.g. m/44'/637'/0'/0'/0')
  * Detailed description: {@link https://github.com/bitcoin/bips/blob/master/bip-0044.mediawiki}
  * @param mnemonics.
  * @returns AptosAccount
  */
  static fromDerivePath(path: string, mnemonics: string): AptosAccount {
   if (!AptosAccount.isValidPath(path)) {
     throw new Error("Invalid derivation path");
   }

   const normalizeMnemonics = mnemonics
     .trim()
     .split(/\s+/)
     .map((part) => part.toLowerCase())
     .join(" ");

   const { key } = derivePath(path, bytesToHex(bip39.mnemonicToSeedSync(normalizeMnemonics)));

   return new AptosAccount(new Uint8Array(key));
}
```

### Supporting one mnemonic per multiple account wallets

This is not recommended because the one-mnemonic-to-many-accounts paradigm makes
it harder to handle rotated keys (the mnemonic changes for one account but not
others). However, many wallets from other ecosystems use this paradigm, and take
these steps to generate accounts

1. Generate a mnemonic phrase, for example with BIP39.
2. Get the master seed from that mnemonic phrase.
3. Use the BIP44-derived path to retrieve private keys (e.g. `m/44'/637'/i'/0'/0'`)
   where `i` is the account index.

- See the [Aptos TypeScript SDK's implementation for the derive path](https://github.com/aptos-labs/aptos-core/blob/1bc5fd1f5eeaebd2ef291ac741c0f5d6f75ddaef/ecosystem/typescript/sdk/src/aptos_account.ts#L49-L69)

4. Increase `i` until all the accounts the user wants to import are found.

- Note: The iteration should be limited, if an account doesn't exist during
  iteration, keep iterating for a constant `address_gap_limit` (10 for now) to see
  if there are any other accounts. If an account is found we will continue to
  iterate as normal.

i.e.

```typescript
const gapLimit = 10;
let currentGap = 0;

for (let i = 0; currentGap < gapLimit; i += 1) {
  const derivationPath = `m/44'/637'/${i}'/0'/0'`;
  const account = fromDerivePath(derivationPath, mnemonic);
  const response = account.getResources();
  if (response.status !== 404) {
    wallet.addAccount(account);
    currentGap = 0;
  } else {
    currentGap += 1;
  }
}
```

## Wallet and dapp communication

More important than account creation, is how wallets and dapps communicate.

[Following AIP-62](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-62.md), the Wallet standard defines an API for wallet and application interactions.

### Wallet Interface Standard

A wallet must implement a [AptosWallet interface](https://github.com/aptos-labs/wallet-standard/blob/main/src/wallet.ts) with the wallet provider info and features:

```typescript
class MyWallet implements AptosWallet {
  url: string;
  version: "1.0.0";
  name: string;
  icon:
    | `data:image/svg+xml;base64,${string}`
    | `data:image/webp;base64,${string}`
    | `data:image/png;base64,${string}`
    | `data:image/gif;base64,${string}`;
  chains: AptosChain;
  features: AptosFeatures;
  accounts: readonly AptosWalletAccount[];
}
```

A wallet must implement a [AptosWalletAccount interface](https://github.com/aptos-labs/wallet-standard/blob/main/src/account.ts) that represents the accounts that have been authorized by the dapp.

```typescript
enum AptosAccountVariant {
  Ed25519,
  MultiEd25519,
  SingleKey,
  MultiKey,
}

class AptosWalletAccount implements WalletAccount {
  address: string;

  publicKey: Uint8Array;

  chains: AptosChain;

  features: AptosFeatures;

  variant: AptosAccountVariant;

  label?: string;

  icon?:
    | `data:image/svg+xml;base64,${string}`
    | `data:image/webp;base64,${string}`
    | `data:image/png;base64,${string}`
    | `data:image/gif;base64,${string}`
    | undefined;
}
```

If the wallet is a web extension wallet (i.e installed through the chrome extension store), the wallet must register itself using the [registerWallet](https://github.com/wallet-standard/wallet-standard/blob/master/packages/core/wallet/src/register.ts#L25) method to notify the dapp it is ready to be used.

```typescript
const myWallet = new MyWallet();

registerWallet(myWallet);
```

A wallet is considered a valid Aptos wallet if it implements the standard [required features](https://github.com/aptos-labs/wallet-standard/blob/main/src/detect.ts#L16).

A wallet must throw a [AptosWalletError](https://github.com/aptos-labs/wallet-standard/blob/main/src/errors.ts). The standard requires to support `Unauthorized` and `InternalError` but a wallet can throw a custom `AptosWalletError` error

```typescript
// Using the default message
if (error) {
  throw new AptosWalletError(AptosWalletErrorCode.Unauthorized);
}
// Using a custom message
if (error) {
  throw new AptosWalletError(
    AptosWalletErrorCode.Unauthorized,
    "My custom unauthorized message"
  );
}
// Using a custom error
if (error) {
  throw new AptosWalletError(-32000, "Invalid Input");
}
```

### Dapp API

<Aside type="note">
  For a dapp to easily integrate with a wallet, it encouraged to use the [Aptos Wallet Adapter Standard](/build/sdks/wallet-adapter).
</Aside>

If for some reason, a dapp decides to implement a custom wallet integration:

A dapp uses the [getAptosWallets()](https://github.com/aptos-labs/wallet-standard/blob/main/src/detect.ts#L40) function which gets all the Aptos standard compatible wallets.

```typescript
import { getAptosWallets } from "@aptos-labs/wallet-standard";

let { aptosWallets, on } = getAptosWallets();
```

On first load, and before the dapp has been loaded, it gets all the wallets that have been registered so far. To keep getting all the registered wallets after this point, the dapp must add an event listener for new wallets that get registered receiving an unsubscribe function, which it can later use to remove the listener.

```typescript
const removeRegisterListener = on("register", function () {
  // The dapp can add new aptos wallets to its own state context as they are registered
  let { aptosWallets } = getAptosWallets();
});

const removeUnregisterListener = on("unregister", function () {
  let { aptosWallets } = getAptosWallets();
});
```

The dapp has an event listener now, so it sees new wallets immediately and doesn't need to poll or list them again. This also works if the dapp loads before any wallets (it will initialize, see no wallets, then see wallets as they load)

A dapp makes a wallet request by calling the feature name that corresponds to the desired action. For example, to use the `connect` feature:

```typescript
const onConnect = () => {
  this.wallet.features["aptos:connect"].connect();
};
```

## Key rotation

Key rotation is currently not implemented in any wallets. Mapping of rotated
keys has been [implemented](https://github.com/aptos-labs/aptos-core/pull/2972), but SDK integration is in progress.

Wallets that import a private key will have to do the following:

1. Derive the authentication key.
2. Lookup the authentication key on-chain in the Account origination table.

- If the account doesn't exist, it's a new account. The address to be used is
  the authentication key.
- If the account does exist, it's a rotated key account, and the address to be
  used will come from the table.

# Wallet Adapter Plugin for SDK Wallet Builders

> Create wallet adapter plugins for SDK wallets to enable dapp integration through the AIP-62 wallet standard

import { Aside, Steps } from '@astrojs/starlight/components';

A wallet adapter plugin allows dapps to use your wallet. With the AIP-62 Wallet standard, dapps can simply update their version of `aptos-wallet-adapter` to connect to newly added Wallet plugins.

Implementing a wallet plugin for an SDK wallet which can be imported via npm has three main steps:

1. Implement a wallet adapter plugin for your SDK wallet.
2. Publish your plugin on npm.
3. Update the `aptos-wallet-adapter` package to let dapps know about your wallet.

## 1. Implement the Wallet Adapter Plugin.

You can use the [`wallet-standard`](https://github.com/aptos-labs/wallet-standard) repo‚Äôs example to implement an [AIP-62](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-62.md) compatible wallet adapter plugin that dapps can automatically recognize.

<Aside type="note">
  For an example of how to implement the Wallet Adapter plugin, see the [Wallet Adapter Demo dapp](https://github.com/aptos-labs/aptos-wallet-adapter/tree/main/apps/nextjs-example). Specifically, [`standardWallet.ts`](https://github.com/aptos-labs/aptos-wallet-adapter/blob/main/apps/nextjs-example/src/utils/standardWallet.ts) contains the plugin implementation, and [`page.tsx`](https://github.com/aptos-labs/aptos-wallet-adapter/blob/main/apps/nextjs-example/src/app/page.tsx) has the React components.
</Aside>

<Steps>
  1. Create a new typescript repository.

  2. Copy the  into that new repo.

  3. Follow the instructions in that example to make it use your wallet to execute the AIP-62 functions.

     <Aside type="note">
       The full list of required functions for AIP-62 compatible wallets can be found [here](https://github.com/aptos-labs/wallet-standard/blob/38defe159b8641ff1763c4db61827c78ab448dab/src/detect.ts#L16).
     </Aside>
</Steps>

## Test your changes by:

<Steps>
  1. Clone the  repository.

  2. Navigate to  in the example dapp.

  3. Replace  with your implementation of the AIP-62 standard.

     1. You will have to update the import in [`aptos-wallet-adapter/apps/nextjs-example/src/app/page.tsx`](https://github.com/aptos-labs/aptos-wallet-adapter/blob/main/apps/nextjs-example/src/app/page.tsx) to use your Wallet instead of `MyWallet`.
     2. For local testing purposes, you can leave the `registerWallet` code, but SDK wallets do not need that once they have been added to the `aptos-wallet-standard` core package.

  4. Run a local version of the dapp by following the instructions in the .

  5. Click ‚ÄúConnect a Wallet‚Äù

     You should see your wallet on the list of connections.

  6. Connect to your wallet.

     1. You can then use the demo dapp features to verify your other wallet features work as expected.
     2. This simulates how a real dapp will interact with your wallet.
</Steps>

## 2. Once tested, publish a new npm package for your SDK wallet code by following [this guide](https://docs.npmjs.com/creating-and-publishing-scoped-public-packages). (Ex. [AptosConnect](https://www.npmjs.com/package/@aptos-connect/wallet-adapter-plugin))

## 3. Update [`wallet-adapter-core`](https://github.com/aptos-labs/aptos-wallet-adapter/tree/main/packages/wallet-adapter-core) to know about your extension.

In order for dapp users who are not already using your wallet to get the option to create an account with your wallet, you need to update [`wallet-adapter-core`](https://github.com/aptos-labs/aptos-wallet-adapter/tree/main/packages/wallet-adapter-core) with your browser extension‚Äôs download link.

<Steps>
  1. Fork the  monorepo. ()

  2. Open your fork in a local editor such as VSCode.

  3. Create a new branch for your changes.

     ```shellscript filename="Terminal"
     git checkout -b your-wallet
     ```

  4. Navigate to .

  5. Import your SDK wallet npm package.

     ```shellscript filename="Terminal"
     pnpm i @yourpackage
     ```

  6. Import your wallet in .

     For example with AptosConnect:

     ```tsx filename="Example.tsx"
     import { AptosConnectWallet } from "@aptos-connect/wallet-adapter-plugin";
     ```

  7. Add code to push an instance of your wallet to sdkWallets inside getSDKWallets (in sdkWallets.ts).

     ```tsx filename="Example.tsx"
     sdkWallets.push(new YourWallet(dappConfig));
     ```

     <Aside type="caution">
       Some wallets may have custom logic required to make sure the right wallet is connected when the user clicks to ‚Äúsign in‚Äù with your Wallet.

       Ex. T Wallet has different Wallet plugins for mainnet and devnet connections.
     </Aside>

  8. In type.ts, update the type AvailableWallets to include your wallet‚Äôs name.

     ```tsx filename="Example.tsx"
     export type AvailableWallets = "Nightly" | "Petra" | "T wallet" | "Your Wallet's Name";
     ```

  9. Update the  at the top-level of the aptos-wallet-adapter to include your wallet in the list of AIP-62 compatible wallets.

  10. Commit and push your changes to your fork.

      <Aside type="note">
        If you have pushed your changes to your fork, a green button should appear at the top of the [`aptos-wallet-adapter`](https://github.com/aptos-labs/aptos-wallet-adapter) repo asking if you would like to create a pull request.
      </Aside>

  11. Follow  to open a pull request for the  repo.

      <Aside type="note">
        Once the changes are merged, dapps that update their `aptos-wallet-adapter` package versions will now be able to see your Wallet.
      </Aside>
</Steps>

## Resources

- Wallet Adapter Demo App
  - [Live site](https://aptos-labs.github.io/aptos-wallet-adapter)
  - [Source code](https://github.com/aptos-labs/aptos-wallet-adapter/tree/main/apps/nextjs-example)
  - See [`standardWallet.ts`](https://github.com/aptos-labs/aptos-wallet-adapter/blob/main/apps/nextjs-example/src/utils/standardWallet.ts) for an example implementation of an AIP-62 compatible wallet-adapter plugin.
- [`wallet-standard`](https://github.com/aptos-labs/wallet-standard) source code.
- [`wallet-adapter-core`](https://github.com/aptos-labs/aptos-wallet-adapter/tree/main/packages/wallet-adapter-core) source code.
- [AIP-62 standard](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-62.md).

# X-Chain Accounts

> Enable cross-chain wallet integration on Aptos using Derivable Account Abstraction for seamless multi-chain user experiences

import { Aside, Steps, TabItem, Tabs } from '@astrojs/starlight/components';

<Aside type="note">
  The feature is currently only available on devnet and testnet and is considered an alpha version; therefore, you can expect breaking changes.
</Aside>

Thanks to [AIP-113 Derivable Account Abstraction](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-113.md), we can manage x-chain signatures flexibly and securely on the Aptos network.
This means that any wallet with an authentication function implementation on the Aptos chain can submit transactions to the Aptos network.

This functionality enables a variety of use cases for dApps, enhancing user experience and onboarding.

### High level flow

When a user enters a dApp that supports x-chain accounts, the interaction and experience feel the same as with any Aptos wallet.
The user connects with a x-chain account (e.g., Phantom for Solana) and can view their Derivable Abstracted Account (DAA) details, sign messages, and submit transactions to the Aptos chain.

When a dapp submits a transaction using a x-chain account, the wallet adapter utilizes the `signIn` function (defined in the x-chain account standard) for domain verification and security. If a specific wallet does not support the `signIn` method, the adapter falls back to using the default `signMessage`.
The wallet is requested to sign a message to submit a transaction on the Aptos network. Once the wallet approves the transaction, it is submitted to the Aptos chain, where it undergoes a signature verification process.

### How does DAA work in a x-chain account?

When a user connects to a dApp using the x-chain account adapter, the adapter computes the user's Derivable Abstracted Account (DAA) address and converts the x-chain account to follow the Aptos wallet standard interface.
This ensures a seamless interaction with the wallet for both developers and end users.

The computation of the DAA address is done using the `authenticationFunction` and the `accountIdentity`, both of which are defined in the wallet adapter:

- `authenticationFunction`: This is a function that exists on-chain and is used to verify the signature of the x-chain account.
- `accountIdentity`: This represents the identity of the account used in the on-chain authentication function to verify the signature of the x-chain account.
  In the Wallet Adapter, the `accountIdentity` is based on the original x-chain account's public key and the dApp domain (e.g., mydomain.com). The format is:
  `${originWalletAddress}${domain}`

<Aside type="note">
  Since the account identity is based on the dApp domain, it is scoped to the dApp context. As a result, each account has a different DAA address on different dApps.
</Aside>

### How to integrate x-chain accounts in my dApp?

Currently, the adapter supports Solana and EVM chains

<Aside type="note">
  It is highly recommended to use the `@aptos-labs/wallet-adapter-react` package for the best experience. Make sure you integrate with the Aptos Wallet Adapter by following these [steps](/build/sdks/wallet-adapter/dapp)
</Aside>

<Tabs>
  {/* Solana */}

  <TabItem label="Solana">
    The wallet adapter follows the [Solana Wallet Standard](https://github.com/wallet-standard/wallet-standard/blob/master/DESIGN.md) to discover wallets.
    Currently, the wallets that have been tested and support cross-chain accounts are:

    |          | Aptos Devnet | Aptos Testnet | Aptos Mainnet |
    | -------- | ------------ | ------------- | ------------- |
    | Phantom  | ‚úÖ            | ‚úÖ             |               |
    | Solflare | ‚úÖ            | ‚úÖ             |               |
    | Backpack | ‚úÖ            | ‚úÖ             |               |
    | OKX      | ‚úÖ            | ‚úÖ             |               |

    Supporting x-chain accounts in a dApp requires only a 2-step installation process.

    <Steps>
      1. Install the @aptos-labs/derived-wallet-solana package

         ```shellscript
         npm install @aptos-labs/derived-wallet-solana
         ```

      2. Import the setupAutomaticSolanaWalletDerivation function

         Once you have installed the `@aptos-labs/derived-wallet-solana` package, you can import and use it.
         In the same file where you import the other wallets, such as `WalletProvider.tsx`, you can add the following:

         ```tsx filename="WalletProvider.tsx"
         import { setupAutomaticSolanaWalletDerivation } from "@aptos-labs/derived-wallet-solana";

         setupAutomaticSolanaWalletDerivation({ defaultNetwork: Network.TESTNET }); // this is the Aptos network your dapp is working with

         ...

         <AptosWalletAdapterProvider
          dappConfig={{
             network: Network.TESTNET,
           }}
         >
           {children}
         <AptosWalletAdapterProvider/>
         ```

      3. Set crossChainWallets dapp config prop to true fot the AptosWalletAdapterProvider

         ```tsx filename="WalletProvider.tsx"
         <AptosWalletAdapterProvider
          dappConfig={{
             network: Network.TESTNET,
             crossChainWallets: true,
           }}
         >
           {children}
         <AptosWalletAdapterProvider/>
         ```
    </Steps>
  </TabItem>

  {/* EVM */}

  <TabItem label="EVM">
    The wallet adapter follows the [EIP-1193](https://eips.ethereum.org/EIPS/eip-1193) to discover wallets.
    Currently, the wallets that have been tested and support cross-chain accounts are:

    |          | Aptos Devnet | Aptos Testnet | Aptos Mainnet |
    | -------- | ------------ | ------------- | ------------- |
    | Metamask | ‚úÖ            | ‚úÖ             |               |
    | Phantom  | ‚úÖ            | ‚úÖ             |               |
    | Coinbase | ‚úÖ            | ‚úÖ             |               |
    | OKX      | ‚úÖ            | ‚úÖ             |               |
    | Exodus   | ‚úÖ            | ‚úÖ             |               |
    | Backpack | ‚úÖ            | ‚úÖ             |               |

    Supporting x-chain accounts in a dApp requires only a 2-step installation process.

    <Steps>
      1. Install the @aptos-labs/derived-wallet-ethereum package

         ```shellscript
         npm install @aptos-labs/derived-wallet-ethereum
         ```

      2. Import the setupAutomaticEthereumWalletDerivation function

         Once you have installed the `@aptos-labs/derived-wallet-ethereum` package, you can import and use it.
         In the same file where you import the other wallets, such as `WalletProvider.tsx`, you can add the following:

         ```tsx filename="WalletProvider.tsx"
         import { setupAutomaticEthereumWalletDerivation } from "@aptos-labs/derived-wallet-ethereum";

         setupAutomaticEthereumWalletDerivation({ defaultNetwork: Network.TESTNET }); // this is the Aptos network your dapp is working with

         ...

         <AptosWalletAdapterProvider
          dappConfig={{
             network: Network.TESTNET,
           }}
         >
           {children}
         <AptosWalletAdapterProvider/>
         ```

      3. Set crossChainWallets dapp config prop to true fot the AptosWalletAdapterProvider

         ```tsx filename="WalletProvider.tsx"
         <AptosWalletAdapterProvider
          dappConfig={{
             network: Network.TESTNET,
             crossChainWallets: true,
           }}
         >
           {children}
         <AptosWalletAdapterProvider/>
         ```
    </Steps>
  </TabItem>
</Tabs>

That will handle the logic and implementation to include the x-chain accounts as if they were Aptos wallets.

### Submitting a transaction

In most cases, allowing users to submit a transaction with a x-chain account to the Aptos chain requires using a sponsor transaction. This is because the x-chain account might not have APT to pay for gas.
Therefore, the dApp should consider maintaining a sponsor account to sponsor the transactions.

<Tabs>
  <TabItem label="Local Sponsor Account">
    ```tsx filename="SignAndSubmitDemo.tsx"
    import React from 'react';
    import { useWallet } from '@aptos-labs/wallet-adapter-react';
    import { Aptos, AptosConfig, Network, Ed25519PrivateKey, PrivateKey, PrivateKeyVariants, Account } from '@aptos-labs/ts-sdk';

    // Initialize an Aptos client
    const config = new AptosConfig({ network: Network.TESTNET });
    const aptos = new Aptos(config);

    // Generate a sponsor account or use an existing account
    const privateKey = new Ed25519PrivateKey(
      PrivateKey.formatPrivateKey(
        "0x123",
        PrivateKeyVariants.Ed25519
      )
    );
    const sponsor = Account.fromPrivateKey({ privateKey });

    const SignAndSubmit = () => {
      const { account, signTransaction } = useWallet();

      const onSignAndSubmitTransaction = async () => {
        if(!account) {
          throw new Error("Account is not connected and unable to sign transaction")
        }

        try {
          // Build the transaction
          const rawTransaction = await aptos.transaction.build.simple({
            data: {
              function: "0x1::aptos_account::transfer",
              functionArguments: [account.address.toString(), 1],
            },
            sender: account.address,
            withFeePayer: true,
          });

          // Send it to the wallet to sign
          const walletSignedTransaction = await signTransaction({
            transactionOrPayload: rawTransaction,
          });

          // Sponsor account signs the transaction to pay for the gas fees
          const sponsorAuthenticator = aptos.transaction.signAsFeePayer({
            signer: sponsor,
            transaction: rawTransaction,
          });

          // Submit the transaction to chain
          const txnSubmitted = await aptosClient(network).transaction.submit.simple(
            {
              transaction: rawTransaction,
              senderAuthenticator: walletSignedTransaction.authenticator,
              feePayerAuthenticator: sponsorAuthenticator,
            }
          );

          // if you want to wait for transaction
          await aptos.waitForTransaction({ transactionHash: txnSubmitted.hash });
        } catch (error) {
          console.error(error);
        }
      };

      return (
        <button onClick={onSignAndSubmitTransaction}>
          Sign and submit transaction
        </button>
      );
    };

    export default SignAndSubmit;
    ```
  </TabItem>

  <TabItem label="Gas Station">
    <Steps>
      1. Follow the [Gas Station docs](https://geomi.dev/docs/gas-stations) to set up a Gas Station service to obtain a gas station API key.

      2. Integrate a Gas Station instance in your application

         ```tsx filename="SignAndSubmitDemo.tsx"
           import {
             GasStationClient,
             GasStationTransactionSubmitter,
           } from "@aptos-labs/gas-station-client";
           import { Network } from "@aptos-labs/ts-sdk";

           const network = Network.TESTNET;
           const gasStationClient = new GasStationClient({
             network,
             apiKey: process.env.GAS_STATION_API_KEY,
           });
           const transactionSubmitter = new GasStationTransactionSubmitter(gasStationClient);
         ```

      3. Then, you can use the `transactionSubmitter` to sponsor only x-chain account transactions

         ```tsx filename="SignAndSubmitDemo.tsx"

         const { signAndSubmitTransaction, wallet } = useWallet();

         const transactionInput = {
           data: {
             function:"0x1::aptos_account::transfer",
             functionArguments: [account.address, 717],
           },
           sender: account.address,
           transactionSubmitter: null
         };

         // If wallet is NOT an Aptos native wallet
         if (!wallet.isAptosNativeWallet) {
           transactionInput.transactionSubmitter = transactionSubmitter;
         }

         const txn = await signAndSubmitTransaction(transactionInput);
         ```
    </Steps>
  </TabItem>
</Tabs>

### Considerations

- Since the origin wallet creates an x-chain account and is most likely not integrated with Aptos, simulation is not available in the wallet.
- While the x-chain account prioritizes DAA, each account also retains the origin wallet, so developers should be able to use it and interact with it

### Resources

- X-Chain Accounts Adapter Demo App
  - [Live site](https://aptos-labs.github.io/aptos-wallet-adapter/nextjs-cross-chain-example/)
  - [Source code](https://github.com/aptos-labs/aptos-wallet-adapter/tree/main/apps/nextjs-x-chain)
- [AIP-113 Derivable Account Abstraction](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-113.md)

# Smart Contracts

> Learn to write secure, efficient smart contracts on Aptos using the Move programming language with examples, tutorials, and developer resources

import { CardGrid, LinkCard } from '@astrojs/starlight/components';

import { RemoteCodeblock } from '~/components/RemoteCodeblock';

Aptos contracts are written using Move, a next generation language for secure, sandboxed, and formally verified programming which is used for multiple chains.
Move allows developers to write programs that flexibly manage and transfer assets while providing security and protections against attacks on those assets.

## üìñ Learn Move

<CardGrid>
  <LinkCard href="/build/smart-contracts/why-move" title="Why Move?" description="Learn why Aptos uses the Move Language" />

  <LinkCard href="/build/smart-contracts/create-package" title="Create Package" description="Get started by learning how to create a Move package" />

  <LinkCard href="/build/smart-contracts/objects" title="Objects" description="Learn how to use the Object standard on Aptos to create composable and flexible primitives on chain" />
</CardGrid>

## üë®‚Äçüíª Move Examples

<CardGrid>
  <LinkCard href="https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/move-examples" title="Aptos Move Examples" description="30+ examples on how to develop Move on Aptos" target="_blank" />

  <LinkCard href="https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/move-examples/move-tutorial" title="Move Tutorial" description="Covers the basics of programming with Move" target="_blank" />

  <LinkCard href="/build/guides/first-move-module" title="Your first Move Module" description="A  example of how to publish your first move module" />
</CardGrid>

Here is a `hello_blockchain` example of move

<RemoteCodeblock permalink="https://github.com/aptos-labs/aptos-core/blob/77e1d222ebc5e7294e115e0d090c001da1d0e072/aptos-move/move-examples/hello_blockchain/sources/hello_blockchain.move#L1-L59" />

## ‚öíÔ∏è Developer Resources

### FAQ and Discussions

- [Aptos Dev Discussions](https://github.com/aptos-labs/aptos-developer-discussions/discussions) for Q\&A about Move.

### Move IDE plugins

- Move on Aptos extension for [VSCode](https://marketplace.visualstudio.com/items?itemName=AptosLabs.move-on-aptos) and [OpenVSX](https://open-vsx.org/extension/aptoslabs/move-on-aptos).
- [Move language plugin for JetBrains IDEs](https://plugins.jetbrains.com/plugin/14721-move-language)

### External Resources

- [Aptos Move by Example](https://move-developers-dao.gitbook.io/aptos-move-by-example)
- [Teach yourself Move on Aptos](https://github.com/econia-labs/teach-yourself-move).
- [Formal Verification, the Move Language, and the Move Prover](https://www.certik.com/resources/blog/2wSOZ3mC55AB6CYol6Q2rP-formal-verification-the-move-language-and-the-move-prover)
- [Pontem Move Playground](https://playground.pontem.network/)
- [Collection of nestable Move resources](https://github.com/taoheorg/taohe)

We have a new Move on Aptos compiler that supports Move 2. See [this page](/build/smart-contracts/compiler_v2) for more information.

# Aptos Coin Standard (Legacy)

> Learn about aptos coin for Move smart contract development on Aptos blockchain.

import { Aside } from '@astrojs/starlight/components';

[Coin](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/coin.move)
provides a standard, type-safe framework for simple, fungible tokens or coins.

<Aside type="note">
  Coin is stored in `0x1::coin`.
</Aside>

## Structures

### Reusability

A coin is defined in Move as:

```move
module 0x1::coin {
  struct Coin<phantom CoinType> has store {
    /// Amount of coin this address has.
    value: u64,
  }
}
```

A Coin uses the `CoinType` to support re-usability of the Coin framework for
distinct Coins. For example, `Coin<A>` and `Coin<B>` are two distinct coins.

### Global store

Coin also supports a resource for storing coins in global store:

```move
module 0x1::coin {
  struct CoinStore<phantom CoinType> has key {
    coin: Coin<CoinType>,
    frozen: bool,
    deposit_events: EventHandle<DepositEvent>,
    withdraw_events: EventHandle<WithdrawEvent>,
  }
}
```

Coin information or metadata is stored in global store under the coin creators
account:

```move
module 0x1::coin {
  struct CoinInfo<phantom CoinType> has key {
    name: string::String,
    /// Symbol of the coin, usually a shorter version of the name.
    /// For example, Singapore Dollar is SGD.
    symbol: string::String,
    /// Number of decimals used to get its user representation.
    /// For example, if `decimals` equals `2`, a balance of `505` coins should
    /// be displayed to a user as `5.05` (`505 / 10 ** 2`).
    decimals: u8,
    /// Amount of this coin type in existence.
    supply: Option<OptionalAggregator>,
  }
}
```

## Primitives

Coin provides the primitives for users creating and managing the coin and the
users who use it.

### Creators

Coin creators and managers can:

- Initialize a coin and set its metadata and supply monitoring.
- Minting and burning Coin value.
- Burning coins from a `CoinStore`.
- Freezing mobility into and out of a `CoinStore`.

### Users

Coin users can:

- Merging two Coin structs of the same type.
- Extracting value from a Coin struct into a new Coin struct.
- Ability to deposit and withdraw from a `CoinStore` and emit events as a result.
- Allows for users to register a `CoinStore<CoinType>` in their account to
  handle coin.

### Coin module key struct

The following tables describe fields at the struct level. For the definitive list,
see the [Aptos Framework](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/doc/overview.md)
containing [`coin`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/doc/coin.md).

##### [`Coin`](https://github.com/aptos-labs/aptos-core/blob/744c2def47cddced878fda9bbd5633022fdb083a/aptos-move/framework/aptos-framework/sources/coin.move#L68)

| Field   | Type | Description                        |
| ------- | ---- | ---------------------------------- |
| `value` | u64  | Value of the token, eg: 1000000000 |

##### [`CoinInfo`](https://github.com/aptos-labs/aptos-core/blob/744c2def47cddced878fda9bbd5633022fdb083a/aptos-move/framework/aptos-framework/sources/coin.move#L92)

| Field      | Type                        | Description                                                                                                                      |
| ---------- | --------------------------- | -------------------------------------------------------------------------------------------------------------------------------- |
| `name`     | String                      | Name of the token, eg: Aptos Coin                                                                                                |
| `symbol`   | String                      | Symbol for the token, eg: APT                                                                                                    |
| `decimals` | u8                          | Determines how the value of coin is represented; for example APT‚Äôs decimal is 8, so a value of 100000000 is represented by 1 APT |
| `supply`   | Option\<OptionalAggregator> | option::some(optional\_aggregator::new(MAX\_U128, parallelizable))                                                               |

### Creating a new CoinType

A coin creator can publish to an on-chain account a new module that defines a
struct to represent a new `CoinType`. The coin creator will then call
`coin:initialize<CoinType>` from that account to register this as a valid coin,
and in return receive back structs that enable calling the functions to burn and
mint coins and freeze `CoinStore`s. These will need to be stored in global
storage by the creator to manage the use of the coin.

```move
module 0x1::coin {
  public fun initialize<CoinType>(
    account: &signer,
    name: string::String,
    symbol: string::String,
    decimals: u8,
    monitor_supply: bool,
  ): (BurnCapability<CoinType>, FreezeCapability<CoinType>, MintCapability<CoinType>) {
    // ...
  }
}
```

The creator has the opportunity to define a name, symbol, decimals, and whether
the total supply for the coin is monitored. The following applies:

- The first three of the above (`name`, `symbol`, `decimals`) are purely
  metadata and have no impact for on-chain applications. Some applications may use
  decimal to equate a single Coin from fractional coin.
- Monitoring supply (`monitor_supply`) helps track total coins in supply.
  However, due to the way the parallel executor works, turning on this option will
  prevent any parallel execution of mint and burn. If the coin will be regularly
  minted or burned, consider disabling `monitor_supply`.

### Minting Coins

If the creator or manager would like to mint coins, they must retrieve a
reference to their `MintCapability`, which was produced in the `initialize`,
and call:

```move
module 0x1::coin {
  public fun mint<CoinType>(
    amount: u64,
    _cap: &MintCapability<CoinType>,
  ): Coin<CoinType> acquires CoinInfo {
    // ...
  }
}
```

This will produce a new Coin struct containing a value as dictated by the
`amount`. If supply is tracked, then it will also be adjusted.

### Burning Coins

If the creator or manager would like to burn coins, they must retrieve a
reference to their `BurnCapability`, which was produced in the `initialize`, and
call:

```move
module 0x1::coin {
  public fun burn<CoinType>(
    coin: Coin<CoinType>,
    _cap: &BurnCapability<CoinType>,
  ) acquires CoinInfo {
    // ...
  }
}
```

The creator or manager can also burn coins from a `CoinStore`:

```move
module 0x1::coin {
  public fun burn_from<CoinType>(
    account_addr: address,
    amount: u64,
    burn_cap: &BurnCapability<CoinType>,
  ) acquires CoinInfo, CoinStore {
   // ...
  }
}
```

<Aside type="note">
  ### burn vs burn\_from

  The function `burn` eliminates the total value stored in the coin, while
  `burn_from` only eliminates a given amount of value from a `CoinStore`. If
  supply is tracked, then it will also be adjusted.

  Burning coins from an account does not emit a `WithdrawEvent` as the
  `withdraw`
  function does.
</Aside>

### Freezing Accounts

If the creator or manager would like to freeze a `CoinStore` on a specific
account, they must retrieve a reference to their `FreezeCapability`, which was
produced in `initialize`, and call:

```move
module 0x1::coin {
  public entry fun freeze_coin_store<CoinType>(
    account_addr: address,
    _freeze_cap: &FreezeCapability<CoinType>,
  ) acquires CoinStore {
    // ...
  }
}
```

### Merging Coins

Two coins of the same type can be merged into a single Coin struct that
represents the accumulated value of the two coins independently by calling:

```move
module 0x1::coin {
  public fun merge<CoinType>(
    dst_coin: &mut Coin<CoinType>,
    source_coin: Coin<CoinType>,
  ) {
    // ...
  }
}
```

### Extracting Coins

A Coin can have value deducted to create another Coin by calling:

```move
module 0x1::coin {
  public fun extract<CoinType>(
		coin: &mut Coin<CoinType>,
		amount: u64,
  ): Coin<CoinType> {
    // ...
  }
}
```

### Withdrawing Coins from CoinStore

A holder of a `CoinStore` can extract a Coin of a specified value by calling:

```move
module 0x1::coin {
  public fun withdraw<CoinType>(
    account: &signer,
    amount: u64,
  ): Coin<CoinType> acquires CoinStore {
    // ...
  }
}
```

<Aside type="note">
  This function will emit a `WithdrawEvent`.
</Aside>

### Depositing Coins into CoinStore

Any entity can deposit coins into an account‚Äôs `CoinStore` by calling:

```move
module 0x1::coin {
  public fun deposit<CoinType>(
		account_addr: address,
		coin: Coin<CoinType>,
  ) acquires CoinStore {
    // ...
  }
}
```

<Aside type="note">
  This function will emit a `DepositEvent`.
</Aside>

### Transferring Coins

A holder of a `CoinStore` can directly transfer coins from their account to
another account‚Äôs `CoinStore` by calling:

```move
module 0x1::coin {
  public entry fun transfer<CoinType>(
    from: &signer,
    to: address,
    amount: u64,
  ) acquires CoinStore {
    // ...
  }
}
```

<Aside type="note">
  This will emit both a `WithdrawEvent` and `DepositEvent` on the respective
  `CoinStore`s.
</Aside>

## Events

```move
module 0x1::coin {
  struct DepositEvent has drop, store {
    amount: u64,
  }
}
```

```move
module 0x1::coin {
  struct WithdrawEvent has drop, store {
    amount: u64,
  }
}
```

# Aptos Standards

> Learn about aptos standards for Move smart contract development on Aptos blockchain.

Standards define a common interoperable interface for all developers to build
upon. They consist of rules to ensure compatibility across applications and
wallets on the Aptos blockchain. See a [list of known coin resource addresses](https://github.com/hippospace/aptos-coin-list)
on Aptos provided by hippospace.

## Move Standards

### [Aptos Object](/build/smart-contracts/objects)

The [Object model](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/object.move)
allows Move to represent a complex type as a set of resources stored within a
single address and offers a rich capability model that allows for fine-grained
resource control and ownership management.

## Asset Standards

### [Digital Asset (DA)](/build/smart-contracts/digital-asset)

The new [Aptos Digital Asset Standard](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-token-objects/sources/token.move)
allows:

- Rich, flexible assets and collectibles.
- Easy enhancement of base functionality to provide richer custom
  functionalities. An example of this is the [aptos\_token module](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-token-objects/sources/aptos_token.move)

Digital Asset (DA) is recommended for any new collections or protocols that want
to build NFT or semi-fungible tokens.

### [Fungible Asset (FA)](/build/smart-contracts/fungible-asset)

The new [Aptos Fungible Asset Standard](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/fungible_asset.move)
is a standard meant for simple, type-safe, and fungible assets based on object
model intending to replace Aptos coin. Fungible Asset (FA) offers more features
and flexibility to Aptos move developers on creating and managing fungible assets.

## Legacy Standards

### [Aptos Token](/build/smart-contracts/aptos-token)

The old
existing [Token module](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-token/sources/token.move),
on the other hand:

- Encapsulates rich, flexible assets and collectibles. These assets are discrete
  (non-decimal) and can be fungible, semi-fungible, or non-fungible.
- The token standard is in its own `AptosToken` package at the Address `0x3` to
  allow for rapid iteration based on feedback from the community.

### [Aptos Coin](/build/smart-contracts/aptos-coin)

The [Coin module](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/coin.move)
is a lightweight standard meant for simple, type-safe, and fungible assets. The
coin standard is separated out into its own Move module to ensure that:

- Applications and users can create and use simple tokens, with high performance
  and low gas overhead.
- The Coin standard is part of the Aptos core framework, so it can be used for
  currencies, including the gas currency.

# Aptos Token Standard (Legacy)

> Learn about aptos token for Move smart contract development on Aptos blockchain.

import { ThemedImage } from '~/components/ThemedImage';

import { Aside } from '@astrojs/starlight/components';

## Overview of NFT

An [NFT](https://en.wikipedia.org/wiki/Non-fungible_token) is a non-fungible [token](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-token/sources/token.move) or data stored on a blockchain that
uniquely defines ownership of an asset. NFTs were first defined in [EIP-721](https://eips.ethereum.org/EIPS/eip-721)
and later expanded upon in [EIP-1155](https://eips.ethereum.org/EIPS/eip-1155).
NFTs are typically defined using the following properties:

- `name`: The name of the asset. It must be unique within a collection.
- `description`: The description of the asset.
- `uri`: A URL pointer to off-chain for more information about the asset. The
  asset could be media such as an image or video or more metadata.
- `supply`: The total number of units of this NFT. Many NFTs have only a single
  supply, while those that have more than one are referred to as editions.

Additionally, most NFTs are part of a collection or a set of NFTs with a common
attribute, for example, a theme, creator, or minimally contract. Each collection
has a similar set of attributes:

- `name`: The name of the collection. The name must be unique within the
  creator's account.
- `description`: The description of the collection.
- `uri`: A URL pointer to off-chain for more information about the asset. The
  asset could be media such as an image or video or more metadata.
- `supply`: The total number of NFTs in this collection.
- `maximum`: The maximum number of NFTs that this collection can have. If
  `maximum` is set to 0, then supply is not tracked.

## Design principles

The [Aptos token standard](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-token/sources/token.move) is developed with the following principles:

- **Interoperability**: Provide a standard implementation to improve
  interoperability across the ecosystem projects. Moreover, Move being a static
  language without dynamic dispatch makes this principle even more imperative.
- **Liquidity**: Achieve maximal liquidity by defining the NFT, fungible
  (non-decimal) and semi-fungible tokens in one contract. These different types of
  tokens can be easily stored, transferred and transacted in the same way. As a
  consequence, it becomes easier to achieve maximal interoperability across the
  marketplaces, exchanges, and other methods of exchange.
- **Rich on-chain token properties**: Enable the customization of on-chain token
  properties. Users can define their own properties and store them on-chain. This
  can potentially eliminate the need for the off-chain metadata.
- **Reduced overhead**: Reduce the cost of creating large amounts of NFTs from
  fungible tokens. This can lead to, for example, reduced overhead for similar
  tokens by the reuse of on-chain metadata for certain fungible tokens.

<Aside type="note">
  **Fungible token ‚Üí NFT**<br />
  The Aptos token standard supports [mutation of a fungible token to an
  NFT](#evolving-from-fungible-token-to-nft).
</Aside>

### Storing customized token properties on-chain

The Aptos token standard uses the [`PropertyMap`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-token/sources/property_map.move) module to store on-chain
properties of tokens. `PropertyMap` maps a string key to a property value
on-chain, which stores the value in Binary Canonical Serialization (BCS) format
and its type. Currently, only primitive types (bool, u8, u64, u128, address and
String) are supported in `PropertyMap`. Applications, such as [Aptos Names](https://www.aptosnames.com/),
define application specific properties that are read and written by the
applications smart contract.

#### Default properties

You can add your properties to [`default_properties`](https://github.com/aptos-labs/aptos-core/blob/e62fd09cb1c916d857fa655b3f174991ef8698b3/aptos-move/framework/aptos-token/sources/token.move#L98) in the TokenData. The
properties defined here are shared by all tokens by default.

The `default_properties` field is a key-value store with type information. It
leverages the PropertyMap module which contain functions for serializing and
deserializing different primitive types to the property value.

#### Token properties

You can also use the `token_properties` defined in the token itself for
customization on-chain. You can create customized values for a property of this
specific token, thereby allowing a token to have a different property value from
its default.

Note that limits exist to storing customized token properties on-chain, namely
1000 properties per token with field names limited to 128 characters.

### Evolving from fungible token to NFT

Fungible tokens share the same default property values. However, these property
values can evolve over time and become different from each other. To support
such evolution of token properties, the Aptos token standard provides the
`property_version` field. Here is how it works:

- During the token creation (minting), all tokens initially have
  `property_version` set to `0` and these tokens can be stacked together as
  fungible token.
- When the creators mutate the default properties of a token, the mutated token
  will be assigned a unique `property_version` to create a new [`token_id`](https://github.com/aptos-labs/aptos-core/blob/bba1690d7268759bd86ccd7459d7967172f1da24/aptos-move/framework/aptos-token/sources/token.move#L288)
  to differentiate it from other fungible tokens. This unique `token_id` allows
  the token to have its own property values, and all further mutation of this
  token does **not** change the `property_version` again. This token essentially
  becomes an NFT now.

#### Configuring mutability

To make mutability explicit for both the creator and owner, the Aptos token
standard provides [`mutability_config`](https://github.com/aptos-labs/aptos-core/blob/bba1690d7268759bd86ccd7459d7967172f1da24/aptos-move/framework/aptos-token/sources/token.move#L100)
at both the collection level and the token level to control which fields are
mutable. Configurable here means the creator can configure this field to be
mutable or immutable during creation.

### Storing metadata off-chain

Follow the standard below to ensure your NFT can be correctly displayed by
various wallets.

You should store the metadata in a JSON file located in an onchain data solution like [Irys](https://docs.irys.xyz/), and provide the URL to the
JSON file in the `uri` field of the token or the collection. We recommend the
developers follow the [ERC-1155 off-chain data](https://eips.ethereum.org/EIPS/eip-1155)
schema to format their JSON files.

```json
{
  "image": "https://gateway.irys.xyz/QH3rksVhbFg5L9vvjGzb4POUibCEG-TGPInmofp-O-o",
  "animation_url": "https://gateway.irys.xyz/QH3rksVhbFg5L9vvjHzb4POUibCEG-TGPInmofp-O-o",
  "external_url": "https://petra.app/",
  "attributes": [
    {
      "trait_type": "web",
      "value": "yes"
    },
    {
      "trait_type": "mobile",
      "value": "yes"
    },
    {
      "trait_type": "extension",
      "value": "yes"
    }
  ],
  "properties": {
    "files": [
      {
        "uri": "https://gateway.irys.xyz/QH3rksVhbFg5L9vvjGzb4POUibCEG-ENXUnmofp-O-o",
        "type": "image/png"
      },
      {
        "uri": "https://gateway.irys.xyz/QH3rksVhbFg5L9vvjGzb4POUibCEG-UENCnmofp-O-o",
        "type": "unknown",
        "cdn": true
      },
      {
        "uri": "https://gateway.irys.xyz/QH3rksVhbFg5L9vvjGzb4POUibCEG-DJHUUnmofp-O-o",
        "type": "video/mp4"
      }
    ],
    "category": "video"
  }
}
```

- `image`: URL to the image asset. You may use the `?ext={file_extension}` query
  to provide information on the file type.
- `animation_url`: URL to the multimedia attachment of the asset. You may use
  the same `file_extension` query to provide the file type.
- `external_url`: URL to an external website where the user can also view the
  image.
- `attributes` - Object array, where an object should contain `trait_type` and
  `value` fields. `value` can be a string or a number.
- `properties.files`: Object array, where an object should contain the URI and
  type of the file that is part of the asset. The type should match the file
  extension. The array should also include files specified in `image` and
  `animation_url` fields, as well as any other files associated with the asset.
  You may use the `?ext={file_extension}` query to provide information on the file
  type.
- `properties.category`: Has supported categories:
- `image` - PNG, GIF, JPG
- `video` - MP4, MOV
- `audio` - MP3, FLAC, WAV
- `vr` - 3D models; GLB, GLTF
- `html` - HTML pages; scripts and relative paths within the HTML page are also
  supported

You can also host your files on CDN to provide faster loading time by using the
`cdn` flag in the file object. When the file exists, this should be the primary
location to read the media file (`video`, `audio`, `vr`) by wallet. If the file
is no longer available, the wallet can fall back to use the `animation_url` to
load the file.

```json
{
  "properties": {
    "files": [
      {
        "uri": "https://watch.videodelivery.net/52a52c4a261c88f19d267931426c9be6",
        "type": "unknown",
        "cdn": true
      }
    ]
  }
}
```

## Token data model

The following diagram depicts the flow of token data through Aptos:

<ThemedImage
  alt="Signed Transaction Flow"
  sources={{
light: '~/images/aptos-token-standard-flow.svg',
dark: '~/images/aptos-token-standard-flow-dark.svg',
}}
/>

## Token resources

As shown in the diagram above, token-related data are stored at both the
creator‚Äôs account and the owner‚Äôs account.

### Struct-level resources

The following tables describe fields at the struct level. For the definitive
list, see the [Aptos Token Framework](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-token/doc/overview.md).

#### Resource stored at the creator‚Äôs address

| Field                                                                                                                                                                 | Description                                                                                                                                                                                                                                                |
| --------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [`Collections`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-token/doc/token.md#resource-collections)                                | Maintains a table called `collection_data`, which maps the collection name to the `CollectionData`. It also stores all the `TokenData` that this creator creates.                                                                                          |
| [`CollectionData`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-token/doc/token.md#struct-collectiondata)                            | Stores the collection metadata. The supply is the number of tokens created for the current collection. The maximum is the upper bound of tokens in this collection.                                                                                        |
| [`CollectionMutabilityConfig`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-token/doc/token.md#0x3_token_CollectionMutabilityConfig) | Specifies which field is mutable.                                                                                                                                                                                                                          |
| [`TokenData`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-token/doc/token.md#0x3_token_TokenData)                                   | Acts as the main struct for holding the token metadata. Properties is a where users can add their own properties that are not defined in the token data. Users can mint more tokens based on the `TokenData`, and those tokens share the same `TokenData`. |
| [`TokenMutabilityConfig`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-token/doc/token.md#0x3_token_TokenMutabilityConfig)           | Controls which fields are mutable.                                                                                                                                                                                                                         |
| [`TokenDataId`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-token/doc/token.md#0x3_token_TokenDataId)                               | An ID used for representing and querying `TokenData` on-chain. This ID mainly contains three fields including creator address, collection name and token name.                                                                                             |
| [`Royalty`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-token/doc/token.md#0x3_token_Royalty)                                       | Specifies the denominator and numerator for calculating the royalty fee. It also has the payee account address for depositing the royalty.                                                                                                                 |
| `PropertyValue`                                                                                                                                                       | Contains both value of a property and type of property.                                                                                                                                                                                                    |

#### Resource stored at the owner‚Äôs address

| Field                                                                                                                                 | Description                                                                                                                                                            |
| ------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [`TokenStore`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-token/doc/token.md#0x3_token_TokenStore) | The main struct for storing the token owned by this address. It maps `TokenId` to the actual token.                                                                    |
| [`Token`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-token/doc/token.md#0x3_token_Token)           | The amount is the number of tokens.                                                                                                                                    |
| [`TokenId`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-token/doc/token.md#0x3_token_TokenId)       | `TokenDataId` points to the metadata of this token. The `property_version` represents a token with mutated `PropertyMap` from `default_properties` in the `TokenData`. |

For more detailed descriptions, see [Aptos Token Framework](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-token/doc/overview.md).

## Token lifecycle

### Token creation

Every Aptos token belongs to a collection. The developer first needs to create a
collection through `create_collection_script` and then create the token
belonging to the collection `create_token_script`. To achieve parallel
`TokenData` and `Token` creation, a developer can create unlimited collection
and `TokenData` where the `maximum` of the collection and `TokenData` are set as
`0`. With this setting, the token contract won‚Äôt track the supply of types of
token (`TokenData` count) and supply of token within each token type. As the
result, the `TokenData` and token can be created in parallel.

Aptos also enforces simple validation of the input size and prevents duplication:

- Token name - unique within each collection
- Collection name - unique within each account
- Token and collection name length - smaller than 128 characters
- URI length - smaller than 512 characters
- Property map - can hold at most 1000 properties, and each key should be
  smaller than 128 characters

### Token mutation

Our standard supports mutation with a principle that the mutable fields are
specified during the token creation. This allows the token owner to be informed
which fields are mutable when they get the token from the creator. Our contract
uses `CollectionMutabilityConfig` to check if a field is mutable. Our contract
uses `TokenMutabilityConfig` to check if a `TokenData` field is mutable.

For mutation of properties, we have both

- `default_properties` stored in `TokenData` shared by all tokens belonging to
  the `TokenData`
- `token_properties` stored in the token itself

To mutate `default_properties`, developers can use `mutate_tokendata_property`
to mutate the properties when `TokenMutabilityConfig` is set to `true`.

> **CAUTION: Set the `TokenMutabilityConfig` field to `false` unless it is
> absolutely necessary. Allowing `default_properties` to be mutable provides
> creators too much power; creators can change the burnable config to provide
> themselves the authority to burn tokens after token creation.**

To mutate `token_properties` stored in the token, our standard uses the
`TOKEN_PROPERTY_MUTABLE` property stored in `default_properties`. When the
creator creates the `TokenData` with the `TOKEN_PROPERTY_MUTABLE` property
set to `true`, the creator can mutate `token_properties`. Note that if the
`mutate_tokendata_property` is set to `true`, creators can mutate the
`token_properties` anyway since they can overwrite the setting in
`default_properties`.

### Token burn

We provide `burn` and `burn_by_creator` functions for token owners and token
creators to burn (or destroy) tokens. However, these two functions are also
guarded by configs that are specified during the token creation so that both
creator and owner are clear on who can burn the token. Burn is allowed only when
the `BURNABLE_BY_OWNER` property is set to `true` in `default_properties`. Burn
by creator is allowed when `BURNABLE_BY_CREATOR` is `true` in
`default_properties`. Once all the tokens belonging to a `TokenData` are burned,
the `TokenData` will be removed from the creator‚Äôs account. Similarly, if all
`TokenData` belonging to a collection are removed, the `CollectionData` will be
removed from the creator‚Äôs account.

### Token transfer

We provide three different modes for transferring tokens between the sender and
receiver.

#### Two-step transfer

To protect users from receiving undesired NFTs, they must be first offered NFTs,
and then accept the offered NFTs. Then only the offered NFTs will be deposited
in the users' token stores. This is the default token transfer behavior. For
example:

1. If Alice wants to send Bob an NFT, she must first offer Bob this NFT. This
   NFT is still stored under Alice‚Äôs account.
2. Only when Bob claims the NFT, will the NFT be removed from Alice‚Äôs account
   and stored in Bob‚Äôs token store.

<Aside type="note">
  **Token transfer module**<br />
  The token transfer is implemented in the
  [`token_transfers`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-token/sources/token_transfers.move)
  module.
</Aside>

#### Transfer with opt-in

If a user wants to receive direct transfer of the NFT, skipping the initial
steps of offer and claim, then the user can call [`opt_in_direct_transfer`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-token/doc/token.md#0x3_token_opt_in_direct_transfer)
to allow other people to directly transfer the NFTs into the user's token store.
After opting into direct transfer, the user can call [`transfer`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-token/doc/token.md#0x3_token_transfer)
to transfer tokens directly. For example, Alice and anyone can directly send a
token to Bob's token store once Bob opts in.

<Aside type="note">
  **Turning off direct transfer**<br />
  The user can also turn off this direct transfer behavior by calling the same
  `opt_in_direct_transfer` function to reset to the default behavior.
</Aside>

#### Multi-agent transfer

The sender and receiver can both sign a transfer transaction to directly
transfer a token from the sender to receiver [`direct_transfer_script`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-token/doc/token.md#function-direct_transfer_script).
For example, once Alice and Bob both sign the transfer transaction, the token
will be directly transferred from Alice's account to Bob.

# Binary Canonical Serialization (BCS)

> Learn about bcs for Move smart contract development on Aptos blockchain.

import { TabItem, Tabs } from '@astrojs/starlight/components';

Binary Canonical Serialization (BCS) is the serialization format used on the Aptos
blockchain. It is a binary canonical non-self-describing serialization format
that is used to serialize data structures.  BCS is used to serialize all data
on-chain, provide binary responses on the REST API, and encode input arguments
to transactions.

## Overview

Because BCS is not a self describing format, the reader must know the format of
the bytes ahead of time.

## Primitive Types

8-bit, 16-bit, 32-bit, 64-bit, 128-bit, and 256-bit unsigned integers are
supported.  They are serialized in little-endian byte order.

### Bool (boolean)

Booleans are serialized as a single byte.  `true` is serialized as `0x01` and
`false` is serialized as `0x00`.  All other values are invalid.

| Value   | Bytes  |
| ------- | ------ |
| `true`  | `0x01` |
| `false` | `0x00` |

<Tabs>
  <TabItem label="Move">
    ```move filename="bool.move"
    #[test_only]
    module 0x42::example {
      use std::bcs;
      use std::from_bcs;

      #[test]
      fun test_bool() {
        // Serialize
        let val: bool = true;
        let bytes: vector<u8> = bcs::to_bytes(&val);
        assert!(bytes == vector[0x01]);

        // Deserialize
        let val_des = from_bcs::to_bool(bytes);
        assert!(val_des == true);
      }
    }
    ```
  </TabItem>

  <TabItem label="Rust">
    ```rust filename="bool.rs"
    // Serialize
    let val: bool = true;
    let bytes: Vec<u8> = bcs::to_bytes(&val).unwrap();
    assert_eq!(bytes, vec![0x01]);

    // Deserialize
    let val_des = bcs::from_bytes::<bool>(&bytes).unwrap();
    assert_eq!(val_des, true);
    ```
  </TabItem>

  <TabItem label="TypeScript">
    ```typescript filename="bool.ts"
    import { Serializer, Deserializer } from "@aptos-labs/ts-sdk";

    // Serialize
    const ser = new Serializer();
    ser.serializeBool(true);
    const bytes = ser.toUint8Array();
    console.log(bytes == Uint8Array.from([1]));

    // Deserialize
    const des = new Deserializer(bytes);
    const val = des.deserializeBool();
    console.log(val == true);
    ```
  </TabItem>

  <TabItem label="Go">
    ```go filename="bool.go"
    import (
      "github.com/aptos-labs/aptos-go-sdk"
    )

    func main() {
      // Serialize
      ser := bcs.Serializer{}
      ser.Bool(true)
      trueBytes := ser.ToBytes()
      trueBytes == []byte{0x01}

      // Deserialize
      des := bcs.NewDeserializer(trueBytes)
      val := des.Bool()
      val == true
    }
    ```
  </TabItem>
</Tabs>

### U8 (unsigned 8-bit integer)

Unsigned 8-bit integers are serialized as a single byte.

<Tabs>
  <TabItem label="Move">
    ```move filename="u8.move"
    #[test_only]
    module 0x42::example {
      use std::bcs;
      use std::from_bcs;

      #[test]
      fun test_u8() {
        // Serialize
        let val: u8 = 1;
        let bytes: vector<u8> = bcs::to_bytes(&val);
        assert!(bytes == vector[0x01]);

        // Deserialize
        let val_des = from_bcs::to_u8(bytes);
        assert!(val_des == 1);
      }
    }
    ```
  </TabItem>

  <TabItem label="Rust">
    ```rust filename="u8.rs"
    // Serialize
    let val: u8 = 1;
    let bytes: Vec<u8> = bcs::to_bytes(&val).unwrap();
    assert_eq!(bytes, vec![0x01]);

    // Deserialize
    let val_des = bcs::from_bytes::<u8>(&bytes).unwrap();
    assert_eq!(val_des, 1);
    ```
  </TabItem>

  <TabItem label="TypeScript">
    ```typescript filename="bool.ts"
    import { Serializer, Deserializer } from "@aptos-labs/ts-sdk";

    // Serialize
    const ser = new Serializer();
    ser.serializeU8(1);
    const bytes = ser.toUint8Array();
    console.log(bytes == Uint8Array.from([1]));

    // Deserialize
    const des = new Deserializer(bytes);
    const val = des.deserializeU8();
    console.log(val == 1);
    ```
  </TabItem>

  <TabItem label="Go">
    ```go filename="bool.go"
    import (
      "github.com/aptos-labs/aptos-go-sdk"
    )

    func main() {
      // Serialize
      ser := bcs.Serializer{}
      ser.U8(1)
      trueBytes := ser.ToBytes()
      trueBytes == []byte{0x01}

      // Deserialize
      des := bcs.NewDeserializer(trueBytes)
      val := des.U8()
      val == 1
    }
    ```
  </TabItem>
</Tabs>

### U16 (unsigned 16-bit integer)

Unsigned 16-bit integers are serialized as 2 bytes in little-endian byte order.

<Tabs>
  <TabItem label="Move">
    ```move filename="u16.move"
    #[test_only]
    module 0x42::example {
     use std::bcs;
     use std::from_bcs;

     #[test]
     fun test_u16() {
       // Serialize
       let val: u16 = 1000;
       let bytes: vector<u8> = bcs::to_bytes(&val);
       assert!(bytes == vector[0xe8, 0x03]);

       // Deserialize
       let val_des = from_bcs::to_u16(bytes);
       assert!(val_des == 1000);
     }
    }
    ```
  </TabItem>

  <TabItem label="Rust">
    ```rust filename="u16.rs"
    // Serialize
    let val: u16 = 1000;
    let bytes: Vec<u8> = bcs::to_bytes(&val).unwrap();
    assert_eq!(bytes, vec![0xe8, 0x03]);

    // Deserialize
    let val_des = bcs::from_bytes::<u16>(&bytes).unwrap();
    assert_eq!(val_des, 1000);
    ```
  </TabItem>

  <TabItem label="TypeScript">
    ```typescript filename="u16.ts"
    import { Serializer, Deserializer } from "@aptos-labs/ts-sdk";

    // Serialize
    const ser = new Serializer();
    ser.serializeU16(1000);
    const bytes = ser.toUint8Array();
    console.log(bytes == Uint8Array.from([0xe8, 0x03]));

    // Deserialize
    const des = new Deserializer(bytes);
    const val = des.deserializeU16();
    console.log(val == 1000);
    ```
  </TabItem>

  <TabItem label="Go">
    ```go filename="u16.go"
    import (
      "github.com/aptos-labs/aptos-go-sdk"
    )

    func main() {
      // Serialize
      ser := bcs.Serializer{}
      ser.U16(1000)
      bytes := ser.ToBytes()
      bytes == []byte{0xe8, 0x03}

      // Deserialize
      des := bcs.NewDeserializer(bytes)
      val := des.U16()
      val == 1000
    }
    ```
  </TabItem>
</Tabs>

### U32 (unsigned 32-bit integer)

Unsigned 32-bit integers are serialized as 4 bytes in little-endian byte order.

<Tabs>
  <TabItem label="Move">
    ```move filename="u32.move"
    #[test_only]
    module 0x42::example {
      use std::bcs;
      use std::from_bcs;

      #[test]
      fun test_u32() {
        // Serialize
        let val: u32 = 1000000000;
        let bytes: vector<u8> = bcs::to_bytes(&val);
        assert!(bytes == vector[0x00, 0xca, 0x9a, 0x3b]);

        // Deserialize
        let val_des = from_bcs::to_u32(bytes);
        assert!(val_des == 1000000000);
      }
    }
    ```
  </TabItem>

  <TabItem label="Rust">
    ```rust filename="u32.rs"
    // Serialize
    let val: u32 = 1000000000;
    let bytes: Vec<u8> = bcs::to_bytes(&val).unwrap();
    assert_eq!(bytes, vec![0x00, 0xca, 0x9a, 0x3b]);

    // Deserialize
    let val_des = bcs::from_bytes::<u32>(&bytes).unwrap();
    assert_eq!(val_des, 1000000000);
    ```
  </TabItem>

  <TabItem label="TypeScript">
    ```typescript filename="u32.ts"
    import { Serializer, Deserializer } from "@aptos-labs/ts-sdk";

    // Serialize
    const ser = new Serializer();
    ser.serializeU32(1000000000);
    const bytes = ser.toUint8Array();
    console.log(bytes == Uint8Array.from([0x00, 0xca, 0x9a, 0x3b]));

    // Deserialize
    const des = new Deserializer(bytes);
    const val = des.deserializeU32();
    console.log(val == 1000000000);
    ```
  </TabItem>

  <TabItem label="Go">
    ```go filename="u32.go"
    import (
      "github.com/aptos-labs/aptos-go-sdk"
    )

    func main() {
      // Serialize
      ser := bcs.Serializer{}
      ser.U32(1000000000)
      bytes := ser.ToBytes()
      bytes == []byte{0x00, 0xca, 0x9a, 0x3b}

      // Deserialize
      des := bcs.NewDeserializer(bytes)
      val := des.U32()
      val == 1000000000
    }
    ```
  </TabItem>
</Tabs>

### U64 (unsigned 64-bit integer)

Unsigned 64-bit integers are serialized as 8 bytes in little-endian byte order.

<Tabs>
  <TabItem label="Move">
    ```move filename="u64.move"
    #[test_only]
    module 0x42::example {
      use std::bcs;
      use std::from_bcs;

      #[test]
      fun test_u64() {
        // Serialize
        let val: u64 = 10000000000000000;
        let bytes: vector<u8> = bcs::to_bytes(&val);
        assert!(bytes == vector[0x00, 0x40, 0x9c, 0x4f, 0x2c, 0x68, 0x00, 0x00]);

        // Deserialize
        let val_des = from_bcs::to_u64(bytes);
        assert!(val_des == 10000000000000000);
      }
    }
    ```
  </TabItem>

  <TabItem label="Rust">
    ```rust filename="u64.rs"
    // Serialize
    let val: u64 = 10000000000000000;
    let bytes: Vec<u8> = bcs::to_bytes(&val).unwrap();
    assert_eq!(bytes, vec![0x00, 0x40, 0x9c, 0x4f, 0x2c, 0x68, 0x00, 0x00]);

    // Deserialize
    let val_des = bcs::from_bytes::<u64>(&bytes).unwrap();
    assert_eq!(val_des, 10000000000000000);
    ```
  </TabItem>

  <TabItem label="TypeScript">
    ```typescript filename="u64.ts"
    import { Serializer, Deserializer } from "@aptos-labs/ts-sdk";

    // Serialize
    const ser = new Serializer();
    ser.serializeU64(10000000000000000n);
    const bytes = ser.toUint8Array();
    console.log(bytes == Uint8Array.from([0x00, 0x40, 0x9c, 0x4f, 0x2c, 0x68, 0x00, 0x00]));

    // Deserialize
    const des = new Deserializer(bytes);
    const val = des.deserializeU64();
    console.log(val == 10000000000000000n);
    ```
  </TabItem>

  <TabItem label="Go">
    ```go filename="u64.go"
    import (
      "github.com/aptos-labs/aptos-go-sdk"
    )

    func main() {
      // Serialize
      ser := bcs.Serializer{}
      ser.U64(10000000000000000)
      bytes := ser.ToBytes()
      bytes == []byte{0x00, 0x40, 0x9c, 0x4f, 0x2c, 0x68, 0x00, 0x00}

      // Deserialize
      des := bcs.NewDeserializer(bytes)
      val := des.U64()
      val == 10000000000000000
    }
    ```
  </TabItem>
</Tabs>

### U128 (unsigned 128-bit integer)

Unsigned 128-bit integers are serialized as 16 bytes in little-endian byte order.

<Tabs>
  <TabItem label="Move">
    ```move filename="u128.move"
    #[test_only]
    module 0x42::example {
      use std::bcs;
      use std::from_bcs;

      #[test]
      fun test_u128() {
        // Serialize
        let val: u128 = 10000000000000000;
        let bytes: vector<u8> = bcs::to_bytes(&val);
        assert!(bytes == vector[0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x40, 0x9c, 0x4f, 0x2c, 0x68, 0x00, 0x00]);

        // Deserialize
        let val_des = from_bcs::to_u128(bytes);
        assert!(val_des == 10000000000000000);
      }
    }
    ```
  </TabItem>

  <TabItem label="Rust">
    ```rust filename="u128.rs"
    // Serialize
    let val: u128 = 10000000000000000;
    let bytes: Vec<u8> = bcs::to_bytes(&val).unwrap();
    assert_eq!(bytes, vec![0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x40, 0x9c, 0x4f, 0x2c, 0x68, 0x00, 0x00]);

    // Deserialize
    let val_des = bcs::from_bytes::<u128>(&bytes).unwrap();
    assert_eq!(val_des, 10000000000000000);
    ```
  </TabItem>

  <TabItem label="TypeScript">
    ```typescript filename="u128.ts"
    import { Serializer, Deserializer } from "@aptos-labs/ts-sdk";

    // Serialize
    const ser = new Serializer();
    ser.serializeU128(10000000000000000n);
    const bytes = ser.toUint8Array();
    console.log(bytes == Uint8Array.from([0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x40, 0x9c, 0x4f, 0x2c, 0x68, 0x00, 0x00]));

    // Deserialize
    const des = new Deserializer(bytes);
    const val = des.deserializeU128();
    console.log(val == 10000000000000000n);
    ```
  </TabItem>

  <TabItem label="Go">
    ```go filename="u128.go"
    import (
      "github.com/aptos-labs/aptos-go-sdk"
      "math/big"
    )

    func main() {
      // Serialize
      ser := bcs.Serializer{}
      val := new(big.Int)
      val.SetString("10000000000000000", 10)
      ser.U128(val)
      bytes := ser.ToBytes()
      bytes == []byte{0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x40, 0x9c, 0x4f, 0x2c, 0x68, 0x00, 0x00}

      // Deserialize
      des := bcs.NewDeserializer(bytes)
      val_des := des.U128()
      val_des.String() == "10000000000000000"
    }
    ```
  </TabItem>
</Tabs>

### U256 (unsigned 256-bit integer)

Unsigned 256-bit integers are serialized as 32 bytes in little-endian byte order.

<Tabs>
  <TabItem label="Move">
    ```move filename="u256.move"
    #[test_only]
    module 0x42::example {
      use std::bcs;
      use std::from_bcs;

      #[test]
      fun test_u256() {
        // Serialize
        let val: u256 = 10000000000000000;
        let bytes: vector<u8> = bcs::to_bytes(&val);
        assert!(bytes == vector[0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x40, 0x9c, 0x4f, 0x2c, 0x68, 0x00, 0x00]);

        // Deserialize
        let val_des = from_bcs::to_u256(bytes);
        assert!(val_des == 10000000000000000);
      }
    }
    ```
  </TabItem>

  <TabItem label="Rust">
    ```rust filename="u256.rs"
    // Serialize
    let val: U256 = U256::from(10000000000000000u64);
    let bytes: Vec<u8> = bcs::to_bytes(&val).unwrap();
    assert_eq!(bytes, vec![0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x40, 0x9c, 0x4f, 0x2c, 0x68, 0x00, 0x00]);

    // Deserialize
    let val_des = bcs::from_bytes::<U256>(&bytes).unwrap();
    assert_eq!(val_des, U256::from(10000000000000000u64));
    ```
  </TabItem>

  <TabItem label="TypeScript">
    ```typescript filename="u256.ts"
    import { Serializer, Deserializer } from "@aptos-labs/ts-sdk";

    // Serialize
    const ser = new Serializer();
    ser.serializeU256(10000000000000000n);
    const bytes = ser.toUint8Array();
    console.log(bytes == Uint8Array.from([0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x40, 0x9c, 0x4f, 0x2c, 0x68, 0x00, 0x00]));

    // Deserialize
    const des = new Deserializer(bytes);
    const val = des.deserializeU256();
    console.log(val == 10000000000000000n);
    ```
  </TabItem>

  <TabItem label="Go">
    ```go filename="u256.go"
    import (
      "github.com/aptos-labs/aptos-go-sdk"
      "math/big"
    )

    func main() {
      // Serialize
      ser := bcs.Serializer{}
      val := new(big.Int)
      val.SetString("10000000000000000", 10)
      ser.U256(val)
      bytes := ser.ToBytes()
      bytes == []byte{0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x40, 0x9c, 0x4f, 0x2c, 0x68, 0x00, 0x00}

      // Deserialize
      des := bcs.NewDeserializer(bytes)
      val_des := des.U256()
      val_des.String() == "10000000000000000"
    }
    ```
  </TabItem>
</Tabs>

### Uleb128 (unsigned 128-bit variable length integer)

Unsigned 128-bit variable length integers are serialized as a variable number of bytes.  The most significant bit of each byte is used to indicate if there are more bytes to read.  The remaining 7 bits are used to store the value.

This is common used for variable lengths of vectors, or for enums.

<Tabs>
  <TabItem label="Move">
    ```move filename="uleb128.move"
    // Currently not supported by itself in Move
    ```
  </TabItem>

  <TabItem label="Rust">
    ```rust filename="uleb128.rs"
    // Currently not supported by itself in Rust with serde
    ```
  </TabItem>

  <TabItem label="TypeScript">
    ```typescript filename="uleb128.ts"
    import { Serializer, Deserializer } from "@aptos-labs/ts-sdk";

    // Serialize
    const ser = new Serializer();
    ser.serializeU32AsUleb128(127);
    const bytes = ser.toUint8Array();
    console.log(bytes == Uint8Array.from([0x7f]));

    const ser = new Serializer();
    ser.serializeU32AsUleb128(128);
    const bytes2 = ser.toUint8Array();
    console.log(bytes2 == Uint8Array.from([0x80, 0x01]));

    // Deserialize
    const des = new Deserializer(bytes2);
    const val = des.deserializeUleb128AsU32();
    console.log(val == 128);
    ```
  </TabItem>

  <TabItem label="Go">
    ```go filename="uleb128.go"
    import (
      "github.com/aptos-labs/aptos-go-sdk"
      "math/big"
    )

    func main() {
      // Serialize
      ser := bcs.Serializer{}
      val := new(big.Int)
      val.SetInt64(127)
      ser.Uleb128(val)
      bytes := ser.ToBytes()
      bytes == []byte{0x7f}

      // Deserialize
      des := bcs.NewDeserializer(bytes)
      val_des := des.Uleb128()
      val_des.Int64() == 127
    }
    ```
  </TabItem>
</Tabs>

### Sequence and FixedSequence

Sequences are serialized as a variable length vector of an item.  The length of
the vector is serialized as a Uleb128 followed by repeated items.  FixedSequences
are serialized without the leading size byte.  The reader must know the number
of bytes prior to deserialization.

<Tabs>
  <TabItem label="Move">
    ```move filename="vector.move"
    #[test_only]
    module 0x42::example {
      use std::bcs;
      use std::from_bcs;

      #[test]
      fun test_vector() {
        // Serialize
        let val = vector[1u8, 2u8, 3u8];
        let bytes = bcs::to_bytes(&val);
        assert!(bytes == vector[3, 1, 2, 3]);

        // Deserialize, only supports bytes for now
        let val_des = from_bcs::to_bytes(bytes);
        assert!(val_des == vector[1, 2, 3]);
      }
    }
    ```
  </TabItem>

  <TabItem label="Rust">
    ```rust filename="vector.rs"
    // Serialize
    let val = vec![1u8, 2u8, 3u8];
    let bytes = bcs::to_bytes(&val).unwrap();
    assert_eq!(bytes, vec![3, 1, 2, 3]);

    // Deserialize
    let val_des = bcs::from_bytes::<Vec<u8>>(&bytes).unwrap();
    assert_eq!(val_des, vec![1, 2, 3]);
    ```
  </TabItem>

  <TabItem label="TypeScript">
    ```typescript filename="vector.ts"
    import { Serializer, Deserializer } from "@aptos-labs/ts-sdk";

    // Serialize
    const ser = new Serializer();
    ser.serializeVector([1, 2, 3], (s, item) => s.serializeU8(item));
    const bytes = ser.toUint8Array();
    console.log(bytes == Uint8Array.from([3, 1, 2, 3]));

    // Deserialize
    const des = new Deserializer(bytes);
    const val = des.deserializeVector((d) => d.deserializeU8());
    console.log(val == [1, 2, 3]);
    ```
  </TabItem>

  <TabItem label="Go">
    ```go filename="vector.go"
    import (
      "github.com/aptos-labs/aptos-go-sdk"
    )

    func main() {
      // Serialize
      ser := bcs.Serializer{}
      ser.SerializeVector([]uint8{1, 2, 3}, func(s *bcs.Serializer, item uint8) {
        s.U8(item)
      })
      bytes := ser.ToBytes()
      bytes == []byte{3, 1, 2, 3}

      // Deserialize
      des := bcs.NewDeserializer(bytes)
      val := des.DeserializeVector(func(d *bcs.Deserializer) uint8 {
        return d.U8()
      })
      val == []uint8{1, 2, 3}
    }
    ```
  </TabItem>
</Tabs>

## Complex types

### String

Strings are serialized as a vector of bytes, however the bytes are encoded as UTF-8.

```rust
// Note that this string has 10 characters but has a byte length of 24
let utf8_str = "√ß√•‚àû‚â†¬¢√µ√ü‚àÇ∆í‚à´";
let expecting = vec![
    24, 0xc3, 0xa7, 0xc3, 0xa5, 0xe2, 0x88, 0x9e, 0xe2, 0x89, 0xa0, 0xc2,
    0xa2, 0xc3, 0xb5, 0xc3, 0x9f, 0xe2, 0x88, 0x82, 0xc6, 0x92, 0xe2, 0x88, 0xab,
];
assert_eq!(to_bytes(&utf8_str)?, expecting);
```

### AccountAddress

AccountAddress is serialized as a fixed 32 byte vector of bytes.

```
@0x1 => [0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x01]
```

### Struct

Structs are serialized as an ordered set of fields.  The fields are serialized in the order they are defined in the struct.

```
struct Color {
  r: u8 = 1,
  g: u8 = 2,
  b: u8 = 3,
} => [0x01, 0x02, 0x03]
```

### Option

Options are serialized as a single byte to determine whether it's filled. If the
option is `None`, the byte is `0x00`. If the option is `Some`, the byte is
`0x01` followed by the serialized value.

```rust
let some_data: Option<u8> = Some(8);
assert_eq!(to_bytes(&some_data)?, vec![1, 8]);

let no_data: Option<u8> = None;
assert_eq!(to_bytes(&no_data)?, vec![0]);
```

### Enum

Enums are serialized as a uleb128 to determine which variant is being used.
The size is followed by the serialized value of the variant.

```rust
#[derive(Serialize)]
enum E {
    Variant0(u16),
    Variant1(u8),
    Variant2(String),
}

let v0 = E::Variant0(8000);
let v1 = E::Variant1(255);
let v2 = E::Variant2("e".to_owned());

assert_eq!(to_bytes(&v0)?, vec![0, 0x40, 0x1F]);
assert_eq!(to_bytes(&v1)?, vec![1, 0xFF]);
assert_eq!(to_bytes(&v2)?, vec![2, 1, b'e']);
```

### Maps

Maps are stored as a sequence of tuples.  The length of the map is serialized as a Uleb128 followed by repeated key-value pairs.

```rust
let mut map = HashMap::new();
map.insert(b'e', b'f');
map.insert(b'a', b'b');
map.insert(b'c', b'd');

let expecting = vec![(b'a', b'b'), (b'c', b'd'), (b'e', b'f')];

assert_eq!(to_bytes(&map)?, to_bytes(&expecting)?);
```

## Reference

- [BCS Specification](https://github.com/diem/bcs)

# The Move Book

> Learn about book in Move programming language for Aptos smart contract development.

Welcome to Move, a next generation language for secure, sandboxed, and formally
verified programming. It has been used as the smart contract language for
several blockchains including Aptos. Move allows developers to write programs
that flexibly manage and transfer assets, while providing the security and
protections against attacks on those assets. However, Move has been developed
with use cases in mind outside a blockchain context as well.

Move takes its cue from [Rust](https://www.rust-lang.org/) by using resource
types with move (hence the name) semantics as an explicit representation of
digital assets, such as currency.

## Who is Aptos Move Book for?

Move was designed and created as a secure, verified, yet flexible programming
language. The first use of Move is for the implementation of the Diem
blockchain, and it is currently being used on Aptos.

This book is suitable for developers with some programming experience
and who want to begin understanding the core programming language and see
examples of its usage.

## Where Do I Start?

Begin with understanding [modules and scripts](/build/smart-contracts/book/modules-and-scripts)
and then work through the [Move Tutorial](/build/smart-contracts/book/move-tutorial).

# Abilities

> Learn about abilities in Move programming language for Aptos smart contract development.

Abilities are a typing feature in Move that control what actions are permissible for values of a given type. This system grants fine-grained control over the "linear" typing behavior of values, as well as if and how values are used in global storage. This is implemented by gating access to certain bytecode instructions so that for a value to be used with the bytecode instruction, it must have the ability required (if one is required at all‚Äînot every instruction is gated by an ability).

{/* TODO future section on detailed walk through, maybe. We have some examples at the end, but it might be helpful to explain why we have precisely this set of abilities */}

{/* If you are already somewhat familiar with abilities from writing Move programs, but are still confused as to what is going on, it might be helpful to skip to the [motivating walkthrough](#motivating-walkthrough) section to get an idea of what the system is set up in the way that it is. --> */}

## The Four Abilities

The four abilities are:

- [`copy`](#copy)
  - Allows values of types with this ability to be copied.
- [`drop`](#drop)
  - Allows values of types with this ability to be popped/dropped.
- [`store`](#store)
  - Allows values of types with this ability to exist inside a struct in global storage.
- [`key`](#key)
  - Allows the type to serve as a key for global storage operations.

### `copy`

The `copy` ability allows values of types with that ability to be copied. It gates the ability to copy values out of local variables with the [`copy`](/build/smart-contracts/book/variables#move-and-copy) operator and to copy values via references with [dereference `*e`](/build/smart-contracts/book/references#reading-and-writing-through-references).

If a value has `copy`, all values contained inside of that value have `copy`.

### `drop`

The `drop` ability allows values of types with that ability to be dropped. By dropped, we mean that value is not transferred and is effectively destroyed as the Move program executes. As such, this ability gates the ability to ignore values in a multitude of locations, including:

- not using the value in a local variable or parameter
- not using the value in a [sequence via `;`](/build/smart-contracts/book/variables#expression-blocks)
- overwriting values in variables in [assignments](/build/smart-contracts/book/variables#assignments)
- overwriting values via references when [writing `*e1 = e2`](/build/smart-contracts/book/references#reading-and-writing-through-references).

If a value has `drop`, all values contained inside of that value have `drop`.

### `store`

The `store` ability allows values of types with this ability to exist inside a struct (resource) in global storage, _but_ not necessarily as a top-level resource in global storage. This is the only ability that does not directly gate an operation. Instead, it gates the existence in global storage when used in tandem with `key`.

If a value has `store`, all values contained inside of that value have `store`

### `key`

The `key` ability allows the type to serve as a key for [global storage operations](/build/smart-contracts/book/global-storage-operators). It gates all global storage operations, so in order for a type to be used with `move_to`, `borrow_global`, `move_from`, etc., the type must have the `key` ability. Note that the operations still must be used in the module where the `key` type is defined (in a sense, the operations are private to the defining module).

If a value has `key`, all values contained inside of that value have `store`. This is the only ability with this sort of asymmetry.

## Builtin Types

Most primitive, builtin types have `copy`, `drop`, and `store` except for `signer`, which just has `drop`

- `bool`, `u8`, `u16`, `u32`, `u64`, `u128`, `u256`, and `address` all have `copy`, `drop`, and `store`.
- `signer` has `drop`
  - Cannot be copied and cannot be put into global storage
- `vector<T>` may have `copy`, `drop`, and `store` depending on the abilities of `T`.
  - See [Conditional Abilities and Generic Types](#conditional-abilities-and-generic-types) for more details.
- Immutable references `&` and mutable references `&mut` both have `copy` and `drop`.
  - This refers to copying and dropping the reference itself, not what they refer to.
  - References cannot appear in global storage, hence they do not have `store`.

None of the primitive types have `key`, meaning none of them can be used directly with the [global storage operations](/build/smart-contracts/book/global-storage-operators).

## Annotating Structs

To declare that a `struct` has an ability, it is declared with `has <ability>` after the struct name but before the fields. For example:

```move
module 0x42::example {
  struct Ignorable has drop { f: u64 }

  struct Pair has copy, drop, store { x: u64, y: u64 }
}
```

In this case: `Ignorable` has the `drop` ability. `Pair` has `copy`, `drop`, and `store`.

All of these abilities have strong guarantees over these gated operations. The operation can be performed on the value only if it has that ability; even if the value is deeply nested inside some other collection!

As such: when declaring a struct‚Äôs abilities, certain requirements are placed on the fields. All fields must satisfy these constraints. These rules are necessary so that structs satisfy the reachability rules for the abilities given above. If a struct is declared with the ability...

- `copy`, all fields must have `copy`.
- `drop`, all fields must have `drop`.
- `store`, all fields must have `store`.
- `key`, all fields must have `store`.
  - `key` is the only ability currently that doesn't require itself.

For example:

```move
module 0x42::example {
  // A struct without any abilities
  struct NoAbilities {}

  struct WantsCopy has copy {
    f: NoAbilities, // ERROR 'NoAbilities' does not have 'copy'
  }
}
```

and similarly:

```move
module 0x42::example {
  // A struct without any abilities
  struct NoAbilities {}

  struct MyResource has key {
    f: NoAbilities, // Error 'NoAbilities' does not have 'store'
  }
}
```

## Conditional Abilities and Generic Types

When abilities are annotated on a generic type, not all instances of that type are guaranteed to have that ability. Consider this struct declaration:

```move
module 0x42::example {
  struct Cup<T> has copy, drop, store, key { item: T }
}
```

It might be very helpful if `Cup` could hold any type, regardless of its abilities. The type system can _see_ the type parameter, so it should be able to remove abilities from `Cup` if it _sees_ a type parameter that would violate the guarantees for that ability.

This behavior might sound a bit confusing at first, but it might be more understandable if we think about collection types. We could consider the builtin type `vector` to have the following type declaration:

```move
vector<T> has copy, drop, store;
```

We want `vector`s to work with any type. We don't want separate `vector` types for different abilities. So what are the rules we would want? Precisely the same that we would want with the field rules above. So, it would be safe to copy a `vector` value only if the inner elements can be copied. It would be safe to ignore a `vector` value only if the inner elements can be ignored/dropped. And, it would be safe to put a `vector` in global storage only if the inner elements can be in global storage.

To have this extra expressiveness, a type might not have all the abilities it was declared with depending on the instantiation of that type; instead, the abilities a type will have depends on both its declaration **and** its type arguments. For any type, type parameters are pessimistically assumed to be used inside the struct, so the abilities are only granted if the type parameters meet the requirements described above for fields. Taking `Cup` from above as an example:

- `Cup` has the ability `copy` only if `T` has `copy`.
- It has `drop` only if `T` has `drop`.
- It has `store` only if `T` has `store`.
- It has `key` only if `T` has `store`.

Here are examples for this conditional system for each ability:

### Example: conditional `copy`

```move
module 0x42::example {
  struct NoAbilities {}

  struct S has copy, drop { f: bool }

  struct Cup<T> has copy, drop, store { item: T }

  fun example(c_x: Cup<u64>, c_s: Cup<S>) {
    // Valid, 'Cup<u64>' has 'copy' because 'u64' has 'copy'
    let c_x2 = copy c_x;
    // Valid, 'Cup<S>' has 'copy' because 'S' has 'copy'
    let c_s2 = copy c_s;
  }

  fun invalid(c_account: Cup<signer>, c_n: Cup<NoAbilities>) {
    // Invalid, 'Cup<signer>' does not have 'copy'.
    // Even though 'Cup' was declared with copy, the instance does not have 'copy'
    // because 'signer' does not have 'copy'
    let c_account2 = copy c_account;
    // Invalid, 'Cup<NoAbilities>' does not have 'copy'
    // because 'NoAbilities' does not have 'copy'
    let c_n2 = copy c_n;
  }
}
```

### Example: conditional `drop`

```move
module 0x42::example {
  struct NoAbilities {}

  struct S has copy, drop { f: bool }

  struct Cup<T> has copy, drop, store { item: T }

  fun unused() {
    Cup<bool> { item: true }; // Valid, 'Cup<bool>' has 'drop'
    Cup<S> { item: S { f: false } }; // Valid, 'Cup<S>' has 'drop'
  }

  fun left_in_local(c_account: Cup<signer>): u64 {
    let c_b = Cup<bool> { item: true };
    let c_s = Cup<S> { item: S { f: false } };
    // Valid return: 'c_account', 'c_b', and 'c_s' have values
    // but 'Cup<signer>', 'Cup<bool>', and 'Cup<S>' have 'drop'
    0
  }

  fun invalid_unused() {
    // Invalid, Cannot ignore 'Cup<NoAbilities>' because it does not have 'drop'.
    // Even though 'Cup' was declared with 'drop', the instance does not have 'drop'
    // because 'NoAbilities' does not have 'drop'
    Cup<NoAbilities> { item: NoAbilities {} };
  }

  fun invalid_left_in_local(): u64 {
    let c_n = Cup<NoAbilities> { item: NoAbilities {} };
    // Invalid return: 'c_n' has a value
    // and 'Cup<NoAbilities>' does not have 'drop'
    0
  }
}
```

### Example: conditional `store`

```move
module 0x42::example {
  struct Cup<T> has copy, drop, store { item: T }

  // 'MyInnerResource' is declared with 'store' so all fields need 'store'
  struct MyInnerResource has store {
    yes: Cup<u64>,
    // Valid, 'Cup<u64>' has 'store'
    // no: Cup<signer>, Invalid, 'Cup<signer>' does not have 'store'
  }

  // 'MyResource' is declared with 'key' so all fields need 'store'
  struct MyResource has key {
    yes: Cup<u64>,
    // Valid, 'Cup<u64>' has 'store'
    inner: Cup<MyInnerResource>,
    // Valid, 'Cup<MyInnerResource>' has 'store'
    // no: Cup<signer>, Invalid, 'Cup<signer>' does not have 'store'
  }
}
```

### Example: conditional `key`

```move
module 0x42::example {
  struct NoAbilities {}

  struct MyResource<T> has key { f: T }

  fun valid(account: &signer) acquires MyResource {
    let addr = signer::address_of(account);
    // Valid, 'MyResource<u64>' has 'key'
    let has_resource = exists<MyResource<u64>>(addr);
    if (!has_resource) {
      // Valid, 'MyResource<u64>' has 'key'
      move_to(account, MyResource<u64> { f: 0 })
    };
    // Valid, 'MyResource<u64>' has 'key'
    let r = borrow_global_mut<MyResource<u64>>(addr)
    r.f = r.f + 1;
  }

  fun invalid(account: &signer) {
    // Invalid, 'MyResource<NoAbilities>' does not have 'key'
    let has_it = exists<MyResource<NoAbilities>>(addr);
    // Invalid, 'MyResource<NoAbilities>' does not have 'key'
    let NoAbilities {} = move_from<NoAbilities>(addr);
    // Invalid, 'MyResource<NoAbilities>' does not have 'key'
    move_to(account, NoAbilities {});
    // Invalid, 'MyResource<NoAbilities>' does not have 'key'
    borrow_global<NoAbilities>(addr);
  }
}
```

# Abort and Assert

> Understand error handling in Move with abort statements, assert macros, and exception management patterns.

[`return`](/build/smart-contracts/book/functions) and `abort` are two control flow constructs that end execution, one for
the current function and one for the entire transaction.

More information on [`return` can be found in the linked section](/build/smart-contracts/book/functions)

## `abort`

`abort` is an expression that takes one argument: an **abort code** of type `u64`. For example:

```move
abort 42
```

The `abort` expression halts execution of the current function and reverts all changes made to global
state by the current transaction. There is no mechanism for "catching" or otherwise handling an
`abort`.

Luckily, in Move transactions are all or nothing, meaning any changes to global storage are made all
at once only if the transaction succeeds. Because of this transactional commitment of changes, after
an abort there is no need to worry about backing out changes. While this approach is lacking in
flexibility, it is incredibly simple and predictable.

Similar to [`return`](/build/smart-contracts/book/functions), `abort` is useful for exiting control flow when some
condition cannot be met.

In this example, the function will pop two items off of the vector, but will abort early if the
vector does not have two items

```move
script {
  use std::vector;
  fun pop_twice<T>(v: &mut vector<T>): (T, T) {
      if (vector::length(v) < 2) abort 42;

      (vector::pop_back(v), vector::pop_back(v))
  }
}
```

This is even more useful deep inside a control-flow construct. For example, this function checks
that all numbers in the vector are less than the specified `bound`. And aborts otherwise

```move
script {
  use std::vector;
  fun check_vec(v: &vector<u64>, bound: u64) {
      let i = 0;
      let n = vector::length(v);
      while (i < n) {
          let cur = *vector::borrow(v, i);
          if (cur > bound) abort 42;
          i = i + 1;
      }
  }
}
```

### `assert`

`assert` is a builtin, macro-like operation provided by the Move compiler. It takes two arguments, a
condition of type `bool` and a code of type `u64`

```move
assert!(condition: bool, code: u64)
assert!(condition: bool) // Since Move 2.0
```

Since the operation is a macro, it must be invoked with the `!`. This is to convey that the
arguments to `assert` are call-by-expression. In other words, `assert` is not a normal function and
does not exist at the bytecode level. It is replaced inside the compiler with

```move
if (condition) () else abort code
```

Since Move 2.0, `assert` without an error code is supported. If this assert is used, the
abort code `0xCA26CBD9BE0B0000` is generated.  In terms of the `std::error` convention, this code has
category `std::error::INTERNAL` and reason `0`.

`assert` is more commonly used than just `abort` by itself. The `abort` examples above can be
rewritten using `assert`

```move
script {
  use std::vector;
  fun pop_twice<T>(v: &mut vector<T>): (T, T) {
      assert!(vector::length(v) >= 2, 42); // Now uses 'assert'

      (vector::pop_back(v), vector::pop_back(v))
  }
}
```

and

```move
script {
  use std::vector;
  fun check_vec(v: &vector<u64>, bound: u64) {
      let i = 0;
      let n = vector::length(v);
      while (i < n) {
          let cur = *vector::borrow(v, i);
          assert!(cur <= bound, 42); // Now uses 'assert'
          i = i + 1;
      }
  }
}
```

Note that because the operation is replaced with this `if-else`, the argument for the `code` is not
always evaluated. For example:

```move
assert!(true, 1 / 0)
```

Will not result in an arithmetic error, it is equivalent to

```move
if (true) () else (1 / 0)
```

So the arithmetic expression is never evaluated!

### Abort codes in the Move VM

When using `abort`, it is important to understand how the `u64` code will be used by the VM.

Normally, after successful execution, the Move VM produces a change-set for the changes made to
global storage (added/removed resources, updates to existing resources, etc.).

If an `abort` is reached, the VM will instead indicate an error. Included in that error will be two
pieces of information:

- The module that produced the abort (address and name)
- The abort code.

For example

```move
module 0x42::example {
  public fun aborts() {
    abort 42
  }
}

script {
  fun always_aborts() {
    0x2::example::aborts()
  }
}
```

If a transaction, such as the script `always_aborts` above, calls `0x2::example::aborts`, the VM
would produce an error that indicated the module `0x2::example` and the code `42`.

This can be useful for having multiple aborts being grouped together inside a module.

In this example, the module has two separate error codes used in multiple functions

```move
module 0x42::example {

  use std::vector;

  const EMPTY_VECTOR: u64 = 0;
  const INDEX_OUT_OF_BOUNDS: u64 = 1;

  // move i to j, move j to k, move k to i
  public fun rotate_three<T>(v: &mut vector<T>, i: u64, j: u64, k: u64) {
    let n = vector::length(v);
    assert!(n > 0, EMPTY_VECTOR);
    assert!(i < n, INDEX_OUT_OF_BOUNDS);
    assert!(j < n, INDEX_OUT_OF_BOUNDS);
    assert!(k < n, INDEX_OUT_OF_BOUNDS);

    vector::swap(v, i, k);
    vector::swap(v, j, k);
  }

  public fun remove_twice<T>(v: &mut vector<T>, i: u64, j: u64): (T, T) {
    let n = vector::length(v);
    assert!(n > 0, EMPTY_VECTOR);
    assert!(i < n, INDEX_OUT_OF_BOUNDS);
    assert!(j < n, INDEX_OUT_OF_BOUNDS);
    assert!(i > j, INDEX_OUT_OF_BOUNDS);

    (vector::remove<T>(v, i), vector::remove<T>(v, j))
  }
}
```

## The type of `abort`

The `abort i` expression can have any type! This is because both constructs break from the normal
control flow, so they never need to evaluate to the value of that type.

The following are not useful, but they will type check

```move
let y: address = abort 0;
```

This behavior can be helpful in situations where you have a branching instruction that produces a
value on some branches, but not all. For example:

```move
script {
  fun example() {
    let b =
        if (x == 0) false
        else if (x == 1) true
        else abort 42;
    //       ^^^^^^^^ `abort 42` has type `bool`
  }
}
```

# Address

> Learn about address types in Move for account identification, authentication, and resource location on Aptos blockchain.

`address` is a built-in type in Move that is used to represent locations (sometimes called accounts) in global storage. An `address` value is a 256-bit (32-byte) identifier. At a given address, two things can be stored: [Modules](/build/smart-contracts/book/modules-and-scripts) and [Resources](/build/smart-contracts/book/structs-and-resources).

Although an `address` is a 256-bit integer under the hood, Move addresses are intentionally opaque---they cannot be created from integers, they do not support arithmetic operations, and they cannot be modified. Even though there might be interesting programs that would use such a feature (e.g., pointer arithmetic in C fills a similar niche), Move does not allow this dynamic behavior because it has been designed from the ground up to support static verification.

You can use runtime address values (values of type `address`) to access resources at that address. You _cannot_ access modules at runtime via address values.

## Addresses and Their Syntax

Addresses come in two flavors, named or numerical. The syntax for a named address follows the
same rules for any named identifier in Move. The syntax of a numerical address is not restricted
to hex-encoded values, and any valid [`u256` numerical value](/build/smart-contracts/book/integers) can be used as an
address value, e.g., `42`, `0xCAFE`, and `2021` are all valid numerical address
literals.

To distinguish when an address is being used in an expression context or not, the
syntax when using an address differs depending on the context where it's used:

- When an address is used as an expression the address must be prefixed by the `@` character, i.e., [`@<numerical_value>`](/build/smart-contracts/book/integers) or `@<named_address_identifier>`.
- Outside of expression contexts, the address may be written without the leading `@` character, i.e., [`<numerical_value>`](/build/smart-contracts/book/integers) or `<named_address_identifier>`.

In general, you can think of `@` as an operator that takes an address from being a namespace item to being an expression item.

## Named Addresses

Named addresses are a feature that allow identifiers to be used in place of
numerical values in any spot where addresses are used, and not just at the
value level. Named addresses are declared and bound as top level elements
(outside of modules and scripts) in Move Packages, or passed as arguments
to the Move compiler.

Named addresses only exist at the source language level and will be fully
substituted for their value at the bytecode level. Because of this, modules
and module members _must_ be accessed through the module's named address
and not through the numerical value assigned to the named address during
compilation, e.g., `use my_addr::foo` is _not_ equivalent to `use 0x2::foo`
even if the Move program is compiled with `my_addr` set to `0x2`. This
distinction is discussed in more detail in the section on [Modules and Scripts](/build/smart-contracts/book/modules-and-scripts).

### Examples

```move
script {
  fun example() {
    let a1: address = @0x1; // shorthand for 0x0000000000000000000000000000000000000000000000000000000000000001
    let a2: address = @0x42; // shorthand for 0x0000000000000000000000000000000000000000000000000000000000000042
    let a3: address = @0xDEADBEEF; // shorthand for 0x00000000000000000000000000000000000000000000000000000000DEADBEEF
    let a4: address = @0x000000000000000000000000000000000000000000000000000000000000000A;
    let a5: address = @std; // Assigns `a5` the value of the named address `std`
    let a6: address = @66;
    let a7: address = @0x42;
  }
}

module 66::some_module {   // Not in expression context, so no @ needed
    use 0x1::other_module; // Not in expression context so no @ needed
    use std::vector;       // Can use a named address as a namespace item when using other modules
    ...
}

module std::other_module {  // Can use a named address as a namespace item to declare a module
    ...
}
```

## Global Storage Operations

The primary purpose of `address` values are to interact with the global storage operations.

`address` values are used with the `exists`, `borrow_global`, `borrow_global_mut`, and `move_from` [operations](/build/smart-contracts/book/global-storage-operators).

The only global storage operation that _does not_ use `address` is `move_to`, which uses [`signer`](/build/smart-contracts/book/signer).

## Ownership

As with the other scalar values built-in to the language, `address` values are implicitly copyable, meaning they can be copied without an explicit instruction such as [`copy`](/build/smart-contracts/book/variables#move-and-copy).

# Bool

> Learn about bool in Move programming language for Aptos smart contract development.

`bool` is Move's primitive type for boolean `true` and `false` values.

## Literals

Literals for `bool` are either `true` or `false`.

## Operations

### Logical

`bool` supports three logical operations:

| Syntax | Description                  | Equivalent Expression                            |
| ------ | ---------------------------- | ------------------------------------------------ |
| `&&`   | short-circuiting logical and | `p && q` is equivalent to `if (p) q else false`  |
| `\|\|` | short-circuiting logical or  | `p \|\| q` is equivalent to `if (p) true else q` |
| `!`    | logical negation             | `!p` is equivalent to `if (p) false else true`   |

### Control Flow

`bool` values are used in several of Move's control-flow constructs:

- [`if (bool) { ... }`](/build/smart-contracts/book/conditionals)
- [`while (bool) { .. }`](/build/smart-contracts/book/loops)
- [`assert!(bool, u64)`](/build/smart-contracts/book/abort-and-assert)

## Ownership

As with the other scalar values built into the language, boolean values are implicitly copyable,
meaning they can be copied without an explicit instruction such as
[`copy`](/build/smart-contracts/book/variables#move-and-copy).

# Move Coding Conventions

> Follow Move coding conventions, style guidelines, and best practices for clean, maintainable smart contract code.

This section lays out some basic coding conventions for Move that the Move team has found helpful. These are only recommendations, and you should feel free to use other formatting guidelines and conventions if you have a preference for them.

## Naming

- **Module names**: should be lowercase snake case, e.g., `fixed_point32`, `vector`.
- **Type names**: should be camel case if they are not a native type, e.g., `Coin`, `RoleId`.
- **Function names**: should be lowercase snake case, e.g., `destroy_empty`.
- **Constant names**: should be upper camel case and begin with an `E` if they represent error codes (e.g., `EIndexOutOfBounds`) and upper snake case if they represent a non-error value (e.g., `MIN_STAKE`).
-
- **Generic type names**: should be descriptive, or anti-descriptive where appropriate, e.g., `T` or `Element` for the Vector generic type parameter. Most of the time the "main" type in a module should be the same name as the module e.g., `option::Option`, `fixed_point32::FixedPoint32`.
- **Module file names**: should be the same as the module name e.g., `option.move`.
- **Script file names**: should be lowercase snake case and should match the name of the "main" function in the script.
- **Mixed file names**: If the file contains multiple modules and/or scripts, the file name should be lowercase snake case, where the name does not match any particular module/script inside.

## Imports

- All module `use` statements should be at the top of the module.
- Functions should be imported and used fully qualified from the module in which they are declared, and not imported at the top level.
- Types should be imported at the top-level. Where there are name clashes, `as` should be used to rename the type locally as appropriate.

For example, if there is a module:

```move
module 0x1::foo {
  struct Foo { }
  const CONST_FOO: u64 = 0;
  public fun do_foo(): Foo { Foo{} }
  // ...
}
```

this would be imported and used as:

```move
module 0x1::bar {
  use 0x1::foo::{Self, Foo};

  public fun do_bar(x: u64): Foo {
    if (x == 10) {
      foo::do_foo()
    } else {
      abort 0
    }
  }
  // ...
}
```

And, if there is a local name-clash when importing two modules:

```move
module 0x1::other_foo {
  struct Foo {}
  // ...
}

module 0x1::importer {
  use 0x1::other_foo::Foo as OtherFoo;
  use 0x1::foo::Foo;
  // ...
}
```

## Comments

- Each module, struct, and public function declaration should be commented.
- Move has doc comments `///`, regular single-line comments `//`, block comments `/* */`, and block doc comments `/** */`.
- Starting Aptos CLI 7.4.0, UTF-8 characters are allowed in comments.

### Comments Example

Doc comments must be directly above the item they are commenting on. For example, the following is valid:

```move
/// My awesome module, doc comment can be used here
module 0x42::example { // double slash can be anywhere

  // Double slash can be anywhere

  /// My awesome constant
  const MY_VALUE: u64 = 5;

  /// My awesome error message
  const E_MY_ERROR: u64 = 10;

  #[view]
  /// My awesome view function
  fun show_me_the_money() {
    // ...
  }

  /* Similarly block comments can be anywhere */
}
```

Below here are examples of doc comments `///` that will fail

```move
module 0x42::example {

  /// My awesome view function <- must be below the annotation, right above the thing commented
  #[view]
  fun show_me_the_money() {
    // ...
    /// Within a function
  }

  /// Not attached to anything
}
```

## Formatting

The Move team plans to write an auto-formatter to enforce formatting conventions. However, in the meantime:

- Four space indentation should be used except for `script` and `address` blocks whose contents should not be indented.
- Lines should be broken if they are longer than 100 characters.
- Structs and constants should be declared before all functions in a module.

# Comparison

> Understand comparison operations and their semantics in Move programming language.

Move supports four comparison operations `<`, `>`, `<=`, and `>=`.

## Operations

| Syntax | Operation                |
| ------ | ------------------------ |
| `<`    | less than                |
| `>`    | greater than             |
| `<=`   | less than or equal to    |
| `>=`   | greater than or equal to |

### Typing

Comparison operations only work if both operands have the same type.

```move
script {
  fun example() {
    0 >= 0; // `true`
    1u128 > 2u128; // `false`
  }
}
```

If the operands have different types, there is a type checking error.

```move
script {
  fun example() {
    1u8 >= 1u128; // ERROR!
    //     ^^^^^ expected an argument of type `u8`
  }
}
```

Prior to language version 2.2, comparison operations only work with integer types. _Since language
version 2.2_, comparison operations work with all types.

| Type           | Semantics                                                                                                   |
| -------------- | ----------------------------------------------------------------------------------------------------------- |
| integer        | compare by the numerical value                                                                              |
| `bool`         | `true` being larger than `false`                                                                            |
| `address`      | compare as 256-bit unsigned integers                                                                        |
| `signer`       | compare by the `address` wrapped by the `signer`                                                            |
| `struct`       | compare by field values first, and then by the number of fields.                                            |
| `vector`       | compare by element values first, and then by the number of elements                                         |
| function value | compare in order by module address, module name, function name, argument type list, and captured value list |
| reference      | compare by the value being referenced                                                                       |

```move
module 0x42::example {
    struct S has copy, drop { f: u64, s: vector<u8> }

    fun true_example(): bool {
        let s1 = S { f: 0, s: b"" };
        let s2 = S { f: 1, s: b"" };
        // return true
        s1 < s2
    }

    fun false_example(): bool {
        let s1 = S { f: 0, s: b"abc" };
        let s2 = S { f: 0, s: b"" };
        // return false
        s1 < s2
    }
}
```

### Typing with references

When comparing [references](/build/smart-contracts/book/references), the values being referenced are compared. The type of the reference (immutable or mutable) does
not matter. This means that you can compare an immutable `&` reference with a mutable one `&mut` of
the same underlying type.

```move
script {
  fun example() {
    let i = &0u64;
    let m = &mut 1u64;

    i > m; // `false`
    m < i; // `false`
    m >= m; // `true`
    i <= i; // `true`
  }
}
```

The above is equivalent to applying an explicit freeze to each mutable reference where needed

```move
script {
  fun example() {
    let i = &0u64;
    let m = &mut 1u64;

    i > freeze(m); // `false`
    freeze(m) < i; // `false`
    m >= m; // `true`
    i <= i; // `true`
  }
}
```

But again, the underlying type must be the same.

```move
script {
  fun example() {
    let i = &0u64;
    let s = &b"";

    i > s; // ERROR!
    //   ^ expected an argument of type '&u64'
  }
}
```

## Comparing to `==` and `!=`

Comparison operations consume operands for integers but automatically borrow them for non-integer types.
This differs from the [equality `==` and inequality `!=`](/build/smart-contracts/book/equality#restrictions) operations, which always consume their operands
and mandate the [`drop` ability](/build/smart-contracts/book/abilities).

```move
module 0x42::example {
  struct Coin has store { value: u64 }
  fun invalid(c1: Coin, c2: Coin) {
    c1 <= c2 // OK!
    c1 == c2 // ERROR!
//  ^^    ^^ These resources would be destroyed!
  }
}
```

# Conditionals

> Learn conditional expressions and control flow patterns in Move with if-else statements and match expressions.

An `if` expression specifies that some code should only be evaluated if a certain condition is true. For example:

```move
script {
  fun example() {
    if (x > 5) x = x - 5
  }
}
```

The condition must be an expression of type `bool`.

An `if` expression can optionally include an `else` clause to specify another expression to evaluate when the condition is false.

```move
script {
  fun example() {
    if (y <= 10) y = y + 1 else y = 10
  }
}
```

Either the "true" branch or the "false" branch will be evaluated, but not both. Either branch can be a single expression or an expression block.

The conditional expressions may produce values so that the `if` expression has a result.

```move
script {
  fun example() {
    let z = if (x < 100) x else 100;
  }
}
```

The expressions in the true and false branches must have compatible types. For example:

```move
script {
  fun example() {
    // x and y must be u64 integers
    let maximum: u64 = if (x > y) x else y;

    // ERROR! branches different types
    let z = if (maximum < 10) 10u8 else 100u64;

    // ERROR! branches different types, as default false-branch is () not u64
    if (maximum >= 10) maximum;
  }
}
```

If the `else` clause is not specified, the false branch defaults to the unit value. The following are equivalent:

```move
script {
  fun example() {
    if (condition) true_branch // implied default: else ()
    if (condition) true_branch else ()
  }
}
```

Commonly, [`if` expressions](/build/smart-contracts/book/conditionals) are used in conjunction with expression blocks.

```move
script {
  fun example() {
    let maximum = if (x > y) x else y;
    if (maximum < 10) {
        x = x + 10;
        y = y + 10;
    } else if (x >= 10 && y >= 10) {
        x = x - 10;
        y = y - 10;
    }
  }
}

```

## Grammar for Conditionals

> _if-expression_ ‚Üí **if (** _expression_ **)** _expression_ _else-clause_<sub>_opt_</sub>

> _else-clause_ ‚Üí **else** _expression_

# Constants

> Learn about constants in Move programming language for Aptos smart contract development.

Constants are a way of giving a name to shared, static values inside of a `module` or `script`.

The constant's must be known at compilation. The constant's value is stored in the compiled module
or script. And each time the constant is used, a new copy of that value is made.

## Declaration

Constant declarations begin with the `const` keyword, followed by a name, a type, and a value. They
can exist in either a script or module

```text
const <name>: <type> = <expression>;
```

For example

```move
script {
  const MY_ERROR_CODE: u64 = 0;

  fun main(input: u64) {
    assert!(input > 0, MY_ERROR_CODE);
  }
}

module 0x42::example {
  const MY_ADDRESS: address = @0x42;

  public fun permissioned(s: &signer) {
    assert!(std::signer::address_of(s) == MY_ADDRESS, 0);
  }
}
```

## Naming

Constants must start with a capital letter `A` to `Z`. After the first letter, constant names can
contain underscores `_`, letters `a` to `z`, letters `A` to `Z`, or digits `0` to `9`.

```move
script {
  const FLAG: bool = false;
  const MY_ERROR_CODE: u64 = 0;
  const ADDRESS_42: address = @0x42;
}
```

Even though you can use letters `a` to `z` in a constant. The
[general style guidelines](/build/smart-contracts/book/coding-conventions) are to use just uppercase letters `A` to `Z`,
with underscores `_` between each word.

This naming restriction of starting with `A` to `Z` is in place to give room for future language
features. It may or may not be removed later.

## Visibility

`public` constants are not currently supported. `const` values can be used only in the declaring
module.

## Valid Expressions

Currently, constants are limited to the primitive types `bool`, `u8`, `u16`, `u32`, `u64`, `u128`, `u256`, `address`, and
`vector<u8>`. Future support for other `vector` values (besides the "string"-style literals) will
come later.

### Values

Commonly, `const`s are assigned a simple value, or literal, of their type. For example

```move
script {
  const MY_BOOL: bool = false;
  const MY_ADDRESS: address = @0x70DD;
  const BYTES: vector<u8> = b"hello world";
  const HEX_BYTES: vector<u8> = x"DEADBEEF";
}
```

### Complex Expressions

In addition to literals, constants can include more complex expressions, as long as the compiler is
able to reduce the expression to a value at compile time.

Currently, equality operations, all boolean operations, all bitwise operations, and all arithmetic
operations can be used.

```move
script {
  const RULE: bool = true && false;
  const CAP: u64 = 10 * 100 + 1;
  const SHIFTY: u8 = {
    (1 << 1) * (1 << 2) * (1 << 3) * (1 << 4)
  };
  const HALF_MAX: u128 = 340282366920938463463374607431768211455 / 2;
  const REM: u256 = 57896044618658097711785492504343953926634992332820282019728792003956564819968 % 654321;
  const EQUAL: bool = 1 == 1;
}
```

If the operation results in a runtime exception, the compiler will give an error that it is
unable to generate the constant's value

```move
script {
  const DIV_BY_ZERO: u64 = 1 / 0; // error!
  const SHIFT_BY_A_LOT: u64 = 1 << 100; // error!
  const NEGATIVE_U64: u64 = 0 - 1; // error!
}
```

Note that constants cannot currently refer to other constants. This feature, along with support for
other expressions, will be added in the future.

## Builtin Constants

Builtin constants are predefined named values which can be used from anywhere in the code. The following constants are supported:

_since language version 2.2_

| Name                            | Value                                                |
| ------------------------------- | ---------------------------------------------------- |
| `__COMPILE_FOR_TESTING__: bool` | `true` when compiling unit tests, `false`  otherwise |

_since language version 2.3_

| Name             | Value               |
| ---------------- | ------------------- |
| `MAX_U8: u8`     | 2<sup>8</sup> - 1   |
| `MAX_U16: u16`   | 2<sup>16</sup> - 1  |
| `MAX_U32: u32`   | 2<sup>32</sup> - 1  |
| `MAX_U64: u64`   | 2<sup>64</sup> - 1  |
| `MAX_U128: u128` | 2<sup>128</sup> - 1 |
| `MAX_U256: u256` | 2<sup>256</sup> - 1 |
| `MAX_I8: i8`     | 2<sup>7</sup> - 1   |
| `MAX_I16: i16`   | 2<sup>15</sup> - 1  |
| `MAX_I32: i32`   | 2<sup>31</sup> - 1  |
| `MAX_I64: i64`   | 2<sup>63</sup> - 1  |
| `MAX_I128: i128` | 2<sup>127</sup> - 1 |
| `MAX_I256: i256` | 2<sup>255</sup> - 1 |
| `MIN_I8: i8`     | -2<sup>7</sup>      |
| `MIN_I16: i16`   | -2<sup>15</sup>     |
| `MIN_I32: i32`   | -2<sup>31</sup>     |
| `MIN_I64: i64`   | -2<sup>63</sup>     |
| `MIN_I128: i128` | -2<sup>127</sup>    |
| `MIN_I256: i256` | -2<sup>255</sup>    |

A builtin constant can be shadowed by a user declaration. For example, the below code is valid in language version 2.3, and the builtin constant will simply be shadowed:

```move
module 0x44::m {
   const MAX_U8: u8 = 255; // User defined constant shadowing builtin constant
}
```

# Enums

> Learn about enum types in Move for defining variant types, pattern matching, and type-safe state representation.

_Since language version 2.0_

Enum types are similar to struct types but support defining multiple _variants_ of the data layout. Each variant has its distinct set of fields. Enum variants are supported in expressions, tools for testing, matching, and deconstructing.

## Declaration of Enum Types

An enum type declaration lists the number of different variants, as seen in the example below:

```move
enum Shape {
    Circle{radius: u64},
    Rectangle{width: u64, height: u64}
}
```

There can be zero or more fields for an enum variant. If no arguments are given, the braces can also be omitted, declaring simple values:

```move
enum Color {
  Red, Blue, Green
}
```

Like struct types, enum types can have abilities. For example, the `Color` enum type would be appropriately declared as copyable, droppable, and storable, like primitive number types:

```move
enum Color has copy, drop, store, key { Red, Blue, Green }
```

Enum types can also have the `key` ability and appear as roots of data in global storage. A common usage of enums in this context is versioning of data:

```move
enum VersionedData has key {
  V1{name: String}
  V2{name: String, age: u64}
}
```

Similar to structs, enum types can be generic and take positional arguments. For example, the type below represents a generic result type, where the variant constructors use positional instead of named arguments (see also [positional structs](/build/smart-contracts/book/structs-and-resources#positional-structs)).

```move
enum Result<T> has copy, drop, store {
  Err(u64),
  Ok(T)
}
```

## Constructing Enum Values

An enum value is constructed similarly to a struct value:

```move
let s: String;
let data = VersionedData::V1{name: s};
```

If the enum variant has no fields, the braces can also be omitted:

```move
let color = Color::Blue;
```

## Name Resolution for Enum Variants

The variant names for an enum need to be qualified by the enum type name, as in `VersionedData::V1`.

> Note: Aliasing via the `use` clause is currently not supported for enum variants, but will be added in later language versions

In certain cases (such as match expressions, below), the Move compiler can infer the enum type from the context, and the qualification by the type name may be omitted:

```move
fun f(data: VersionedData) {
  match (data) { V1{..} => .., ..} // simple variant name OK
}
```

## Matching Enum Values

The value of an enum value can be inspected using a match expression. For example:

```move
fun area(self: &Shape): u64 {
    match (self) {
        Circle{radius}           => mul_with_pi(*radius * *radius),
        Rectangle{width, height} => *width * *height
    }
}
```

Notice above that the value matched is an immutable reference to an enum value. A match expression can also consume a value, or match over a mutable reference for interior updates:

```move
fun scale_radius(self: &mut Shape, factor:  u64) {
    match (self) {
        Circle{radius: r} => *r = *r * factor,
        _                 => {} // do nothing if not a Circle
  }
}
```

The patterns provided in the match expression are evaluated sequentially, in order of textual occurrence, until a match is found. It is a compile time error if not all known patterns are covered.

Patterns can be nested and contain conditions, as in the following example:

```move
let r : Result<Result<u64>> = Ok(Err(42));
let v = match (r) {
  Ok(Err(c)) if c < 42  => 0,
  Ok(Err(c)) if c >= 42 => 1,
  Ok(_)                 => 2,
  _                     => 3
};
assert!(v == 1);
```

Notice that in the above example, the last match clause (`_`) covers both patterns `Ok(Err(_))` and `Err(_)`.  Although at execution time, the earlier clauses match `Ok(Err(c))` for all values of `c`, the compiler cannot be sure all cases are covered due to the conditionals: conditions in match expressions are not considered when tracking coverage.  Thus the first two clauses in the match expression above are not sufficient for match completeness, and an additional clause is required to avoid a compiler error.

## Testing Enum Variants

With the `is` operator, one can examine whether a given enum value is of a given variant:

```move
let data: VersionedData;
if (data is VersionedData::V1) { .. }
```

The operator allows specifying a list of variants, separated by "`|`" characters. The variants need not be qualified by the enum name if the type of the expression being tested is known:

```move
assert!(data is V1|V2);
```

## Selecting From Enum Values

It is possible to directly select a field from an enum value. Recall the definition of versioned data:

```move
enum VersionedData has key {
  V1{name: String}
  V2{name: String, age: u64}
}
```

One can write code as below to directly select the fields of variants:

```move
let s: String;
let data1 = VersionedData::V1{name: s};
let data2 = VersionedData::V2{name: s, age: 20};
assert!(data1.name == data2.name)
assert!(data2.age == 20);
```

Notice that field selection aborts if the enum value has no variant with the given field. This is the case for  `data1.age`.
The abort code used for this case is `0xCA26CBD9BE0B0001`. In terms of the `std::error` convention, this code has
category `std::error::INTERNAL` and reason `1`.

Field selection is only possible if the field is uniquely named and typed throughout all variants. Thus, the following yields a compile time error:

```move
enum VersionedData has key {
  V1{name: String}
  V2{name: u64}
}

data.name
 // ^^^^^ compile time error that `name` field selection is ambiguous
```

## Using Enums Patterns in Lets

An enum variant pattern may be used in a `let` statement:

```move
let data: VersionData;
let V1{name} = data;
```

Unpacking the enum value will abort if the variant is not the expected one. To ensure that all variants of an enum are handled, a `match` expression is recommended instead of a `let`. The `match` is checked at compile time, ensuring that all variants are covered. In some cases, tools like the Move Prover can be used to verify that unexpected aborts cannot happen with a `let`.

## Destroying Enums via Pattern Matching

Similar to struct values, enum values can be destroyed by explicitly unpacking them. Enums can be unpacked with pattern matching in a `match` expression, enum pattern in a `let` binding, or enum pattern in an assignment.

```move
// Note: `Shape` has no `drop` ability, so must be destroyed with explicit unpacking.
enum Shape {
    Circle{radius: u64},
    Rectangle{width: u64, height: u64}
}

fun destroy_empty(self: Shape) {
    match (self) {
        Shape::Circle{radius} => assert!(radius == 0),
        Shape::Rectangle{width, height: _} => assert!(width == 0),
    }
}

fun example_destroy_shapes() {
    let c = Shape::Circle{radius: 0};
    let r = Shape::Rectangle{width: 0, height: 0};
    c.destroy_empty();
    r.destroy_empty();
}
```

## Enum Type Upgrade Compatibility

An enum type can be upgraded by another enum type if the new type only adds new variants at the end of the variant list. All variants present in the old enum type must also appear in the new type, in the same order and starting from the beginning. Consider the `VersionedData` type, which might have begun with a single version:

```move
enum VersionedData has key {
  V1{name: String}
}
```

This type could be upgraded to the version we used so far in this text:

```move
enum VersionedData has key {
  V1{name: String}
  V2{name: String, age: u64}
}
```

The following upgrade would not be allowed, since the order of variants must be preserved:

```move
enum VersionedData has key {
  V2{name: String, age: u64}   // not a compatible upgrade
  V1{name: String}
}
```

# Equality

> Understand equality operations, comparison semantics, and type checking in Move programming language.

Move supports two equality operations `==` and `!=`

## Operations

| Syntax | Operation | Description                                                                 |
| ------ | --------- | --------------------------------------------------------------------------- |
| `==`   | equal     | Returns `true` if the two operands have the same value, `false` otherwise   |
| `!=`   | not equal | Returns `true` if the two operands have different values, `false` otherwise |

### Typing

Both the equal (`==`) and not-equal (`!=`) operations only work if both operands are the same type

```move
script {
  fun example() {
    0 == 0; // `true`
    1u128 == 2u128; // `false`
    b"hello" != x"00"; // `true`
  }
}
```

Equality and non-equality also work over user defined types!

```move
module 0x42::example {
    struct S has copy, drop { f: u64, s: vector<u8> }

    fun always_true(): bool {
        let s = S { f: 0, s: b"" };
        // parens are not needed but added for clarity in this example
        (copy s) == s
    }

    fun always_false(): bool {
        let s = S { f: 0, s: b"" };
        // parens are not needed but added for clarity in this example
        (copy s) != s
    }
}
```

If the operands have different types, there is a type checking error

```move
script {
  fun example() {
    1u8 == 1u128; // ERROR!
    //     ^^^^^ expected an argument of type 'u8'
    b"" != 0; // ERROR!
    //     ^ expected an argument of type 'vector<u8>'
  }
}
```

### Typing with references

When comparing [references](/build/smart-contracts/book/references), the type of the reference (immutable or mutable) does
not matter. This means that you can compare an immutable `&` reference with a mutable one `&mut` of
the same underlying type.

```move
script {
  fun example() {
    let i = &0;
    let m = &mut 1;

    i == m; // `false`
    m == i; // `false`
    m == m; // `true`
    i == i; // `true`
  }
}
```

The above is equivalent to applying an explicit freeze to each mutable reference where needed

```move
script {
  fun example() {
    let i = &0;
    let m = &mut 1;

    i == freeze(m); // `false`
    freeze(m) == i; // `false`
    m == m; // `true`
    i == i; // `true`
  }
}
```

But again, the underlying type must be the same type

```move
script {
  fun example() {
    let i = &0;
    let s = &b"";

    i == s; // ERROR!
    //   ^ expected an argument of type '&u64'
  }
}
```

## Restrictions

Both `==` and `!=` consume the value when comparing them. As a result, the type system enforces that
the type must have [`drop`](/build/smart-contracts/book/abilities). Recall that without the
[`drop` ability](/build/smart-contracts/book/abilities), ownership must be transferred by the end of the function, and such
values can only be explicitly destroyed within their declaring module. If these were used directly
with either equality `==` or non-equality `!=`, the value would be destroyed which would break
[`drop` ability](/build/smart-contracts/book/abilities) safety guarantees!

```move
module 0x42::example {
  struct Coin has store { value: u64 }
  fun invalid(c1: Coin, c2: Coin) {
    c1 == c2 // ERROR!
//  ^^    ^^ These resources would be destroyed!
  }
}
```

But, a programmer can _always_ borrow the value first instead of directly comparing the value, and
reference types have the [`drop` ability](/build/smart-contracts/book/abilities). For example

```move
module 0x42::example {
  struct Coin has store { value: u64 }
  fun swap_if_equal(c1: Coin, c2: Coin): (Coin, Coin) {
    let are_equal = &c1 == &c2; // valid
    if (are_equal) (c2, c1) else (c1, c2)
  }
}
```

## Avoid Extra Copies

While a programmer _can_ compare any value whose type has [`drop`](/build/smart-contracts/book/abilities), a programmer
should often compare by reference to avoid expensive copies.

```move
script {
  fun example() {
    let v1: vector<u8> = function_that_returns_vector();
    let v2: vector<u8> = function_that_returns_vector();
    assert!(copy v1 == copy v2, 42);
    //     ^^^^       ^^^^
    use_two_vectors(v1, v2);

    let s1: Foo = function_that_returns_large_struct();
    let s2: Foo = function_that_returns_large_struct();
    assert!(copy s1 == copy s2, 42);
    //     ^^^^       ^^^^
    use_two_foos(s1, s2);
  }
}
```

This code is perfectly acceptable (assuming `Foo` has [`drop`](/build/smart-contracts/book/abilities)), just not efficient.
The highlighted copies can be removed and replaced with borrows

```move
script {
  fun example() {
    let v1: vector<u8> = function_that_returns_vector();
    let v2: vector<u8> = function_that_returns_vector();
    assert!(&v1 == &v2, 42);
    //     ^      ^
    use_two_vectors(v1, v2);

    let s1: Foo = function_that_returns_large_struct();
    let s2: Foo = function_that_returns_large_struct();
    assert!(&s1 == &s2, 42);
    //     ^      ^
    use_two_foos(s1, s2);
  }
}
```

The efficiency of the `==` itself remains the same, but the `copy`s are removed and thus the program
is more efficient.

# Friends

> Learn about friend functions in Move for controlled access to internal module functionality and secure interfaces.

The `friend` syntax is used to declare modules that are trusted by the current module.
A trusted module is allowed to call any function defined in the current module that have the `public(friend)` visibility.
For details on function visibilities, please refer to the _Visibility_ section in [Functions](/build/smart-contracts/book/functions).

## Friend declaration

A module can declare other modules as friends via friend declaration statements, in the format of

- `friend <address::name>` ‚Äî friend declaration using fully qualified module name like the example below, or

  ```move
  module 0x42::a {
      friend 0x42::b;
  }
  ```

- `friend <module-name-alias>` ‚Äî friend declaration using a module name alias, where the module alias is introduced via the `use` statement.

  ```move
  module 0x42::a {
      use 0x42::b;
      friend b;
  }
  ```

A module may have multiple friend declarations, and the union of all the friend modules forms the friend list.
In the example below, both `0x42::B` and `0x42::C` are considered as friends of `0x42::A`.

```move
module 0x42::a {
    friend 0x42::b;
    friend 0x42::c;
}
```

Unlike `use` statements, `friend` can only be declared in the module scope and not in the expression block scope.
`friend` declarations may be located anywhere a top-level construct (e.g., `use`, `function`, `struct`, etc.) is allowed.
However, for readability, it is advised to place friend declarations near the beginning of the module definition.

Note that the concept of friendship does not apply to Move scripts:

- A Move script cannot declare `friend` modules as doing so is considered meaningless: there is no mechanism to call the function defined in a script.
- A Move module cannot declare `friend` scripts as well because scripts are ephemeral code snippets that are never published to global storage.

### Friend declaration rules

Friend declarations are subject to the following rules:

- A module cannot declare itself as a friend.

  ```move
  module 0x42::m {
    friend Self; // ERROR!
  //       ^^^^ Cannot declare the module itself as a friend
  }

  module 0x43::m {
    friend 0x43::M; // ERROR
  //       ^^^^^^^ Cannot declare the module itself as a friend
  }
  ```

- Friend modules must be known by the compiler

  ```move
  module 0x42::m {
    friend 0x42::nonexistent; // ERROR!
    //     ^^^^^^^^^^^^^^^^^ Unbound module '0x42::nonexistent'
  }
  ```

- Friend modules must be within the same account address. (Note: this is not a technical requirement but rather a policy decision which _may_ be relaxed later.)

  ```move
  module 0x42::m {}

  module 0x43::n {
    friend 0x42::m; // ERROR!
  //       ^^^^^^^ Cannot declare modules out of the current address as a friend
  }
  ```

- Friends relationships cannot create cyclic module dependencies.

  Cycles are not allowed in the friend relationships, e.g., the relation `0x2::a` friends `0x2::b` friends `0x2::c` friends `0x2::a` is not allowed.
  More generally, declaring a friend module adds a dependency upon the current module to the friend module (because the purpose is for the friend to call functions in the current module).
  If that friend module is already used, either directly or transitively, a cycle of dependencies would be created.

  ```move
  address 0x2 {
    module a {
      use 0x2::c;
      friend 0x2::b;

      public fun a() {
        c::c()
      }
    }

    module b {
      friend 0x2::c; // ERROR!
    //       ^^^^^^ This friend relationship creates a dependency cycle: '0x2::b' is a friend of '0x2::a' uses '0x2::c' is a friend of '0x2::b'
    }

    module c {
      public fun c() {}
    }
  }
  ```

- The friend list for a module cannot contain duplicates.

  ```move
  address 0x42 {
    module a {}

    module m {
      use 0x42::a as aliased_a;
      friend 0x42::A;
      friend aliased_a; // ERROR!
    //       ^^^^^^^^^ Duplicate friend declaration '0x42::a'. Friend declarations in a module must be unique
    }
  }
  ```

# Functions

> Learn about functions in Move programming language for Aptos smart contract development.

import { Aside } from '@astrojs/starlight/components';

Function syntax in Move is shared between module functions and script functions. Functions inside of modules are reusable, whereas script functions are only used once to invoke a transaction.

## Declaration

Functions are declared with the `fun` keyword followed by the function name, type parameters, parameters, a return type, acquires annotations, and finally the function body.

```text
fun <identifier><[type_parameters: constraint],*>([identifier: type],*): <return_type> <acquires [identifier],*> <function_body>
```

For example

```move
fun foo<T1, T2>(x: u64, y: T1, z: T2): (T2, T1, u64) { (z, y, x) }
```

### Visibility

Module functions, by default, can only be called within the same module. These internal (sometimes called private) functions cannot be called from other modules or from scripts.

```move
address 0x42 {
module m {
    fun foo(): u64 { 0 }

    fun calls_foo(): u64 { foo() } // valid
}

module other {
    fun calls_m_foo(): u64 {
        0x42::m::foo() // ERROR!
        //       ^^^^^ `foo` is internal to `0x42::m`
    }
}
}

script {
    fun calls_m_foo(): u64 {
        0x42::m::foo() // ERROR!
        //       ^^^^^ `foo` is internal to `0x42::m`
    }
}
```

To allow access from other modules or from scripts, the function must be declared `public` or `public(friend)`.

#### `public` visibility

A `public` function can be called by _any_ function defined in _any_ module or script. As shown in the following example, a `public` function can be called by:

- other functions defined in the same module,
- functions defined in another module, or
- the function defined in a script.

There are also no restrictions for what the argument types a public function can take and its return type.

```move
address 0x42 {
module m {
    public fun foo(): u64 { 0 }

    fun calls_foo(): u64 { foo() } // valid
}

module other {
    fun calls_m_foo(): u64 {
        0x42::m::foo() // valid
    }
}
}

script {
    fun calls_m_foo(): u64 {
        0x42::m::foo() // valid
    }
}
```

### `package` visibility

_Since Language Version 2.0_

A `package` function can be only called within the same package. The notion of a package is
defined by the hosting environment of Move, and not explicit in the language. Typically, the package
is defined by a manifest file `Move.toml` which is processed by the build environment.

The following works, provided the two modules belong to the same package and are at the same address:

```move
module 0x42::m {
  package fun foo(): u64 { 0 }
}

module 0x42::other {
  fun calls_m_foo(): u64 {
    0x42::m::foo() // valid
  }
}
```

An attempt to access `0x42::m::foo` from another package will fail at compile time.

In addition to the notation `package fun`, also the longer notation `public(package) fun` is supported.

Notice that package visibility is a compile time concept which is reduced by the compiler to friend visibility (described [below](#friend-visibility)), which can be verified by the Move VM. The Move VM guarantees that friend functions
cannot be called across address boundaries, independent of what package system a compilation environment supports.

#### `public(friend)` visibility

_Since Language Version 2.0_, `friend fun` replaces `public(friend) fun`. The old notation is still supported.

The `public(friend)` visibility modifier is a more restricted form of the `public` modifier to give more control about where a function can be used. A `public(friend)` function can be called by:

- other functions defined in the same module, or
- functions defined in modules which are explicitly specified in the **friend list** (see [Friends](/build/smart-contracts/book/friends) on how to specify the friend list), and which reside at the same address.

Note that since we cannot declare a script to be a friend of a module, the functions defined in scripts can never call a `public(friend)` function.

```move
address 0x42 {
module m {
    friend 0x42::n;  // friend declaration
    public(friend) fun foo(): u64 { 0 }
    friend fun foo2(): u64 { 0 } // Since Move 2.0

    fun calls_foo(): u64 { foo() } // valid
    fun calls_foo2(): u64 { foo2() } // valid, since Move 2.0
}

module n {
    fun calls_m_foo(): u64 {
        0x42::m::foo() // valid
    }

    fun calls_m_foo2(): u64 {
        0x42::m::foo2() // valid, since Move 2.0
    }
}

module other {
    fun calls_m_foo(): u64 {
        0x42::m::foo() // ERROR!
        //       ^^^^^ `foo` can only be called from a `friend` of module `0x42::m`
    }

    fun calls_m_foo2(): u64 {
        0x42::m::foo2() // ERROR!
        //       ^^^^^^ `foo2` can only be called from a `friend` of module `0x42::m`
    }
}
}

script {
    fun calls_m_foo(): u64 {
        0x42::m::foo() // ERROR!
        //       ^^^^^ `foo` can only be called from a `friend` of module `0x42::m`
    }
}
```

### `entry` modifier

The `entry` modifier is designed to allow module functions to be safely and directly invoked much like scripts. This allows module writers to specify which functions can be invoked to begin execution. The module writer then knows that any non-`entry` function will be called from a Move program already in execution.

Essentially, `entry` functions are the "main" functions of a module, and they specify where Move programs start executing.

Note though, an `entry` function _can_ still be called by other Move functions. So while they _can_ serve as the start of a Move program, they aren't restricted to that case.

For example:

```move
address 0x42 {
module m {
    public entry fun foo() {}

    fun calls_foo() { foo(); } // valid!
}

module n {
    fun calls_m_foo() {
        0x42::m::foo(); // valid!
    }
}

module other {
    public entry fun calls_m_foo() {
        0x42::m::foo(); // valid!
    }
}
}

script {
    fun calls_m_foo() {
        0x42::m::foo(); // valid!
    }
}
```

Even internal functions can be marked as `entry`! This lets you guarantee that the function is called only at the beginning of execution (assuming you do not call it elsewhere in your module)

```move
address 0x42 {
module m {
    entry fun foo() {} // valid! entry functions do not have to be public
}

module n {
    fun calls_m_foo() {
        0x42::m::foo(); // ERROR!
        //       ^^^^^ `foo` is internal to `0x42::m`
    }
}

module other {
    public entry fun calls_m_foo() {
        0x42::m::foo(); // ERROR!
        //       ^^^^^ `foo` is internal to `0x42::m`
    }
}
}

script {
    fun calls_m_foo() {
        0x42::m::foo(); // ERROR!
        //       ^^^^^ `foo` is internal to `0x42::m`
    }
}
```

Entry functions can accept parameters that are: primitive types, reference to a
`signer`, vectors (where the element type is itself acceptable),
and certain standard library types such as `String`, `Object`, and `Option`.
Entry functions must not have any return values.

### Name

Function names can start with letters `a` to `z` or letters `A` to `Z`. After the first character, function names can contain underscores `_`, letters `a` to `z`, letters `A` to `Z`, or digits `0` to `9`.

```move
module 0x42::example {
    // all valid
    fun FOO() {}

    fun bar_42() {}

    fun bAZ19() {}

    // invalid
    fun _bAZ19() {} // Function names cannot start with '_'
}
```

### Type Parameters

After the name, functions can have type parameters

```move
module 0x42::example {
    fun id<T>(x: T): T { x }

    fun example<T1: copy, T2>(x: T1, y: T2): (T1, T1, T2) { (copy x, x, y) }
}
```

For more details, see [Move generics](/build/smart-contracts/book/generics).

### Parameters

Functions parameters are declared with a local variable name followed by a type annotation

```move
module 0x42::example {
    fun add(x: u64, y: u64): u64 { x + y }
}
```

We read this as `x` has type `u64`

A function does not have to have any parameters at all.

```move
module 0x42::example {
    fun useless() {}
}
```

This is very common for functions that create new or empty data structures

```move
module 0x42::example {
    struct Counter { count: u64 }

    fun new_counter(): Counter {
        Counter { count: 0 }
    }
}
```

### Acquires

When a function accesses a resource using `move_from`, `borrow_global`, or `borrow_global_mut`, the function must indicate that it `acquires` that resource. This is then used by Move's type system to ensure the references into global storage are safe, specifically that there are no dangling references into global storage.

```move
module 0x42::example {

    struct Balance has key { value: u64 }

    public fun add_balance(s: &signer, value: u64) {
        move_to(s, Balance { value })
    }

    public fun extract_balance(addr: address): u64 acquires Balance {
        let Balance { value } = move_from<Balance>(addr); // acquires needed
        value
    }
}
```

`acquires` annotations must also be added for transitive calls within the module. Calls to these functions from another module do not need to annotated with these acquires because one module cannot access resources declared in another module--so the annotation is not needed to ensure reference safety.

```move
module 0x42::example {

    struct Balance has key { value: u64 }

    public fun add_balance(s: &signer, value: u64) {
        move_to(s, Balance { value })
    }

    public fun extract_balance(addr: address): u64 acquires Balance {
        let Balance { value } = move_from<Balance>(addr); // acquires needed
        value
    }

    public fun extract_and_add(sender: address, receiver: &signer) acquires Balance {
        let value = extract_balance(sender); // acquires needed here
        add_balance(receiver, value)
    }
}

module 0x42::other {
    fun extract_balance(addr: address): u64 {
        0x42::example::extract_balance(addr) // no acquires needed
    }
}
```

A function can `acquire` as many resources as it needs to

```move
module 0x42::example {
    use std::vector;

    struct Balance has key { value: u64 }

    struct Box<T> has key { items: vector<T> }

    public fun store_two<Item1: store, Item2: store>(
        addr: address,
        item1: Item1,
        item2: Item2,
    ) acquires Balance, Box {
        let balance = borrow_global_mut<Balance>(addr); // acquires needed
        balance.value = balance.value - 2;
        let box1 = borrow_global_mut<Box<Item1>>(addr); // acquires needed
        vector::push_back(&mut box1.items, item1);
        let box2 = borrow_global_mut<Box<Item2>>(addr); // acquires needed
        vector::push_back(&mut box2.items, item2);
    }
}
```

### Return type

After the parameters, a function specifies its return type.

```move
module 0x42::example {
    fun zero(): u64 { 0 }
}
```

Here `: u64` indicates that the function's return type is `u64`.

<Aside type="note">
  A function can return an immutable `&` or mutable `&mut` [reference](/build/smart-contracts/book/references) if derived from an input reference. Keep in mind, this means that a function [cannot return a reference to global storage](/build/smart-contracts/book/references#references-cannot-be-stored) unless it is an [inline function](#inline-functions).
</Aside>

Using tuples, a function can return multiple values:

```move
module 0x42::example {
    fun one_two_three(): (u64, u64, u64) { (0, 1, 2) }
}
```

If no return type is specified, the function has an implicit return type of unit `()`. These functions are equivalent:

```move
module 0x42::example {
    fun just_unit1(): () { () }

    fun just_unit2() { () }

    fun just_unit3() {}
}
```

`script` functions must have a return type of unit `()`:

```move
script {
    fun do_nothing() {}
}
```

As mentioned in the [tuples section](/build/smart-contracts/book/tuples), these tuple "values" are virtual and do not exist at runtime. So for a function that returns unit `()`, it will not be returning any value at all during execution.

### Function body

A function's body is an expression block. The return value of the function is the last value in the sequence

```move
module 0x42::example {
    fun example(): u64 {
        let x = 0;
        x = x + 1;
        x // returns 'x'
    }
}
```

See [the section below for more information on returns](#returning-values)

For more information on expression blocks, see [Move variables](/build/smart-contracts/book/variables).

### Native Functions

Some functions do not have a body specified, and instead have the body provided by the VM. These functions are marked `native`.

Without modifying the VM source code, a programmer cannot add new native functions. Furthermore, it is the intent that `native` functions are used for either standard library code or for functionality needed for the given Move environment.

Most `native` functions you will likely see are in standard library code such as `vector`

```move
module std::vector {
    native public fun empty<Element>(): vector<Element>;
    // ...
}
```

## Calling

When calling a function, the name can be specified either through an alias or fully qualified

```move
module 0x42::example {
    public fun zero(): u64 { 0 }
}

script {
    use 0x42::example::{Self, zero};

    fun call_zero() {
        // With the `use` above all of these calls are equivalent
        0x42::example::zero();
        example::zero();
        zero();
    }
}
```

When calling a function, an argument must be given for every parameter.

```move
module 0x42::example {
    public fun takes_none(): u64 { 0 }

    public fun takes_one(x: u64): u64 { x }

    public fun takes_two(x: u64, y: u64): u64 { x + y }

    public fun takes_three(x: u64, y: u64, z: u64): u64 { x + y + z }
}

script {
    use 0x42::example;

    fun call_all() {
        example::takes_none();
        example::takes_one(0);
        example::takes_two(0, 1);
        example::takes_three(0, 1, 2);
    }
}
```

Type arguments can be either specified or inferred. Both calls are equivalent.

```move
module 0x42::example {
    public fun id<T>(x: T): T { x }
}

script {
    use 0x42::example;

    fun call_all() {
        example::id(0);
        example::id<u64>(0);
    }
}
```

For more details, see [Move generics](/build/smart-contracts/book/generics).

## Returning values

The result of a function, its "return value", is the final value of its function body. For example

```move
module 0x42::example {
    fun add(x: u64, y: u64): u64 {
        x + y
    }
}
```

[As mentioned above](#function-body), the function's body is an [expression block](/build/smart-contracts/book/variables). The expression block can be a sequence of various statements, and the final expression in the block will be the value of that block.

```move
module 0x42::example {
    fun double_and_add(x: u64, y: u64): u64 {
        let double_x = x * 2;
        let double_y = y * 2;
        double_x + double_y
    }
}
```

The return value here is `double_x + double_y`

### `return` expression

A function implicitly returns the value that its body evaluates to. However, functions can also use the explicit `return` expression:

```move
module 0x42::example {
    fun f1(): u64 { return 0 }

    fun f2(): u64 { 0 }
}
```

These two functions are equivalent. In this slightly more involved example, the function subtracts two `u64` values, but returns early with `0` if the second value is too large:

```move
module 0x42::example {
    fun safe_sub(x: u64, y: u64): u64 {
        if (y > x) return 0;
        x - y
    }
}
```

Note that the body of this function could also have been written as `if (y > x) 0 else x - y`.

However, where `return` really shines is in exiting deep within other control flow constructs. In this example, the function iterates through a vector to find the index of a given value:

```move
module 0x42::example {
    use std::vector;
    use std::option::{Self, Option};

    fun index_of<T>(v: &vector<T>, target: &T): Option<u64> {
        let i = 0;
        let n = vector::length(v);
        while (i < n) {
            if (vector::borrow(v, i) == target) return option::some(i);
            i = i + 1
        };

        option::none()
    }
}
```

Using `return` without an argument is shorthand for `return ()`. That is, the following two functions are equivalent:

```move
module 0x42::example {
    fun foo1() { return }

    fun foo2() { return () }
}
```

## Inline Functions

Inline functions are functions whose bodies are expanded in place at the caller location during compile time.
Thus, inline functions do not appear in Move bytecode as a separate functions: all calls to them are expanded away by the compiler.
In certain circumstances, they may lead to faster execution and save gas.
However, users should be aware that they could lead to larger bytecode size: excessive inlining potentially triggers various size restrictions.

One can define an inline function by adding the `inline` keyword to a function declaration as shown below:

```move
module 0x42::example {
    inline fun percent(x: u64, y: u64): u64 { x * 100 / y }
}
```

If we call this inline function as `percent(2, 200)`, the compiler will replace this call with the inline function's body, as if the user has written `2 * 100 / 200`.

### Function parameters and lambda expressions

Inline functions support _function parameters_, which accept lambda expressions (i.e., anonymous functions) as arguments.
This feature allows writing several common programming patterns elegantly.
Similar to inline functions, lambda expressions are also expanded at call site.

A lambda expression includes a list of parameter names (enclosed within `||`) followed by the body.
Some simple examples are: `|x| x + 1`, `|x, y| x + y`, `|| 1`, `|| { 1 }`.
A lambda's body can refer to variables available in the scope where the lambda is defined: this is also known as capturing.
Such variables can be read or written (if mutable) by the lambda expression.

The type of function parameter is written as `|<list of parameter types>| <return type>`.
For example, when the function parameter type is `|u64, u64| bool`, any lambda expression that takes two `u64` parameters and returns a `bool` value can be provided as the argument.

Below is an example that showcases many of these concepts in action (this example is taken from the `std::vector` module):

```move
module 0x42::example {
    /// Fold the function over the elements.
    /// E.g, `fold(vector[1,2,3], 0, f)` is the same as `f(f(f(0, 1), 2), 3)`.
    public inline fun fold<Accumulator, Element>(
        v: vector<Element>,
        init: Accumulator,
        f: |Accumulator, Element|Accumulator
    ): Accumulator {
        let accu = init;
        // Note: `for_each` is an inline function, but is not shown here.
        for_each(v, |elem| accu = f(accu, elem));
        accu
    }
}
```

The type signature of the elided public inline function `for_each` is `fun for_each<Element>(v: vector<Element>, f: |Element|)`.
Its second parameter `f` is a function parameter which accepts any lambda expression that consumes an `Element` and returns nothing.
In the code example, we use the lambda expression `|elem| accu = f(accu, elem)` as an argument to this function parameter.
Note that this lambda expression captures the variable `accu` from the outer scope.

### Current restrictions

There are plans to loosen some of these restrictions in the future, but for now,

- Only inline functions can have function parameters.
- Only explicit lambda expressions can be passed as an argument to an inline function's function parameters.
- Inline functions and lambda expressions
  - cannot have `return` expressions; or free `break` or `continue` expressions (occurring outside of a loop)
  - cannot return lambda expressions.
- Cyclic recursion involving only inline functions is not allowed.
- Parameters in lambda expressions must not be type annotated (e.g., `|x: u64| x + 1` is not allowed): their types are inferred.

### Additional considerations

- Avoid using module-private constants/methods in public inline functions.
  When such inline functions are called outside of that module, an in-place expansion at call site leads to invalid access of the private constants/methods.
- Avoid marking large functions that are called at different locations as inline. Also avoid inline functions calling lots of other inline functions transitively.
  These may lead to excessive inlining and increase the bytecode size.
- Inline functions can be useful for returning references to global storage, which non-inline functions cannot do.

### Inline functions and references

As mentioned briefly [in a "tip" above](#return-type) `inline` functions can use references more freely than normal functions.

For example, actual arguments to a call to a non-`inline` function may not be aliased unsafely
(multiple `&` parameters referring to the same object, with at least one of them `&mut`),
but calls to `inline` functions do not necessarily have that restriction, as long as no reference
usage conflicts remain after the function is inlined.

```move
inline fun add(dest: &mut u64, a: &u64, b: &u64) {
    *dest = *a + *b;
}

fun user(...) {
    ...
    x = 3;
    add(&mut x, &x, &x);  // legal only because of inlining
    ...
}
```

A reference-typed value returned from a non-inline function must be derived from a reference parameter
passed to the function, but this need not be the case for an inline function, as long as the referred
value is in the function scope after inlining.

The exact details of reference safety and "borrow checking" are complex and documented elsewhere.
Advanced Move users find new expressiveness by understanding that
"borrow checking" happens only after all `inline` function calls are expanded.

However, with this power comes new responsibility: documentation of a nontrivial `inline` function should
probably explain any underlying restrictions on reference parameters and results at a call site.

## Dot (receiver) function call style

_Since language version 2.0_

By using the well-known name `self` as the first parameter for a function declaration, one can enable calling this function with the `.` syntax -- often also called receiver style syntax. Example:

```move
module 0x42::example {
    struct S {}

    fun foo(self: &S, x: u64) { /* ... */ }

    //...

    fun example() {
        let s = S {};
        s.foo(1);
    }
}
```

The call `s.foo(1)` is syntactic sugar for `foo(&s, 1)`. Notice that the compiler automatically inserts the reference operator. The 2nd, old notation is still available for `foo`, so one can incrementally introduce the new call style without breaking existing code.

The type of the `self` argument can be a struct or an immutable or mutable reference to a struct. The struct must be declared in the same module as the function.

Notice that you do not need to `use` the modules which introduce receiver functions. The compiler will find those functions automatically based on the argument type of `s` in a call like `s.foo(1)`. This, in combination with the automatic insertion of reference operators, can make code using this syntax significantly more concise.

The receiver style syntax can also be used on generic functions, like shown below for the generic function `std::vector::remove<T>(self: &mut vector<T>, i: u64): T`.

```move
module 0x42::example {
   fun bar() {
       let v = vector[1, 2, 3];
       let e1 = v.remove(0); // type params inferred for `remove<T>`
       assert!(e1 == 1);
       let e2 = v.remove::<u8>(0); // type params explicitly specified
       assert!(e2 == 2);
   }
}
```

## Function Values

_Since language version 2.2_

Move supports _function values_ as first-class citizen of the language. A function value is constructed from the name of a function or by a lambda expression, and is evaluated by passing parameters to it and causing the underlying function to be executed. This feature is often also called _dynamic dispatch_. Which concrete function is called, is not known to the caller, and determined from the runtime value. Dynamic dispatch is an important tool for composing applications. Move makes dynamic dispatch safe by providing builtin protection mechanisms against reentrancy, which can be further refined by user choice.

### Function Types

The type of functions values is already known from [inline functions](#function-parameters-and-lambda-expressions). A function type is denoted, for example, as `|u64|bool`, indicating a function which takes a number and returns a boolean. Lists of types are separated by comma, as in `|u64, bool|(bool,u4)`.

Function types can have associated abilities, written as `|u64|bool has copy`. Multiple abilities are separated by plus, as in `|u64|bool has copy+drop`. If no abilities are provided, the value can be only moved around and evaluated (for evaluation of function values, see [below](#function-evaluation)).

Function values can be stored in fields of structs or enums. In this case, the field type inherits the abilities of the struct:

```move
struct S has key {
  func: |u64| bool /* has store */  // not needed since inherited
}
```

### Operations on Functions

A function value is evaluated by providing the corresponding number of parameters, similar as when calling a named function. During evaluation, the function value is _consumed_. Hence if the value needs to be evaluated multiple times, its type must have the `copy` ability:

```move
let f: |u64|bool has copy = |x| x > 0;
assert!(f(1) == f(2))
```

Function values support equality and ordering. Note that those relations are based on the name of the underlying function behind a runtime value, and do not reflect semantic equivalence.

### Function Type Wrappers

Function types, specifically if they come together with abilities, can be verbose, and if the same type of function type is used many times in the code, repetitive. For this purpose, Move recognizes struct wrappers around function types as a special case. They can be used to effectively create named function types:

```move
struct Predicate<T>(|&T|bool) has copy;
```

Move supports this feature by automatically converting function values into the wrapper type and vice versa. Examples:

```move
let f: Predicate<u64> = |x| *x > 0; // lambda converts to Predicate
assert!(f(&22)) // Predicate callable
```

### Denoting Function Values

Function values can be constructed by directly using a function name. The resulting function type is derived from the signature of the underlying function, with abilities `copy+drop`. If the function is public, those function values have the `store` ability as well:

```move
public fun is_even(x: u64): bool { x % 2 == 0 }
fun is_odd(x: u64): bool { x % 2 == 1 }
...
let f: |u64|bool has copy+drop+store = is_even;
let g: |u64|bool has copy+drop = is_odd;
```

A _persistent_ function is required to build a storable function value because it needs to be guaranteed that the underlying function exists and can be safely restored from storage at any point in the future. However, code upgrade may change the underlying implementation of the function, while its signature is persistent.

While `public` and `entry` functions are persistent by default, a non-public function needs to be marked with the attribute `#[persistent]` to become storable:

```move
#[persistent] fun is_odd(x: u64): bool { x % 2 == 1 }
...
let g: |u64|bool has copy+drop+store = is_odd;
```

Using the `#[persistent]` attribute is preferred if the only objective is to make a function storable, avoiding security implications with public or entry visibility.

### Lambda Expressions and Closures

Function values can be denoted by _lambda expressions_ (as also available as parameters for [inline functions](#function-parameters-and-lambda-expressions)). Lambda expressions can capture context variables _by value_: those values are moved (or copied) into a _closure_, from where they are produced when the function is evaluated. Examples:

```move
struct S(u64); // cannot be copied or dropped
...
let s = S(1);
let add = |y| { let S(x) = s; x + y }; // s will be moved into the closure
assert!(add(2) == 3)
```

Closures with captured values are lexicographical ordered using first the name of the underlying function (which maybe generated from lambda lifting), and then the captured values.

The type of the closure constructed by a lambda expression is inferred from the expression (for example, the type of `add` in the example above is inferred as `|u64|u64`). The abilities of this function type are derived as follows. By default, the function underlying a closure is a private function, so the function itself is `copy+drop` (and not `store`). This is intersected with the abilities of all the captured context variables. However, there is a special case for lambdas where instead of a private function an underlying persistent function can be identified, such that the lambda just 'delays' certain arguments of this function. This pattern is also called 'currying' in functional programming (named after the mathematician Curry). Here are some examples:

```move
#[persistent] fun add(x: u64, y: u64) { x + y }
...
let x = 22;
let f: |u64|u64 has copy+drop+store = |y| add(x, y);  // 1st argument captured, 2nd argument delayed
let f: |u64|u64 has copy+drop+store = |y| add(y, x);  // 1st argument delayed, 2nd argument captured
```

Notice it is not possible to _capture_ reference values at this point of time in Move. Thus, the following code does not compile:

```move
let x = &22;
let f = |y| add(*x, y) // DOES NOT COMPILE
```

Related, it is not possible to mutate any locals in the context of a lambda. Specifically, the following pattern as known from lambdas with inline functions, is not supported:

```move
let x = 0;
collection.for_each(|e| x += e) // DOES NOT COMPILE
```

However, the actual parameters of lambdas can be references, only captured values are restricted. For example:

```move
let x = 22;
let f : |&u64|u64 = |y| add(x, *y)
```

### Reentrancy Check

Via dynamic dispatch of function values, reentrancy of modules in a chain of function calls is possible. If module `m1` uses module `m2`, and `m1` calls `m2::f` passing a function value to it, this function value can callback into `m1`. This situation is called _reentrancy_, and is not possible in Move without function values, since the module usage relation is acyclic.

The Move VM dynamically detects reentrancy of a module, and _locks_ all resources declared in this module from being accessed. Thus during reentrancy of `m`, calling resource operations like `&m::R[addr]`, `&mut m::R[addr]`, and `move_from<m::R>` lead to an abort. Here is an example:

```move
module 0x42::caller {
  use 0x42::callee;
  struct R{ count: u64 } has key;
  fun calling() acquires R {
     let r = &mut R[@addr];
     // This callback is OK, because `R` is not accessed
     callee::call_me(r, |x| do_something(x))
     // This callback will lead to reentrancy runtime error
     callee::call_me(r, |_| R[@addr].count += 1)
     r.call_count += 1
  }
  fun do_something(r: &mut R) { .. }
}

module 0x42::callee {
  fun call_me<T(x: &mut T, action: |&mut T|) {
    action(x)
  }
}
```

Notice that dispatching a function value to a concrete function in the same module is also considered to be reentrancy. If the function `callee::call_me` would be moved into the module `caller`, the same semantics is in effect.

The default reentrancy check ensures consistency of Move's reference semantics and suppresses side effects of reentrancy for the resources owned by the re-entered module. However, re-entered code is allowed to still access resource state managed by modules outside the reentrancy path. Such state accesses can be considered bad design, but they exist.
For these purposes, the `#[module_lock]` attribute can be attached to a function:

```move
module 0x42::account { ... }
module 0x42::caller {
  #[module_lock] // without this lock, the notify call could withdraw more than intended.
  fun transfer(from: address, to: address, amount: u64, notify: |u64|) {
    // Oops. This should be really differently designed, using `Coin` type and moving it.
    assert!(account::balance(from) - MIN_BALANCE >= amount);
    account::deposit(to, amount)
    notify(amount); // attempt to re-enter `transfer` is blocked
    account::withdraw(from, amount);
  }
}
```

While a function with this attribute is running, all calls reentering any module will lead to an abort, given a stronger protection.

The attribute `#[module_lock]` restriction is not the default behavior since it is too strong for typical patterns of higher-order programming. For example, `collection.find(|x| cond(x))` will lead to a reentrancy of the module which contains this expression, from the module which defines the collection type.

# Generics

> Learn about generics in Move programming language for Aptos smart contract development.

Generics can be used to define functions and structs over different input data types. This language feature is sometimes referred to as _parametric polymorphism_. In Move, we will often use the term generics interchangeably with type parameters and type arguments.

Generics are commonly used in library code, such as in vector, to declare code that works over any possible instantiation (that satisfies the specified constraints). In other frameworks, generic code can sometimes be used to interact with global storage many different ways that all still share the same implementation.

## Declaring Type Parameters

Both functions and structs can take a list of type parameters in their signatures, enclosed by a pair of angle brackets `<...>`.

### Generic Functions

Type parameters for functions are placed after the function name and before the (value) parameter list. The following code defines a generic identity function that takes a value of any type and returns that value unchanged.

```move
module 0x42::example {
  fun id<T>(x: T): T {
    // this type annotation is unnecessary but valid
    (x: T)
  }
}
```

Once defined, the type parameter `T` can be used in parameter types, return types, and inside the function body.

### Generic Structs

Type parameters for structs are placed after the struct name, and can be used to name the types of the fields.

```move
module 0x42::example {
  struct Foo<T> has copy, drop { x: T }

  struct Bar<T1, T2> has copy, drop {
    x: T1,
    y: vector<T2>,
  }
}
```

Note that [type parameters do not have to be used](#unused-type-parameters)

## Type Arguments

### Calling Generic Functions

When calling a generic function, one can specify the type arguments for the function's type parameters in a list enclosed by a pair of angle brackets.

```move
module 0x42::example {
  fun foo() {
    let x = id<bool>(true);
  }
}
```

If you do not specify the type arguments, Move's [type inference](#type-inference) will supply them for you.

### Using Generic Structs

Similarly, one can attach a list of type arguments for the struct's type parameters when constructing or destructing values of generic types.

```move
module 0x42::example {
  fun foo() {
    let foo = Foo<bool> { x: true };
    let Foo<bool> { x } = foo;
  }
}
```

If you do not specify the type arguments, Move's [type inference](#type-inference) will supply them for you.

### Type Argument Mismatch

If you specify the type arguments, and they conflict with the actual values supplied, an error will be given:

```move
module 0x42::example {
  fun foo() {
    let x = id<u64>(true); // error! true is not a u64
  }
}
```

and similarly:

```move
module 0x42::example {
  fun foo() {
    let foo = Foo<bool> { x: 0 }; // error! 0 is not a bool
    let Foo<address> { x } = foo; // error! bool is incompatible with address
  }
}
```

## Type Inference

In most cases, the Move compiler will be able to infer the type arguments, so you don't have to write them down explicitly. Here's what the examples above would look like if we omit the type arguments:

```move
module 0x42::example {
  fun foo() {
    let x = id(true);
    //        ^ <bool> is inferred

    let foo = Foo { x: true };
    //           ^ <bool> is inferred

    let Foo { x } = foo;
    //     ^ <bool> is inferred
  }
}
```

Note: when the compiler is unable to infer the types, you'll need annotate them manually. A common scenario is to call a function with type parameters appearing only at return positions.

```move
module 0x2::m {
  use std::vector;

  fun foo() {
    // let v = vector::new();
    //                    ^ The compiler cannot figure out the element type.

    let v = vector::new<u64>();
    //                 ^~~~~ Must annotate manually.
  }
}
```

However, the compiler will be able to infer the type if that return value is used later in that function:

```move
module 0x2::m {
  use std::vector;

  fun foo() {
    let v = vector::new();
    //                 ^ <u64> is inferred
    vector::push_back(&mut v, 42);
  }
}
```

## Unused Type Parameters

For a struct definition,
an unused type parameter is one that
does not appear in any field defined in the struct,
but is checked statically at compile time.
Move allows unused type parameters so the following struct definition is valid:

```move
module 0x2::m {
  struct Foo<T> {
    foo: u64
  }
}
```

This can be convenient when modeling certain concepts. Here is an example:

```move
module 0x2::m {
  // Currency Specifiers
  struct Currency1 {}
  struct Currency2 {}

  // A generic coin type that can be instantiated using a currency
  // specifier type.
  //   e.g. Coin<Currency1>, Coin<Currency2> etc.
  struct Coin<Currency> has store {
    value: u64
  }

  // Write code generically about all currencies
  public fun mint_generic<Currency>(value: u64): Coin<Currency> {
    Coin { value }
  }

  // Write code concretely about one currency
  public fun mint_concrete(value: u64): Coin<Currency1> {
    Coin { value }
  }
}
```

In this example,
`struct Coin<Currency>` is generic on the `Currency` type parameter,
which specifies the currency of the coin and
allows code to be written either
generically on any currency or
concretely on a specific currency.
This genericity applies even when the `Currency` type parameter
does not appear in any of the fields defined in `Coin`.

### Phantom Type Parameters

In the example above,
although `struct Coin` asks for the `store` ability,
neither `Coin<Currency1>` nor `Coin<Currency2>` will have the `store` ability.
This is because of the rules for
[Conditional Abilities and Generic Types](/build/smart-contracts/book/abilities#conditional-abilities-and-generic-types)
and the fact that `Currency1` and `Currency2` don't have the `store` ability,
despite the fact that they are not even used in the body of `struct Coin`.
This might cause some unpleasant consequences.
For example, we are unable to put `Coin<Currency1>` into a wallet in the global storage.

One possible solution would be to
add spurious ability annotations to `Currency1` and `Currency2`
(i.e., `struct Currency1 has store {}`).
But, this might lead to bugs or security vulnerabilities
because it weakens the types with unnecessary ability declarations.
For example, we would never expect a resource in the global storage to have a field in type `Currency1`,
but this would be possible with the spurious `store` ability.
Moreover, the spurious annotations would be infectious,
requiring many functions generic on the unused type parameter to also include the necessary constraints.

Phantom type parameters solve this problem.
Unused type parameters can be marked as _phantom_ type parameters,
which do not participate in the ability derivation for structs.
In this way,
arguments to phantom type parameters are not considered when deriving the abilities for generic types,
thus avoiding the need for spurious ability annotations.
For this relaxed rule to be sound,
Move's type system guarantees that a parameter declared as `phantom` is either
not used at all in the struct definition, or
it is only used as an argument to type parameters also declared as `phantom`.

#### Declaration

In a struct definition
a type parameter can be declared as phantom by adding the `phantom` keyword before its declaration.
If a type parameter is declared as phantom we say it is a phantom type parameter.
When defining a struct, Move's type checker ensures that every phantom type parameter is either
not used inside the struct definition or
it is only used as an argument to a phantom type parameter.

More formally,
if a type is used as an argument to a phantom type parameter
we say the type appears in _phantom position_.
With this definition in place,
the rule for the correct use of phantom parameters can be specified as follows:
**A phantom type parameter can only appear in phantom position**.

The following two examples show valid uses of phantom parameters.
In the first one,
the parameter `T1` is not used at all inside the struct definition.
In the second one, the parameter `T1` is only used as an argument to a phantom type parameter.

```move
module 0x2::m {
  struct S1<phantom T1, T2> { f: u64 }
  //                ^^
  //                Ok: T1 does not appear inside the struct definition


  struct S2<phantom T1, T2> { f: S1<T1, T2> }
  //                                ^^
  //                                Ok: T1 appears in phantom position
}
```

The following code shows examples of violations of the rule:

```move
module 0x2::m {
  struct S1<phantom T> { f: T }
  //                        ^
  //                        Error: Not a phantom position

  struct S2<T> { f: T }

  struct S3<phantom T> { f: S2<T> }
  //                           ^
  //                           Error: Not a phantom position
}
```

#### Instantiation

When instantiating a struct,
the arguments to phantom parameters are excluded when deriving the struct abilities.
For example, consider the following code:

```move
module 0x2::m {
  struct S<T1, phantom T2> has copy { f: T1 }
  struct NoCopy {}
  struct HasCopy has copy {}
}
```

Consider now the type `S<HasCopy, NoCopy>`.
Since `S` is defined with `copy` and all non-phantom arguments have `copy`
then `S<HasCopy, NoCopy>` also has `copy`.

#### Phantom Type Parameters with Ability Constraints

Ability constraints and phantom type parameters are orthogonal features in the sense that
phantom parameters can be declared with ability constraints.
When instantiating a phantom type parameter with an ability constraint,
the type argument has to satisfy that constraint,
even though the parameter is phantom.
For example, the following definition is perfectly valid:

```move
module 0x2::m {
  struct S<phantom T: copy> {}
}
```

The usual restrictions apply and `T` can only be instantiated with arguments having `copy`.

## Constraints

In the examples above, we have demonstrated how one can use type parameters to define "unknown" types that can be plugged in by callers at a later time. This however means the type system has little information about the type and has to perform checks in a very conservative way. In some sense, the type system must assume the worst case scenario for an unconstrained generic. Simply put, by default generic type parameters have no [abilities](/build/smart-contracts/book/abilities).

This is where constraints come into play: they offer a way to specify what properties these unknown types have so the type system can allow operations that would otherwise be unsafe.

### Declaring Constraints

Constraints can be imposed on type parameters using the following syntax.

```move
// T is the name of the type parameter
T: <ability> (+ <ability>)*
```

The `<ability>` can be any of the four [abilities](/build/smart-contracts/book/abilities), and a type parameter can be constrained with multiple abilities at once. So all the following would be valid type parameter declarations:

```move
T: copy
T: copy + drop
T: copy + drop + store + key
```

### Verifying Constraints

Constraints are checked at call sites so the following code won't compile.

```move
module 0x2::m {
  struct Foo<T: key> { x: T }

  struct Bar { x: Foo<u8> }
  //                  ^ error! u8 does not have 'key'

  struct Baz<T> { x: Foo<T> }
  //                     ^ error! T does not have 'key'
}
```

```move
module 0x2::m {
  struct R {}

  fun unsafe_consume<T>(x: T) {
    // error! x does not have 'drop'
  }

  fun consume<T: drop>(x: T) {
    // valid!
    // x will be dropped automatically
  }

  fun foo() {
    let r = R {};
    consume<R>(r);
    //      ^ error! R does not have 'drop'
  }
}
```

```move
module 0x2::m {
  struct R {}

  fun unsafe_double<T>(x: T) {
    (copy x, x)
    // error! x does not have 'copy'
  }

  fun double<T: copy>(x: T) {
    (copy x, x) // valid!
  }

  fun foo(): (R, R) {
    let r = R {};
    double<R>(r)
    //     ^ error! R does not have 'copy'
  }
}
```

For more information, see the abilities section on [conditional abilities and generic types](/build/smart-contracts/book/abilities#conditional-abilities-and-generic-types).

## Limitations on Recursions

### Recursive Structs

Generic structs can not contain fields of the same type, either directly or indirectly, even with different type arguments. All the following struct definitions are invalid:

```move
module 0x2::m {
  struct Foo<T> {
    x: Foo<u64> // error! 'Foo' containing 'Foo'
  }

  struct Bar<T> {
    x: Bar<T> // error! 'Bar' containing 'Bar'
  }

  // error! 'A' and 'B' forming a cycle, which is not allowed either.
  struct A<T> {
    x: B<T, u64>
  }

  struct B<T1, T2> {
    x: A<T1>,
    y: A<T2>
  }
}
```

### Advanced Topic: Type-level Recursions

Move allows generic functions to be called recursively. However, when used in combination with generic structs, this could create an infinite number of types in certain cases, and allowing this means adding unnecessary complexity to the compiler, vm and other language components. Therefore, such recursions are forbidden.

Allowed:

```move
module 0x2::m {
  struct A<T> {}

  // Finitely many types -- allowed.
  // foo1<T> -> foo1<T> -> foo1<T> -> ... is valid
  fun foo1<T>() {
    foo1<T>();
  }

  // Finitely many types -- allowed.
  // foo2<T> -> foo2<A<u64>> -> foo2<A<u64>> -> ... is valid
  fun foo2<T>() {
    foo2<A<u64>>();
  }
}
```

Not allowed:

```move
module 0x2::m {
  struct A<T> {}

  // Infinitely many types -- NOT allowed.
  // error!
  // foo<T> -> foo<A<T>> -> foo<A<A<T>>> -> ...
  fun foo<T>() {
    foo<A<T>>();
  }
}
```

```move
module 0x2::n {
  struct A<T> {}

  // Infinitely many types -- NOT allowed.
  // error!
  // foo<T1, T2> -> bar<T2, T1> -> foo<T2, A<T1>>
  //   -> bar<A<T1>, T2> -> foo<A<T1>, A<T2>>
  //   -> bar<A<T2>, A<T1>> -> foo<A<T2>, A<A<T1>>>
  //   -> ...
  fun foo<T1, T2>() {
    bar<T2, T1>();
  }

  fun bar<T1, T2>() {
    foo<T1, A<T2>>();
  }
}
```

Note, the check for type level recursions is based on a conservative analysis on the call sites and does NOT take control flow or runtime values into account.

```move
module 0x2::m {
  struct A<T> {}

  fun foo<T>(n: u64) {
    if (n > 0) {
      foo<A<T>>(n - 1);
    };
  }
}
```

The function in the example above will technically terminate for any given input and therefore only creating finitely many types, but it is still considered invalid by Move's type system.

# Global Storage - Operators

> Master global storage operations including borrow_global, move_to, move_from for resource management on Aptos.

Move programs can create, delete, and update [resources](/build/smart-contracts/book/structs-and-resources) in global storage using the following five instructions:

| Operation                               | Description                                                     | Aborts?                                 |
| --------------------------------------- | --------------------------------------------------------------- | --------------------------------------- |
| `move_to<T>(&signer,T)`                 | Publish `T` under `signer.address`                              | If `signer.address` already holds a `T` |
| `move_from<T>(address): T`              | Remove `T` from `address` and return it                         | If `address` does not hold a `T`        |
| `borrow_global_mut<T>(address): &mut T` | Return a mutable reference to the `T` stored under `address`    | If `address` does not hold a `T`        |
| `borrow_global<T>(address): &T`         | Return an immutable reference to the `T` stored under `address` | If `address` does not hold a `T`        |
| `exists<T>(address): bool`              | Return `true` if a `T` is stored under `address`                | Never                                   |

Each of these instructions is parameterized by a type `T` with the [`key` ability](/build/smart-contracts/book/abilities). However, each type `T` _must be declared in the current module_. This ensures that a resource can only be manipulated via the API exposed by its defining module. The instructions also take either an [`address`](/build/smart-contracts/book/address) or [`&signer`](/build/smart-contracts/book/signer) representing the account address where the resource of type `T` is stored.

See also [index notation (`[]`)](#index-notation-for-storage-operators) for accessing global storage.

## References to resources

References to global resources returned by `borrow_global` or `borrow_global_mut` mostly behave like references to local storage: they can be extended, read, and written using ordinary [reference operators](/build/smart-contracts/book/references) and passed as arguments to other function. However, there is one important difference between local and global references: **a function cannot return a reference that points into global storage**. For example, these two functions will each fail to compile:

```move
module 0x42::example {
  struct R has key { f: u64 }
  // will not compile
  fun ret_direct_resource_ref_bad(a: address): &R {
    borrow_global<R>(a) // error!
  }
  // also will not compile
  fun ret_resource_field_ref_bad(a: address): &u64 {
    &borrow_global<R>(a).f // error!
  }
}
```

Move must enforce this restriction to guarantee absence of dangling references to global
storage. [This section](#reference-safety-for-global-resources) contains much more detail for the interested reader.

## Global storage operators with generics

Global storage operations can be applied to generic resources with both instantiated and uninstantiated generic type parameters:

```move
module 0x42::example {
  struct Container<T> has key { t: T }

  // Publish a Container storing a type T of the caller's choosing
  fun publish_generic_container<T>(account: &signer, t: T) {
    move_to<Container<T>>(account, Container { t })
  }

  /// Publish a container storing a u64
  fun publish_instantiated_generic_container(account: &signer, t: u64) {
    move_to<Container<u64>>(account, Container { t })
  }
}
```

The ability to index into global storage via a type parameter chosen at runtime is a powerful Move feature known as _storage polymorphism_. For more on the design patterns enabled by this feature, see [Move generics](/build/smart-contracts/book/generics).

## Example: `Counter`

The simple `Counter` module below exercises each of the five global storage operators. The API exposed by this module allows:

- Anyone to publish a `Counter` resource under their account
- Anyone to check if a `Counter` exists under any address
- Anyone to read or increment the value of a `Counter` resource under any address
- An account that stores a `Counter` resource to reset it to zero
- An account that stores a `Counter` resource to remove and delete it

```move
module 0x42::counter {
  use std::signer;

  /// Resource that wraps an integer counter
  struct Counter has key { i: u64 }

  /// Publish a `Counter` resource with value `i` under the given `account`
  public fun publish(account: &signer, i: u64) {
    // "Pack" (create) a Counter resource. This is a privileged operation that
    // can only be done inside the module that declares the `Counter` resource
    move_to(account, Counter { i })
  }

  /// Read the value in the `Counter` resource stored at `addr`
  public fun get_count(addr: address): u64 acquires Counter {
    borrow_global<Counter>(addr).i
  }

  /// Increment the value of `addr`'s `Counter` resource
  public fun increment(addr: address) acquires Counter {
    let c_ref = &mut borrow_global_mut<Counter>(addr).i;
    *c_ref = *c_ref + 1
  }

  /// Reset the value of `account`'s `Counter` to 0
  public fun reset(account: &signer) acquires Counter {
    let c_ref = &mut borrow_global_mut<Counter>(signer::address_of(account)).i;
    *c_ref = 0
  }

  /// Delete the `Counter` resource under `account` and return its value
  public fun delete(account: &signer): u64 acquires Counter {
    // remove the Counter resource
    let c = move_from<Counter>(signer::address_of(account));
    // "Unpack" the `Counter` resource into its fields. This is a
    // privileged operation that can only be done inside the module
    // that declares the `Counter` resource
    let Counter { i } = c;
    i
  }

  /// Return `true` if `addr` contains a `Counter` resource
  public fun exists_at(addr: address): bool {
    exists<Counter>(addr)
  }
}
```

## Annotating functions with `acquires`

_Note: Since language version 2.2, acquires annotations are optional. If no acquires is given, it will be inferred._

In the `counter` example, you might have noticed that the `get_count`, `increment`, `reset`, and `delete` functions are annotated with `acquires Counter`. A Move function `m::f` must be annotated with `acquires T` if and only if:

- The body of `m::f` contains a `move_from<T>`, `borrow_global_mut<T>`, or `borrow_global<T>` instruction, or
- The body of `m::f` invokes a function `m::g` declared in the same module that is annotated with `acquires`

For example, the following function inside `Counter` would need an `acquires` annotation:

```move
module 0x42::example {
  // Needs `acquires` because `increment` is annotated with `acquires`
  fun call_increment(addr: address): u64 acquires Counter {
    counter::increment(addr)
  }
}
```

However, the same function _outside_ `Counter` would not need an annotation:

```move
module 0x43::m {
  use 0x42::counter;

  // Ok. Only need annotation when resource acquired by callee is declared
  // in the same module
  fun call_increment(addr: address): u64 {
    counter::increment(addr)
  }
}
```

If a function touches multiple resources, it needs multiple `acquires`:

```move
module 0x42::two_resources {
  struct R1 has key { f: u64 }
  struct R2 has key { g: u64 }

  fun double_acquires(a: address): u64 acquires R1, R2 {
    borrow_global<R1>(a).f + borrow_global<R2>(a).g
  }
}
```

The `acquires` annotation does not take generic type parameters into account:

```move
module 0x42::m {
  struct R<T> has key { t: T }

  // `acquires R`, not `acquires R<T>`
  fun acquire_generic_resource<T: store>(a: address) acquires R {
    let _ = borrow_global<R<T>>(a);
  }

  // `acquires R`, not `acquires R<u64>
  fun acquire_instantiated_generic_resource(a: address) acquires R {
    let _ = borrow_global<R<u64>>(a);
  }
}
```

Finally: redundant `acquires` are not allowed. Adding this function inside `Counter` will result in a compilation error:

```move
module 0x42::m {
  // This code will not compile because the body of the function does not use a global
  // storage instruction or invoke a function with `acquires`
  fun redundant_acquires_bad() acquires Counter {}
}
```

For more information on `acquires`, see [Move functions](/build/smart-contracts/book/functions).

## Reference Safety For Global Resources

Move prohibits returning global references and requires the `acquires` annotation to prevent dangling references. This allows Move to live up to its promise of static reference safety (i.e., no dangling references, no `null` or `nil` dereferences) for all [reference](/build/smart-contracts/book/references) types.

This example illustrates how the Move type system uses `acquires` to prevent a dangling reference:

```move
module 0x42::dangling {
  struct T has key { f: u64 }

  fun borrow_then_remove_bad(a: address) acquires T {
    let t_ref: &mut T = borrow_global_mut<T>(a);
    let t = remove_t(a); // type system complains here
    // t_ref now dangling!
    let uh_oh = *&t_ref.f;
  }

  fun remove_t(a: address): T acquires T {
    move_from<T>(a)
  }
}
```

In this code, line 6 acquires a reference to the `T` stored at address `a` in global storage. The callee `remove_t` then removes the value, which makes `t_ref` a dangling reference.

Fortunately, this cannot happen because the type system will reject this program. The `acquires` annotation on `remove_t` lets the type system know that line 7 is dangerous, without having to recheck or introspect the body of `remove_t` separately!

The restriction on returning global references prevents a similar, but even more insidious problem:

```move
address 0x42 {
  module m1 {
    struct T has key {}

    public fun ret_t_ref(a: address): &T acquires T {
      borrow_global<T>(a) // error! type system complains here
    }

    public fun remove_t(a: address) acquires T {
      let T {} = move_from<T>(a);
    }
  }

  module m2 {
    fun borrow_then_remove_bad(a: address) {
      let t_ref = m1::ret_t_ref(a);
      let t = m1::remove_t(a); // t_ref now dangling!
    }
  }
}
```

Line 16 acquires a reference to a global resource `m1::T`, then line 17 removes that same resource, which makes `t_ref` dangle. In this case, `acquires` annotations do not help us because the `borrow_then_remove_bad` function is outside the `m1` module that declares `T` (recall that `acquires` annotations can only be used for resources declared in the current module). Instead, the type system avoids this problem by preventing the return of a global reference at line 6.

Fancier type systems that would allow returning global references without sacrificing reference safety are possible, and we may consider them in future iterations of Move. We chose the current design because it strikes a good balance between being expressive, annotation burden, and type system complexity.

## Index Notation for Storage Operators

_Since language version 2.0_

Instead of the verbose `borrow_global` and `borrow_global_mut` functions, one
can also use index notations to access global storage.

The table below gives an overview of index notations for storage:

| Indexing Syntax         | Storage Operation                          |
| ----------------------- | ------------------------------------------ |
| `&T[address]`           | `borrow_global<T>(address)`                |
| `&mut T[address]`       | `borrow_global_mut<T>(address)`            |
| `T[address]`            | `*borrow_global<T>(address)`               |
| `T[address] = x`        | `*borrow_global_mut<T>(address) = x`       |
| `&T[address].field`     | `&borrow_global<T>(address).field`         |
| `&mut T[address].field` | `&mut borrow_global_mut<T>(address).field` |
| `T[address].field`      | `borrow_global<T>(address).field`          |
| `T[address].field = x`  | `borrow_global_mut<T>(address).field = x`  |

Here `T` represents a generic resource type that can take type parameters.

Notice that `T[address].field` fetches a reference to the resource from storage and then makes a copy of the field value (which must
have the copy ability); it is a shortcut for `*&T[address].field`.

Examples:

```move
struct R has key, drop { value: bool }

fun f1() acquires R {
  let x = &mut R[@0x1];
  x.value = false;
  assert!(R[@0x1].value == false);
  R[@0x1].value = true;
  assert!(R[@0x1].value == true);
}
```

# Global Storage - Structure

> Understand global storage organization, resource management, and data access patterns in Move smart contracts.

The purpose of Move programs is to [read from and write to](/build/smart-contracts/book/global-storage-operators) tree-shaped persistent global storage. Programs cannot access the filesystem, network, or any other data outside of this tree.

In pseudocode, the global storage looks something like:

```move
module 0x42::example {
  struct GlobalStorage {
    resources: Map<(address, ResourceType), ResourceValue>,
    modules: Map<(address, ModuleName), ModuleBytecode>
  }
}
```

Structurally, global storage is a [forest](https://en.wikipedia.org/wiki/Tree_\(graph_theory\)) consisting of trees rooted at an account [`address`](/build/smart-contracts/book/address). Each address can store both [resource](/build/smart-contracts/book/structs-and-resources) data values and [module](/build/smart-contracts/book/modules-and-scripts) code values. As the pseudocode above indicates, each `address` can store at most one resource value of a given type and at most one module with a given name.

# Integers

> Learn about integers in Move programming language for Aptos smart contract development.

Move supports six unsigned integer types: `u8`, `u16`, `u32`, `u64`, `u128`, and `u256`. Values of these types range from 0 to a maximum that depends on the size of the type.

| Type                             | Value Range              |
| -------------------------------- | ------------------------ |
| Unsigned 8-bit integer, `u8`     | 0 to 2<sup>8</sup> - 1   |
| Unsigned 16-bit integer, `u16`   | 0 to 2<sup>16</sup> - 1  |
| Unsigned 32-bit integer, `u32`   | 0 to 2<sup>32</sup> - 1  |
| Unsigned 64-bit integer, `u64`   | 0 to 2<sup>64</sup> - 1  |
| Unsigned 128-bit integer, `u128` | 0 to 2<sup>128</sup> - 1 |
| Unsigned 256-bit integer, `u256` | 0 to 2<sup>256</sup> - 1 |

_Since version 2.3_, Move also supports signed integer types:

| Type                           | Value Range                             |
| ------------------------------ | --------------------------------------- |
| Signed 8-bit integer, `i8`     | -2<sup>7</sup> to 2<sup>7</sup> - 1     |
| Signed 16-bit integer, `i16`   | -2<sup>15</sup> to 2<sup>15</sup> - 1   |
| Signed 32-bit integer, `i32`   | -2<sup>31</sup> to 2<sup>31</sup> - 1   |
| Signed 64-bit integer, `i64`   | -2<sup>63</sup> to 2<sup>63</sup> - 1   |
| Signed 128-bit integer, `i128` | -2<sup>127</sup> to 2<sup>127</sup> - 1 |
| Signed 256-bit integer, `i256` | -2<sup>255</sup> to 2<sup>255</sup> - 1 |

## Literals

Literal values for these types are specified either as a sequence of digits (e.g.,`112`) or as hex literals, e.g., `0xFF`. The type of the literal can optionally be added as a suffix, e.g., `112u8`. If the type is not specified, the compiler will try to infer the type from the context where the literal is used. If the type cannot be inferred, it is assumed to be `u64`.

Number literals can be separated by underscores for grouping and readability. (e.g.,`1_234_5678`, `1_000u128`, `0xAB_CD_12_35`).

To denote a negative number, it can be prefixed by the `-` sign. (e.g., `-112`)

If a literal is too large for its specified (or inferred) size range, an error is reported.

### Examples

```move
script {
  fun example() {
    // literals with explicit annotations;
    let explicit_u8 = 1u8;
    let explicit_u16 = 1u16;
    let explicit_u32 = 1u32;
    let explicit_u64 = 2u64;
    let explicit_u128 = 3u128;
    let explicit_u256 = 1u256;
    let explicit_u64_underscored = 154_322_973u64;
    let explicit_i8 = -1i8;
    let explicit_i64 = -2i64;

    // literals with simple inference
    let simple_u8: u8 = 1;
    let simple_u16: u16 = 1;
    let simple_u32: u32 = 1;
    let simple_u64: u64 = 2;
    let simple_u128: u128 = 3;
    let simple_u256: u256 = 1;

    // literals with more complex inference
    let complex_u8 = 1; // inferred: u8
    // right hand argument to shift must be u8
    let _unused = 10 << complex_u8;

    let x: u8 = 38;
    let complex_u8 = 2; // inferred: u8
    // arguments to `+` must have the same type
    let _unused = x + complex_u8;

    let complex_u128 = 133_876; // inferred: u128
    // inferred from function argument type
    function_that_takes_u128(complex_u128);

    // literals can be written in hex
    let hex_u8: u8 = 0x1;
    let hex_u16: u16 = 0x1BAE;
    let hex_u32: u32 = 0xDEAD80;
    let hex_u64: u64 = 0xCAFE;
    let hex_u128: u128 = 0xDEADBEEF;
    let hex_u256: u256 = 0x1123_456A_BCDE_F;
  }
}
```

## Operations

### Arithmetic

Each of these types supports the same set of checked arithmetic operations. For all of these operations, both arguments (the left and right side operands) _must_ be of the same type. If you need to operate over values of different types, you will need to first perform a [cast](#casting). Similarly, if you expect the result of the operation to be too large for the integer type, perform a [cast](#casting) to a larger size before performing the operation.

All arithmetic operations abort instead of behaving in a way that mathematical integers would not (e.g., overflow, underflow, divide-by-zero).

| Syntax  | Operation           | Aborts If                                      |
| ------- | ------------------- | ---------------------------------------------- |
| `a + b` | addition            | Result is too large/small for the integer type |
| `a - b` | subtraction         | Result is less than zero                       |
| `a * b` | multiplication      | Result is too large/small for the integer type |
| `a % b` | modular division    | The divisor is `0`                             |
| `a / b` | truncating division | The divisor is `0`, or result overflow         |
| `-a`    | negation            | Negated result too large (e.g. `-MIN_I64`)     |

### Bitwise

The _unsigned_ integer types support the following bitwise operations that treat each number as a series of individual bits, either 0 or 1, instead of as numerical integer values.

Bitwise operations do not abort.

| Syntax | Operation   | Description                                           |
| ------ | ----------- | ----------------------------------------------------- |
| `&`    | bitwise and | Performs a boolean and for each bit pairwise          |
| `\|`   | bitwise or  | Performs a boolean or for each bit pairwise           |
| `^`    | bitwise xor | Performs a boolean exclusive or for each bit pairwise |

### Bit Shifts

Similar to the bitwise operations, each _unsigned_ integer type supports bit shifts. But unlike the other operations, the right-hand side operand (how many bits to shift by) must _always_ be a `u8` and need not match the left side operand (the number you are shifting).

Bit shifts abort if the number of bits to shift by is greater than or equal to `8`, `16`, `32`, `64`, `128` or `256` for `u8`, `u16`, `u32`, `u64`, `u128` and `u256` respectively.

| Syntax | Operation   | Aborts if                                                                           |
| ------ | ----------- | ----------------------------------------------------------------------------------- |
| `<<`   | shift left  | Number of bits to shift by is greater than or equal to the size of the integer type |
| `>>`   | shift right | Number of bits to shift by is greater than or equal to the size of the integer type |

### Comparisons

All integer types support the ["comparison"](/build/smart-contracts/book/comparison) operations. Both arguments need to be of the same type. If you need to compare integers of different types, you will need to [cast](#casting) one of them first.

Comparison operations do not abort.

| Syntax | Operation                |
| ------ | ------------------------ |
| `<`    | less than                |
| `>`    | greater than             |
| `<=`   | less than or equal to    |
| `>=`   | greater than or equal to |

### Equality

Like all types with [`drop`](/build/smart-contracts/book/abilities) in Move, all integer types support the ["equal"](/build/smart-contracts/book/equality) and ["not equal"](/build/smart-contracts/book/equality) operations. Both arguments need to be of the same type. If you need to compare integers of different types, you will need to [cast](#casting) one of them first.

Equality operations do not abort.

| Syntax | Operation |
| ------ | --------- |
| `==`   | equal     |
| `!=`   | not equal |

For more details see the section on [equality](/build/smart-contracts/book/equality)

## Casting

Integer types of one size can be cast to integer types of another size. Integers are the only types in Move that support casting.

Casts _do not_ truncate. Casting will abort if the result is too large or too small for the specified type.

| Syntax     | Operation                                            | Aborts if                                           |
| ---------- | ---------------------------------------------------- | --------------------------------------------------- |
| `(e as T)` | Cast integer expression `e` into an integer type `T` | `e` is too large or too small to represent as a `T` |

Any integer can be cast into any other integer type, including signed to unsigned and unsigned to signed, provided the target type is able to represent the source type.

For example:

- `(x as u8)`
- `(y as u16)`
- `(873u16 as u32)`
- `(2u8 as u64)`
- `(1 + 3 as u128)`
- `(4/2 + 12345 as u256)`

Notice that since Language Version 2.0, casts don't always need to be in parentheses. Thus, `x as u8` is a valid expression.

## Ownership

As with the other scalar values built-in to the language, integer values are implicitly copyable, meaning they can be copied without an explicit instruction such as [`copy`](/build/smart-contracts/book/variables#move-and-copy).

# While, For, and Loop

> Master loop constructs in Move including while loops, iteration patterns, and control flow for smart contracts.

Move offers three constructs for looping: `while`, `for`, and `loop`.

## `while` loops

The `while` construct repeats the body (an expression of type unit) until the condition (an expression of type `bool`) evaluates to `false`.

Here is an example of simple `while` loop that computes the sum of the numbers from `1` to `n`:

```move
script {
  fun sum(n: u64): u64 {
    let sum = 0;
    let i = 1;
    while (i <= n) {
      sum = sum + i;
      i = i + 1
    };

    sum
  }
}
```

Infinite loops are allowed:

```move
script {
  fun foo() {
    while (true) { }
  }
}
```

### `break`

The `break` expression can be used to exit a loop before the condition evaluates to `false`. For example, this loop uses `break` to find the smallest factor of `n` that's greater than 1:

```move
script {
  fun smallest_factor(n: u64): u64 {
    // assuming the input is not 0 or 1
    let i = 2;
    while (i <= n) {
      if (n % i == 0) break;
      i = i + 1
    };

    i
  }
}
```

The `break` expression cannot be used outside of a loop.

### `continue`

The `continue` expression skips the rest of the loop and continues to the next iteration. This loop uses `continue` to compute the sum of `1, 2, ..., n`, except when the number is divisible by 10:

```move
script {
  fun sum_intermediate(n: u64): u64 {
    let sum = 0;
    let i = 0;
    while (i < n) {
      i = i + 1;
      if (i % 10 == 0) continue;
      sum = sum + i;
    };

    sum
  }
}
```

The `continue` expression cannot be used outside of a loop.

### The type of `break` and `continue`

`break` and `continue`, much like `return` and `abort`, can have any type. The following examples illustrate where this flexible typing can be helpful:

```move
script {
  fun pop_smallest_while_not_equal(
    v1: vector<u64>,
    v2: vector<u64>,
  ): vector<u64> {
    let result = vector::empty();
    while (!vector::is_empty(&v1) && !vector::is_empty(&v2)) {
      let u1 = *vector::borrow(&v1, vector::length(&v1) - 1);
      let u2 = *vector::borrow(&v2, vector::length(&v2) - 1);
      let popped =
        if (u1 < u2) vector::pop_back(&mut v1)
        else if (u2 < u1) vector::pop_back(&mut v2)
        else break; // Here, `break` has type `u64`
      vector::push_back(&mut result, popped);
    };

    result
  }
}
```

```move
script {
  fun pick(
    indexes: vector<u64>,
    v1: &vector<address>,
    v2: &vector<address>
  ): vector<address> {
    let len1 = vector::length(v1);
    let len2 = vector::length(v2);
    let result = vector::empty();
    while (!vector::is_empty(&indexes)) {
      let index = vector::pop_back(&mut indexes);
      let chosen_vector =
        if (index < len1) v1
        else if (index < len2) v2
        else continue; // Here, `continue` has type `&vector<address>`
      vector::push_back(&mut result, *vector::borrow(chosen_vector, index))
    };

    result
  }
}
```

## The `for` expression

The `for` expression iterates over a range defined using integer-typed `lower_bound` (inclusive) and `upper_bound` (non-inclusive) expressions, executing its loop body for each element of the range. `for` is designed for scenarios where the number of iterations of a loop is determined by a specific range.

Here is an example of a `for` loop that computes the sum of the elements in a range from `0` to `n-1`:

```move
script {
  fun sum(n: u64): u64 {
    let sum = 0;
    for (i in 0..n) {
      sum = sum + i;
    };

    sum
  }
}
```

The loop iterator variable (`i` in the above example) currently must be a numeric type (inferred from the bounds), and the bounds `0` and `n` here can be replaced by arbitrary numeric expressions. Each is only evaluated once at the start of the loop. The iterator variable `i` is assigned the `lower_bound` (in this case `0`) and incremented after each loop iteration; the loop exits when the iterator `i` reaches or exceeds `upper_bound` (in this case `n`).

### `break` and `continue` in `for` loops

Similar to `while` loops, the `break` expression can be used in `for` loops to exit prematurely. The `continue` expression can be used to skip the current iteration and move to the next. Here's an example that demonstrates the use of both `break` and `continue`. The loop will iterate through numbers from `0` to `n-1`, summing up them up. It will skip numbers that are divisible by `3` (using `continue`) and stop when it encounters a number greater than `10` (using `break`):

```move
script {
  fun sum_conditional(n: u64): u64 {
    let sum = 0;
    for (iter in 0..n) {
      if (iter > 10) {
        break; // Exit the loop if the number is greater than 10
      };
      if (iter % 3 == 0) {
        continue; // Skip the current iteration if the number is divisible by 3
      };

      sum = sum + iter;
    };

    sum
  }
}
```

## The `loop` expression

The `loop` expression repeats the loop body (an expression with type `()`) until it hits a `break`

Without a `break`, the loop will continue forever

```move
script {
  fun foo() {
    let i = 0;
    loop { i = i + 1 }
  }
}

```

Here is an example that uses `loop` to write the `sum` function:

```move
script {
  fun sum(n: u64): u64 {
    let sum = 0;
    let i = 0;
    loop {
      i = i + 1;
      if (i > n) break;
      sum = sum + i
    };

    sum
  }
}
```

As you might expect, `continue` can also be used inside a `loop`. Here is `sum_intermediate` from above rewritten using `loop` instead of `while`

```move
script {
  fun sum_intermediate(n: u64): u64 {
    let sum = 0;
    let i = 0;
    loop {
      i = i + 1;
      if (i % 10 == 0) continue;
      if (i > n) break;
      sum = sum + i
    };

    sum
  }
}
```

## The type of `while`, `loop`, and `for` expression

Move loops are typed expressions. The `while` and `for` expression always has type `()`.

```move
script {
  fun example() {
    let () = while (i < 10) { i = i + 1 };
    let () = for (i in 0..10) {};
  }
}
```

If a `loop` contains a `break`, the expression has type unit `()`

```move
script {
  fun example() {
    (loop { if (i < 10) i = i + 1 else break }: ());
    let () = loop { if (i < 10) i = i + 1 else break };
  }
}
```

If `loop` does not have a `break` or a `continue`, `loop` can have any type much like `return`, `abort`, `break`, and `continue`.

```move
script {
  fun example() {
    (loop (): u64);
    (loop (): address);
    (loop (): &vector<vector<u8>>);
  }
}
```

## Loop Labels

_Since language version 2.1_

A `while` or `loop` statement can have a label which can be referred to by a `break` or `continue` statement. In the presence of nested loops, this allows to refer to outer loops. Example:

```move
script {
  fun example(x: u64): u64 {
    'label1: while (x > 10) {
      loop {
        if (x % 2 == 0) {
          x -= 1;
          continue 'label1;
        } else if (x < 10) {
          break 'label1
        } else
          x -= 2
      }
    };
    x
  }
}
```

# Modules and Scripts

> Learn about modules and scripts in Move programming language for Aptos smart contract development.

import { Aside } from '@astrojs/starlight/components';

Move has two different types of programs: \***Modules**\* and \*\*_Scripts_\*\*. Modules are libraries that define struct types along with functions that operate on these types. Struct types define the schema of Move's [global storage](/build/smart-contracts/book/global-storage-structure), and module functions define the rules for updating storage. Modules themselves are also stored in global storage. A scripts is an executable entrypoint similar to a `main` function in a conventional language. A script typically calls functions of a published module that perform updates to global storage. Scripts are ephemeral code snippets that are not published in global storage.

A Move source file (or **compilation unit**) may contain multiple modules and scripts. However, publishing a module or executing a script are separate VM operations.

## Syntax

### Scripts

<Aside type="note">
  To learn how to publish and execute a Move script, follow the [Move Scripts](/build/smart-contracts/scripts/script-tutorial) example.
</Aside>

A script has the following structure:

```text
script {
    <use>*
    <constants>*
    fun <identifier><[type parameters: constraint]*>([identifier: type]*) <function_body>
}
```

A `script` block must start with all of its [`use`](/build/smart-contracts/book/uses) declarations, followed by any [constants](/build/smart-contracts/book/constants) and (finally) the main
[function](/build/smart-contracts/book/functions) declaration.
The main function can have any name (i.e., it need not be called `main`), is the only function in a script block, can have any number of
arguments, and must not return a value. Here is an example with each of these components:

```move
script {
    // Import the debug module published at the named account address std.
    use std::debug;

    const ONE: u64 = 1;

    fun main(x: u64) {
        let sum = x + ONE;
        debug::print(&sum)
    }
}
```

Scripts have very limited power‚Äîthey cannot declare friends, struct types or access global storage. Their primary purpose is to invoke module functions.

### Modules

A module has the following syntax:

```move
module <address>::<identifier> {
    (<use> | <friend> | <type> | <function> | <constant>)*
}
```

where `<address>` is a valid [named or literal address](/build/smart-contracts/book/address).

For example:

```move
module 0x42::example {
    struct Example has copy, drop { i: u64 }

    use std::debug;
    friend 0x42::another_example;

    const ONE: u64 = 1;

    public fun print(x: u64) {
        let sum = x + ONE;
        let example = Example { i: sum };
        debug::print(&sum)
    }
}
```

The `module 0x42::example` part specifies that the module `example` will be published under the [account address](/build/smart-contracts/book/address) `0x42` in [global storage](/build/smart-contracts/book/global-storage-structure).

Modules can also be declared using [named addresses](/build/smart-contracts/book/address). For example:

```move
module example_addr::example {
    struct Example has copy, drop { a: address }

    use std::debug;
    friend example_addr::another_example;

    public fun print() {
        let example = Example { a: @example_addr };
        debug::print(&example)
    }
}
```

Because named addresses only exist at the source language level and during compilation,
named addresses will be fully substituted for their value at the bytecode
level. For example if we had the following code:

```move
script {
    fun example() {
        my_addr::m::foo(@my_addr);
    }
}
```

and we compiled it with `my_addr` set to `0xC0FFEE`, then it would be equivalent
to the following operationally:

```move
script {
    fun example() {
        0xC0FFEE::m::foo(@0xC0FFEE);
    }
}
```

However, at the source level, these _are not equivalent_‚Äîthe function
`m::foo` _must_ be accessed through the `my_addr` named address, and not through
the numerical value assigned to that address.

Module names can start with letters `a` to `z` or letters `A` to `Z`. After the first character, module names can contain underscores `_`, letters `a` to `z`, letters `A` to `Z`, or digits `0` to `9`.

```move
module my_module {}
module foo_bar_42 {}
```

Typically, module names start with a lowercase letter. A module named `my_module` should be stored in a source file named `my_module.move`.

All elements inside a `module` block can appear in any order.
Fundamentally, a module is a collection of [`types`](/build/smart-contracts/book/structs-and-resources) and [`functions`](/build/smart-contracts/book/functions).
The [`use`](/build/smart-contracts/book/uses) keyword is used to import types from other modules.
The [`friend`](/build/smart-contracts/book/friends) keyword specifies a list of trusted modules.
The [`const`](/build/smart-contracts/book/constants) keyword defines private constants that can be used in the functions of a module.

# Move 2 Release Notes

> Explore Move 2.0 language features, improvements, and migration guide for enhanced smart contract development on Aptos.

The Move 2 language releases are described on this page. The reference documentation of the new features is integrated into the book, and marked in the text with "_Since language version 2.n_".

## Move 2.3

The Move 2.3 language release adds the following features to Move:

- **Signed Integer Types**: Move now supports `i8`, `i16`, `i32`, `i64`, `i128`, and `i256` signed integer types. See the [reference doc here](/build/smart-contracts/book/integers).
- **Builtin Constants**: Move now supports a number of builtin constants, namely min/max values for integer types (e.g. `MAX_U64`, `MIN_I32`), as well as a constant to determine whether code is running in testing mode. See the [reference doc here](/build/smart-contracts/book/constants#builtin-constants).

## Move 2.2

The Move 2.2 language release adds the following features to Move:

- **Optional Acquires**: The `acquires` annotation on function declarations can be omitted, to be inferred by the compiler.
- **Function Values**: Move now supports function values, which can be passed around as parameters and stored in resources. See the [reference doc here](/build/smart-contracts/book/functions#function-values).
- **Comparison Operations**: Move now supports comparison operations (`<`, `>`, `<=`, `>=`) on all types. See the [reference doc here](/build/smart-contracts/book/comparison#typing).

## Move 2.1

The Move 2.1 language release adds the following features to Move:

- **Compound Assignments** One can now use `x += n`, `x -= n`, etc. to combine assignments and arithmetic operations. See [reference doc here](/build/smart-contracts/book/variables#compound-assignments) for the supported operations.

- **Loop Labels** One can now use labels for loops and have a `break` or `continue` expression refer to those labels. This allows to continue or break outer loops from within nested loops. See [reference doc here](/build/smart-contracts/book/loops#loop-labels).

- **Underscore function parameters are wildcards, not symbols** Function parameters named `_` no longer act like variables: they do not bind a value, and multiple such parameters to a function does not cause a conflict.  Using `_` in a value expression will yield an error, as it has no value.  This makes the behavior of `_` more like the wildcard it is in patterns and let expressions, where it does not bind a value.

## Move 2.0

The Move 2.0 language release adds the following features to Move:

- **Enum Types** add the option to define different variants of data layout in one storable type. They are documented in the [Enum Type section](/build/smart-contracts/book/enums).

- **Receiver Style Functions** add the ability to call functions in the familiar notation `value.func(arg)`. They are documented in [this section](/build/smart-contracts/book/functions#dot-receiver-function-call-style).

- **Index Notation** allows access to [elements of vectors](/build/smart-contracts/book/vector#index-notation-for-vectors) and of [resource storage](/build/smart-contracts/book/global-storage-operators#index-notation-for-storage-operators) with notations like `&mut vector[index]`, or `&mut Resource[addr]`, respectively.

- **Positional Structs** allow to define wrapper types such as `struct Wrapped(u64)`. Positional structs are described [here](/build/smart-contracts/book/structs-and-resources#positional-structs). Enum variants are also allowed to be positional.

- **Dot-dot pattern wildcards** enable statements like `let Struct{x, ..} = value` to match selective parts of data. They are described [here](/build/smart-contracts/book/structs-and-resources#partial-patterns). Those patterns are also allowed for enum variants.

- **Package visibility** allows to declare a function to be visible anywhere inside, but not outside a package. Friend functions continue to be supported, although package visibility is in many cases more suitable. As a more concise notation, package and friend functions can be simply declared as `package fun` or `friend fun`, respectively, instead of the longer `public(package) fun` and `public(friend) fun`. This feature is documented [here](/build/smart-contracts/book/functions#package-visibility).

- **Assert abort code optional** The `assert!` macro can now be used with just one argument, omitting the abort code, in which case a default code will be chosen. See also [here](/build/smart-contracts/book/abort-and-assert#assert).

- **New Cast Syntax** Until now, casts had to always be in parentheses, requiring code like `function((x as u256))`. This requirement is now dropped and casts can be top-level expressions without parenthesis, as in `function(x as u256)`. One still needs to write `(x as u64) + (y as u64)` in expressions. This similarly applies to the new enum variant test, `data is VersionedData::V1`.

- **Well-defined evaluation order** The evaluation order in the cases below is now well-defined (these were previously unspecified):
  - The (a) arguments to a function call, and the (b) operand expressions in a binary operation, are both evaluated from left-to-right.
  - Given a "mutate" expression (see [mutating through a reference](/build/smart-contracts/book/variables#mutating-through-a-reference)) of the form `*lexp = rexp`, where `lexp` is an expression of type `&mut T` and `rexp` is an expression of type `T`, `rexp` is evaluated first, followed by `lexp`.

- **Bug fix for acquires annotation** [A function should be annotated with `acquires`](/build/smart-contracts/book/functions#acquires) if and only if it accesses a resource using `move_from`, `borrow_global`, or `borrow_global_mut`, either directly or transitively through a call. Otherwise, it is an error. Previously, when the transitive call graph included a cycle, such errors were not reported: this was incorrect behavior. We have now corrected this behavior to report these errors even when the transitive call graph has cycles.

# Move Tutorial

> Learn about move tutorial in Move programming language for Aptos smart contract development.

Please refer to the [Move Core Language Tutorial](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/move-examples/move-tutorial).

# Package Upgrades

> Learn how to upgrade Move packages safely with compatibility checks and migration strategies on Aptos.

import { Aside } from '@astrojs/starlight/components';

Move code (e.g., Move modules) on the Aptos blockchain can be upgraded. This
allows code owners and module developers to update and evolve their contracts
under a single, stable, well-known account address that doesn't change. If a
module upgrade happens, all consumers of that module will automatically receive
the latest version of the code (e.g., the next time they interact with it).

The Aptos blockchain natively supports different _upgrade policies_, which allow
move developers to explicitly define the constraints around how their move code
can be upgraded. The default policy is _backwards compatible_. This means that
code upgrades are accepted only if they guarantee that no existing resource storage
or public APIs are broken by the upgrade (including public functions).
This compatibility checking is possible because of Move's strongly typed bytecode
semantics.

We note, however, that even compatible upgrades can have hazardous effects on
applications and dependent Move code (for example, if the semantics of the underlying
module are modified). As a result, developers should be careful when depending on
third-party Move code that can be upgraded on-chain. See
[Security considerations for dependencies](#security-considerations-for-dependencies)
for more details.

## How it works

Move code upgrades on the Aptos blockchain happen at the [Move package](/build/smart-contracts/book/packages)
granularity. A package specifies an upgrade policy in the `Move.toml` manifest:

```toml
[package]
name = "MyApp"
version = "0.0.1"
upgrade_policy = "compatible"
...
```

<Aside type="note">
  Aptos checks compatibility at the time a Move package is published via an Aptos transaction. This transaction will abort if deemed incompatible.
</Aside>

## How to upgrade

To upgrade already published Move code, simply attempt to republish the code at
the same address that it was previously published. This can be done by following the
instructions for code compilation and publishing using the
[Aptos CLI](/build/cli/working-with-move-contracts). For an example,
see the [Your First Move Module](/build/guides/first-move-module) tutorial.

## Upgrade policies

There are two different upgrade policies currently supported by Aptos:

- `compatible`: these upgrades must be backwards compatible, specifically:
  - For storage, all old struct declarations must be the same in
    the new code. This ensures that the existing state of storage is
    correctly interpreted by the new code. However, new struct declarations
    can be added.
  - For APIs, all existing public functions must have the same signature as
    before. New functions, including public and entry functions, can be added.
- `immutable`: the code is not upgradeable and is guaranteed to stay the same
  forever.

Those policies are ordered regarding strength such that `compatible < immutable`,
i.e., compatible is weaker than immutable. The policy of a package on-chain can
only get stronger, not weaker. Moreover, the policy of all dependencies of a
package must be stronger or equal to the policy of the given package. For example,
an `immutable` package cannot refer directly or indirectly to a `compatible` package.
This gives users the guarantee that no unexpected updates can happen under the hood.

Note that there is one exception to the above rule: framework packages
installed at addresses `0x1` to `0xa` are exempted from the dependency check.
This is necessary so one can define an `immutable` package based on the standard
libraries, which have the `compatible` policy to allow critical upgrades and fixes.

## Compatibility rules

When using `compatible` upgrade policy, a module package can be upgraded. However, updates to existing modules already
published previously need to be compatible and follow the rules below:

- All existing structs' fields cannot be updated. This means no new fields can be added and existing fields cannot be
  modified.
- All public and entry functions cannot change their signature (argument types, type argument, return types). However,
  argument names can change.
- `public(friend)` functions are treated as private and thus their signature can arbitrarily change. This is safe as
  only modules in the same package can call friend functions anyway, and they need to be updated if the signature changes.
- [Enum type upgrade compatibility rules](/build/smart-contracts/book/enums#enum-type-upgrade-compatibility).
- Existing abilities on a struct/enum type cannot be removed (but abilities can be added).

When updating your modules, if you see an incompatible error, make sure to check the above rules and fix any violations.

## Security considerations for dependencies

As mentioned above, even compatible upgrades can have disastrous effects for
applications that depend on the upgraded code. These effects can come from bugs,
but they can also be the result of malicious upgrades. For example,
an upgraded dependency can suddenly make all functions abort, breaking the
operation of your Move code. Alternatively, an upgraded dependency can make
all functions suddenly cost much more gas to execute then before the upgrade.
As result, dependencies to upgradeable packages need to be handled with care:

- The safest dependency is, of course, an `immutable` package. This guarantees
  that the dependency will never change, including its transitive dependencies.
  In order to update an immutable package, the owner would have to introduce a
  new major version, which is practically like deploying a new, separate
  and independent package. This is because major versioning can be expressed
  only by name (e.g., `module feature_v1` and `module feature_v2`). However,
  not all package owners like to publish their code as `immutable`, because this
  takes away the ability to fix bugs and update the code in place.
- If you have a dependency to a `compatible` package, it is highly
  recommended you know and understand the entity publishing the package.
  The highest level of assurance is when the package is governed by a
  Decentralized Autonomous Organization (DAO) where no single user can initiate
  an upgrade; a vote or similar has to be taken. This is the case for the Aptos
  framework.

## Programmatic upgrade

In general, Aptos offers, via the Move module `aptos_framework::code`,
ways to publish code from anywhere in your smart contracts. However,
notice that code published in the current transaction can be executed
only after that transaction ends.

The Aptos framework itself, including all the on-chain administration logic, is
an example for programmatic upgrade. The framework is marked as `compatible`.
Upgrades happen via specific generated governance scripts. For more details,
see [Aptos Governance](/network/blockchain/governance).

# Packages

> Learn about packages in Move programming language for Aptos smart contract development.

import { FileTree } from '@astrojs/starlight/components';

Packages allow Move programmers to more easily re-use code and share it
across projects. The Move package system allows programmers to easily do the following:

- Define a package containing Move code;
- Parameterize a package by [named addresses](/build/smart-contracts/book/address);
- Import and use packages in other Move code and instantiate named addresses;
- Build packages and generate associated compilation artifacts from packages; and
- Work with a common interface around compiled Move artifacts.

## Package Layout and Manifest Syntax

A Move package source directory contains a `Move.toml` package manifest
file along with a set of subdirectories:

<FileTree>
  - a\_move\_package/
    - Move.toml
    - sources (required)/
      - module.move
      - \*.move
    - examples (optional, test & dev mode)/
    - scripts (optional, can also put in sources)/
    - doc\_templates (optional)/
    - tests (optional, test mode)/
</FileTree>

The directories marked `required` _must_ be present in order for the directory
to be considered a Move package and to be compiled. Optional directories can
be present, and if so will be included in the compilation process. Depending on
the mode that the package is built with (`test` or `dev`), the `tests` and
`examples` directories will be included as well.

The `sources` directory can contain both Move modules and Move scripts (both
Move scripts and modules containing script functions). The `examples`
directory can hold additional code to be used only for development and/or
tutorial purposes that will not be included when compiled outside `test` or
`dev` mode.

A `scripts` directory is supported so Move scripts can be separated
from modules if that is desired by the package author. The `scripts`
directory will always be included for compilation if it is present.
Documentation will be built using any documentation templates present in
the `doc_templates` directory.

### Move.toml

The Move package manifest is defined within the `Move.toml` file and has the
following syntax. Optional fields are marked with `*`, `+` denotes
one or more elements:

```toml filename="Move.toml"
[package]
name = <string>                  # e.g., "MoveStdlib"
version = "<uint>.<uint>.<uint>" # e.g., "0.1.1"
license* = <string>              # e.g., "MIT", "GPL", "Apache 2.0"
authors* = [<string>]            # e.g., ["Joe Smith (joesmith@noemail.com)", "Jane Smith (janesmith@noemail.com)"]

[addresses]  # (Optional section) Declares named addresses in this package and instantiates named addresses in the package graph
# One or more lines declaring named addresses in the following format
<addr_name> = "_" | "<hex_address>" # e.g., std = "_" or my_addr = "0xC0FFEECAFE"

[dependencies] # (Optional section) Paths to dependencies and instantiations or renamings of named addresses from each dependency
# One or more lines declaring dependencies in the following format
<string> = { local = <string>, addr_subst* = { (<string> = (<string> | "<hex_address>"))+ } } # local dependencies
<string> = { git = <URL ending in .git>, subdir=<path to dir containing Move.toml inside git repo>, rev=<git commit hash or branch name>, addr_subst* = { (<string> = (<string> | "<hex_address>"))+ } } # git dependencies

[dev-addresses] # (Optional section) Same as [addresses] section, but only included in "dev" and "test" modes
# One or more lines declaring dev named addresses in the following format
<addr_name> = "_" | "<hex_address>" # e.g., std = "_" or my_addr = "0xC0FFEECAFE"

[dev-dependencies] # (Optional section) Same as [dependencies] section, but only included in "dev" and "test" modes
# One or more lines declaring dev dependencies in the following format
<string> = { local = <string>, addr_subst* = { (<string> = (<string> | <address>))+ } }
```

An example of a minimal package manifest with one local dependency and one git dependency:

```toml
[package]
name = "AName"
version = "0.0.0"
```

An example of a more standard package manifest that also includes the Move
standard library and instantiates the named address `Std` from it with the
address value `0x1`:

```toml
[package]
name = "AName"
version = "0.0.0"
license = "Apache 2.0"

[addresses]
address_to_be_filled_in = "_"
specified_address = "0xB0B"

[dependencies]
# Local dependency
LocalDep = { local = "projects/move-awesomeness", addr_subst = { "std" = "0x1" } }
# Git dependency
MoveStdlib = { git = "https://github.com/aptos-labs/aptos-framework", subdir="move-stdlib", rev = "mainnet" }

[dev-addresses] # For use when developing this module
address_to_be_filled_in = "0x101010101"
```

Most of the sections in the package manifest are self-explanatory, but named
addresses can be a bit difficult to understand, so it's worth examining them in
a bit more detail.

## Named Addresses During Compilation

Recall that Move has [named addresses](/build/smart-contracts/book/address) and that
named addresses cannot be declared in Move. Because of this, until now
named addresses and their values needed to be passed to the compiler on the
command line. With the Move package system this is no longer needed, and
you can declare named addresses in the package, instantiate other named
addresses in scope, and rename named addresses from other packages within
the Move package system manifest file. Let's go through each of these
individually:

### Declaration

Let's say we have a Move module in `example_pkg/sources/A.move` as follows:

```move
module named_addr::A {
  public fun x(): address { @named_addr }
}
```

We could in `example_pkg/Move.toml` declare the named address `named_addr` in
two different ways. The first:

```toml
[package]
name = "ExamplePkg"
# ...
[addresses]
named_addr = "_"
```

Declares `named_addr` as a named address in the package `ExamplePkg` and
that _this address can be any valid address value_. Therefore, an importing
package can pick the value of the named address `named_addr` to be any address
it wishes. Intuitively you can think of this as parameterizing the package
`ExamplePkg` by the named address `named_addr`, and the package can then be
instantiated later on by an importing package.

`named_addr` can also be declared as:

```toml
[package]
name = "ExamplePkg"
# ...
[addresses]
named_addr = "0xCAFE"
```

which states that the named address `named_addr` is exactly `0xCAFE` and cannot be
changed. This is useful so other importing packages can use this named
address without needing to worry about the exact value assigned to it.

With these two different declaration methods, there are two ways that
information about named addresses can flow in the package graph:

- The former ("unassigned named addresses") allows named address values to flow
  from the importation site to the declaration site.
- The latter ("assigned named addresses") allows named address values to flow
  from the declaration site upwards in the package graph to usage sites.

With these two methods for flowing named address information throughout the
package graph the rules around scoping and renaming become important to
understand.

## Scoping and Renaming of Named Addresses

A named address `N` in a package `P` is in scope if:

1. It declares a named address `N`; or
2. A package in one of `P`'s transitive dependencies declares the named address
   `N` and there is a dependency path in the package graph between `P` and the
   declaring package of `N` with no renaming of `N`.

Additionally, every named address in a package is exported. Because of this and
the above scoping rules each package can be viewed as coming with a set of
named addresses that will be brought into scope when the package is imported,
e.g., if the `ExamplePkg` package was imported, that importation would bring
into scope the `named_addr` named address. Because of this, if `P` imports two
packages `P1` and `P2` both of which declare a named address `N` an issue
arises in `P`: which "`N`" is meant when `N` is referred to in `P`? The one
from `P1` or `P2`? To prevent this ambiguity around which package a named
address is coming from, we enforce that the sets of scopes introduced by all
dependencies in a package are disjoint, and provide a way to _rename named
addresses_ when the package that brings them into scope is imported.

Renaming a named address when importing can be done as follows in our `P`,
`P1`, and `P2` example above:

```toml
[package]
name = "P"
# ...
[dependencies]
P1 = { local = "some_path_to_P1", addr_subst = { "P1N" = "N" } }
P2 = { local = "some_path_to_P2"  }
```

With this renaming `N` refers to the `N` from `P2` and `P1N` will refer to `N`
coming from `P1`:

```move
module N::A {
    public fun x(): address { @P1N }
}
```

It is important to note that _renaming is not local_: once a named address `N`
has been renamed to `N2` in a package `P` all packages that import `P` will not
see `N` but only `N2` unless `N` is reintroduced from outside of `P`. This is
why rule (2) in the scoping rules at the start of this section specifies a
"dependency path in the package graph between `P` and the declaring
package of `N` with no renaming of `N`."

### Instantiation

Named addresses can be instantiated multiple times across the package graph as
long as it is always with the same value. It is an error if the same named
address (regardless of renaming) is instantiated with differing values across
the package graph.

A Move package can only be compiled if all named addresses resolve to a value.
This presents issues if the package wishes to expose an uninstantiated named
address. This is what the `[dev-addresses]` section solves. This section can
set values for named addresses, but cannot introduce any named addresses.
Additionally, only the `[dev-addresses]` in the root package are included in
`dev` mode. For example a root package with the following manifest would not compile
outside of `dev` mode since `named_addr` would be uninstantiated:

```toml
[package]
name = "ExamplePkg"
# ...
[addresses]
named_addr = "_"

[dev-addresses]
named_addr = "0xC0FFEE"
```

## Usage, Artifacts, and Data Structures

The Move package system comes with a command line option as part of the Move
CLI `move <flags> <command> <command_flags>`. Unless a
particular path is provided, all package commands will run in the current working
directory. The full list of commands and flags for the Move CLI can be found by
running `move --help`.

### Usage

A package can be compiled either through the Move CLI commands, or as a library
command in Rust with the function `compile_package`. This will create a
`CompiledPackage` that holds the compiled bytecode along with other compilation
artifacts (source maps, documentation, ABIs) in memory. This `CompiledPackage`
can be converted to an `OnDiskPackage` and vice versa -- the latter being the data of
the `CompiledPackage` laid out in the file system in the following format:

<FileTree>
  - a\_move\_package/
    - .../
    - build/
      - dependency\_name/
        - BuildInfo.yaml
        - bytecode\_modules/
          - module\_name.mv
          - \*.mv
        - source\_maps/
          - module\_name.mvsm
          - \*.mvsm
        - bytecode\_scripts/
          - script\_name.mv
          - \*.mv
        - abis/
          - script\_name.abi
          - \*.abi
          - module\_name/
            - function\_name.abi
            - \*.abi
        - sources/
          - module\_name.move
      - dependency\_name2 .../
</FileTree>

See the `move-package` crate for more information on these data structures and
how to use the Move package system as a Rust library.

## Using Bytecode for Dependencies

Move bytecode can be used as dependencies when the Move source code for those dependencies are not available locally. To use this feature, you will need co-locate the files in directories at the same level and then specify their paths in the corresponding `Move.toml` files.

## Requirements and limitations

Using local bytecode as dependencies requires bytecode files to be downloaded locally, and the actual address for each named address must be specified in either `Move.toml` or through `--named-addresses`.

Note, both `aptos move prove` and `aptos move test` commands, currently, do not support bytecode as dependencies.

## Recommended structure

We use an example to illustrate the development flow of using this feature. Suppose we want to compile the package `A`. The package layout is:

<FileTree>
  - A/
    - Move.toml
    - sources/
      - AModule.move
</FileTree>

`A.move` is defined below, depending on the modules `Bar` and `Foo`:

```move filename="A/AModule.move"
module A::AModule {
    use B::Bar;
    use C::Foo;
    public fun foo(): u64 {
        Bar::foo() + Foo::bar()
    }
}
```

Suppose the source of `Bar` and `Foo` are not available but the corresponding bytecode `Bar.mv` and `Foo.mv` are available locally. To use them as dependencies, we would:

Specify `Move.toml` for `Bar` and `Foo`. Note that named addresses are already instantiated with the actual address in the bytecode. In our example, the actual address for `C` is already bound to `0x3`. As a result, `[addresses]` must be specified `C` as `0x3`, as shown below:

```toml filename="workspace/C/Move.toml"
[package]
name = "Foo"
version = "0.0.0"

[addresses]
C = "0x3"
```

Place the bytecode file and the corresponding `Move.toml` file in the same directory with the bytecode in a `build` subdirectory. Note an empty `sources` directory is **required**. For instance, the layout of the folder `B` (for the package `Bar`) and `C` (for the package `Foo`) would resemble:

<FileTree>
  - workspace/
    - A/
      - Move.toml
      - sources/
        - AModule.move
    - B/
      - Move.toml
      - sources/
      - build/
        - Bar.mv
    - C/
      - Move.toml
      - sources/
      - build/
        - Foo/
          - bytecode\_modules/
            - Foo.mv
</FileTree>

Specify `[dependencies]` in the `Move.toml` of the target (first) package with the location of the dependent (secondary) packages. For instance, assuming all three package directories are at the same level, `Move.toml` of `A` would resemble:

```toml filename="workspace/A/Move.toml"
[package]
name = "A"
version = "0.0.0"

[addresses]
A = "0x2"

[dependencies]
Bar = { local = "../B" }
Foo = { local = "../C" }
```

Note that if both the bytecode and the source code of the same package exist in the search paths, the compiler will complain that the declaration is duplicated.

## Overriding the Standard Libraries

When working with third-party packages, you might encounter issues where different versions of the Move and Aptos standard library packages are referenced.

This can lead to package resolution failures.

```
"Error": "Move compilation failed:
  Unable to resolve packages for package 'C':
    While resolving dependency 'B' in package 'C':
      Unable to resolve package dependency 'B':
        While resolving dependency 'AptosFramework' in package 'B':
          Unable to resolve package dependency 'AptosFramework':
            Conflicting dependencies found: package 'AptosFramework' conflicts with 'AptosFramework'
```

To resolve this, you can override the standard library packages using a command-line option. This allows you to enforce a specific version of the standard libraries across your entire dependency tree.

You can apply the override to commands like `aptos move compile`, `aptos move run`, and others. Here is the syntax:

```
--override-std <network name>
```

Where `network_name` can be one of the following:

- devnet
- testnet
- mainnet

# References

> Learn about references in Move for borrowing values, memory safety, and efficient data access without ownership transfer.

Move has two types of references: immutable `&` and mutable `&mut`. Immutable references are read
only, and cannot modify the underlying value (or any of its fields). Mutable references allow for
modifications via a write through that reference. Move's type system enforces an ownership
discipline that prevents reference errors.

For more details on the rules of references, see [Structs and Resources](/build/smart-contracts/book/structs-and-resources)

## Reference Operators

Move provides operators for creating and extending references as well as converting a mutable
reference to an immutable one. Here and elsewhere, we use the notation `e: T` for "expression `e`
has type `T`".

| Syntax      | Type                                                  | Description                                                    |
| ----------- | ----------------------------------------------------- | -------------------------------------------------------------- |
| `&e`        | `&T` where `e: T` and `T` is a non-reference type     | Create an immutable reference to `e`                           |
| `&mut e`    | `&mut T` where `e: T` and `T` is a non-reference type | Create a mutable reference to `e`.                             |
| `&e.f`      | `&T` where `e.f: T`                                   | Create an immutable reference to field `f` of struct `e`.      |
| `&mut e.f`  | `&mut T` where `e.f: T`                               | Create a mutable reference to field `f` of struct`e`.          |
| `freeze(e)` | `&T` where `e: &mut T`                                | Convert the mutable reference `e` into an immutable reference. |

The `&e.f` and `&mut e.f` operators can be used both to create a new reference into a struct or to
extend an existing reference:

```move
script {
  fun example() {
    let s = S { f: 10 };
    let f_ref1: &u64 = &s.f; // works
    let s_ref: &S = &s;
    let f_ref2: &u64 = &s_ref.f; // also works
  }
}
```

A reference expression with multiple fields works as long as both structs are in the same module:

```move
module 0x42::example {
  struct A { b: B }
  struct B { c : u64 }

  fun f(a: &A): &u64 {
    &a.b.c
  }
}
```

Finally, note that references to references are not allowed:

```move
script {
  fun example() {
    let x = 7;
    let y: &u64 = &x;
    let z: &&u64 = &y; // will not compile
  }
}
```

## Reading and Writing Through References

Both mutable and immutable references can be read to produce a copy of the referenced value.

Only mutable references can be written. A write `*x = v` discards the value previously stored in `x`
and updates it with `v`.

Both operations use the C-like `*` syntax. However, note that a read is an expression, whereas a
write is a mutation that must occur on the left hand side of an equals.

| Syntax     | Type                                | Description                         |
| ---------- | ----------------------------------- | ----------------------------------- |
| `*e`       | `T` where `e` is `&T` or `&mut T`   | Read the value pointed to by `e`    |
| `*e1 = e2` | `()` where `e1: &mut T` and `e2: T` | Update the value in `e1` with `e2`. |

In order for a reference to be read, the underlying type must have the
[`copy` ability](/build/smart-contracts/book/abilities) as reading the reference creates a new copy of the value. This rule
prevents the copying of resource values:

```move
module 0x42::coin {
  struct Coin {} // Note does not have copy

  fun copy_resource_via_ref_bad(c: Coin) {
      let c_ref = &c;
      let counterfeit: Coin = *c_ref; // not allowed!
      pay(c);
      pay(counterfeit);
  }
}
```

Dually: in order for a reference to be written to, the underlying type must have the
[`drop` ability](/build/smart-contracts/book/abilities) as writing to the reference will discard (or "drop") the old value.
This rule prevents the destruction of resource values:

```move
module 0x42::coin {
  struct Coin {} // Note does not have drop

  fun destroy_resource_via_ref_bad(ten_coins: Coin, c: Coin) {
      let ref = &mut ten_coins;
      *ref = c; // not allowed--would destroy 10 coins!
  }
}
```

## `freeze` inference

A mutable reference can be used in a context where an immutable reference is expected:

```move
script {
  fun example() {
    let x = 7;
    let y: &u64 = &mut x;
  }
}
```

This works because the under the hood, the compiler inserts `freeze` instructions where they are
needed. Here are a few more examples of `freeze` inference in action:

```move
module 0x42::example {
  fun takes_immut_returns_immut(x: &u64): &u64 { x }

  // freeze inference on return value
  fun takes_mut_returns_immut(x: &mut u64): &u64 { x }

  fun expression_examples() {
    let x = 0;
    let y = 0;
    takes_immut_returns_immut(&x); // no inference
    takes_immut_returns_immut(&mut x); // inferred freeze(&mut x)
    takes_mut_returns_immut(&mut x); // no inference

    assert!(&x == &mut y, 42); // inferred freeze(&mut y)
  }

  fun assignment_examples() {
    let x = 0;
    let y = 0;
    let imm_ref: &u64 = &x;

    imm_ref = &x; // no inference
    imm_ref = &mut y; // inferred freeze(&mut y)
  }
}
```

### Subtyping

With this `freeze` inference, the Move type checker can view `&mut T` as a subtype of `&T`. As shown
above, this means that anywhere for any expression where a `&T` value is used, a `&mut T` value can
also be used. This terminology is used in error messages to concisely indicate that a `&mut T` was
needed where a `&T` was supplied. For example

```move
module 0x42::example {
  fun read_and_assign(store: &mut u64, new_value: &u64) {
    *store = *new_value
  }

  fun subtype_examples() {
    let x: &u64 = &0;
    let y: &mut u64 = &mut 1;

    x = &mut 1; // valid
    y = &2; // invalid!

    read_and_assign(y, x); // valid
    read_and_assign(x, y); // invalid!
  }
}
```

will yield the following error messages

```shellscript
error:

    ‚îå‚îÄ‚îÄ example.move:12:9 ‚îÄ‚îÄ‚îÄ
    ‚îÇ
 12 ‚îÇ         y = &2; // invalid!
    ‚îÇ         ^ Invalid assignment to local 'y'
    ¬∑
 12 ‚îÇ         y = &2; // invalid!
    ‚îÇ             -- The type: '&{integer}'
    ¬∑
  9 ‚îÇ         let y: &mut u64 = &mut 1;
    ‚îÇ                -------- Is not a subtype of: '&mut u64'
    ‚îÇ

error:

    ‚îå‚îÄ‚îÄ example.move:15:9 ‚îÄ‚îÄ‚îÄ
    ‚îÇ
 15 ‚îÇ         read_and_assign(x, y); // invalid!
    ‚îÇ         ^^^^^^^^^^^^^^^^^^^^^ Invalid call of '0x42::example::read_and_assign'. Invalid argument for parameter 'store'
    ¬∑
  8 ‚îÇ         let x: &u64 = &0;
    ‚îÇ                ---- The type: '&u64'
    ¬∑
  3 ‚îÇ     fun read_and_assign(store: &mut u64, new_value: &u64) {
    ‚îÇ                                -------- Is not a subtype of: '&mut u64'
    ‚îÇ
```

The only other types currently that has subtyping are [tuples](/build/smart-contracts/book/tuples)

## Ownership

Both mutable and immutable references can always be copied and extended _even if there are existing
copies or extensions of the same reference_:

```move
script {
  fun reference_copies(s: &mut S) {
    let s_copy1 = s; // ok
    let s_extension = &mut s.f; // also ok
    let s_copy2 = s; // still ok
    // ...
  }
}
```

This might be surprising for programmers familiar with Rust's ownership system, which would reject
the code above. Move's type system is more permissive in its treatment of
[copies](/build/smart-contracts/book/variables#move-and-copy), but equally strict in ensuring unique ownership of mutable
references before writes.

### References Cannot Be Stored

References and tuples are the _only_ types that cannot be stored as a field value of structs, which
also means that they cannot exist in global storage. All references created during program execution
will be destroyed when a Move program terminates; they are entirely ephemeral. This invariant is
also true for values of types without the `store` [ability](/build/smart-contracts/book/abilities), but note that
references and tuples go a step further by never being allowed in structs in the first place.

This is another difference between Move and Rust, which allows references to be stored inside of
structs.

Currently, Move cannot support this because references cannot be
[serialized](https://en.wikipedia.org/wiki/Serialization), but _every Move value must be
serializable_. This requirement comes from Move's
[persistent global storage](/build/smart-contracts/book/global-storage-structure), which needs to serialize values to
persist them across program executions. Structs can be written to global storage, and thus they must
be serializable.

One could imagine a fancier, more expressive, type system that would allow references to be stored
in structs _and_ ban those structs from existing in global storage. We could perhaps allow
references inside of structs that do not have the `store` [ability](/build/smart-contracts/book/abilities), but that would
not completely solve the problem: Move has a fairly complex system for tracking static reference
safety, and this aspect of the type system would also have to be extended to support storing
references inside of structs. In short, Move's type system (particularly the aspects around
reference safety) would have to expand to support stored references. But it is something we are
keeping an eye on as the language evolves.

# Signer

> Understand the signer type in Move for transaction authentication and authorization in Aptos smart contracts.

`signer` is a built-in Move resource type. A `signer` is a
[capability](https://en.wikipedia.org/wiki/Object-capability_model) that allows the holder to act on
behalf of a particular `address`. You can think of the native implementation as being:

```move
module 0x1::signer {
  struct signer has drop { a: address }
}
```

A `signer` is somewhat similar to a Unix [UID](https://en.wikipedia.org/wiki/User_identifier) in
that it represents a user authenticated by code _outside_ of Move (e.g., by checking a cryptographic
signature or password).

## Comparison to `address`

A Move program can create any `address` value without special permission using address literals:

```move
script {
  fun example() {
    let a1 = @0x1;
    let a2 = @0x2;
    // ... and so on for every other possible address
  }
}
```

However, `signer` values are special because they cannot be created via literals or
instructions--only by the Move VM. Before the VM runs a script with parameters of type `signer`, it
will automatically create `signer` values and pass them into the script:

```move
script {
    use std::signer;
    fun main(s: signer) {
        assert!(signer::address_of(&s) == @0x42, 0);
    }
}
```

This script will abort with code `0` if the script is sent from any address other than `0x42`.

A Move script can have an arbitrary number of `signer`s as long as the `signer`s are a prefix
to any other arguments. In other words, all of the `signer` arguments must come first:

```move
script {
    use std::signer;
    fun main(s1: signer, s2: signer, x: u64, y: u8) {
        // ...
    }
}
```

This is useful for implementing _multi-signer scripts_ that atomically act with the authority of
multiple parties. For example, an extension of the script above could perform an atomic currency
swap between `s1` and `s2`.

## `signer` Operators

The `std::signer` standard library module provides two utility functions over `signer` values:

| Function                                    | Description                                                    |
| ------------------------------------------- | -------------------------------------------------------------- |
| `signer::address_of(&signer): address`      | Return the `address` wrapped by this `&signer`.                |
| `signer::borrow_address(&signer): &address` | Return a reference to the `address` wrapped by this `&signer`. |

In addition, the `move_to<T>(&signer, T)` [global storage operator](/build/smart-contracts/book/global-storage-operators)
requires a `&signer` argument to publish a resource `T` under `signer.address`'s account. This
ensures that only an authenticated user can elect to publish a resource under their `address`.

## Ownership

Unlike simple scalar values, `signer` values are not copyable, meaning they cannot be copied from
any operation whether it be through an explicit [`copy`](/build/smart-contracts/book/variables#move-and-copy) instruction
or through a [dereference `*`](/build/smart-contracts/book/references#reading-and-writing-through-references).

# Libraries

> Explore the Move standard library with built-in functions, utilities, and common patterns for smart contract development.

Aptos provides multiple useful libraries for developers. The complete up-to-date
docs can be found [here](/move-reference).

# Structs and Resources

> Learn about structs and resources in Move programming language for Aptos smart contract development.

A _struct_ is a user-defined data structure containing typed fields. Structs can store any
non-reference type, including other structs.

We often refer to struct values as _resources_ if they cannot be copied and cannot be dropped. In
this case, resource values must have ownership transferred by the end of the function. This property
makes resources particularly well served for defining global storage schemas or for representing
important values (such as a token).

By default, structs are linear and ephemeral. By this we mean that they: cannot be copied, cannot be
dropped, and cannot be stored in global storage. This means that all values have to have ownership
transferred (linear) and the values must be dealt with by the end of the program's execution
(ephemeral). We can relax this behavior by giving the struct [abilities](/build/smart-contracts/book/abilities) which allow
values to be copied or dropped and also to be stored in global storage or to define global storage
schemas.

## Defining Structs

Structs must be defined inside a module:

```move
module 0x2::m {
    struct Foo { x: u64, y: bool }
    struct Bar {}
    struct Baz { foo: Foo, }
    //                   ^ note: it is fine to have a trailing comma
}
```

Structs cannot be recursive, so the following definition is invalid:

```move
module 0x2::m {
  struct Foo { x: Foo }
  //              ^ error! Foo cannot contain Foo
}
```

For positional structs which used numbered instead of named fields, see
the [positional structs](#positional-structs) section.

As mentioned above: by default, a struct declaration is linear and ephemeral. So to allow the value
to be used with certain operations (that copy it, drop it, store it in global storage, or use it as
a storage schema), structs can be granted [abilities](/build/smart-contracts/book/abilities) by annotating them with
`has <ability>`:

```move
module 0x2::m {
  struct Foo has copy, drop { x: u64, y: bool }
}
```

For more details, see the [annotating structs](/build/smart-contracts/book/abilities#annotating-structs) section.

### Naming

Structs must start with a capital letter `A` to `Z`. After the first letter, struct names can
contain underscores `_`, letters `a` to `z`, letters `A` to `Z`, or digits `0` to `9`.

```move
module 0x2::m {
  struct Foo {}
  struct BAR {}
  struct B_a_z_4_2 {}
}
```

This naming restriction of starting with `A` to `Z` is in place to give room for future language
features. It may or may not be removed later.

## Using Structs

### Creating Structs

Values of a struct type can be created (or "packed") by indicating the struct name, followed by
value for each field:

```move
module 0x2::m {
  struct Foo has drop { x: u64, y: bool }
  struct Baz has drop { foo: Foo }

  fun example() {
    let foo = Foo { x: 0, y: false };
    let baz = Baz { foo };
  }
}
```

If you initialize a struct field with a local variable whose name is the same as the field, you can
use the following shorthand:

```move
module 0x2::m {
  fun example() {
    let baz = Baz { foo: foo };
    // is equivalent to
    let baz = Baz { foo };
  }
}
```

This is sometimes called "field name punning".

### Destroying Structs via Pattern Matching

Struct values can be destroyed by binding or assigning them patterns.

```move
module 0x2::m {
  struct Foo { x: u64, y: bool }
  struct Bar { foo: Foo }
  struct Baz {}

  fun example_destroy_foo() {
    let foo = Foo { x: 3, y: false };
    let Foo { x, y: foo_y } = foo;
    //        ^ shorthand for `x: x`

    // two new bindings
    //   x: u64 = 3
    //   foo_y: bool = false
  }

  fun example_destroy_foo_wildcard() {
    let foo = Foo { x: 3, y: false };
    let Foo { x, y: _ } = foo;

    // only one new binding since y was bound to a wildcard
    //   x: u64 = 3
  }

  fun example_destroy_foo_assignment() {
    let x: u64;
    let y: bool;
    Foo { x, y } = Foo { x: 3, y: false };

    // mutating existing variables x & y
    //   x = 3, y = false
  }

  fun example_foo_ref() {
    let foo = Foo { x: 3, y: false };
    let Foo { x, y } = &foo;

    // two new bindings
    //   x: &u64
    //   y: &bool
  }

  fun example_foo_ref_mut() {
    let foo = Foo { x: 3, y: false };
    let Foo { x, y } = &mut foo;

    // two new bindings
    //   x: &mut u64
    //   y: &mut bool
  }

  fun example_destroy_bar() {
    let bar = Bar { foo: Foo { x: 3, y: false } };
    let Bar { foo: Foo { x, y } } = bar;
    //             ^ nested pattern

    // two new bindings
    //   x: u64 = 3
    //   y: bool = false
  }

  fun example_destroy_baz() {
    let baz = Baz {};
    let Baz {} = baz;
  }
}
```

### Borrowing Structs and Fields

The `&` and `&mut` operator can be used to create references to structs or fields. These examples
include some optional type annotations (e.g., `: &Foo`) to demonstrate the type of operations.

```move
module 0x2::m {
  fun example() {
    let foo = Foo { x: 3, y: true };
    let foo_ref: &Foo = &foo;
    let y: bool = foo_ref.y;  // reading a field via a reference to the struct
    let x_ref: &u64 = &foo.x;

    let x_ref_mut: &mut u64 = &mut foo.x;
    *x_ref_mut = 42;  // modifying a field via a mutable reference
  }
}
```

It is possible to borrow inner fields of nested structs:

```move
module 0x2::m {
  fun example() {
    let foo = Foo { x: 3, y: true };
    let bar = Bar { foo };

    let x_ref = &bar.foo.x;
  }
}
```

You can also borrow a field via a reference to a struct:

```move
module 0x2::m {
  fun example() {
    let foo = Foo { x: 3, y: true };
    let foo_ref = &foo;
    let x_ref = &foo_ref.x;
    // this has the same effect as let x_ref = &foo.x
  }
}
```

### Reading and Writing Fields

If a field is copyable, you can read and copy a field's value by dereferencing the borrowed field:

```move
module 0x2::m {
  fun example() {
    let foo = Foo { x: 3, y: true };
    let bar = Bar { foo: copy foo };
    let x: u64 = *&foo.x;
    let y: bool = *&foo.y;
    let foo2: Foo = *&bar.foo;
  }
}
```

The dot operator can be used to read and copy any copyable field of a struct without explicit
borrowing and dereferencing:

```move
module 0x2::m {
  fun example() {
    let foo = Foo { x: 3, y: true };
    let x = foo.x;  // x == 3
    let y = foo.y;  // y == true

    let bar = Bar { foo };
    let foo2: Foo = *&bar.foo; // `Foo` must be copyable
    let foo3: Foo = bar.foo;   // same as the statement above
  }
}
```

Dot operators can be chained to access nested fields:

```move
module 0x2::m {
  fun example() {
    let baz = Baz { foo: Foo { x: 3, y: true } };
    let x = baz.foo.x; // x = 3;
  }
}
```

Furthermore, the dot syntax can be used to modify fields.

```move
module 0x2::m {
  fun example() {
    let foo = Foo { x: 3, y: true };
    foo.x = 42;     // foo = Foo { x: 42, y: true }
    foo.y = !foo.y; // foo = Foo { x: 42, y: false }
    let bar = Bar { foo };            // bar = Bar { foo: Foo { x: 42, y: false } }
    bar.foo.x = 52;                   // bar = Bar { foo: Foo { x: 52, y: false } }
    bar.foo = Foo { x: 62, y: true }; // bar = Bar { foo: Foo { x: 62, y: true } }
  }
}
```

The dot syntax also works via a reference to a struct:

```move
module 0x2::m {
  fun example() {
    let foo = Foo { x: 3, y: true };
    let foo_ref = &mut foo;
    foo_ref.x = foo_ref.x + 1;
  }
}
```

## Privileged Struct Operations

Most struct operations on a struct type `T` can only be performed inside the module that declares
`T`:

- Struct types can only be created ("packed"), destroyed ("unpacked") inside the module that defines
  the struct.
- The fields of a struct are only accessible inside the module that defines the struct.

Following these rules, if you want to modify your struct outside the module, you will need to
provide public APIs for them. The end of the chapter contains some examples of this.

However, struct _types_ are always visible to another module or script:

```move
// m.move
module 0x2::m {
  struct Foo has drop { x: u64 }

  public fun new_foo(): Foo {
    Foo { x: 42 }
  }
}
```

```move
// n.move
module 0x2::n {
  use 0x2::m;

  struct Wrapper has drop {
    foo: m::Foo
  }

  fun f1(foo: m::Foo) {
    let x = foo.x;
    //      ^ error! cannot access fields of `foo` here
  }

  fun f2() {
    let foo_wrapper = Wrapper { foo: m::new_foo() };
  }
}
```

Note that structs do not have visibility modifiers (e.g., `public` or `private`).

## Ownership

As mentioned above in [Defining Structs](#defining-structs), structs are by default linear and
ephemeral. This means they cannot be copied or dropped. This property can be very useful when
modeling real world resources like money, as you do not want money to be duplicated or get lost in
circulation.

```move
module 0x2::m {
  struct Foo { x: u64 }

  public fun copying_resource() {
    let foo = Foo { x: 100 };
    let foo_copy = copy foo; // error! 'copy'-ing requires the 'copy' ability
    let foo_ref = &foo;
    let another_copy = *foo_ref // error! dereference requires the 'copy' ability
  }

  public fun destroying_resource1() {
    let foo = Foo { x: 100 };

    // error! when the function returns, foo still contains a value.
    // This destruction requires the 'drop' ability
  }

  public fun destroying_resource2(f: &mut Foo) {
    *f = Foo { x: 100 } // error!
                        // destroying the old value via a write requires the 'drop' ability
  }
}
```

To fix the second example (`fun destroying_resource1`), you would need to manually "unpack" the
resource:

```move
module 0x2::m {
  struct Foo { x: u64 }

  public fun destroying_resource1_fixed() {
    let foo = Foo { x: 100 };
    let Foo { x: _ } = foo;
  }
}
```

Recall that you are only able to deconstruct a resource within the module in which it is defined.
This can be leveraged to enforce certain invariants in a system, for example, conservation of money.

If on the other hand, your struct does not represent something valuable, you can add the abilities
`copy` and `drop` to get a struct value that might feel more familiar from other programming
languages:

```move
module 0x2::m {
  struct Foo has copy, drop { x: u64 }

  public fun run() {
    let foo = Foo { x: 100 };
    let foo_copy = copy foo;
    // ^ this code copies foo, whereas `let x = foo` or
    // `let x = move foo` both move foo

    let x = foo.x;            // x = 100
    let x_copy = foo_copy.x;  // x = 100

    // both foo and foo_copy are implicitly discarded when the function returns
  }
}
```

## Positional Structs

_Since language version 2.0_

A struct can be declared to have _positional fields_, fields which are not named
but numbered. Positional structs behave similar to regular structs,
except providing a different syntax which may be more suitable for use cases with
only a few fields.

Fields of positional structs are assigned in the order they appear. In the below
example, field `0` is of type `u64` and field `1` of type `u8`:

```move
module 0x2::m {
  struct Pair(u64, u8);
}
```

Abilities for positional structs are declared _after_ and not before the field list,

```move
module 0x2::m {
  struct Pair(u64, u8) has copy, drop;
}
```

For pure type tags, often used for phantom types in Move code, the list of arguments
can be also completely omitted:

```move
module 0x2::m {
  struct TypeTag has copy, drop;
}
```

Values of positional structs are created and deconstructed as shown below:
using `PositionalStructs(arguments)`:

```move
module 0x2::m {
  fun work() {
    let value = Pair(1, true);
    let Pair(number, boolean) = value;
    assert!(number == 1 && boolean == true);
  }
}
```

Fields of positional structs can be accessed using the position as a field selector. For example, in the above code example, `value.0` and `value.1` can be used to access the two fields without deconstructing the `value`.
`positional_struct.0`.

## Partial Patterns

_Since language version 2.0_

Patterns can use the `..` notation to match any remaining, non-listed fields in structs or variants with named fields, and omitted fields at either the beginning or end of a struct or variant with positional fields. Here are
some examples:

```move
module 0x2::m {
  struct Foo{ x: u8, y: u16, z: u32 }
  struct Bar(u8, u16, u32);

  fun foo_get_x(self: &Foo): u16 {
    let Foo{y, ..} = self;
    x
  }

  fun bar_get_0(self: &Foo): u8 {
    let Bar(x, ..) = self;
    x
  }

  fun bar_get_2(self: &Foo): u52 {
    // For positional structs, one can also put the
    // .. at the beginning.
    let Bar(.., z) = self;
    z
  }
}
```

Notice that partial patterns can currently not be used as the left-hand side of assignment.
While one can use `let Bar(x, ..) = v`, we do not yet support `let x; Bar(x, ..) = v`.

## Storing Resources in Global Storage

Structs with the `key` ability can be saved directly in
[persistent global storage](/build/smart-contracts/book/global-storage-operators). All values stored within those `key`
structs must have the `store` ability. See the [ability](/build/smart-contracts/book/abilities) and
[global storage](/build/smart-contracts/book/global-storage-operators) chapters for more detail.

## Examples

Here are two short examples of how you might use structs to represent valuable data (in the case of
`Coin`) or more classical data (in the case of `Point` and `Circle`).

### Example 1: Coin

{/* <!-- TODO link to access control for mint --> */}

```move
module 0x2::m {
  // We do not want the Coin to be copied because that would be duplicating this "money",
  // so we do not give the struct the 'copy' ability.
  // Similarly, we do not want programmers to destroy coins, so we do not give the struct the
  // 'drop' ability.
  // However, we *want* users of the modules to be able to store this coin in persistent global
  // storage, so we grant the struct the 'store' ability. This struct will only be inside of
  // other resources inside of global storage, so we do not give the struct the 'key' ability.
  struct Coin has store {
    value: u64,
  }

  public fun mint(value: u64): Coin {
    // You would want to gate this function with some form of access control to prevent
    // anyone using this module from minting an infinite amount of coins.
    Coin { value }
  }

  public fun withdraw(coin: &mut Coin, amount: u64): Coin {
    assert!(coin.value >= amount, 1000);
    coin.value = coin.value - amount;
    Coin { value: amount }
  }

  public fun deposit(coin: &mut Coin, other: Coin) {
    let Coin { value } = other;
    coin.value = coin.value + value;
  }

  public fun split(coin: Coin, amount: u64): (Coin, Coin) {
    let other = withdraw(&mut coin, amount);
    (coin, other)
  }

  public fun merge(coin1: Coin, coin2: Coin): Coin {
    deposit(&mut coin1, coin2);
    coin1
  }

  public fun destroy_zero(coin: Coin) {
    let Coin { value } = coin;
    assert!(value == 0, 1001);
  }
}
```

### Example 2: Geometry

```move
module 0x2::point {
  struct Point has copy, drop, store {
    x: u64,
    y: u64,
  }

  public fun new(x: u64, y: u64): Point {
    Point {
      x, y
    }
  }

  public fun x(p: &Point): u64 {
    p.x
  }

  public fun y(p: &Point): u64 {
    p.y
  }

  fun abs_sub(a: u64, b: u64): u64 {
    if (a < b) {
      b - a
    }
    else {
      a - b
    }
  }

  public fun dist_squared(p1: &Point, p2: &Point): u64 {
    let dx = abs_sub(p1.x, p2.x);
    let dy = abs_sub(p1.y, p2.y);
    dx*dx + dy*dy
  }
}
```

```move
module 0x2::circle {
  use 0x2::point::{Self, Point};

  struct Circle has copy, drop, store {
    center: Point,
    radius: u64,
  }

  public fun new(center: Point, radius: u64): Circle {
    Circle { center, radius }
  }

  public fun overlaps(c1: &Circle, c2: &Circle): bool {
    let dist_squared_value = point::dist_squared(&c1.center, &c2.center);
    let r1 = c1.radius;
    let r2 = c2.radius;
    dist_squared_value <= r1*r1 + 2*r1*r2 + r2*r2
  }
}
```

# Table of Contents

> Learn about summary in Move programming language for Aptos smart contract development.

## Getting Started

- [Modules and Scripts](/build/smart-contracts/book/modules-and-scripts)
- [Move Tutorial](/build/smart-contracts/book/move-tutorial)

## Language Release Notes

- [Move 2](/build/smart-contracts/book/move-2)

## Primitive Types

- [Integers](/build/smart-contracts/book/integers)
- [Bool](/build/smart-contracts/book/bool)
- [Address](/build/smart-contracts/book/address)
- [Vector](/build/smart-contracts/book/vector)
- [Signer](/build/smart-contracts/book/signer)
- [References](/build/smart-contracts/book/references)
- [Tuples and Unit](/build/smart-contracts/book/tuples)

## Basic Concepts

- [Local Variables and Scopes](/build/smart-contracts/book/variables)
- [Equality](/build/smart-contracts/book/equality)
- [Abort and Assert](/build/smart-contracts/book/abort-and-assert)
- [Conditionals](/build/smart-contracts/book/conditionals)
- [While, For, and Loop](/build/smart-contracts/book/loops)
- [Functions](/build/smart-contracts/book/functions)
- [Structs and Resources](/build/smart-contracts/book/structs-and-resources)
- [Enum Types](/build/smart-contracts/book/enums)
- [Constants](/build/smart-contracts/book/constants)
- [Generics](/build/smart-contracts/book/generics)
- [Type Abilities](/build/smart-contracts/book/abilities)
- [Uses and Aliases](/build/smart-contracts/book/uses)
- [Friends](/build/smart-contracts/book/friends)
- [Packages](/build/smart-contracts/book/packages)
- [Package Upgrades](/build/smart-contracts/book/package-upgrades)
- [Unit Tests](/build/smart-contracts/book/unit-testing)

## Global Storage

- [Global Storage Structure](/build/smart-contracts/book/global-storage-structure)
- [Global Storage Operators](/build/smart-contracts/book/global-storage-operators)

## Reference

- [Standard Library](/build/smart-contracts/book/standard-library)
- [Coding Conventions](/build/smart-contracts/book/coding-conventions)

# Tuples and Unit

> Understand tuple types in Move for grouping multiple values and function return patterns in smart contract development.

Move does not fully support tuples as one might expect coming from another language with them as a
[first-class value](https://en.wikipedia.org/wiki/First-class_citizen). However, in order to support multiple return values, Move has tuple-like
expressions. These expressions do not result in a concrete value at runtime (there are no tuples in
the bytecode), and as a result they are very limited: they can only appear in expressions (usually
in the return position for a function); they cannot be bound to local variables; they cannot be
stored in structs; and tuple types cannot be used to instantiate generics.

Similarly, [unit `()`](https://en.wikipedia.org/wiki/Unit_type) is a type created by the Move source language in order to be expression based.
The unit value `()` does not result in any runtime value. We can consider unit`()` to be an empty
tuple, and any restrictions that apply to tuples also apply to unit.

It might feel weird to have tuples in the language at all given these restrictions. But one of the
most common use cases for tuples in other languages is for functions to allow functions to return
multiple values. Some languages work around this by forcing the users to write structs that contain
the multiple return values. However, in Move, you cannot put references inside of
[structs](/build/smart-contracts/book/structs-and-resources). This required Move to support multiple return values. These
multiple return values are all pushed on the stack at the bytecode level. At the source level, these
multiple return values are represented using tuples.

## Literals

Tuples are created by a comma separated list of expressions inside of parentheses.

| Syntax          | Type                                                                         | Description                                                  |
| --------------- | ---------------------------------------------------------------------------- | ------------------------------------------------------------ |
| `()`            | `(): ()`                                                                     | Unit, the empty tuple, or the tuple of arity 0               |
| `(e1, ..., en)` | `(e1, ..., en): (T1, ..., Tn)` where `e_i: Ti` s.t. `0 < i <= n` and `n > 0` | A `n`-tuple, a tuple of arity `n`, a tuple with `n` elements |

Note that `(e)` does not have type `(e): (t)`, in other words there is no tuple with one element. If
there is only a single element inside the parentheses, the parentheses are only used for
disambiguation and do not carry any other special meaning.

Sometimes, tuples with two elements are called "pairs" and tuples with three elements are called
"triples."

### Examples

```move
module 0x42::example {
  // all 3 of these functions are equivalent

  // when no return type is provided, it is assumed to be `()`
  fun returns_unit_1() { }

  // there is an implicit () value in empty expression blocks
  fun returns_unit_2(): () { }

  // explicit version of `returns_unit_1` and `returns_unit_2`
  fun returns_unit_3(): () { () }


  fun returns_3_values(): (u64, bool, address) {
    (0, false, @0x42)
  }
  fun returns_4_values(x: &u64): (&u64, u8, u128, vector<u8>) {
    (x, 0, 1, b"foobar")
  }
}
```

## Operations

The only operation that can be done on tuples currently is destructuring.

### Destructuring

For tuples of any size, they can be destructured in either a `let` binding or in an assignment.

For example:

```move
module 0x42::example {
  // all 3 of these functions are equivalent
  fun returns_unit() {}
  fun returns_2_values(): (bool, bool) { (true, false) }
  fun returns_4_values(x: &u64): (&u64, u8, u128, vector<u8>) { (x, 0, 1, b"foobar") }

  fun examples(cond: bool) {
    let () = ();
    let (x, y): (u8, u64) = (0, 1);
    let (a, b, c, d) = (@0x0, 0, false, b"");

    () = ();
    (x, y) = if (cond) (1, 2) else (3, 4);
    (a, b, c, d) = (@0x1, 1, true, b"1");
  }

  fun examples_with_function_calls() {
    let () = returns_unit();
    let (x, y): (bool, bool) = returns_2_values();
    let (a, b, c, d) = returns_4_values(&0);

    () = returns_unit();
    (x, y) = returns_2_values();
    (a, b, c, d) = returns_4_values(&1);
  }
}
```

For more details, see [Move Variables](/build/smart-contracts/book/variables).

## Subtyping

Along with references, tuples are the only other type that have [subtyping](https://en.wikipedia.org/wiki/Subtyping) in Move. Tuples have
subtyping only in the sense that they subtype with references (in a covariant way).

For example:

```move
script {
  fun example() {
    let x: &u64 = &0;
    let y: &mut u64 = &mut 1;

    // (&u64, &mut u64) is a subtype of (&u64, &u64)
    // since &mut u64 is a subtype of &u64
    let (a, b): (&u64, &u64) = (x, y);

    // (&mut u64, &mut u64) is a subtype of (&u64, &u64)
    // since &mut u64 is a subtype of &u64
    let (c, d): (&u64, &u64) = (y, y);

    // error! (&u64, &mut u64) is NOT a subtype of (&mut u64, &mut u64)
    // since &u64 is NOT a subtype of &mut u64
    let (e, f): (&mut u64, &mut u64) = (x, y);
  }
}
```

## Ownership

As mentioned above, tuple values don't really exist at runtime. And currently they cannot be stored
into local variables because of this (but it is likely that this feature will come soon). As such,
tuples can only be moved currently, as copying them would require putting them into a local variable
first.

# Unit Tests

> Learn about unit testing in Move programming language for Aptos smart contract development.

Unit testing for Move adds three new annotations to the Move source language:

- `#[test]`
- `#[test_only]`, and
- `#[expected_failure]`.

They respectively mark a function as a test, mark a module or module member (`use`, function, or struct) as code to be included for testing only, and mark that a test is expected to fail. These annotations can be placed on a function with any visibility. Whenever a module or module member is annotated as `#[test_only]` or `#[test]`, it will not be included in the compiled bytecode unless it is compiled for testing.

## Testing Annotations: Their Meaning and Usage

Both the `#[test]` and `#[expected_failure]` annotations can be used either with or without arguments.

Without arguments, the `#[test]` annotation can only be placed on a function with no parameters. This annotation simply marks this function as a test to be run by the unit testing harness.

```move
module 0x42::example {
  #[test] // OK
  fun this_is_a_test() { /* ... */ }

  #[test] // Will fail to compile since the test takes an argument
  fun this_is_not_correct(arg: signer) { /* ... */ }
}
```

### Expected Failure

A test can also be annotated as an `#[expected_failure]`. This
annotation marks that the test is expected to raise an error.

You can ensure that a test is aborting with a specific abort `<code>`
by annotating it with `#[expected_failure(abort_code = <code>)]`,
corresponding to the parameter to an `abort` statement (or
failing `assert!` macro).

Instead of an `abort_code`, an `expected_failure` may specify program
execution errors, such as `arithmetic_error`, `major_status`,
`vector_error`, and `out_of_gas`. For more specificity, a
`minor_status` may optionally be specified.

If the error is expected from a specific location, that may also be specified:
`#[expected_failure(abort_code = <code>, location = <loc>)]`.
If the test then fails with the right error but in a different module, the test will also fail.
Note that `<loc>` can be `Self`(in the current module) or a qualified name, e.g. `vector::std`.

Only functions that have the `#[test]` annotation can also be annotated as an #`[expected_failure]`.

```move
module 0x42::example {
  #[test]
  #[expected_failure]
  public fun this_test_will_abort_and_pass() { abort 1 }

  #[test]
  #[expected_failure]
  public fun test_will_error_and_pass() { 1/0; }

  #[test]
  #[expected_failure(abort_code = 0, location = Self)]
  public fun test_will_error_and_fail() { 1/0; }

  #[test, expected_failure] // Can have multiple in one attribute. This test will pass.
  public fun this_other_test_will_abort_and_pass() { abort 1 }

  #[test]
  #[expected_failure(vector_error, minor_status = 1, location = Self)]
  fun borrow_out_of_range() { /* ... */ }
  #[test]
  #[expected_failure(abort_code = 26113, location = extensions::table)]
  fun test_destroy_fails() { /* ... */ }
}
```

### Test parameters

With arguments, a test annotation takes the form `#[test(<param_name_1> = <address>, ..., <param_name_n> = <address>)]`. If a function is annotated in such a manner, the function's parameters must be a permutation of the parameters `<param_name_1>, ..., <param_name_n>`, i.e., the order of these parameters as they occur in the function and their order in the test annotation do not have to be the same, but they must be able to be matched up with each other by name.

Only parameters with a type of `signer` are supported as test parameters. If a parameter other than `signer` is supplied, the test will result in an error when run.

```move
module 0x42::example {
  #[test(arg = @0xC0FFEE)] // OK
  fun this_is_correct_now(arg: signer) { /* ... */ }

  #[test(wrong_arg_name = @0xC0FFEE)] // Not correct: arg name doesn't match
  fun this_is_incorrect(arg: signer) { /* ... */ }

  #[test(a = @0xC0FFEE, b = @0xCAFE)] // OK. We support multiple signer arguments, but you must always provide a value for that argument
  fun this_works(a: signer, b: signer) { /* ... */ }

  // somewhere a named address is declared
  #[test_only] // test-only named addresses are supported
  address TEST_NAMED_ADDR = @0x1;
  ...
  #[test(arg = @TEST_NAMED_ADDR)] // Named addresses are supported!
  fun this_is_correct_now(arg: signer) { /* ... */ }
}
```

### Arbitrary code to support tests

A module and any of its members can be declared as test only. In such a case the item will only be included in the compiled Move bytecode when compiled in test mode. Additionally, when compiled outside of test mode, any non-test `use`s of a `#[test_only]` module will raise an error during compilation.

```move
#[test_only] // test only attributes can be attached to modules
module 0x42::abc { /*... */ }

module 0x42::other {
  #[test_only] // test only attributes can be attached to named addresses
  address ADDR = @0x1;

  #[test_only] // .. to uses
  use 0x1::some_other_module;

  #[test_only] // .. to structs
  struct SomeStruct { /* ... */ }

  #[test_only] // .. and functions. Can only be called from test code, but not a test
  fun test_only_function(/* ... */) { /* ... */ }
}
```

## Running Unit Tests

Unit tests for a Move package can be run with the `aptos move test` command. See [package](/build/smart-contracts/book/packages) for more info.

When running tests, every test will either `PASS`, `FAIL`, or `TIMEOUT`. If a test case fails, the location of the failure along with the function name that caused the failure will be reported if possible. You can see an example of this below.

A test will be marked as timing out if it exceeds the maximum number of instructions that can be executed for any single test. This bound can be changed using the options below, and its default value is set to 100000 instructions. Additionally, while the result of a test is always deterministic, tests are run in parallel by default, so the ordering of test results in a test run is non-deterministic unless running with only one thread (see `OPTIONS` below).

There are also a number of options that can be passed to the unit testing binary to fine-tune testing and to help debug failing tests. These can be found using the help flag:

```shellscript filename="Terminal"
$ aptos move test -h
```

## Example

A simple module using some of the unit testing features is shown in the following example:

First create an empty package inside an empty directory:

```shellscript filename="Terminal"
$ aptos move init --name TestExample
```

Next add the following to the `Move.toml`:

```toml
[dependencies]
MoveStdlib = { git = "https://github.com/aptos-labs/aptos-framework.git", subdir="aptos-move/framework/move-stdlib", rev = "main", addr_subst = { "std" = "0x1" } }
```

Next add the following module under the `sources` directory:

```move
// filename: sources/my_module.move
module 0x1::my_module {

  struct MyCoin has key { value: u64 }

  public fun make_sure_non_zero_coin(coin: MyCoin): MyCoin {
    assert!(coin.value > 0, 0);
    coin
  }

  public fun has_coin(addr: address): bool {
    exists<MyCoin>(addr)
  }

  #[test]
  fun make_sure_non_zero_coin_passes() {
    let coin = MyCoin { value: 1 };
    let MyCoin { value: _ } = make_sure_non_zero_coin(coin);
  }

  #[test]
  // Or #[expected_failure] if we don't care about the abort code
  #[expected_failure(abort_code = 0, location = Self)]
  fun make_sure_zero_coin_fails() {
    let coin = MyCoin { value: 0 };
    let MyCoin { value: _ } = make_sure_non_zero_coin(coin);
  }

  #[test_only] // test only helper function
  fun publish_coin(account: &signer) {
    move_to(account, MyCoin { value: 1 })
  }

  #[test(a = @0x1, b = @0x2)]
  fun test_has_coin(a: signer, b: signer) {
    publish_coin(&a);
    publish_coin(&b);
    assert!(has_coin(@0x1), 0);
    assert!(has_coin(@0x2), 1);
    assert!(!has_coin(@0x3), 1);
  }
}
```

### Running Tests

You can then run these tests with the `aptos move test` command:

```shellscript filename="Terminal"
$ aptos move test
BUILDING MoveStdlib
BUILDING TestExample
Running Move unit tests
[ PASS    ] 0x1::my_module::make_sure_non_zero_coin_passes
[ PASS    ] 0x1::my_module::make_sure_zero_coin_fails
[ PASS    ] 0x1::my_module::test_has_coin
Test result: OK. Total tests: 3; passed: 3; failed: 0
```

### Using Test Flags

#### `-f <str>` or `--filter <str>`

This will only run tests whose fully qualified name contains `<str>`. For example if we wanted to only run tests with `"zero_coin"` in their name:

```shellscript filename="Terminal"
$ aptos move test -f zero_coin
CACHED MoveStdlib
BUILDING TestExample
Running Move unit tests
[ PASS    ] 0x1::my_module::make_sure_non_zero_coin_passes
[ PASS    ] 0x1::my_module::make_sure_zero_coin_fails
Test result: OK. Total tests: 2; passed: 2; failed: 0
```

#### `--coverage`

This will compute code being covered by test cases and generate coverage summary.

```shellscript filename="Terminal"
$ aptos move test --coverage
INCLUDING DEPENDENCY AptosFramework
INCLUDING DEPENDENCY AptosStdlib
INCLUDING DEPENDENCY MoveStdlib
BUILDING TestExample
Running Move unit tests
[ PASS    ] 0x1::my_module::make_sure_non_zero_coin_passes
[ PASS    ] 0x1::my_module::make_sure_zero_coin_fails
[ PASS    ] 0x1::my_module::test_has_coin
Test result: OK. Total tests: 3; passed: 3; failed: 0
+-------------------------+
| Move Coverage Summary   |
+-------------------------+
Module 0000000000000000000000000000000000000000000000000000000000000001::my_module
>>> % Module coverage: 100.00
+-------------------------+
| % Move Coverage: 100.00  |
+-------------------------+
Please use `aptos move coverage -h` for more detailed source or bytecode test coverage of this package
```

Then by running `aptos move coverage`, we can get more detailed coverage information. These can be found using the help flag:

```shellscript filename="Terminal"
$ aptos move coverage -h
```

# Uses and Aliases

> Learn about uses in Move programming language for Aptos smart contract development.

The `use` syntax can be used to create aliases to members in other modules. `use` can be used to
create aliases that last either for the entire module, or for a given expression block scope.

## Syntax

There are several different syntax cases for `use`. Starting with the most simple, we have the
following for creating aliases to other modules

```move
use <address>::<module name>;
use <address>::<module name> as <module alias name>;
```

For example

```move
script {
  use std::vector;
  use std::vector as V;
}
```

`use std::vector;` introduces an alias `vector` for `std::vector`. This means that anywhere you
would want to use the module name `std::vector` (assuming this `use` is in scope), you could use
`vector` instead. `use std::vector;` is equivalent to `use std::vector as vector;`

Similarly `use std::vector as V;` would let you use `V` instead of `std::vector`

```move
module 0x42::example {
  use std::vector;
  use std::vector as V;

  fun new_vecs(): (vector<u8>, vector<u8>, vector<u8>) {
    let v1 = std::vector::empty();
    let v2 = vector::empty();
    let v3 = V::empty();
    (v1, v2, v3)
  }
}
```

If you want to import a specific module member (such as a function, struct, or constant). You can
use the following syntax.

```move
use <address>::<module name>::<module member>;
use <address>::<module name>::<module member> as <member alias>;
```

For example

```move
script {
  use std::vector::empty;
  use std::vector::empty as empty_vec;
}
```

This would let you use the function `std::vector::empty` without full qualification. Instead, you
could use `empty` and `empty_vec` respectively. Again, `use std::vector::empty;` is equivalent to
`use std::vector::empty as empty;`

```move
module 0x42::example {
  use std::vector::empty;
  use std::vector::empty as empty_vec;

  fun new_vecs(): (vector<u8>, vector<u8>, vector<u8>) {
    let v1 = std::vector::empty();
    let v2 = empty();
    let v3 = empty_vec();
    (v1, v2, v3)
  }
}
```

If you want to add aliases for multiple module members at once, you can do so with the following
syntax

```move
use <address>::<module name>::{<module member>, <module member> as <member alias> ... };
```

For example

```move
module 0x42::example {
  use std::vector::{push_back, length as len, pop_back};

  fun swap_last_two<T>(v: &mut vector<T>) {
    assert!(len(v) >= 2, 42);
    let last = pop_back(v);
    let second_to_last = pop_back(v);
    push_back(v, last);
    push_back(v, second_to_last)
  }
}
```

If you need to add an alias to the Module itself in addition to module members, you can do that in a
single `use` using `Self`. `Self` is a member of sorts that refers to the module.

```move
script {
  use std::vector::{Self, empty};
}
```

For clarity, all the following are equivalent:

```move
script {
  use std::vector;
  use std::vector as vector;
  use std::vector::Self;
  use std::vector::Self as vector;
  use std::vector::{Self};
  use std::vector::{Self as vector};
}
```

If needed, you can have as many aliases for any item as you like

```move
module 0x42::example {
  use std::vector::{
    Self,
    Self as V,
    length,
    length as len,
  };

  fun pop_twice<T>(v: &mut vector<T>): (T, T) {
    // all options available given the `use` above
    assert!(vector::length(v) > 1, 42);
    assert!(V::length(v) > 1, 42);
    assert!(length(v) > 1, 42);
    assert!(len(v) > 1, 42);

    (vector::pop_back(v), vector::pop_back(v))
  }
}
```

## Inside a `module`

Inside a `module` all `use` declarations are usable regardless of the order of declaration.

```move
module 0x42::example {
  use std::vector;

  fun example(): vector<u8> {
    let v = empty();
    vector::push_back(&mut v, 0);
    vector::push_back(&mut v, 10);
    v
  }

  use std::vector::empty;
}
```

The aliases declared by `use` in the module are usable within that module.

Additionally, the aliases introduced cannot conflict with other module members. See
[Uniqueness](#uniqueness) for more details

## Inside an expression

You can add `use` declarations to the beginning of any expression block

```move
module 0x42::example {

  fun example(): vector<u8> {
    use std::vector::{empty, push_back};

    let v = empty();
    push_back(&mut v, 0);
    push_back(&mut v, 10);
    v
  }
}
```

As with `let`, the aliases introduced by `use` in an expression block are removed at the end of that
block.

```move
module 0x42::example {

  fun example(): vector<u8> {
    let result = {
      use std::vector::{empty, push_back};
      let v = empty();
      push_back(&mut v, 0);
      push_back(&mut v, 10);
      v
    };
    result
  }
}
```

Attempting to use the alias after the block ends will result in an error

```move
module 0x42::example {
  fun example(): vector<u8> {
    let result = {
      use std::vector::{empty, push_back};
      let v = empty();
      push_back(&mut v, 0);
      push_back(&mut v, 10);
      v
    };
    let v2 = empty(); // ERROR!
//           ^^^^^ unbound function 'empty'
    result
  }
}
```

Any `use` must be the first item in the block. If the `use` comes after any expression or `let`, it
will result in a parsing error

```move
script {
  fun example() {
    {
      let x = 0;
      use std::vector; // ERROR!
      let v = vector::empty();
    }
  }
}

```

## Naming rules

Aliases must follow the same rules as other module members. This means that aliases to structs or
constants must start with `A` to `Z`

```move
address 0x42 {
  module data {
    struct S {}
    const FLAG: bool = false;
    fun foo() {}
  }
  module example {
    use 0x42::data::{
      S as s, // ERROR!
      FLAG as fLAG, // ERROR!
      foo as FOO,  // valid
      foo as bar, // valid
    };
  }
}
```

## Uniqueness

Inside a given scope, all aliases introduced by `use` declarations must be unique.

For a module, this means aliases introduced by `use` cannot overlap

```move
module 0x42::example {
  use std::vector::{empty as foo, length as foo}; // ERROR!
  //                                        ^^^ duplicate 'foo'

  use std::vector::empty as bar;
  use std::vector::length as bar; // ERROR!
  //                         ^^^ duplicate 'bar'
}
```

And, they cannot overlap with any of the module's other members

```move
address 0x42 {
  module data {
    struct S {}
  }
  module example {
    use 0x42::data::S;

    struct S { value: u64 } // ERROR!
    //     ^ conflicts with alias 'S' above
  }
}
```

Inside an expression block, they cannot overlap with each other, but they can
[shadow](#shadowing) other aliases or names from an outer scope

## Shadowing

`use` aliases inside of an expression block can shadow names (module members or aliases) from the
outer scope. As with shadowing of locals, the shadowing ends at the end of the expression block;

```move
module 0x42::example {

  struct WrappedVector { vec: vector<u64> }

  fun empty(): WrappedVector {
    WrappedVector { vec: std::vector::empty() }
  }

  fun example1(): (WrappedVector, WrappedVector) {
    let vec = {
      use std::vector::{empty, push_back};
      // 'empty' now refers to std::vector::empty

      let v = empty();
      push_back(&mut v, 0);
      push_back(&mut v, 1);
      push_back(&mut v, 10);
      v
    };
    // 'empty' now refers to Self::empty

    (empty(), WrappedVector { vec })
  }

  fun example2(): (WrappedVector, WrappedVector) {
    use std::vector::{empty, push_back};
    let w: WrappedVector = {
      use 0x42::example::empty;
      empty()
    };
    push_back(&mut w.vec, 0);
    push_back(&mut w.vec, 1);
    push_back(&mut w.vec, 10);

    let vec = empty();
    push_back(&mut vec, 0);
    push_back(&mut vec, 1);
    push_back(&mut vec, 10);

    (w, WrappedVector { vec })
  }
}
```

## Unused Use or Alias

An unused `use` will result in an error

```move
module 0x42::example {
  use std::vector::{empty, push_back}; // ERROR!
  //                       ^^^^^^^^^ unused alias 'push_back'

  fun example(): vector<u8> {
    empty()
  }
}
```

# Local Variables and Scope

> Learn about variables in Move programming language for Aptos smart contract development.

Local variables in Move are lexically (statically) scoped. New variables are introduced with the
keyword `let`, which will shadow any previous local with the same name. Locals are mutable and can
be updated both directly and via a mutable reference.

## Declaring Local Variables

### `let` bindings

Move programs use `let` to bind variable names to values:

```move
script {
  fun example() {
    let x = 1;
    let y = x + x;
  }
}
```

`let` can also be used without binding a value to the local.

```move
script {
  fun example() {
    let x;
  }
}
```

The local can then be assigned a value later.

```move
script {
  fun example() {
    let x;
    if (cond) {
      x = 1
    } else {
      x = 0
    }
  }
}
```

This can be very helpful when trying to extract a value from a loop when a default value cannot be
provided.

```move
script {
  fun example() {
    let x;
    let cond = true;
    let i = 0;
    loop {
      (x, cond) = foo(i);
      if (!cond) break;
      i = i + 1;
    }
  }
}
```

### Variables must be assigned before use

Move's type system prevents a local variable from being used before it has been assigned.

```move
script {
  fun example() {
    let x;
    x + x; // ERROR!
  }
}
```

```move
script {
  fun example() {
    let x;
    if (cond) x = 0;
    x + x; // ERROR!
  }
}
```

```move
script {
  fun example() {
    let x;
    while (cond) x = 0;
    x + x; // ERROR!
  }
}
```

### Valid variable names

Variable names can contain underscores `_`, letters `a` to `z`, letters `A` to `Z`, and digits `0`
to `9`. Variable names must start with either an underscore `_` or a letter `a` through `z`. They
_cannot_ start with uppercase letters.

```move
script {
  fun example() {
    // all valid
    let x = e;
    let _x = e;
    let _A = e;
    let x0 = e;
    let xA = e;
    let foobar_123 = e;

    // all invalid
    let X = e; // ERROR!
    let Foo = e; // ERROR!
  }
}
```

### Type annotations

The type of local variable can almost always be inferred by Move's type system. However, Move
allows explicit type annotations that can be useful for readability, clarity, or debuggability. The
syntax for adding a type annotation is:

```move
script {
  fun example() {
    let x: T = e; // "Variable x of type T is initialized to expression e"
  }
}
```

Some examples of explicit type annotations:

```move
module 0x42::example {

  struct S { f: u64, g: u64 }

  fun annotated() {
    let u: u8 = 0;
    let b: vector<u8> = b"hello";
    let a: address = @0x0;
    let (x, y): (&u64, &mut u64) = (&0, &mut 1);
    let S { f, g: f2 }: S = S { f: 0, g: 1 };
  }
}
```

Note that the type annotations must always be to the right of the pattern:

```move
script {
  fun example() {
    let (x: &u64, y: &mut u64) = (&0, &mut 1); // ERROR! should be let (x, y): ... =
  }
}
```

### When annotations are necessary

In some cases, a local type annotation is required if the type system cannot infer the type. This
commonly occurs when the type argument for a generic type cannot be inferred. For example:

```move
script {
  fun example() {
    let _v1 = vector::empty(); // ERROR!
    //        ^^^^^^^^^^^^^^^ Could not infer this type. Try adding an annotation
    let v2: vector<u64> = vector::empty(); // no error
  }
}
```

In a rarer case, the type system might not be able to infer a type for divergent code (where all the
following code is unreachable). Both `return` and [`abort`](/build/smart-contracts/book/abort-and-assert) are expressions
and can have any type. A [`loop`](/build/smart-contracts/book/loops) has type `()` if it has a `break`, but if there is no
break out of the `loop`, it could have any type. If these types cannot be inferred, a type
annotation is required. For example, this code:

```move
script {
  fun example() {
    let a: u8 = return ();
    let b: bool = abort 0;
    let c: signer = loop ();

    let x = return (); // ERROR!
    //  ^ Could not infer this type. Try adding an annotation
    let y = abort 0; // ERROR!
    //  ^ Could not infer this type. Try adding an annotation
    let z = loop (); // ERROR!
    //  ^ Could not infer this type. Try adding an annotation
  }
}
```

Adding type annotations to this code will expose other errors about dead code or unused local
variables, but the example is still helpful for understanding this problem.

### Multiple declarations with tuples

`let` can introduce more than one local at a time using tuples. The locals declared inside the
parenthesis are initialized to the corresponding values from the tuple.

```move
script {
  fun example() {
    let () = ();
    let (x0, x1) = (0, 1);
    let (y0, y1, y2) = (0, 1, 2);
    let (z0, z1, z2, z3) = (0, 1, 2, 3);
  }
}
```

The type of the expression must match the arity of the tuple pattern exactly.

```move
script {
  fun example() {
    let (x, y) = (0, 1, 2); // ERROR!
    let (x, y, z, q) = (0, 1, 2); // ERROR!
  }
}
```

You cannot declare more than one local with the same name in a single `let`.

```move
script {
  fun example() {
    let (x, x) = 0; // ERROR!
  }
}
```

### Multiple declarations with structs

`let` can also introduce more than one local at a time when destructuring (or matching against) a
struct. In this form, the `let` creates a set of local variables that are initialized to the values
of the fields from a struct. The syntax looks like this:

```move
script {
  fun example() {
    struct T { f1: u64, f2: u64 }
  }
}
```

```move
script {
  fun example() {
    let T { f1: local1, f2: local2 } = T { f1: 1, f2: 2 };
    // local1: u64
    // local2: u64
  }
}
```

Here is a more complicated example:

```move
module 0x42::example {
  struct X { f: u64 }
  struct Y { x1: X, x2: X }

  fun new_x(): X {
    X { f: 1 }
  }

  fun example() {
    let Y { x1: X { f }, x2 } = Y { x1: new_x(), x2: new_x() };
    assert!(f + x2.f == 2, 42);

    let Y { x1: X { f: f1 }, x2: X { f: f2 } } = Y { x1: new_x(), x2: new_x() };
    assert!(f1 + f2 == 2, 42);
  }
}
```

Fields of structs can serve double duty, identifying the field to bind _and_ the name of the
variable. This is sometimes referred to as punning.

```move
script {
  fun example() {
    let X { f } = e;
  }
}
```

is equivalent to:

```move
script {
  fun example() {
    let X { f: f } = e;
  }
}
```

As shown with tuples, you cannot declare more than one local with the same name in a single `let`.

```move
script {
  fun example() {
    let Y { x1: x, x2: x } = e; // ERROR!
  }
}
```

### Destructuring against references

In the examples above for structs, the bound value in the let was moved, destroying the struct value
and binding its fields.

```move
script {
  fun example() {
    struct T { f1: u64, f2: u64 }
  }
}
```

```move
script {
  fun example() {
    let T { f1: local1, f2: local2 } = T { f1: 1, f2: 2 };
    // local1: u64
    // local2: u64
  }
}
```

In this scenario the struct value `T { f1: 1, f2: 2 }` no longer exists after the `let`.

If you wish instead to not move and destroy the struct value, you can borrow each of its fields. For
example:

```move
script {
  fun example() {
    let t = T { f1: 1, f2: 2 };
    let T { f1: local1, f2: local2 } = &t;
    // local1: &u64
    // local2: &u64
  }
}
```

And similarly with mutable references:

```move
script {
  fun example() {
    let t = T { f1: 1, f2: 2 };
    let T { f1: local1, f2: local2 } = &mut t;
    // local1: &mut u64
    // local2: &mut u64
  }
}
```

This behavior can also work with nested structs.

```move
module 0x42::example {
  struct X { f: u64 }
  struct Y { x1: X, x2: X }

  fun new_x(): X {
    X { f: 1 }
  }

  fun example() {
    let y = Y { x1: new_x(), x2: new_x() };

    let Y { x1: X { f }, x2 } = &y;
    assert!(*f + x2.f == 2, 42);

    let Y { x1: X { f: f1 }, x2: X { f: f2 } } = &mut y;
    *f1 = *f1 + 1;
    *f2 = *f2 + 1;
    assert!(*f1 + *f2 == 4, 42);
  }
}
```

### Ignoring Values

In `let` bindings, it is often helpful to ignore some values. Local variables that start with `_`
will be ignored and not introduce a new variable

```move
module 0x42::example {
  fun three(): (u64, u64, u64) {
    (0, 1, 2)
  }

  fun example() {
    let (x1, _, z1) = three();
    let (x2, _y, z2) = three();
    assert!(x1 + z1 == x2 + z2, 42);
  }
}
```

This can be necessary at times as the compiler will error on unused local variables

```move
module 0x42::example {
  fun example() {
    let (x1, y, z1) = three(); // ERROR!
    //       ^ unused local 'y'
  }
}
```

### General `let` grammar

All the different structures in `let` can be combined! With that we arrive at this general
grammar for `let` statements:

> _let-binding_ ‚Üí **let** _pattern-or-list_ _type-annotation_<sub>_opt_</sub> _initializer_<sub>_opt_</sub>

> _pattern-or-list_ ‚Üí _pattern_ | **(** _pattern-list_ **)**

> _pattern-list_ ‚Üí _pattern_ **,**<sub>_opt_</sub> | _pattern_ **,** _pattern-list_

> _type-annotation_ ‚Üí **:** _type_

> _initializer_ ‚Üí **=** _expression_

The general term for the item that introduces the bindings is a _pattern_. The pattern serves to
both destructure data (possibly recursively) and introduce the bindings. The pattern grammar is as
follows:

> _pattern_ ‚Üí _local-variable_ | _struct-type_ **\{** _field-binding-list_ **}**

> _field-binding-list_ ‚Üí _field-binding_ **,**<sub>_opt_</sub> | _field-binding_ **,** _field-binding-list_

> _field-binding_ ‚Üí _field_ | _field_ **:** _pattern_

A few concrete examples with this grammar applied:

```move
script {
  fun example() {
    let (x, y): (u64, u64) = (0, 1);
    //       ^                           local-variable
    //       ^                           pattern
    //          ^                        local-variable
    //          ^                        pattern
    //          ^                        pattern-list
    //       ^^^^                        pattern-list
    //      ^^^^^^                       pattern-or-list
    //            ^^^^^^^^^^^^           type-annotation
    //                         ^^^^^^^^  initializer
    //  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ let-binding

    let Foo { f, g: x } = Foo { f: 0, g: 1 };
    //      ^^^                                    struct-type
    //            ^                                field
    //            ^                                field-binding
    //               ^                             field
    //                  ^                          local-variable
    //                  ^                          pattern
    //               ^^^^                          field-binding
    //            ^^^^^^^                          field-binding-list
    //      ^^^^^^^^^^^^^^^                        pattern
    //      ^^^^^^^^^^^^^^^                        pattern-or-list
    //                      ^^^^^^^^^^^^^^^^^^^^   initializer
    //  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ let-binding
  }
}
```

## Mutations

### Assignments

After the local is introduced (either by `let` or as a function parameter), the local can be
modified via an assignment:

```move
script {
  fun example(e: u8) {
    let x = 0;
    x = e
  }
}
```

Unlike `let` bindings, assignments are expressions. In some languages, assignments return the value
that was assigned, but in Move, the type of any assignment is always `()`.

```move

script {
  fun example(e: u8) {
    let x = 0;
    (x = e) == ()
  }
}
```

Practically, assignments being expressions means that they can be used without adding a new
expression block with braces (`{`...`}`).

```move
script {
  fun example(e: u8) {
    let x = 0;
    if (cond) x = 1 else x = 2;
  }
}
```

The assignment uses the same pattern syntax scheme as `let` bindings:

```move
module 0x42::example {
    struct X { f: u64 }

    fun new_x(): X {
        X { f: 1 }
    }

    // This example will complain about unused variables and assignments.
    fun example() {
       let (x, _, z) = (0, 1, 3);
       let (x, y, f, g);

       (X { f }, X { f: x }) = (new_x(), new_x());
       assert!(f + x == 2, 42);

       (x, y, z, f, _, g) = (0, 0, 0, 0, 0, 0);
    }
}
```

Note that a local variable can only have one type, so the type of the local cannot change between
assignments.

```move
script {
  fun example() {
    let x;
    x = 0;
    x = false; // ERROR!
  }
}
```

### Mutating through a reference

In addition to directly modifying a local with assignment, a local can be modified via a mutable
reference `&mut`.

```move
script {
  fun example() {
    let x = 0;
    let r = &mut x;
    *r = 1;
    assert!(x == 1, 42);
  }
}
```

This is particularly useful if either:

(1) You want to modify different variables depending on some condition.

```move
script {
  fun example() {
    let x = 0;
    let y = 1;
    let r = if (cond) {
      &mut x
    } else {
      &mut y
    };
    *r = *r + 1;
  }
}
```

(2) You want another function to modify your local value.

```move
script {
  fun example() {
    let x = 0;
    modify_ref(&mut x);
  }
}
```

This sort of modification is how you modify structs and vectors!

```move
script {
  use 0x1::vector;

  fun example() {
    let v = vector::empty();
    vector::push_back(&mut v, 100);
    assert!(*vector::borrow(&v, 0) == 100, 42);
  }
}
```

For more details, see [Move references](/build/smart-contracts/book/references).

### Compound Assignments

_Since language version 2.1_

Move also supports compound assignment operators. These are like an assignment to a variable,
or a mutation through a reference, except that the assigned location must already have a value,
which is read and operated on before being stored back into the location.
Currently these are only applicable to numeric values.

| Syntax | Description                                                  |
| ------ | ------------------------------------------------------------ |
| `+=`   | Performs addition and updates the left-hand value            |
| `-=`   | Performs subtraction and updates the left-hand value         |
| `*=`   | Performs multiplication and updates the left-hand value      |
| `%=`   | Performs modular division and updates the left-hand value    |
| `/=`   | Performs truncating division and updates the left-hand value |
| `&=`   | Performs bitwise and updates the left-hand value             |
| `\|=`  | Performs bitwise or and updates the left-hand value          |
| `^=`   | Performs bitwise xor and updates the left-hand value         |
| `<<=`  | Performs shift left and updates the left-hand value          |
| `>>=`  | Performs shift right and updates the left-hand value         |

For `e1 += e2`, the **modifying operand** `e2` is evaluated first, followed by the **assigned operand** `e1`.
The result of performing `+` on the operand values is then stored in the left-hand side location.
The assigned operand is only evaluated once. Similarly for all other operations listed in the table above.

```move
module 0x42::example {
  struct S { f: u64 }

  fun example() {
    let x = 41;
    x += 1;
    assert!(x == 42);

    let y = 41;
    let p = &mut y;
    *p += 1;
    assert!(*p == 42);

    let z = S { f: 41 };
    z.f += 1;
    assert!(z.f == 42);
  }
}
```

## Scopes

Any local declared with `let` is available for any subsequent expression, _within that scope_.
Scopes are declared with expression blocks, `{`...`}`.

Locals cannot be used outside the declared scope.

```move
script {
  fun example() {
    let x = 0;
    {
      let y = 1;
    };
    x + y // ERROR!
    //  ^ unbound local 'y'
  }
}
```

But, locals from an outer scope _can_ be used in a nested scope.

```move
script {
  fun example() {
    {
      let x = 0;
      {
        let y = x + 1; // valid
      }
    }
  }
}
```

Locals can be mutated in any scope where they are accessible. That mutation survives with the local,
regardless of the scope that performed the mutation.

```move
script {
  fun example() {
    let x = 0;
    x = x + 1;
    assert!(x == 1, 42);
    {
      x = x + 1;
      assert!(x == 2, 42);
    };
    assert!(x == 2, 42);
  }
}
```

### Expression Blocks

An expression block is a series of statements separated by semicolons (`;`). The resulting value of
an expression block is the value of the last expression in the block.

```move
script {
  fun example() {
    { let x = 1; let y = 1; x + y }
  }
}
```

In this example, the result of the block is `x + y`.

A statement can be either a `let` declaration or an expression. Remember that assignments (`x = e`)
are expressions of type `()`.

```move
script {
  fun example() {
    { let x; let y = 1; x = 1; x + y }
  }
}
```

Function calls are another common expression of type `()`. Function calls that modify data are
commonly used as statements.

```move
script {
  fun example() {
    { let v = vector::empty(); vector::push_back(&mut v, 1); v }
  }
}
```

This is not just limited to `()` types---any expression can be used as a statement in a sequence!

```move
script {
  fun example() {
    {
      let x = 0;
      x + 1; // value is discarded
      x + 2; // value is discarded
      b"hello"; // value is discarded
    }
  }
}
```

But! If the expression contains a resource (a value without the `drop` [ability](/build/smart-contracts/book/abilities)),
you will get an error. This is because Move's type system guarantees that any value that is dropped
has the `drop` [ability](/build/smart-contracts/book/abilities). (Ownership must be transferred or the value must be
explicitly destroyed within its declaring module.)

```move
script {
  fun example() {
    {
      let x = 0;
      Coin { value: x }; // ERROR!
      //  ^^^^^^^^^^^^^^^^^ unused value without the `drop` ability
      x
    }
  }
}
```

If a final expression is not present in a block---that is, if there is a trailing semicolon `;`,
there is an implicit [unit `()` value](https://en.wikipedia.org/wiki/Unit_type). Similarly, if the expression block is empty, there is an
implicit unit `()` value.

```move
script {
  fun example() {
    // Both are equivalent
    { x = x + 1; 1 / x; };
    { x = x + 1; 1 / x; () };
  }
}
```

```move
script {
  fun example() {
    // Both are equivalent
    {}
    { () }
  }
}
```

An expression block is itself an expression and can be used anyplace an expression is used. (Note:
The body of a function is also an expression block, but the function body cannot be replaced by
another expression.)

```move
script {
  fun example() {
    let my_vector: vector<vector<u8>> = {
      let v = vector::empty();
      vector::push_back(&mut v, b"hello");
      vector::push_back(&mut v, b"goodbye");
      v
    };
  }
}
```

(The type annotation is not needed in this example and only added for clarity.)

### Shadowing

If a `let` introduces a local variable with a name already in scope, that previous variable can no
longer be accessed for the rest of this scope. This is called _shadowing_.

```move
script {
  fun example() {
    let x = 0;
    assert!(x == 0, 42);

    let x = 1; // x is shadowed
    assert!(x == 1, 42);
  }
}
```

When a local is shadowed, it does not need to retain the same type as before.

```move
script {
  fun example() {
    let x = 0;
    assert!(x == 0, 42);

    let x = b"hello"; // x is shadowed
    assert!(x == b"hello", 42);
  }
}
```

After a local is shadowed, the value stored in the local still exists, but will no longer be
accessible. This is important to keep in mind with values of types without the
[`drop` ability](/build/smart-contracts/book/abilities), as ownership of the value must be transferred by the end of the
function.

```move
module 0x42::example {
  struct Coin has store { value: u64 }

  fun unused_resource(): Coin {
    let x = Coin { value: 0 }; // ERROR!
    //  ^ This local still contains a value without the `drop` ability
    x.value = 1;
    let x = Coin { value: 10 };
    x
    // ^ Invalid return
  }
}
```

When a local is shadowed inside a scope, the shadowing only remains for that scope. The shadowing is
gone once that scope ends.

```move
script {
  fun example() {
    let x = 0;
    {
      let x = 1;
      assert!(x == 1, 42);
    };
    assert!(x == 0, 42);
  }
}

```

Remember, locals can change type when they are shadowed.

```move
script {
  fun example() {
    let x = 0;
    {
      let x = b"hello";
      assert!(x = b"hello", 42);
    };
    assert!(x == 0, 42);
  }
}
```

## Move and Copy

All local variables in Move can be used in two ways, either by `move` or `copy`. If one or the other
is not specified, the Move compiler is able to infer whether a `copy` or a `move` should be used.
This means that in all the examples above, a `move` or a `copy` would be inserted by the
compiler. A local variable cannot be used without the use of `move` or `copy`.

`copy` will likely feel the most familiar coming from other programming languages, as it creates a
new copy of the value inside the variable to use in that expression. With `copy`, the local
variable can be used more than once.

```move
script {
  fun example() {
    let x = 0;
    let y = copy x + 1;
    let z = copy x + 2;
  }
}
```

Any value with the `copy` [ability](/build/smart-contracts/book/abilities) can be copied in this way.

`move` takes the value out of the local variable _without_ copying the data. After a `move` occurs,
the local variable is unavailable.

```move
script {
  fun example() {
    let x = 1;
    let y = move x + 1;
    //      ------ Local was moved here
    let z = move x + 2; // Error!
    //      ^^^^^^ Invalid usage of local 'x'
    y + z;
  }
}
```

### Safety

Move's type system will prevent a value from being used after it is moved. This is the same safety
check described in [`let` declaration](#let-bindings) that prevents local variables from being used
before it is assigned a value.

{/* For more information, see TODO future section on ownership and move semantics. */}

### Inference

As mentioned above, the Move compiler will infer a `copy` or `move` if one is not indicated. The
algorithm for doing so is quite simple:

- Any value with the `copy` [ability](/build/smart-contracts/book/abilities) is given a `copy`.
- Any reference (both mutable `&mut` and immutable `&`) is given a `copy`.
  - Except under special circumstances where it is made a `move` for predictable borrow checker
    errors.
- Any other value is given a `move`.
- If the compiler can prove that the source value with copy ability is not used after the
  assignment, then a move may be used instead of a copy for performance, but this will be invisible
  to the programmer (except in possible decreased time or gas cost).

For example:

```move
module 0x42::example {
  struct Foo {
    f: u64
  }

  struct Coin has copy {
    value: u64
  }

  fun example() {
    let s = b"hello";
    let foo = Foo { f: 0 };
    let coin = Coin { value: 0 };

    let s2 = s; // copy
    let foo2 = foo; // move
    let coin2 = coin; // copy

    let x = 0;
    let b = false;
    let addr = @0x42;
    let x_ref = &x;
    let coin_ref = &mut coin2;

    let x2 = x; // copy
    let b2 = b; // copy
    let addr2 = @0x42; // copy
    let x_ref2 = x_ref; // copy
    let coin_ref2 = coin_ref; // copy
  }
}
```

# Vector

> Master vector operations in Move for dynamic arrays, collections, and list manipulation in smart contracts.

`vector<T>` is the only primitive collection type provided by Move. A `vector<T>` is a homogeneous
collection of `T`'s that can grow or shrink by pushing/popping values off the "end".

A `vector<T>` can be instantiated with any type `T`. For example, `vector<u64>`, `vector<address>`,
`vector<0x42::MyModule::MyResource>`, and `vector<vector<u8>>` are all valid vector types.

## Literals

### General `vector` Literals

Vectors of any type can be created with `vector` literals.

| Syntax                | Type                                                                          | Description                                |
| --------------------- | ----------------------------------------------------------------------------- | ------------------------------------------ |
| `vector[]`            | `vector[]: vector<T>` where `T` is any single, non-reference type             | An empty vector                            |
| `vector[e1, ..., en]` | `vector[e1, ..., en]: vector<T>` where `e_i: T` s.t. `0 < i <= n` and `n > 0` | A vector with `n` elements (of length `n`) |

In these cases, the type of the `vector` is inferred, either from the element type or from the
vector's usage. If the type cannot be inferred, or simply for added clarity, the type can be
specified explicitly:

```move
vector<T>[]: vector<T>
vector<T>[e1, ..., en]: vector<T>
```

#### Example Vector Literals

```move
script {
  fun example() {
    (vector[]: vector<bool>);
    (vector[0u8, 1u8, 2u8]: vector<u8>);
    (vector<u128>[]: vector<u128>);
    (vector<address>[@0x42, @0x100]: vector<address>);
  }
}
```

### `vector<u8>` literals

A common use-case for vectors in Move is to represent "byte arrays", which are represented with
`vector<u8>`. These values are often used for cryptographic purposes, such as a public key or a hash
result. These values are so common that specific syntax is provided to make the values more
readable, as opposed to having to use `vector[]` where each individual `u8` value is specified in
numeric form.

There are currently two supported types of `vector<u8>` literals, _byte strings_ and _hex strings_.

#### Byte Strings

Byte strings are quoted string literals prefixed by a `b`, e.g. `b"Hello!\n"`.

These are ASCII encoded strings that allow for escape sequences. Currently, the supported escape
sequences are:

| Escape Sequence | Description                                    |
| --------------- | ---------------------------------------------- |
| `\n`            | New line (or Line feed)                        |
| `\r`            | Carriage return                                |
| `\t`            | Tab                                            |
| `\\`            | Backslash                                      |
| `\0`            | Null                                           |
| `\"`            | Quote                                          |
| `\xHH`          | Hex escape, inserts the hex byte sequence `HH` |

#### Hex Strings

Hex strings are quoted string literals prefixed by a `x`, e.g. `x"48656C6C6F210A"`.

Each byte pair, ranging from `00` to `FF`, is interpreted as hex encoded `u8` value. So each byte
pair corresponds to a single entry in the resulting `vector<u8>`.

#### Example String Literals

```move
script {
  fun byte_and_hex_strings() {
    assert!(b"" == x"", 0);
    assert!(b"Hello!\n" == x"48656C6C6F210A", 1);
    assert!(b"\x48\x65\x6C\x6C\x6F\x21\x0A" == x"48656C6C6F210A", 2);
    assert!(
        b"\"Hello\tworld!\"\n \r \\Null=\0" ==
            x"2248656C6C6F09776F726C6421220A200D205C4E756C6C3D00",
        3
    );
  }
}
```

## Operations

`vector` provides several operations via the `std::vector` module in the Move standard
library, as shown below. More operations may be added over time.
Up-to-date document on `vector` can be found [here](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/move-stdlib/doc/vector.md).

| Function                                                                              | Description                                                                                                                                                        | Aborts?                                                  |
| ------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------ | -------------------------------------------------------- |
| `vector::empty<T>(): vector<T>`                                                       | Create an empty vector that can store values of type `T`                                                                                                           | Never                                                    |
| `vector::is_empty<T>(self: &vector<T>): bool`                                         | Return `true` if the vector `self` has no elements and `false` otherwise.                                                                                          | Never                                                    |
| `vector::singleton<T>(t: T): vector<T>`                                               | Create a vector of size 1 containing `t`                                                                                                                           | Never                                                    |
| `vector::length<T>(self: &vector<T>): u64`                                            | Return the length of the vector `self`                                                                                                                             | Never                                                    |
| `vector::push_back<T>(self: &mut vector<T>, t: T)`                                    | Add `t` to the end of `self`                                                                                                                                       | Never                                                    |
| `vector::pop_back<T>(self: &mut vector<T>): T`                                        | Remove and return the last element in `self`                                                                                                                       | If `self` is empty                                       |
| `vector::borrow<T>(self: &vector<T>, i: u64): &T`                                     | Return an immutable reference to the element at index `i`                                                                                                          | If `i` is not in bounds                                  |
| `vector::borrow_mut<T>(self: &mut vector<T>, i: u64): &mut T`                         | Return a mutable reference to the element at index `i`                                                                                                             | If `i` is not in bounds                                  |
| `vector::destroy_empty<T>(self: vector<T>)`                                           | Delete `self`                                                                                                                                                      | If `self` is not empty                                   |
| `vector::append<T>(self: &mut vector<T>, other: vector<T>)`                           | Add the elements in `other` to the end of `self`                                                                                                                   | Never                                                    |
| `vector::reverse_append<T>(self: &mut vector<T>, other: vector<T>)`                   | Pushes all of the elements of the `other` vector into the `self` vector, in the reverse order as they occurred in `other`                                          | Never                                                    |
| `vector::contains<T>(self: &vector<T>, e: &T): bool`                                  | Return true if `e` is in the vector `self`. Otherwise, returns `false`                                                                                             | Never                                                    |
| `vector::swap<T>(self: &mut vector<T>, i: u64, j: u64)`                               | Swaps the elements at the `i`th and `j`th indices in the vector `self`                                                                                             | If `i` or `j` is out of bounds                           |
| `vector::reverse<T>(self: &mut vector<T>)`                                            | Reverses the order of the elements in the vector `self` in place                                                                                                   | Never                                                    |
| `vector::reverse_slice<T>(self: &mut vector<T>, l: u64, r: u64)`                      | Reverses the order of the elements `[l, r)` in the vector `self` in place                                                                                          | If `l > r` or if `l` or `r` is out of bounds             |
| `vector::index_of<T>(self: &vector<T>, e: &T): (bool, u64)`                           | Return `(true, i)` if `e` is in the vector `self` at index `i`. Otherwise, returns `(false, 0)`                                                                    | Never                                                    |
| `vector::insert<T>(self: &mut vector<T>, i: u64, e: T)`                               | Insert a new element `e` at position `0 <= i <= length`, using `O(length - i)` time                                                                                | If `i` is out of bounds                                  |
| `vector::remove<T>(self: &mut vector<T>, i: u64): T`                                  | Remove the `i`th element of the vector `self`, shifting all subsequent elements. This is O(n) and preserves ordering of elements in the vector                     | If `i` is out of bounds                                  |
| `vector::swap_remove<T>(self: &mut vector<T>, i: u64): T`                             | Swap the `i`th element of the vector `self` with the last element and then pop the element, This is O(1), but does not preserve ordering of elements in the vector | If `i` is out of bounds                                  |
| `vector::trim<T>(self: &mut vector<T>, new_len: u64): vector<T>`                      | Trim the vector `self` to the smaller size `new_len` and return the evicted elements in order                                                                      | If `new_len > self.length()`                             |
| `vector::trim_reverse<T>(self: &mut vector<T>, new_len: u64): vector<T>`              | Trim the vector `self` to the smaller size `new_len` and return the evicted elements in the reverse order                                                          | If `new_len > self.length()`                             |
| `vector::rotate<T>(self: &mut vector<T>, rot: u64): u64`                              | `rotate(&mut [1, 2, 3, 4, 5], 2) -> [3, 4, 5, 1, 2]` in place, returns the split point i.e., `3` in this example                                                   | If `rot <= self.length()` does not hold                  |
| `vector::rotate_slice<T>(self: &mut vector<T>, left: u64, rot: u64, right: u64): u64` | rotate a slice `[left, right)` with `left <= rot <= right` in place, returns the split point                                                                       | If `left <= rot <= right <= self.length()` does not hold |

Example:

```move
script {
  use std::vector;

  fun example() {
    let v = vector::empty<u64>();
    vector::push_back(&mut v, 5);
    vector::push_back(&mut v, 6);

    assert!(*vector::borrow(&v, 0) == 5, 42);
    assert!(*vector::borrow(&v, 1) == 6, 42);
    assert!(vector::pop_back(&mut v) == 6, 42);
    assert!(vector::pop_back(&mut v) == 5, 42);
  }
}
```

## Index Notation for Vectors

_Since language version 2.0_

Index notation using square brackets (`[]`) is available for vector operations, simplifying syntax
and making programs easier to understand. The index notation is simply syntactic sugar which
is reduced to existing operations by the compiler;  the named operations are also still supported.

The table below gives an overview of index notations for vectors:

| Indexing Syntax   | Vector Operation                           |
| ----------------- | ------------------------------------------ |
| `&v[i]`           | `vector::borrow(&v, i)`                    |
| `&mut v[i]`       | `vector::borrow_mut(&mut v, i)`            |
| `v[i]`            | `*vector::borrow(&v, i)`                   |
| `v[i] = x`        | `*vector::borrow_mut(&mut v, i) = x`       |
| `&v[i].field`     | `&vector::borrow(&v, i).field`             |
| `&mut v[i].field` | `&mut vector::borrow_mut(&mut v, i).field` |
| `v[i].field`      | `vector::borrow(&v, i).field`              |
| `v[i].field = x`  | `vector::borrow_mut(&mut v, i).field = x`  |

As an example, here is a bubble sort algorithm for vectors using index notation:

```move
fun bubble_sort(v: vector<u64>) {
  use std::vector;
  let n = vector::length(&v);
  let i = 0;

  while (i < n) {
    let j = 0;
    while (j < n - i - 1) {
      if (v[j] > v[j + 1]) {
        let t = v[j];
        v[j] = v[j + 1];
        v[j + 1] = t;
      };
      j = j + 1;
    };
    i = i + 1;
  };
}
```

## Destroying and copying vectors

Some behaviors of `vector<T>` depend on the abilities of the element type, `T`. For example, vectors
containing elements that do not have `drop` cannot be implicitly discarded like `v` in the example
above--they must be explicitly destroyed with `vector::destroy_empty`.

Note that `vector::destroy_empty` will abort at runtime unless `vec` contains zero elements:

```move
script {
  fun destroy_any_vector<T>(vec: vector<T>) {
    vector::destroy_empty(vec) // deleting this line will cause a compiler error
  }
}
```

But no error would occur for dropping a vector that contains elements with `drop`:

```move
script {
  fun destroy_droppable_vector<T: drop>(vec: vector<T>) {
    // valid!
    // nothing needs to be done explicitly to destroy the vector
  }
}
```

Similarly, vectors cannot be copied unless the element type has `copy`. In other words, a
`vector<T>` has `copy` if and only if `T` has `copy`.

For more details see the sections on [type abilities](/build/smart-contracts/book/abilities) and [generics](/build/smart-contracts/book/generics).

## Ownership

As mentioned [above](#destroying-and-copying-vectors), `vector` values can be copied only if the
elements can be copied.

# Move On Aptos Compiler

> Learn about compiler_v2 for Move smart contract development on Aptos blockchain.

The Move on Aptos compiler (codename 'compiler v2') translates Move source code into Move bytecode. It unifies the architectures of the Move compiler and the Move Prover, enabling faster innovation in the Move language. It also offers new tools for defining code optimizations which can be leveraged to generate more gas efficient code for Move programs.

The Move on Aptos compiler supports Move 2, the latest revision of the Move language. Head over to the [release page in the book](/build/smart-contracts/book/move-2) to learn more about the new features in Move 2. Starting at Aptos CLI v6.0.0, this language version and the Move on Aptos compiler are the default. Note that Move 2 is generally backwards compatible with Move 1.

## Move on Aptos Release State

Move on Aptos is in production and is now the default compiler, with Move 2 being the default language version.

## Reporting an Issue

If you run into issues, please use [this link to create a github issue][bug]. If you are able to provide a small piece of Move code which reproduces the issue, debugging and fixing it will be easier for us.

[bug]: https://github.com/aptos-labs/aptos-core/issues/new?title=[compiler-v2]%20%3CPLEASE%20NAME%20IT%3E&body=%3CPLEASE%20DESCRIBE%20IT%3E&labels=compiler-v2&projects=aptos-labs/16

## Using Move on Aptos Compiler

Ensure to have installed the latest version of the Aptos CLI:

```shellscript filename="Terminal"
aptos update aptos # on supported OS
brew upgrade aptos # on MacOS
```

Move on Aptos compiler and Move 2 are now the default, requiring no changes to your usage. Examples:

```shellscript filename="Terminal"
aptos move compile
aptos move test
aptos move prove
```

# Compiling (Move)

> Learn about compiling for Move smart contract development on Aptos blockchain.

import { Aside, FileTree } from '@astrojs/starlight/components';

<Aside type="note">
  Ensure that your [CLI](/build/cli) is up to date before compiling.
</Aside>

## `aptos move compile`

Once you have a package set up, you can compile your Move code by doing:

```shellscript filename="Terminal"
aptos move compile
```

If run successfully, you should receive a Terminal output like so

```shellscript filename="Terminal"
{
  "Result": [
    "<PUBLISHING_ADDRESS>::<MODULE_NAME>"
  ]
}
```

<Aside type="note">
  You may need to add named addresses, especially for examples.  For example, with the Hello Blockchain Move example, you will need to add the `hello_blockchain` named address:

  ```shellscript filename="Terminal"
  aptos move compile --named-addresses hello_blockchain=default
  ```
</Aside>

## Unpacking Build

Compiled Move packages contain a folder structure that resembles the one below.

<FileTree>
  - build/
    - package\_name/
      - bytecode\_modules/
        - dependencies/
        - module\_name.mv
      - source\_maps/
        - dependencies/
        - module\_name.mvsm
      - sources/
        - dependencies/
        - module\_name.move
      - BuildInfo.yaml
  - scripts/
  - sources/
    - module\_name.move
  - tests/
  - Move.toml
</FileTree>

### `bytecode_modules`

The bytecode modules folder contains the compiled Move bytecode for your module(s) (such as `module_name.mv`).
To learn more about the bytecode and its security features, see [why move?](/build/smart-contracts/why-move)

### `source_maps`

The source maps folder contains source maps (such as `module_name.mvsm`) which allow
users to map the compiled bytecode back to the source code and relevant dependencies.

# Confidential Asset (CA)

> Learn about confidential asset for Move smart contract development on Aptos blockchain.

import { ThemedImage } from '~/components/ThemedImage';

import { Aside } from '@astrojs/starlight/components';

The Confidential Asset Standard (also known as "Confidential Asset" or "CA") is a privacy-focused protocol for managing Fungible Assets (FA).
It allows users to perform transactions with hidden FA amounts while keeping sender and recipient addresses publicly visible.

This standard allows any FA to be wrapped into a corresponding Confidential Asset, ensuring compatibility with existing tokens.
It supports 64-bit transfers, and balances of up to 128 bits.

Operations on Confidential Asset balances (confidential balances), require zero-knowledge proofs (ZKPs) to verify transaction correctness
without revealing hidden amounts and other sensitive data.

<Aside type="note">
  Interacting directly with Confidential Asset's smart contracts is highly complex.
  Developers are encouraged to create external services to manage tasks like generating ZKPs, recovering keys, and decrypting balances.
  To assist with this, we've developed a TypeScript SDK, with full documentation available [here](/build/sdks/ts-sdk/confidential-asset).
</Aside>

<Aside type="note">
  This documentation explains the contract's operations and offers insights into the protocol core processes.
  Cryptographic and mathematical details are explained superficially.
</Aside>

## Confidential Asset Store

For every confidential asset a user registers, they generate a unique keypair:

- An encryption key (EK) stored on-chain.
- A decryption key (DK) kept securely by the user.

These keys are standalone and should not be confused with the user's Aptos account keys.

Each confidential balance is split into two parts:

- `pending_balance` - accumulates all incoming transactions.
- `actual_balance` - used exclusively for outgoing transactions.

Both balances are encrypted with the same user's EK, ensuring underlying amounts remain private.

<Aside type="note">
  This separation protects against "front-running" attacks.
  Specifically, if there was a single balance, an attacker could revert a user's transaction by sending a small payment,
  altering the balance and, consequently, invalidating the user's ZKP.
</Aside>

The confidential balance and its associated encryption key are stored in the `ConfidentialAssetStore` resource.
The `ConfidentialAssetStore` is instantiated for each confidential asset the user has and managed by the `confidential_asset` module:

```move filename="confidential_asset.move"
struct ConfidentialAssetStore has key {
    pending_balance: confidential_balance::CompressedConfidentialBalance,
    actual_balance: confidential_balance::CompressedConfidentialBalance,
    ek: twisted_elgamal::CompressedPubkey,
    // ...
}
```

## Confidential Balance

Confidential balances handle token amounts by splitting them into smaller units called chunks.
Each chunk represents a portion of the total amount and is encrypted individually using the user‚Äôs EK.
This design ensures efficient management of balances.

### Chunks

The pending balance consists of four chunks that hold all incoming transfers.
It can handle up to 2^16 64-bit transfers before requiring a rollover to the actual balance.
During this accumulation, the pending balance chunks can grow up to 32 bits each.

The actual balance consists of eight chunks, supporting 128-bit values.
After any operation the actual balance should be [normalized](#normaliztion) back to 16-bit chunks to maintain efficient decryption.

The `ConfidentialBalance` struct from the `confidential_balance` module is used to represent both the pending and actual balances:

```move filename="confidential_asset.move"
struct ConfidentialBalance has drop {
    chunks: vector<twisted_elgamal::Ciphertext>,
}
```

### Encryption and Decryption

Encryption involves:

- Splitting the total amount into 16-bit chunks.
- Applying the user's EK to encrypt each chunk individually.

Decryption involves:

- Applying the user‚Äôs DK to decrypt each chunk.
- Solving a discrete logarithm (DL) problem for each chunk to recover the original values.
- Combining the recovered values to reconstruct the total amount.

### Normalization

Normalization ensures chunks are always reduced to manageable sizes (16 bits).
Without normalization, chunks can grow too large, making the decryption process (solving DL) significantly slower or even impractical.
This mechanism is automatically applied to the actual balance after each operation,
ensuring that users can always decrypt their balances, even as balances grow through multiple transactions.
Only after a rollover, users are required to normalize the actual balance [manually](#normalization).

### Homomorphic Encryption

The protocol utilizes Homomorphic encryption, allowing arithmetic operations on confidential balances without their decryption.
This capability is essential for updating the receiver's pending balance during transfers and for rollovers,
where the user's pending balance is added to the actual one.

## Architecture

The diagram below shows the relationship between Confidential Asset modules:

<ThemedImage
  alt="CA Modules Relationship"
  sources={{
light: '~/images/ca-diagram-light.png',
dark: '~/images/ca-diagram-dark.png',
}}
/>

Users interact with the `confidential_asset` module to perform operations on their confidential balances.
The `confidential_asset` module calls the `confidential_balance` module to manage the confidential balances and the `confidential_proof` module to verify ZKPs.
Under the hood, the `confidential_balance` module uses the `twisted_elgamal` module for operations on chunks.

## Entry functions

### Register

```move filename="confidential_asset.move"
public entry fun register(sender: &signer, token: Object<Metadata>, ek: vector<u8>)
```

```move filename="confidential_asset.move"
#[view]
public fun has_confidential_asset_store(user: address, token: Object<Metadata>): bool
```

Users must register a `ConfidentialAssetStore` for each token they intend to transact with.
As part of this process, users are required to generate a keypair (EK and DK) on their end.

When a `ConfidentialAssetStore` is first registered, the confidential balance is set to zero,
represented as zero ciphertexts for both the `pending_balance` and `actual_balance`.

You can also check if a user has a `ConfidentialAssetStore` for a specific token using the `has_confidential_asset_store` function.

<Aside type="note">
  Although it is recommended to generate a unique keypair for each token to enhance security,
  it's not restricted to reuse the same encryption key across multiple tokens if preferred.
</Aside>

<Aside type="caution">
  This operation is expensive as it initializes a new storage and storage fees far exceed execution fees.
  However, users call it only once per token.
</Aside>

```move filename="register_example.move"
#[test_only]
module confidential_asset_example::register_example {
    /// ...

    fun register(bob: &signer, token: Object<Metadata>) {
        let bob_addr = signer::address_of(bob);

        // It's a test-only function, so we don't need to worry about the security of the keypair.
        let (_bob_dk, bob_ek) = twisted_elgamal::generate_twisted_elgamal_keypair();

        let bob_ek = twisted_elgamal::pubkey_to_bytes(&bob_ek);

        confidential_asset::register(bob, token, bob_ek);

        print(&utf8(b"Bob's pending balance is zero:"));
        print(&confidential_asset::pending_balance(bob_addr, token));

        print(&utf8(b"Bob's actual balance is zero:"));
        print(&confidential_asset::actual_balance(bob_addr, token));

        print(&utf8(b"Bob's encryption key is set:"));
        print(&confidential_asset::encryption_key(bob_addr, token));
    }
}
```

### Deposit

```move filename="confidential_asset.move"
public entry fun deposit(sender: &signer, token: Object<Metadata>, amount: u64)
```

```move filename="confidential_asset.move"
public entry fun deposit_to(sender: &signer, token: Object<Metadata>, to: address, amount: u64)
```

The `deposit` and `deposit_to` functions bring tokens into the protocol, transferring the passed amount
from primary FA store of the sender to the pending balance of the recipient.

The amount in this function is publicly visible, as adding new tokens to the protocol requires a normal transfer.
However, tokens within the protocol become obfuscated through confidential transfers, ensuring privacy in subsequent transactions.

<Aside type="note">
  If you want to have a hidden amount from the beginning, use the `confidential_transfer` function instead.
</Aside>

```move filename="deposit_example.move"
#[test_only]
module confidential_asset_example::deposit_example {
    /// ...

    fun deposit(bob: &signer, alice: &signer, token: Object<Metadata>) {
        let bob_addr = signer::address_of(bob);
        let alice_addr = signer::address_of(alice);

        // It's a test-only function, so we don't need to worry about the security of the keypair.
        let (bob_dk, bob_ek) = twisted_elgamal::generate_twisted_elgamal_keypair();
        let (alice_dk, alice_ek) = twisted_elgamal::generate_twisted_elgamal_keypair();

        let bob_ek = twisted_elgamal::pubkey_to_bytes(&bob_ek);
        let alice_ek = twisted_elgamal::pubkey_to_bytes(&alice_ek);

        confidential_asset::register(bob, token, bob_ek);
        confidential_asset::register(alice, token, alice_ek);

        print(&utf8(b"Bob's FA balance before the deposit is 500:"));
        print(&primary_fungible_store::balance(bob_addr, token));

        assert!(primary_fungible_store::balance(bob_addr, token) == 500);

        let bob_amount = 100;
        let alice_amount = 200;

        // The balance is not hidden yet, because we explicitly pass the amount to the function.
        confidential_asset::deposit(bob, token, bob_amount);
        confidential_asset::deposit_to(bob, token, alice_addr, alice_amount);

        print(&utf8(b"Bob's FA balance after the deposit is 200:"));
        print(&primary_fungible_store::balance(bob_addr, token));

        assert!(primary_fungible_store::balance(bob_addr, token) == 200);

        print(&utf8(b"Bob's pending balance is not zero:"));
        print(&confidential_asset::pending_balance(bob_addr, token));

        // In real world, we would not be able to see the someone else's balance as it requires
        // the knowledge of the decryption key.
        // The balance decryption requires solving the discrete logarithm problem,
        // so we just check if the passed amount is correct for simplicity.
        assert!(confidential_asset::verify_pending_balance(bob_addr, token, &bob_dk, bob_amount));

        print(&utf8(b"Alice's pending balance is not zero:"));
        print(&confidential_asset::pending_balance(alice_addr, token));

        assert!(confidential_asset::verify_pending_balance(alice_addr, token, &alice_dk, alice_amount));
    }
}

```

### Rollover Pending Balance

```move filename="confidential_asset.move"
public entry fun rollover_pending_balance(sender: &signer, token: Object<Metadata>)
```

The `rollover_pending_balance` function adds the pending balance to the actual one, resetting the pending balance to zero.
It works with no additional proofs as this function utilizes properties of the [Homomorphic encryption](#homomorphic-encryption) used in the protocol.

<Aside type="note">
  You cannot spend money from the pending balance directly. It must be rolled over to the actual balance first.
</Aside>

<Aside type="caution">
  The actual balance must be [normalized](#normalization) before performing a rollover.
  If it is not normalized, you can use the [`normalize`](#normalize) function to do so.
</Aside>

<Aside type="caution">
  Calling the `rollover_pending_balance` function in a separate transaction is crucial for preventing "front-running" attacks.
</Aside>

```move filename="rollover_example.move"
#[test_only]
module confidential_asset_example::rollover_example {
    /// ...

    fun rollover(bob: &signer, token: Object<Metadata>) {
        let bob_addr = signer::address_of(bob);

        // It's a test-only function, so we don't need to worry about the security of the keypair.
        let (bob_dk, bob_ek) = twisted_elgamal::generate_twisted_elgamal_keypair();

        let bob_ek = twisted_elgamal::pubkey_to_bytes(&bob_ek);

        let bob_amount = 100;

        confidential_asset::register(bob, token, bob_ek);
        confidential_asset::deposit(bob, token, bob_amount);

        print(&utf8(b"Bob's pending balance is NOT zero:"));
        print(&confidential_asset::pending_balance(bob_addr, token));

        print(&utf8(b"Bob's actual balance is zero:"));
        print(&confidential_asset::actual_balance(bob_addr, token));

        assert!(confidential_asset::verify_pending_balance(bob_addr, token, &bob_dk, bob_amount));
        assert!(confidential_asset::verify_actual_balance(bob_addr, token, &bob_dk, 0));

        // No explicit normalization is required, as the actual balance is already normalized.
        assert!(confidential_asset::is_normalized(bob_addr, token));

        confidential_asset::rollover_pending_balance(bob, token);

        print(&utf8(b"Bob's pending balance is zero:"));
        print(&confidential_asset::pending_balance(bob_addr, token));

        print(&utf8(b"Bob's actual balance is NOT zero:"));
        print(&confidential_asset::actual_balance(bob_addr, token));

        assert!(confidential_asset::verify_pending_balance(bob_addr, token, &bob_dk, 0));
        assert!(confidential_asset::verify_actual_balance(bob_addr, token, &bob_dk, (bob_amount as u128)));
    }
}
```

### Confidential Transfer

```move filename="confidential_asset.move"
public entry fun confidential_transfer(
    sender: &signer,
    token: Object<Metadata>,
    to: address,
    new_balance: vector<u8>,
    sender_amount: vector<u8>,
    recipient_amount: vector<u8>,
    auditor_eks: vector<u8>,
    auditor_amounts: vector<u8>,
    zkrp_new_balance: vector<u8>,
    zkrp_transfer_amount: vector<u8>,
    sigma_proof: vector<u8>)
```

The `confidential_transfer` function transfers tokens from the sender's actual balance to the recipient's
pending balance. The sender encrypts the transferred amount using the recipient's encryption key, enabling the recipient's
confidential balance to be updated [homomorphically](#homomorphic-encryption).

To ensure transparency, the sender could also encrypt the transferred amount using the auditors' EKs,
allowing the auditors to decrypt the transferred amount on their end.

<Aside type="caution">
  If the global auditor is set, it must be included in the `auditor_eks` list as the FIRST element (see the example below).
</Aside>

<Aside type="note">
  Once a user has participated in at least one transfer, their balance becomes "hidden".
  This means that neither the transferred amount nor the updated balances of the sender and recipient are visible to external observers.
</Aside>

```move filename="transfer_example.move"
#[test_only]
module confidential_asset_example::transfer_example {
    /// ...

    fun transfer(bob: &signer, alice: &signer, token: Object<Metadata>) {
        let bob_addr = signer::address_of(bob);
        let alice_addr = signer::address_of(alice);

        // It's a test-only function, so we don't need to worry about the security of the keypair.
        let (bob_dk, bob_ek) = twisted_elgamal::generate_twisted_elgamal_keypair();
        let (alice_dk, alice_ek) = twisted_elgamal::generate_twisted_elgamal_keypair();

        // Note: If the asset-specific auditor is set, we need to include it in the `auditor_eks` vector as the FIRST element.
        //
        // let asset_auditor_ek = confidential_asset::get_auditor(token);
        // let auditor_eks = vector[];
        // if (asset_auditor_ek.is_some()) {
        //     auditor_eks.push_back(asset_auditor_ek.extract());
        // };

        let (_, auditor_ek) = twisted_elgamal::generate_twisted_elgamal_keypair();
        let auditor_eks = vector[auditor_ek];

        let bob_ek_bytes = twisted_elgamal::pubkey_to_bytes(&bob_ek);
        let alice_ek_bytes = twisted_elgamal::pubkey_to_bytes(&alice_ek);

        confidential_asset::register(bob, token, bob_ek_bytes);
        confidential_asset::register(alice, token, alice_ek_bytes);

        // Bob's current balance is 300, and he wants to transfer 50 to Alice, whose balance is zero.
        let bob_current_amount = 300;
        let bob_new_amount = 250;
        let transfer_amount = 50;
        let alice_current_amount = 0;
        let alice_new_amount = 50;

        confidential_asset::deposit(bob, token, bob_current_amount);
        confidential_asset::rollover_pending_balance(bob, token);

        print(&utf8(b"Bob's actual balance is 300"));
        assert!(confidential_asset::verify_actual_balance(bob_addr, token, &bob_dk, (bob_current_amount as u128)));

        print(&utf8(b"Alice's pending balance is zero"));
        assert!(confidential_asset::verify_pending_balance(alice_addr, token, &alice_dk, alice_current_amount));

        let current_balance = confidential_balance::decompress_balance(
            &confidential_asset::actual_balance(bob_addr, token)
        );

        let (
            proof,
            // New balance is the balance after the transfer encrypted with the sender's encryption key.
            // It will be set as the new actual balance for the sender.
            new_balance,
            // Transfer amount encrypted with the sender's encryption key.
            // Used for indexing purposes only.
            sender_amount,
            // Transfer amount encrypted with the recipient's encryption key.
            // It will be Homomorphically added to the recipient's pending balance.
            recipient_amount,
            // Transfer amount encrypted with the auditors' encryption keys.
            // It won't be stored on-chain, but an auditor can decrypt the transfer amount with its dk.
            auditor_amounts
        ) = confidential_proof::prove_transfer(
            &bob_dk,
            &bob_ek,
            &alice_ek,
            transfer_amount,
            bob_new_amount,
            &current_balance,
            &auditor_eks,
        );

        let (
            sigma_proof,
            zkrp_new_balance,
            zkrp_transfer_amount
        ) = confidential_proof::serialize_transfer_proof(&proof);

        confidential_asset::confidential_transfer(
            bob,
            token,
            alice_addr,
            confidential_balance::balance_to_bytes(&new_balance),
            confidential_balance::balance_to_bytes(&sender_amount),
            confidential_balance::balance_to_bytes(&recipient_amount),
            confidential_asset::serialize_auditor_eks(&auditor_eks),
            confidential_asset::serialize_auditor_amounts(&auditor_amounts),
            zkrp_new_balance,
            zkrp_transfer_amount,
            sigma_proof
        );

        print(&utf8(b"Bob's actual balance is 250"));
        assert!(confidential_asset::verify_actual_balance(bob_addr, token, &bob_dk, bob_new_amount));

        print(&utf8(b"Alice's pending balance is 50"));
        assert!(confidential_asset::verify_pending_balance(alice_addr, token, &alice_dk, alice_new_amount));
    }
}
```

### Withdraw

```move filename="confidential_asset.move"
public entry fun withdraw(
    sender: &signer,
    token: Object<Metadata>,
    amount: u64,
    new_balance: vector<u8>,
    zkrp_new_balance: vector<u8>,
    sigma_proof: vector<u8>)
```

```move filename="confidential_asset.move"
public entry fun withdraw_to(
    sender: &signer,
    token: Object<Metadata>,
    to: address,
    amount: u64,
    new_balance: vector<u8>,
    zkrp_new_balance: vector<u8>,
    sigma_proof: vector<u8>)
```

The `withdraw` and `withdraw_to` allow a user to withdraw tokens from the protocol,
transferring the passed amount from the actual balance of the sender to the primary FA store of the recipient.
This function enables users to release tokens while not revealing their remaining balances.

<Aside type="caution">
  Attempting to withdraw more tokens than available will cause an error.
</Aside>

```move filename="withdraw_example.move"
#[test_only]
module confidential_asset_example::withdraw_example {
    /// ...

    fun withdraw(bob: &signer, alice: &signer, token: Object<Metadata>) {
        let bob_addr = signer::address_of(bob);
        let alice_addr = signer::address_of(alice);

        // It's a test-only function, so we don't need to worry about the security of the keypair.
        let (bob_dk, bob_ek) = twisted_elgamal::generate_twisted_elgamal_keypair();
        let (_alice_dk, alice_ek) = twisted_elgamal::generate_twisted_elgamal_keypair();

        let bob_ek_bytes = twisted_elgamal::pubkey_to_bytes(&bob_ek);
        let alice_ek_bytes = twisted_elgamal::pubkey_to_bytes(&alice_ek);

        confidential_asset::register(bob, token, bob_ek_bytes);
        confidential_asset::register(alice, token, alice_ek_bytes);

        let bob_current_amount = 500;
        let bob_new_amount = 450;
        let transfer_amount = 50;

        // Bob withdraws all available tokens
        confidential_asset::deposit(bob, token, (bob_current_amount as u64));
        confidential_asset::rollover_pending_balance(bob, token);

        print(&utf8(b"Alice's FA balance before the withdrawal is zero:"));
        print(&primary_fungible_store::balance(alice_addr, token));

        assert!(primary_fungible_store::balance(alice_addr, token) == 0);

        print(&utf8(b"Bob's actual balance before the withdrawal is 500"));
        assert!(confidential_asset::verify_actual_balance(bob_addr, token, &bob_dk, bob_current_amount));

        let current_balance = confidential_balance::decompress_balance(
            &confidential_asset::actual_balance(bob_addr, token)
        );

        let (proof, new_balance) = confidential_proof::prove_withdrawal(
            &bob_dk,
            &bob_ek,
            transfer_amount,
            bob_new_amount,
            &current_balance
        );

        let new_balance = confidential_balance::balance_to_bytes(&new_balance);
        let (sigma_proof, zkrp_new_balance) = confidential_proof::serialize_withdrawal_proof(&proof);

        confidential_asset::withdraw_to(
            bob,
            token,
            alice_addr,
            transfer_amount,
            new_balance,
            zkrp_new_balance,
            sigma_proof
        );

        print(&utf8(b"Alice's FA balance after the withdrawal is 50:"));
        print(&primary_fungible_store::balance(alice_addr, token));

        assert!(primary_fungible_store::balance(alice_addr, token) == 50);

        print(&utf8(b"Bob's actual balance after the withdrawal is 450"));
        assert!(confidential_asset::verify_actual_balance(bob_addr, token, &bob_dk, bob_new_amount));
    }
}
```

### Rotate Encryption Key

```move filename="confidential_asset.move"
public entry fun rotate_encryption_key(
    sender: &signer,
    token: Object<Metadata>,
    new_ek: vector<u8>,
    new_balance: vector<u8>,
    zkrp_new_balance: vector<u8>,
    sigma_proof: vector<u8>)
```

```move filename="confidential_asset.move"
public entry fun rotate_encryption_key_and_unfreeze(
    sender: &signer,
    token: Object<Metadata>,
    new_ek: vector<u8>,
    new_confidential_balance: vector<u8>,
    zkrp_new_balance: vector<u8>,
    rotate_proof: vector<u8>)
```

```move filename="confidential_asset.move"
public entry fun rollover_pending_balance_and_freeze(sender: &signer, token: Object<Metadata>)
```

The `rotate_encryption_key` function modifies the user's EK and re-encrypts the actual balance with the new EK.
This function checks that the pending balance is zero before proceeding, guaranteeing that the user does not lose funds during the rotation.

To facilitate the rotation process:

- The pending balance must first be rolled over and frozen by calling `rollover_pending_balance_and_freeze`.
  This prevents new transactions from being processed during the key rotation.
- Then the EK can be rotated and unfrozen using `rotate_encryption_key_and_unfreeze`.

<Aside type="caution">
  Calling `rotate_encryption_key` with a non-zero pending balance will cause an error.
</Aside>

```move filename="rotate_example.move"
#[test_only]
module confidential_asset_example::rotate_example {
    /// ...

    fun rotate(bob: &signer, token: Object<Metadata>) {
        let bob_addr = signer::address_of(bob);

        // It's a test-only function, so we don't need to worry about the security of the keypair.
        let (bob_current_dk, bob_current_ek) = twisted_elgamal::generate_twisted_elgamal_keypair();
        let (bob_new_dk, bob_new_ek) = twisted_elgamal::generate_twisted_elgamal_keypair();

        let bob_current_ek_bytes = twisted_elgamal::pubkey_to_bytes(&bob_current_ek);
        let bob_new_ek_bytes = twisted_elgamal::pubkey_to_bytes(&bob_new_ek);

        let bob_amount = 100;

        confidential_asset::register(bob, token, bob_current_ek_bytes);
        confidential_asset::deposit(bob, token, (bob_amount as u64));

        // We need to rollover the pending balance and freeze the token to prevent any new deposits being come.
        confidential_asset::rollover_pending_balance_and_freeze(bob, token);

        print(&utf8(b"Bob's encryption key before the rotation:"));
        print(&confidential_asset::encryption_key(bob_addr, token));

        assert!(confidential_asset::verify_actual_balance(bob_addr, token, &bob_current_dk, bob_amount));

        let current_balance = confidential_balance::decompress_balance(
            &confidential_asset::actual_balance(bob_addr, token)
        );

        let (proof, new_balance) = confidential_proof::prove_rotation(
            &bob_current_dk,
            &bob_new_dk,
            &bob_current_ek,
            &bob_new_ek,
            bob_amount,
            &current_balance
        );

        let (
            sigma_proof,
            zkrp_new_balance
        ) = confidential_proof::serialize_rotation_proof(&proof);

        // After rotating the encryption key, we unfreeze the token to allow new deposits.
        confidential_asset::rotate_encryption_key_and_unfreeze(
            bob,
            token,
            bob_new_ek_bytes,
            confidential_balance::balance_to_bytes(&new_balance),
            zkrp_new_balance,
            sigma_proof
        );

        print(&utf8(b"Bob's encryption key after the rotation:"));
        print(&confidential_asset::encryption_key(bob_addr, token));

        // Note that here we use the new decryption key to verify the actual balance.
        assert!(confidential_asset::verify_actual_balance(bob_addr, token, &bob_new_dk, bob_amount));
    }
}
```

### Normalize

```move filename="confidential_asset.move"
public entry fun normalize(
    sender: &signer,
    token: Object<Metadata>,
    new_balance: vector<u8>,
    zkrp_new_balance: vector<u8>,
    sigma_proof: vector<u8>)
```

```move filename="confidential_asset.move"
public fun is_normalized(user: address, token: Object<Metadata>): bool
```

The `normalize` function ensures that the actual balance is reduced to 16-bit chunks for [efficient decryption](#normalization).
This is necessary only before the `rollover_pending_balance` operation, which requires the actual balance to be normalized beforehand.

All other functions, such as `withdraw` or `confidential_transfer`, handle normalization implicitly, making manual normalization unnecessary in those cases.

<Aside type="note">
  All functions except `rollover_pending_balance` perform implicit normalization.
</Aside>

<Aside type="caution">
  Calling a `rollover_pending_balance` when the actual balance is already normalized will cause an error.
  You can check if the actual balance is normalized using the `is_normalized` function.
</Aside>

```move filename="normalize_example.move"
#[test_only]
module confidential_asset_example::normalize_example {
    /// ...

    fun normalize(bob: &signer, token: Object<Metadata>) {
        let bob_addr = signer::address_of(bob);

        // It's a test-only function, so we don't need to worry about the security of the keypair.
        let (bob_dk, bob_ek) = twisted_elgamal::generate_twisted_elgamal_keypair();

        let bob_ek_bytes = twisted_elgamal::pubkey_to_bytes(&bob_ek);

        let bob_amount = 500;

        confidential_asset::register(bob, token, bob_ek_bytes);
        confidential_asset::deposit(bob, token, (bob_amount as u64));

        // The rollover function is the only function that requires the actual balance to be normalized
        // beforehand and leaves it unnormalized after execution, no matter what the pending balance was.
        confidential_asset::rollover_pending_balance(bob, token);

        assert!(!confidential_asset::is_normalized(bob_addr, token));

        confidential_asset::deposit(bob, token, (bob_amount as u64));

        // Before performing a second rollover, the actual balance must be normalized.
        // You will get an error if you try to rollover an unnormalized balance:
        // confidential_asset::rollover_pending_balance(bob, token);

        let current_balance = confidential_balance::decompress_balance(
            &confidential_asset::actual_balance(bob_addr, token)
        );

        let (
            proof,
            new_balance
        ) = confidential_proof::prove_normalization(
            &bob_dk,
            &bob_ek,
            bob_amount,
            &current_balance
        );

        let (sigma_proof, zkrp_new_balance) = confidential_proof::serialize_normalization_proof(&proof);

        confidential_asset::normalize(
            bob,
            token,
            confidential_balance::balance_to_bytes(&new_balance),
            zkrp_new_balance,
            sigma_proof
        );

        assert!(confidential_asset::is_normalized(bob_addr, token));
        assert!(confidential_asset::verify_actual_balance(bob_addr, token, &bob_dk, bob_amount));

        // A rollover can be performed once the balance is normalized.
        // Note that functions like `withdraw` and `confidential_transfer` do not require the actual balance
        // to be normalized beforehand, as zk-proofs guarantee that the actual balance is normalized after
        // their execution.
        confidential_asset::rollover_pending_balance(bob, token);
    }
}
```

## Useful Resources

- [Confidential Asset SDK](/build/sdks/ts-sdk/confidential-asset)

# Create Package (Move)

> Learn about create package for Move smart contract development on Aptos blockchain.

import { Aside, FileTree, Steps } from '@astrojs/starlight/components';

import { RemoteCodeblock } from '~/components/RemoteCodeblock';

<Aside type="note">
  We recommend installing the Aptos CLI before beginning.
  If you haven't already installed the Aptos CLI, see the [CLI section](/build/cli)
</Aside>

<Steps>
  1. aptos move init

     In a new project directory, initialize a Move package by running:

     ```shellscript filename="Terminal"
     aptos move init --name <PROJECT_NAME>
     ```

     You should now have a Move project that looks like so:

     <FileTree>
       - scripts/
       - sources/
       - tests/
       - Move.toml
     </FileTree>

     <Aside type="note">
       You can also create a Move package from a [template](/build/cli/start-from-template).
     </Aside>

  2. Update Move.toml

     In `Move.toml`, fill in the following key information:

     1. `name`: name of your package
     2. `version`: package version (default is `"0.0.0"`)
     3. `addresses`: Describes which address the module will be deployed to.  These are named addresses that can be used as aliases.  In the below example, we will use `hello_blockchain` as the named address.
     4. `dependencies`: You will likely want to use `AptosFramework` and other [Third Party Dependencies](/build/smart-contracts/third-party-dependencies)

     Below is an example

     ```toml filename="Move.toml"
     [package]
     name = "Examples"
     version = "0.0.0"

     [addresses]
     hello_blockchain = "_"

     [dependencies.AptosFramework]
     git = "https://github.com/aptos-labs/aptos-framework.git"
     rev = "mainnet"
     subdir = "aptos-framework"
     ```

  3. Add to sources directory

     Add your code in the `sources` directory. Here we have a `hello_blockchain.move` example.

     <RemoteCodeblock permalink="https://github.com/aptos-labs/aptos-core/blob/afd3706c17bcccfb39a9d6059aecbfa648ed295d/aptos-move/move-examples/hello_blockchain/sources/hello_blockchain.move#L1-L64" />
</Steps>

# Cryptography

> Learn about cryptography for Move smart contract development on Aptos blockchain.

import { Aside } from '@astrojs/starlight/components';

Cryptography plays an integral role in ensuring the security, integrity, confidentiality, and immutability of data in blockchain systems. The Aptos adapter for Move provides developers with an array of cryptographic primitives to cater to this need. This document delves into the cryptographic functionalities offered by Move on Aptos and elucidates the principles that drive their design.

## Cryptographic primitives

Move, through the Aptos adapter, encompasses several fundamental cryptographic tools:

1. [Cryptographic Hash Functions](#cryptographic-hash-functions) ‚Äì Algorithms that produce a fixed-size output (hash) from variable-sized input data. Supported functions include SHA2-256, SHA3-256, Keccak256, and Blake2b-256.
2. [Digital Signature Verification](#digital-signature-verification) ‚Äì Algorithms for signing a message to ensure its integrity, authenticate its sender, ensure non-repudiation, or any combination thereof. Supported signature schemes include Ed25519, ECDSA, and BLS.
3. [Elliptic Curve Arithmetic](#elliptic-curve-arithmetic) ‚Äì Elliptic curves are one of the building blocks of advanced cryptographic primitives, such as digital signatures, public-key encryption or verifiable secret sharing. Supported curves include Ristretto255, BN254 and BLS12-381.
4. [Zero-Knowledge Proofs (ZKP)](#building-powerful-cryptographic-applications) ‚Äì These cryptographic techniques enable a party to prove that a relation $R(x; w)$ is satisfied on a public statement $x$ without leaking the secret witness $w$ that makes it hold. Currently, we support Groth16 ZKP verification and Bulletproofs ZK range proof verification.

Three fundamental principles guide the design and integration of the Aptos cryptographic extensions into Move:

1. **Economic Gas Usage** ‚Äì Striving to minimize gas costs for Move developers by implementing key primitives as [Move native functions](/build/smart-contracts/book/functions#native-functions). For example, see the module for [BLS signatures over BLS12-381 elliptic curves](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-stdlib/sources/cryptography/bls12381.move).
2. **Type-Safe APIs** ‚Äì Ensuring that APIs are resistant to common mistakes, type-safety enhances code reliability and promotes an efficient development process. For an example, see the [Ed25519 signature module](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-stdlib/sources/cryptography/ed25519.move).
3. **Empowerment of Developers** ‚Äì In instances where native functions are unavailable, we empower developers to build their own cryptographic primitives on top of abstract cryptographic building blocks such as _finite fields_ and _Abelian groups_. Refer to the [`aptos_std::crypto_algebra`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-stdlib/sources/cryptography/crypto_algebra.move) module for more insights.

Continue reading to delve a bit deeper and uncover some of the intricacies behind these extensions, as well as the range of applications they empower. For the most comprehensive understanding of this subject, refer to the [cryptography Move modules code](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/framework/aptos-stdlib/sources/cryptography).

## Cryptographic hash functions

Developers can now use more cryptographic hash functions in Move via the [`aptos_std::aptos_hash`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-stdlib/sources/hash.move) module:

| Hash function | Hash size (bits) | Cost for hashing 1KiB (in internal gas units) | Collision-resistance security (bits) |
| ------------- | ---------------- | --------------------------------------------- | ------------------------------------ |
| Keccak256     | 256              | 1,001,600                                     | 128                                  |
| SHA2-256      | 256              | 1,084,000                                     | 128                                  |
| SHA2-512      | 512              | 1,293,600                                     | 256                                  |
| SHA3-256      | 256              | 1,001,600                                     | 128                                  |
| SHA3-512      | 512              | 1,114,000                                     | 256                                  |
| RIPEMD160     | 160              | 1,084,000                                     | 80 (**weak**)                        |
| Blake2b-256   | 256              | 342,200                                       | 128                                  |

All hash functions have the same security properties (e.g., one-wayness, collision resistance, etc.), but their security levels are different.

<Aside type="caution">
  RIPEMD160 should be avoided as a collision-resistant function due to its 80-bit security level. It is mainly supported for backward-compatibility reasons: e.g., Bitcoin address derivation relies on RIPEMD160.
</Aside>

Some of these functions can be used for interoperability with other chains (e.g., verifying Ethereum Merkle proofs via [`aptos_std::aptos_hash::keccak256`](https://github.com/aptos-labs/aptos-core/blob/137acee4c6dddb1c86398dce25b041d78a3028d3/aptos-move/framework/aptos-stdlib/sources/hash.move#L35)).
Others, have lower gas costs, such as [`aptos_std::aptos_hash::blake2b_256`](https://github.com/aptos-labs/aptos-core/blob/137acee4c6dddb1c86398dce25b041d78a3028d3/aptos-move/framework/aptos-stdlib/sources/hash.move#L69).
In general, a wider variety of hash functions give developers additional freedom in terms of both security and interoperability with other off-chain cryptographic systems.

## Digital signature verification

Developers can now use a _type-safe_ API for verifying many kinds of digital signatures in Move:

| Signature scheme                                                                                                                                           | Curve         | Sig. size (bytes) | PK size (bytes) | Malleability | Assumptions | Pros          | Cons                |
| ---------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------- | ----------------- | --------------- | ------------ | ----------- | ------------- | ------------------- |
| [ECDSA](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-stdlib/sources/cryptography/secp256k1.move)                          | secp256k1     | 64                | 64              | Yes          | GGM         | Wide adoption | Security proof      |
| [Ed25519](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-stdlib/sources/cryptography/ed25519.move)                          | Edwards 25519 | 64                | 32              | No           | DLA, ROM    | Fast          | Subtleties          |
| [MultiEd25519](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-stdlib/sources/cryptography/multi_ed25519.move)               | Edwards 25519 | $4 + t \cdot 64$  | $n \cdot 32$    | No           | DLA, ROM    | Easy-to-adopt | Large sig. size     |
| [MinPK BLS](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-stdlib/sources/cryptography/bls12381.move)                       | BLS12-381     | 96                | 48              | No           | CDH, ROM    | Versatile     | Slower verification |
| [MinSig BLS](https://github.com/aptos-labs/aptos-core/blob/7d4fb98c6604c67e526a96f55668e7add7aaebf6/aptos-move/move-examples/drand/sources/drand.move#L57) | BLS12-381     | 48                | 96              | No           | CDH, ROM    | Versatile     | Slower verification |

<Aside type="note">
  - CDH stands for the _"Computational Diffie-Hellman Assumption"_
  - DLA stands for the _"Discrete Log Assumption"_
  - GGM stands for the _"Generic Group Model"_
  - ROM stands for the _"Random Oracle Model"_
</Aside>

The digital signature modules above can be used to build smart contract-based wallets, secure claiming mechanisms for airdrops, or any digital-signature-based access-control mechanism for dapps.

The right choice of a signature scheme in your dapp could depend on many factors:

1. **Backwards-compatibility**
   - If your dapp's user base predominantly uses a particular signing mechanism, it would be prudent to support that mechanism for ease of transition and adoption.
     - Example: If users mainly sign using Ed25519, it becomes a logical choice.
2. **Ease-of-implementation**
   - While theoretically sound, complex protocols may be challenging to implement in practice.
     - Example: Even though $t$-out-of-$n$ threshold protocols for Ed25519 exist, their intricacy on the signer's side might push developers toward MultiEd25519 due to its more straightforward signing implementation.
3. **Efficiency**
   - Depending on the dapp's requirements, you might prioritize one aspect of efficiency over another.
     - Signature size vs. public key size: Some applications might prioritize a smaller signature footprint, while others might emphasize a compact PK.
     - Signing time vs. verification time: For certain dapps, the signing speed might be more crucial, while for others, rapid signature verification could be the priority.
4. **Security analysis**
   - It is essential to consider the underlying assumptions and potential vulnerabilities of a signature scheme.
     - Example: ECDSA's security is proven under strong assumptions such as the Generic Group Model (GGM).
     - Malleability concerns: Some signature schemes are susceptible to malleability, where a valid signature, $\sigma$, can be mauled into a different yet still valid signature, $\sigma$, for the same message $m$.
5. **Versatility**
   - The adaptability and flexibility of signature schemes are important to consider, so you may properly accommodate the cryptographic needs of your dapp.
     - Example: $t$-out-of-$n$ threshold BLS signatures are very simple to implement.

<Aside type="caution">
  Despite its careful, principled design[^ed25519], Ed25519 has known implementation subtleties. For example, different implementations could easily disagree on the validity of signatures, especially when batch verification is employed[^devalence]$^,$[^eddsa].
</Aside>

<Aside type="note">
  Our [`aptos_std::bls12381`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-stdlib/sources/cryptography/bls12381.move) module for [MinPK BLS](https://datatracker.ietf.org/doc/html/draft-irtf-cfrg-bls-signature-05#name-variants) supports verification of individual signatures, **multi**-signatures, **aggregate** signatures and **threshold** signatures.
</Aside>

## Elliptic curve arithmetic

While the [hash function](#cryptographic-hash-functions) and [digital signature](#digital-signature-verification) modules should provide enough functionality for most applications, some applications will require more powerful cryptography.
Normally, developers of such applications would have to wait until their desired cryptographic functionality is implemented efficiently as a [Move native function](/build/smart-contracts/book/functions#native-functions) in the [Aptos Move framework](/network/blockchain/move).
Instead, we expose basic building blocks that developers can use to implement their own cryptographic primitives directly in the Move language and do so **efficiently**.

Specifically, we currently expose low-level arithmetic operations on two popular elliptic curve groups and their associated finite fields:

1. Ristretto255, via [`aptos_std::ristretto255`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-stdlib/sources/cryptography/ristretto255.move)
2. BLS12-381, via [`aptos_std::crypto_algebra`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-stdlib/sources/cryptography/crypto_algebra.move)
   and the marker types in [`aptos_std::bls12381_algebra`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-stdlib/sources/cryptography/bls12381_algebra.move)
3. BN254, similarly via `aptos_std::crypto_algebra` and the marker types in [`aptos_std::bls12381_algebra`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-stdlib/sources/cryptography/bn254_algebra.move)

These modules support low-level operations such as:

- scalar multiplication of elliptic curve points
- multi-scalar multiplications (MSMs)
- pairings
- scalar addition, multiplication, inversion
- hashing to a scalar or to a point
- and many more

Examples of powerful applications that can be built on top include:

1. **Validity rollups** ‚Äì See the [`groth16` zkSNARK verifier example](#groth16-zksnark-verifier).
2. **Randomness-based games** ‚Äì See the [`drand` verifier example](#verifying-randomness-from-the-drand-beacon).
3. **Privacy-preserving applications** ‚Äì See the [`veiled_coin` example](#veiled-coins).

### Ristretto255 arithmetic

The [`aptos_std::ristretto255`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-stdlib/sources/cryptography/ristretto255.move) module provides support for elliptic curve arithmetic on the popular [Ristretto255 curve](https://ristretto.group/).
One of the main advantages of Ristretto255 is that it is a prime order group (unlike the Edwards 25519 curve), which obviates small-subgroup attacks on higher-level cryptosystems built on top of it.
Furthermore, Ristretto255 serialization is canonical and deserialization only accepts canonical encodings, which obviates malleability issues in higher-level protocols.

This module has proven useful for implementing several cryptographic primitives:

1. **Zero-knowledge $\Sigma$-protocols** ‚Äì See the [`veiled_coin` example](#veiled-coins).
2. **ElGamal** encryption ‚Äì See [`aptos_std::ristretto255_elgamal`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-stdlib/sources/cryptography/ristretto255_elgamal.move)
3. **Pedersen** commitments ‚Äì See [`aptos_std::ristretto255_pedersen`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-stdlib/sources/cryptography/ristretto255_pedersen.move)
4. **Bulletproofs** ZK range proofs[^bulletproofs] ‚Äì See [`aptos_std::ristretto255_bulletproofs`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-stdlib/sources/cryptography/ristretto255_bulletproofs.move)

Need ideas for a cryptosystem to build on top of `ristretto255`?
A popular primitive that you could easily build would be the [schnorrkel](https://github.com/w3f/schnorrkel) signature scheme, which is a hardened version of Schnorr signatures over Ristretto255 groups.

### Generic elliptic curve arithmetic

What is better than one curve? More curves!

The [`aptos_std::crypto_algebra`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-stdlib/sources/cryptography/crypto_algebra.move) provides elliptic curve arithmetic operations for **any** supported elliptic curve, including pairing-friendly curves.
As a consequence, Move developers can implement a cryptosystem generically over **any** curve that is or will be supported in the future.
Compared to fixing a particular curve in the code (e.g., by implementing against the [Ristretto255 module](#ristretto255-arithmetic)), this approach provides more flexibility and lowers development time when migrating to a different curve.

Although currently the `crypto_algebra` module only supports arithmetic over BN254 and BLS12-381 curves (via the marker types declared in [`aptos_std::bls12381_algebra`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-stdlib/sources/cryptography/bls12381_algebra.move) and in [`aptos_std::bn254_algebra`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-stdlib/sources/cryptography/bn254_algebra.move)), more curves will be supported into the future (e.g., Ristretto255, BLS12-377, BW6-761, secp256k1, secp256r1).

As an example, a Move developer can implement the popular Boneh-Lynn-Shacham (BLS) signature scheme generically over **any** curve by using [type arguments](/build/smart-contracts/book/functions#type-parameters) for the curve type in their implementation:

```rust
use std::option;
use aptos_std::crypto_algebra::{eq, pairing, one, deserialize, hash_to};

/// Example of a BLS signature verification function that works over any pairing-friendly
/// group triple `Gr1`, `Gr2`, `GrT` where signatures are in `Gr1` and PKs in `Gr2`.
/// Points are serialized using the format in `FormatG1` and `FormatG2` and the hashing
/// method is `HashMethod`.
///
/// WARNING: This example is type-unsafe and probably not a great fit for production code.
public fun bls_verify_sig<Gr1, Gr2, GrT, FormatG1, FormatG2, HashMethod>(
    dst:        vector<u8>,
    signature:  vector<u8>,
    message:    vector<u8>,
    public_key: vector<u8>): bool
{
    let sig  = option::extract(&mut deserialize<Gr1, FormatG1>(&signature));
    let pk   = option::extract(&mut deserialize<Gr2, FormatG2>(&public_key));
    let hash = hash_to<Gr1, HashMethod>(&dst, &message);

    // Checks if $e(H(m), pk) = e(sig, g_2)$, where $g_2$ generates $\mathbb{G}_2$
    eq(
        &pairing<Gr1, Gr2, GrT>(&hash, &pk),
        &pairing<Gr1, Gr2, GrT>(&sig, &one<Gr2>())
    )
}
```

Using the `bls_verify_sig` _generic_ function from above, developers can verify BLS signatures over **any** of the supported (pairing-friendly) curves.
For example, one can verify [MinSig BLS](https://datatracker.ietf.org/doc/html/draft-irtf-cfrg-bls-signature-05#name-variants) signatures over BLS12-381 curves by calling the function above with the right BLS12-381 marker types as its type arguments:

```rust
use aptos_std::bls12381_algebra::{
    G1, G2, Gt, FormatG1Compr, FormatG2Compr, HashG1XmdSha256SswuRo
};

// Aborts with code 1 if the MinSig BLS signature over the BLS12-381 curve fails to verify.
assert(
    bls_verify_sig<G1, G2, Gt, FormatG1Compr, FormatG2Compr, HashG1XmdSha256SswuRo>(
        dst, signature, message, public_key
    ),
    1
);
```

For more use cases of the `crypto_algebra` module, check out some Move examples:

1. [Verifying Groth16 zkSNARK proofs](#groth16-zksnark-verifier) over **any** curve
2. [Verifying randomness from the `drand` beacon](#verifying-randomness-from-the-drand-beacon)

## Building powerful cryptographic applications

### Veiled coins

The [`veiled_coin` example](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-experimental/sources/veiled_coin/) demonstrates how to use [the Ristretto255 modules from above](#ristretto255-arithmetic) to add a reasonable layer of confidentiality to coin balances and transactions.

Specifically, users can **veil** their balance, keeping it hidden from everyone, including validators.
Furthermore, a user can send a **veiled transaction** that hides the transaction amount from everybody, including validators.
An important caveat is that veiled transactions do **not** hide the identities of the sender or the recipient.

<Aside type="danger">
  This module is educational. It is **not** production-ready. Using it could lead to loss of funds.
</Aside>

### Groth16 zkSNARK verifier

The [`groth16` example](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/move-examples/groth16_example/sources/groth16.move) demonstrates how to verify Groth16 zkSNARK proofs[^groth16], which are the shortest, fastest-to-verify, general-purpose zero-knowledge proofs.
Importantly, as explained [above](#generic-elliptic-curve-arithmetic), this implementation is _generic_ over **any** curve, making it very easy for Move developers to use it with their favorite (supported) curves.

If you need help converting your `snarkjs` Groth16 VK, proof and public inputs to the expected format for the Move verifier above, you can use [this community tool](https://github.com/zjma/snarkjs-to-aptos).

<Aside type="note">
  This code has not been audited by a third-party organization. If using it in a production system, proceed at your own risk.
</Aside>

### Verifying randomness from the `drand` beacon

The [`drand` example](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/move-examples/drand/sources) shows how to verify public randomness from the [drand](https://drand.love) randomness beacon.
This randomness can be used in games or any other chance-based smart contract.
We give a simple example of a lottery implemented on top of `drand` randomness in [`lottery.move`](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/move-examples/drand/sources/lottery.move).

<Aside type="note">
  This code has not been audited by a third-party organization. If using it in a production system, proceed at your own risk.
</Aside>

Another application that can be built on top of `drand` is time-lock encryption[^tlock], which allows users to encrypt information such that it can only be decrypted in a future block.
We do not currently have an implementation but the reader is encouraged to write one!

[^bulletproofs]: _bulletproofs:_ **Bulletproofs: Short Proofs for Confidential Transactions and More**; by B. B√ºnz and J. Bootle and D. Boneh and A. Poelstra and P. Wuille and G. Maxwell; in 2018 IEEE Symposium on Security and Privacy

[^devalence]: _devalence:_ **It‚Äôs 255:19AM. Do you know what your validation criteria are?**, by Henry de Valence, [https://hdevalence.ca/blog/2020-10-04-its-25519am](https://hdevalence.ca/blog/2020-10-04-its-25519am)

[^ed25519]: _ed25519:_ **Ed25519: high-speed high-security signatures**, by Daniel J. Bernstein, Niels Duif, Tanja Lange, Peter Schwabe, Bo-Yin Yang, [https://ed25519.cr.yp.to/](https://ed25519.cr.yp.to/)

[^eddsa]: _eddsa:_ **Taming the Many EdDSAs**, by Konstantinos Chalkias, Fran√ßois Garillot, Valeria Nikolaenko, in SSR 2020, [https://dl.acm.org/doi/abs/10.1007/978-3-030-64357-7\_4](https://dl.acm.org/doi/abs/10.1007/978-3-030-64357-7_4)

[^groth16]: _groth16:_ **On the Size of Pairing-Based Non-interactive Arguments**; by Groth, Jens; in EUROCRYPT 2016

[^tlock]: _tlock:_ **tlock: Practical Timelock Encryption from Threshold BLS**; by Nicolas Gailly and Kelsey Melissaris and Yolan Romailler; [https://eprint.iacr.org/2023/189](https://eprint.iacr.org/2023/189)

# Debugging Move

> Learn about debugging for Move smart contract development on Aptos blockchain.

Move was designed to be simple and safe, but like with all programming languages,
bugs can still occur. This guide will help you debug your Move code and figure out
what went wrong.

Please feel free to contribute with additional tooling and information that can
help others in the community.

## Debugging with the Aptos CLI

### Simulation on transaction submission

You can use the Aptos CLI to simulate entry functions prior to executing them.

Normally, a transaction will fail in simulation if it won't work on-chain. For example:

```shellscript name="Terminal"
aptos move run --function-id 0x1::aptos_account::transfer --args address:0x1 u64:1000000000000000000
{
  "Error": "Simulation failed with status: Move abort in 0x1::coin: EINSUFFICIENT_BALANCE(0x10006): Not enough coins to complete transaction"
}
```

The same applies to Move scripts as well. For example:

```shellscript name="Terminal"
 aptos move run-script --script-path <script_path> ...
```

### Local Simulation

Additionally, for some situations, local simulation, may give additional information and
[print out any debug statements you have in your code](/build/cli/working-with-move-contracts#printing-debugging-information).

```shellscript name="Terminal"
aptos move run --function-id 0x1::aptos_account::transferred --args address:0x1 u64:1000000000000000000 --local

Simulating transaction locally...
{
  "Result": {
    "transaction_hash": "0x4115316915d409ba4106632c82d4b09220035ffdbd0b86bbe29a586d03d06318",
    "gas_used": 3,
    "gas_unit_price": 100,
    "sender": "78077fe8db589e1a3407170cf8af3bd60a8c95737918c15dd6f49dcbecc7900a",
    "success": false,
    "version": 56634003,
    "vm_status": "status FUNCTION_RESOLUTION_FAILURE of type Verification with message Function 0x1::aptos_account::transferred does not exist"
  }
}
```

### Gas Profiling and Tracing

Adding the gas profile will additionally add the ability to trace how much gas is
used in computation:

```shellscript name="Terminal"
aptos move run --function-id 0x1::aptos_account::transferred --args address:0x1 u64:1000000000000000000 --profile-gas

Simulating transaction locally using the gas profiler...
Gas report saved to gas-profiling/txn-a90ca655-0x1-aptos_account-transferred.
{
  "Result": {
    "transaction_hash": "0xa90ca6550dcdd7f514f4cdcdee7dc1fbee17082fcf68f3db3e5755a93b89bcfc",
    "gas_used": 3,
    "gas_unit_price": 100,
    "sender": "78077fe8db589e1a3407170cf8af3bd60a8c95737918c15dd6f49dcbecc7900a",
    "success": false,
    "version": 56651618,
    "vm_status": "status FUNCTION_RESOLUTION_FAILURE of type Verification with message Function 0x1::aptos_account::transferred does not exist"
  }
}
```

And this will generate a gas report viewable in HTML format:

```shellscript name="Terminal"
open  gas-profiling/txn-a90ca655-0x1-aptos_account-transferred/index.html
```

## Evaluating performance

```shellscript name="Terminal"
aptos move run --function-id 0x1::aptos_account::transfer --args address:0x1 u64:1 --benchmark

Benchmarking transaction locally...
Running time (cold code cache): 22.144458ms
Running time (warm code cache): 669.5¬µs
{
  "Result": {
    "transaction_hash": "0x7cdf37ff4d798b3ac3f1e860a40428853e381598a511b9291f2a49e5ff6262a0",
    "gas_used": 11,
    "gas_unit_price": 100,
    "sender": "78077fe8db589e1a3407170cf8af3bd60a8c95737918c15dd6f49dcbecc7900a",
    "success": true,
    "version": 56679764,
    "vm_status": "status EXECUTED of type Execution"
  }
}
```

# Object Code Deployment

> Learn about deployment for Move smart contract development on Aptos blockchain.

import { Steps } from '@astrojs/starlight/components';

This document goes through how you can deploy code to [Objects](/build/smart-contracts/objects). This is the recommended way to deploy code to the blockchain, as this reduces deployment complexity,
and safely manages access control policies for the code owner. Note that in this context, code refers to [packages](/build/smart-contracts/book/packages).

Deploying code to objects will guarantee the following:

- Each deployment publishes to a new address.
- Only the **owner of the code object** can upgrade and freeze the code.

This means you can transfer the object to a new owner, and they will have full ownership of the code. You are granting them the rights to upgrade and freeze the code.
There is no need to manage seeds, or deploy to a new address on each deployment. Object code deployment greatly simplifies the deployment process.

## Instructions

Below are the instructions on how to compile, deploy and upgrade code to objects.

<Steps>
  1. Compile code

     Make sure `<named_address>` is left as a placeholder `_`. This is needed as the CLI command will override the address. `<named_address>` value represents the owner of the code, or the owner of the object to deploy the code to.
     Here is an example as `<named_address>` with the value `my_address`.

     ```toml filename="Move.toml"
     [addresses]
     my_address = "_"
     ```

     Compile your move code running the below command.

     - Replace `<named_address>` with the named address.
     - Replace `<your_address>` with the address of your account.

     ```shellscript filename="Terminal"
     aptos move compile --named-addresses <named_address>=<your_address>
     ```

  2. Deploy code to an object

     Deploy the compiled code to an object via the command:

     - Replace `<named_address>` with the named address.

     ```shellscript filename="Terminal"
     aptos move deploy-object --address-name <named_address>
     ```

     **An example can be found below:**

     ```shellscript filename="Terminal"
     aptos move deploy-object --address-name my_address
     ```

     This will ask if you want to publish the code under the specified object address.

     **Example output:**

     ```shellscript filename="Terminal"
     Do you want to publish this package at object address 0x8d6eb306bcf6c61dbaa0dbf8daa8252e121b63e95991afcab3b12d3be7f001ab [yes/no] >
     ```

     **Congrats, you have deployed your code to a new object with a unique address!**

     Take note of the object address as you will need it later for upgrades.

  3. Transfer and upgrade code in an existing package

     First, you may want to transfer the object from the deployer account to an admin account. The admin account will have rights to upgrade the code.

     Here's how you can do it via CLI, here your `deployer_account` should be the current owner of the object.

     ```shellscript
     aptos move run --function-id 0x1::object::transfer --type-args 0x1::object::ObjectCore --args address:<object_address> address:<new_owner_address> --profile <deployer_account_profile>
     ```

     Here's how you can do it via the typescript SDK:

     ```typescript
     const transaction = await aptos.transaction.build.simple({
       sender: deployerAccount.accountAddress,
       data: {
     	  function: "0x1::object::transfer",
           typeArguments: [`0x1::object::ObjectCore`],
     	  functionArguments: [object_address, new_owner_address],
       },
     });
     ```

     Now you can upgrade the code with the designated admin account, as shown below.

     If you wish to upgrade the code in the object deployed, run the following:

     - Replace `<named_address>` with the existing named address.
     - Replace `<code_object_addr>` with the address of the object hosting the code.

     Note: the value for the account name should now be the object address, as the package containing the module(s) is now deployed to that address.

     ```shellscript filename="Terminal"
     aptos move upgrade-object --address-name <named_address> --object-address <code_object_addr>
     ```

     Example of the command above:

     ```shellscript filename="Terminal"
     aptos move upgrade-object --address-name my_address --object-address 0x8d6eb306bcf6c61dbaa0dbf8daa8252e121b63e95991afcab3b12d3be7f001ab
     ```

     This will ask if you want to upgrade the existing code deployed at the object address.

     **Example output:**

     ```shellscript filename="Terminal"
     Do you want to upgrade the package 'MyPackage' at object address 0x8d6eb306bcf6c61dbaa0dbf8daa8252e121b63e95991afcab3b12d3be7f001ab [yes/no]
     ```

     **Congrats, you have upgraded your code in the existing object!**
</Steps>

# Aptos Digital Asset Standard

> Learn about digital asset for Move smart contract development on Aptos blockchain.

import { ThemedImage } from '~/components/ThemedImage';

import { GraphQLEditor } from '~/components/react/GraphQLEditor';

import { Aside } from '@astrojs/starlight/components';

The Digital Asset (DA) standard is a modern Non-Fungible Token (NFT) standard for Aptos. NFTs represent unique assets on-chain, and are stored in collections. These NFTs can be customized to later be transferred, soulbound, burned, mutated, or customized via your own smart contracts.

This standard replaces the legacy [Aptos Token Standard](/build/smart-contracts/aptos-token). The most important improvements to note are:

| **Improvement**         | **Description**                                                                                                |
| ----------------------- | -------------------------------------------------------------------------------------------------------------- |
| **Token Extension**     | Tokens can be easily extended since they are implemented using Move [Objects](/build/smart-contracts/objects). |
| **Direct NFT Transfer** | You can now directly transfer NFTs without the recipient ‚Äúopting-in‚Äù on-chain.                                 |
| **NFT Composability**   | NFTs can own other NFTs for easy composability.                                                                |

If you want a simple way to mint NFTs without the ability to customize or extend their functionality, you can use the `aptos_token` module which implements the DA standard (see the section on how to use it below).

<Aside type="note">
  Note that all Digital Asset modules are deployed at the reserved address `0x4`.
</Aside>

## Using the Digital Asset Standard

This standard is implemented with two Objects:

1. `Collection`s - A set of NFTs with a name and a bit of context for the group.
2. `Token`s - Digital assets which represent unique assets. These are often used to represent NFTs and usually use a `uri` link to point to more info about the asset (ex. a link to an image, video, etc.).

<ThemedImage
  alt="Digital Asset token and collection relationship"
  sources={{
light: '~/images/digital-asset-light.svg',
dark: '~/images/digital-asset-dark.svg',
}}
/>

All `Token`s are required to have a reference to a parent `Collection`, but the parent `Collection` does **not** own the `Token`. Newly minted `Token`s are usually owned by the creator. From there, they can be transferred to other accounts.

## Collections

| **Field**       | **Description**                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |
| --------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Description** | An optional string smaller than 2048 characters (modifiable with a `MutatorRef`).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
| **Name**        | A required string to identify the `Collection`. The name must be unique within each account. That means a single creator account cannot create more than one `Collection` with the same name.                                                                                                                                                                                                                                                                                                                                                                                                  |
| **Royalty**     | An optional [`Royalty`](/move-reference/mainnet/aptos-token-objects/royalty#Royalty) struct indicating what % of the sale price goes to the creator of the `Collection`. This can be changed with a `MutatorRef` generated by the [Royalty module](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-token-objects/sources/royalty.move). The Royalty module is an extension for the DA standard. See example usage in [`aptos_token.move`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-token-objects/sources/aptos_token.move). |
| **URI length**  | An optional string that is smaller than 512 characters which links to relevant content for the `Collection` (modifiable with a `MutatorRef`).                                                                                                                                                                                                                                                                                                                                                                                                                                                  |

### Creating a `Collection`

There are two ways to create a `Collection` depending on whether you want there to be a maximum supply of `Token`s it can hold.

#### Fixed Maximum Supply

To make a `Collection` with a fixed supply you can use `collection::create_fixed_collection` like so:

```move filename="example.move"
use aptos_token_objects::collection;
use std::option::{Self, Option};
use aptos_framework::string;

public entry fun create_collection(creator: &signer) {
    let max_supply = 1000;
    let royalty = option::none();

    // Maximum supply cannot be changed after collection creation
    collection::create_fixed_collection(
        creator,
        string::utf8(b"My Collection Description"),
        max_supply,
        string::utf8(b"My Collection"),
        royalty,
        string::utf8(b"https://mycollection.com"),
    );
}
```

#### Unlimited Supply

To create a `Collection` with unlimited supply you can use `collection::create_unlimited_collection`:

```move filename="example.move"
use std::option::{Self, Option};
use aptos_framework::string;

public entry fun create_collection(creator: &signer) {
    let royalty = option::none();

    collection::create_unlimited_collection(
        creator,
        string::utf8(b"My Collection Description"),
        string::utf8(b"My Collection"),
        royalty,
        string::utf8(b"https://mycollection.com"),
    );
}
```

<Aside type="caution">
  A `Collection`'s maximum supply cannot be changed after creation.
</Aside>

### Customizing a `Collection`

Since each `Collection` is a [Move Object](/build/smart-contracts/objects), you can customize it by generating permissions called `Ref`s. Each `Ref` allows you to modify an aspect of the Object later on. Beyond the normal [Object Refs](/build/smart-contracts/object/creating-objects), `Collection`s can also get a `MutatorRef` by calling `get_mutator_ref` like so:

```move filename="example.move"
use std::option::{Self, Option};
use aptos_framework::string;

public entry fun create_collection(creator: &signer) {
    let royalty = option::none();
    let collection_constructor_ref = &collection::create_unlimited_collection(
        creator,
        string::utf8(b"My Collection Description"),
        string::utf8(b"My Collection"),
        royalty,
        string::utf8(b"https://mycollection.com"),
    );
    let mutator_ref = collection::get_mutator_ref(collection_constructor_ref);
    // Store the mutator ref somewhere safe
}
```

<Aside type="caution">
  Refs **must** be generated at creation time of an Object. The `ConstructorRef` used to generate other `Ref`s expires as soon as the transaction to create the Object is finished.
</Aside>

You can further customize your `Collection` by adding more resources or functionalities via smart contract. For example, a `Collection` can track when it was created in order to limit when `Token`s can be minted like so:

```move filename="example.move"
use std::option::{Self, Option};
use aptos_framework::string;

struct MyCollectionMetadata has key {
    creation_timestamp_secs: u64,
}

public entry fun create_collection(creator: &signer) {
    let royalty = option::none();
    // Constructor ref is a non-storable struct returned when creating a new object.
    // It can generate an object signer to add resources to the collection object.
    let collection_constructor_ref = &collection::create_unlimited_collection(
creator,
        string::utf8(b"My Collection Description"),
        string::utf8(b"My Collection"),
        royalty,
        string::utf8(b"https://mycollection.com"),
    );
    // Constructor ref can be exchanged for signer to add resources to the collection object.
    let collection_signer = &object::generate_signer(collection_constructor_ref);
    move_to(collection_signer, MyCollectionMetadata { creation_timestamp_secs: timestamp::now_seconds() } })
}
```

## Tokens

| **Field**       | **Description**                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |
| --------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Description** | An optional string smaller than 2048 characters (modifiable with a `MutatorRef`).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
| **Name**        | A required string to identify the `Token` that is unique within each `Collection`. This means a single `Collection` account cannot have more than one `Token` with the same name.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
| **Royalty**     | An optional [`Royalty`](/move-reference/mainnet/aptos-token-objects/royalty#Royalty) struct indicating what % of the sale price goes to the creator of the `Collection`. This can be changed with a `MutatorRef` generated by the [Royalty module](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-token-objects/sources/royalty.move) (an extension for the DA standard. See example usage in [`aptos_token.move`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-token-objects/sources/aptos_token.move)). Usually royalty is set on collections, but setting it on `Token`s allows the individual `Token` to have a custom royalty amount. |
| **URI length**  | An optional string that is smaller than 512 characters which links to relevant content for the `Collection` (modifiable with a `MutatorRef`).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |

### Creating Tokens

There are a few ways to create a `Token`:

1. Named tokens. These use the name of the `Token` to generate a named Object. This makes it easy to find the address for the token if you know the token and `Collection` name, but named Objects are not deletable. Trying to delete the a named token will only delete the data, not the Object itself.

```move filename="example.move"
use aptos_token_objects::token;
use std::option::{Self, Option};

public entry fun mint_token(creator: &signer) {
    let royalty = option::none();
    token::create_named_token(
        creator,
        "Collection Name",
        "Description",
        "Token Name",
        royalty,
        "https://mycollection.com/my-named-token.jpeg",
    );
}
```

<Aside type="note">
  You can derive the address for named tokens by:

  1. Concatenating the creator address, collection name and token name.
  2. Doing a sha256 hash of that new string.
</Aside>

2. ‚ÄúUnnamed‚Äù tokens. These create unnamed _Objects_ (which **are** deletable) but still have a `Token` name. Because the Object address is not deterministic, you must use an Indexer to find the address for them.

```move filename="example.move"
use aptos_token_objects::token;
use std::option::{Self, Option};
use aptos_framework::string;

public entry fun mint_token(creator: &signer) {
    let royalty = option::none();
    token::create(
        creator,
        string::utf8(b"Collection Name"),
        string::utf8(b"Description"),
        string::utf8(b"Token Name"),
        royalty,
        string::utf8(b"https://mycollection.com/my-named-token.jpeg"),
    );
}
```

### Finding Unnamed Token Addresses via Indexer

You can find the addresses of your recently created ‚Äúunnamed‚Äù `Token`s by using the [Aptos Indexer](/build/indexer/indexer-api) with queries like the following:

1. Looking up the collection id by using your account address and the name of the `Collection`.

<GraphQLEditor
  query={`query GetCollectionIdByName(
  $creatorAddress: String!
  $collectionName: String!
) {
  current_collections_v2(
    where: {
      creator_address: { _eq: $creatorAddress }
      collection_name: { _eq: $collectionName }
    }
  ) {
    collection_name
    collection_id
  }
}`}
  variables={`{
  "creatorAddress": "0x8726af08ea897c35c8137601ce1789992dacdd0eb0b724531a4e7dea035d950f",
  "collectionName": "Horse Emojis"
}`}
/>

2. Then look up the address (`token_data_id`) of the `Token` by using the `collection_id` (from above) and the name of the token:

<GraphQLEditor
  query={`query GetTokenID($collection_id: String!, $token_name: String!) {
  current_token_datas_v2(
    where: {
      collection_id: { _eq: $collection_id }
      token_name: { _eq: $token_name }
    }
  ) {
    token_name
    description
    token_data_id
  }
}`}
  variables={`{
  "collection_id": "0x158dc6481aec80004d0f21a8994757e3c8203fc37b0f508be2a5364ad99e649e",
  "token_name": "Horse Emojis #127"
}`}
/>

<Aside type="note">
  In general, using unnamed tokens give you the most flexibility because the Object can be deleted later, but named tokens simplify looking up addresses.
</Aside>

### Using Tokens

#### Transfer Tokens

Transferring a `Token` can be done by calling [`object::transfer`](/move-reference/mainnet/aptos-framework/object#transfer).

```move filename="example.move"
public entry fun transfer<T: key>(owner: &signer, object: object::Object<T>, to: address)
```

#### Burning Tokens

Burning / deleting a `Token` requires storing a `BurnRef` with `token::generate_burn_ref`, then calling `token::burn`.

```move filename="example.move"
module 0x42::example {
  use std::option;
  use aptos_token_objects::token::{Self, BurnRef, Token};
  use std::string::utf8;
  use aptos_framework::object::{Self, Object};

  struct CustomData has key, drop {
    burn_ref: BurnRef,
  }

  public entry fun mint_token(creator: &signer) {
    let token_constructor_ref = &token::create(
      creator,
      utf8(b"My Collection"),
      utf8(b"My named Token description"),
      utf8(b"My named token"),
      option::none(),
      utf8(b"https://mycollection.com/my-named-token.jpeg"),
    );

    let token_signer = &object::generate_signer(token_constructor_ref);

    let burn_ref = token::generate_burn_ref(token_constructor_ref);

    // Store the burn ref somewhere safe
    move_to(token_signer, CustomData {
      burn_ref,
    });
  }

  public entry fun burn_token(token: Object<Token>) acquires CustomData {
    let token_address = object::object_address(&token);
    // Remove all custom data from the token object.
    // Retrieve the burn ref from storage
    let CustomData { burn_ref } = move_from<CustomData>(token_address);
    // Burn the token
    token::burn(burn_ref);
  }
}
```

<Aside type="caution">
  If any custom resources were moved onto the Token, those must be removed / deleted first before`token::burn` can delete the Token. For named tokens which cannot be deleted, `token::burn` will For named Tokens `token::burn` will remove all Token content instead.
</Aside>

#### Modifying Tokens After Creation

Mutating a `Token`‚Äôs `URI` or `description` requires a `MutatorRef` (which must be generated when creating the `Token`, then stored for later).

```move filename="example.move"
module 0x42::example {
  use std::option;
  use aptos_token_objects::token::{Self, MutatorRef, Token};
  use std::string::utf8;
  use aptos_framework::object::{Self, Object};

  struct CustomData has key, drop {
    mutator_ref: MutatorRef,
  }

  public entry fun mint_token(creator: &signer) {
    // Constructor ref is a non-storable struct returned when creating a new object.
    // It can be exchanged for signer to add resources to the token object.
    let token_constructor_ref = &token::create(
      creator,
      utf8(b"My Collection"),
      utf8(b"My named Token description"),
      utf8(b"My named Token"),
      option::none(),
      utf8(b"https://mycollection.com/my-named-token.jpeg"),
    );

    let token_signer = &object::generate_signer(token_constructor_ref);

    let mutator_ref = token::generate_mutator_ref(token_constructor_ref);

    // Store the mutator ref somewhere safe
    move_to(token_signer, CustomData {
      mutator_ref,
    });
  }

  public entry fun mutate_token(token: Object<Token>) acquires CustomData {
    let token_address = object::object_address(&token);
    // Retrieve the mutator ref from storage
    let CustomData { mutator_ref } = move_from<CustomData>(token_address);
    // Change token description
    token::set_description(&mutator_ref, utf8(b"This is my named Token description"));
  }
}
```

<Aside type="caution">
  Changing the royalty requires generating a _separate_ `MutatorRef` from the [Royalty module](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-token-objects/sources/royalty.move).
</Aside>

#### Extending Tokens

`Token`s can be extended either by adding additional resources (since they are an Object) or using `Ref`s to modify the Object.

## Aptos Token

For NFT creators who want to avoid writing their own logic for how your NFT should work, you can use the [`aptos_token`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-token-objects/sources/aptos_token.move) module to mint an NFT. This module is already deployed at `0x4` and allows you to:

1. Mint a `Token` you can transfer with royalties.
2. Mint a soulbound `Token`.
3. Manage the resources your NFT has.

See the `aptos_token` [reference docs](/move-reference/mainnet/aptos-token-objects/aptos_token) for all the helper functions you can use.

<Aside type="caution">
  The main drawback of using the `aptos_token` module is that the Tokens are not extensible (the `mint` function does not return a `ConstructorRef`).
</Aside>

### Minting with `aptos_token`

Minting a `Token` using `aptos_token` requires the same parameters as any token that implements the DA standard. In addition though, the `aptos_token` module allows you to specify a property map of key/value pairs for any other properties your specific NFT may require.

You can mint your `Token` by calling `aptos_token::mint` like so:

```move filename="example.move"
public entry fun mint(
    creator: &signer,
    collection: String,
    description: String,
    name: String,
    uri: String,
    property_keys: vector<String>,
    property_types: vector<String>,
    property_values: vector<vector<u8>>,
) acquires AptosCollection, AptosToken
```

#### Soulbound Tokens

To mint a soul bound `Token`, you can call [`aptos_token::mint_soul_bound`](/move-reference/mainnet/aptos-token-objects/aptos_token#mint_soul_bound) instead:

```move filename="example.move"
public entry fun mint_soul_bound(
    creator: &signer,
    collection: String,
    description: String,
    name: String,
    uri: String,
    property_keys: vector<String>,
    property_types: vector<String>,
    property_values: vector<vector<u8>>,
    soul_bound_to: address,
) acquires AptosCollection
```

<Aside type="caution">
  In the near future, a new module `TokenMinter` will be released to replace `aptos_token`. You can follow the status of that proposal [here](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-72.md).
</Aside>

## Examples and Useful Links

- [Digital Asset Examples](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/move-examples/token_objects)
- [Digital Asset Marketplace Example](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/move-examples/marketplace)
- [Source code](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-token-objects/sources/token.move)
- [`aptos_token` source code](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-token-objects/sources/aptos_token.move)

# Aptos Error Codes

> Learn about error codes for Move smart contract development on Aptos blockchain.

This page catalogs common errors encountered in the Aptos blockchain and
explains how to resolve them wherever possible. As with all software, the code
itself is the source of truth for error handling and will always contain entries
not found here. Instead, this matrix aims to help you address those errors most
typically found, misunderstood, or both.

For the sources of these errors, see:

- [vm\_status.rs](https://github.com/aptos-labs/aptos-core/blob/main/third_party/move/move-core/types/src/vm_status.rs)
- [error.move](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/move-stdlib/sources/error.move)
- [account.move](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/account/account.move)
- [coin.move](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/coin.move)
- [token.move](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-token/sources/token.move)
- [token\_transfers.move](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-token/sources/token_transfers.move)

Help us update this list by sending pull requests containing the errors you
encounter. If you don't know how to resolve the error, as described int the
_Action_ column, simply leave it blank.

## Frequent Errors

### INSUFFICIENT\_BALANCE\_FOR\_TRANSACTION\_FEE

This means that the highest possible gas used for the transaction is greater than
the balance of APT in the transaction sender's (or fee payer's) account.  To resolve,
please submit with a lower max gas amount, and try again.

For example, if the max gas amount is 1000 gas units, and the gas unit price is `100` octas, the total
APT required in the account would be `0.00100000` APT (`1000 * 100 / 100000000`).  The default is often `200000` gas units which
would end up requiring `0.20000000` APT.  If you are having issues with this, please
reach out to your wallet provider.

### OUT\_OF\_GAS

This means that the transaction used more gas than the sender specified as the max
gas amount for the transaction, and aborted as a result.  To resolve, please
try to increase the max gas amount, and submit the transaction again.

### SEQUENCE\_NUMBER\_TOO\_OLD

This means that the transaction's sequence number in the sender's account has already
been used and committed to the blockchain.  In order to submit a new transaction
to the blockchain, please try and submit it again with a new sequence number.

### SEQUENCE\_NUMBER\_TOO\_NEW

This only occurs in simulation, but means that the sequence number being submitted
is greater than the next sequence number for the account.  Please reduce the
sequence number and try again.

## Move Virtual Machine (VM)

{/* TODO improve formatting on table */}

| Error                                                           |                                                                                                                                                                                                                                                                            Meaning                                                                                                                                                                                                                                                                            | Possible Resolution                                                                                                                                   |
| --------------------------------------------------------------- | :-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: | ----------------------------------------------------------------------------------------------------------------------------------------------------- |
| LOOKUP\_FAILED                                                  |                                                                                                                                                                                                                                            A function that is being called isn't present on the network being used                                                                                                                                                                                                                                            | Check that your dependencies on-chain have the same version                                                                                           |
| UNKNOWN\_VALIDATION\_STATUS                                     |                                                                                                                                                                                                                                                          We don't want the default value to be valid.                                                                                                                                                                                                                                                         | N/A                                                                                                                                                   |
| INVALID\_SIGNATURE                                              |                                                                                                                                                                                                                                                              The transaction has a bad signature.                                                                                                                                                                                                                                                             | Submit a new transaction with a new signature                                                                                                         |
| INVALID\_AUTH\_KEY                                              |                                                                                                                                                                                                                                                                Bad account authentication key.                                                                                                                                                                                                                                                                | Submit a new transaction with a new signature, check that the account matches the authentication key and hasn't been rotated                          |
| SEQUENCE\_NUMBER\_TOO\_OLD                                      |                                                                                                                                                                                                                                                                  Sequence number is too old.                                                                                                                                                                                                                                                                  | Submit a new transaction with a newer sequence number from the account                                                                                |
| SEQUENCE\_NUMBER\_TOO\_NEW                                      |                                                                                                                                                                                                                                                                  Sequence number is too new.                                                                                                                                                                                                                                                                  | Submit a new transaction with a new signature                                                                                                         |
| INSUFFICIENT\_BALANCE\_FOR\_TRANSACTION\_FEE                    |                                                                                                                                                                                                       Insufficient balance to pay for max\_gas specified in the transaction. Balance needs to be above max\_gas\_amount \* gas\_unit\_price to proceed.                                                                                                                                                                                                       | Fund the account with more APT to pay for the gas fee                                                                                                 |
| TRANSACTION\_EXPIRED                                            |                                                                                                                                                                                                                                                                  The transaction has expired.                                                                                                                                                                                                                                                                 | Submit a new transaction with an expiration time further in the future                                                                                |
| SENDING\_ACCOUNT\_DOES\_NOT\_EXIST                              |                                                                                                                                                                                                                                                              The sending account does not exist.                                                                                                                                                                                                                                                              | Create the account prior to sending the transaction again                                                                                             |
| REJECTED\_WRITE\_SET                                            |                                                                                                                                                                                                                                   This write set transaction was rejected because it did not meet the requirements for one.                                                                                                                                                                                                                                   | N/A                                                                                                                                                   |
| INVALID\_WRITE\_SET                                             |                                                                                                                                                                                                                                               This write set transaction cannot be applied to the current state.                                                                                                                                                                                                                                              | N/A                                                                                                                                                   |
| EXCEEDED\_MAX\_TRANSACTION\_SIZE                                |                                                                                                                                                                                                                                                Length of program field in raw transaction exceeded max length.                                                                                                                                                                                                                                                | The transaction is too large for a single transaction; if this is a package publish, try to break it into multiple packages                           |
| UNKNOWN\_SCRIPT                                                 |                                                                                                                                                                                                                                                        This script is not in our allowlist of scripts.                                                                                                                                                                                                                                                        | N/A                                                                                                                                                   |
| UNKNOWN\_MODULE                                                 |                                                                                                                                                                                                                                                         Transaction is trying to publish a new module.                                                                                                                                                                                                                                                        | N/A                                                                                                                                                   |
| MAX\_GAS\_UNITS\_EXCEEDS\_MAX\_GAS\_UNITS\_BOUND                |                                                                                                                                                                                                                                          Max gas units submitted with transaction exceeds max gas units bound in VM.                                                                                                                                                                                                                                          | Decrease the max gas amount in the transaction below the maximum value in the gas schedule                                                            |
| MAX\_GAS\_UNITS\_BELOW\_MIN\_TRANSACTION\_GAS\_UNITS            |                                                                                                                                                                                                                              Max gas units submitted with transaction not enough to cover the intrinsic cost of the transaction.                                                                                                                                                                                                                              | Increase the max gas amount above the minimum value in the gas schedule                                                                               |
| GAS\_UNIT\_PRICE\_BELOW\_MIN\_BOUND                             |                                                                                                                                                                                                                                      Gas unit price submitted with transaction is below minimum gas price set in the VM.                                                                                                                                                                                                                                      | Increase the gas unit price below the minimum gas unit price in the gas schedule                                                                      |
| GAS\_UNIT\_PRICE\_ABOVE\_MAX\_BOUND                             |                                                                                                                                                                                                                                  Gas unit price submitted with the transaction is above the maximum gas price set in the VM.                                                                                                                                                                                                                                  | Decrease the gas unit price below the maximum gas unit price in the gas schedule                                                                      |
| INVALID\_GAS\_SPECIFIER                                         |                                                                                                                                                                                                                     Gas specifier submitted is either malformed (not a valid identifier), or does not refer to an accepted gas specifier.                                                                                                                                                                                                                     | N/A                                                                                                                                                   |
| SENDING\_ACCOUNT\_FROZEN                                        |                                                                                                                                                                                                                                                                 The sending account is frozen.                                                                                                                                                                                                                                                                | N/A                                                                                                                                                   |
| UNABLE\_TO\_DESERIALIZE\_ACCOUNT                                |                                                                                                                                                                                                                                                            Unable to deserialize the account blob.                                                                                                                                                                                                                                                            | N/A                                                                                                                                                   |
| CURRENCY\_INFO\_DOES\_NOT\_EXIST                                |                                                                                                                                                                                                                                                           The currency info was unable to be found.                                                                                                                                                                                                                                                           | N/A                                                                                                                                                   |
| INVALID\_MODULE\_PUBLISHER                                      |                                                                                                                                                                                                                                                The account sender doesn't have permissions to publish modules.                                                                                                                                                                                                                                                | N/A                                                                                                                                                   |
| NO\_ACCOUNT\_ROLE                                               |                                                                                                                                                                                                                                                                The sending account has no role.                                                                                                                                                                                                                                                               | N/A                                                                                                                                                   |
| BAD\_CHAIN\_ID                                                  |                                                                                                                                                                                                                                             The transaction's chain\_id does not match the one published on-chain.                                                                                                                                                                                                                                            | Verify that your chain ID matches the chain ID for your network                                                                                       |
| SEQUENCE\_NUMBER\_TOO\_BIG                                      |                                                                                                                                                                                                                                     The sequence number is too large and would overflow if the transaction were executed.                                                                                                                                                                                                                                     | N/A                                                                                                                                                   |
| BAD\_TRANSACTION\_FEE\_CURRENCY                                 |                                                                                                                                                                                                                                                The gas currency is not registered as a TransactionFee currency.                                                                                                                                                                                                                                               | N/A                                                                                                                                                   |
| FEATURE\_UNDER\_GATING                                          |                                                                                                                                                                                                                                    The feature requested is intended for a future Aptos version instead of the current one.                                                                                                                                                                                                                                   | N/A                                                                                                                                                   |
| SECONDARY\_KEYS\_ADDRESSES\_COUNT\_MISMATCH                     |                                                                                                                                                                                                                            The number of secondary signer addresses is different from the number of secondary public keys provided.                                                                                                                                                                                                                           | Verify the multi-agent or multi-ed25519 secondary signer addresses match the secondary public keys                                                    |
| SIGNERS\_CONTAIN\_DUPLICATES                                    |                                                                                                                                                                                                                                    There are duplicates among signers, including the sender and all the secondary signers.                                                                                                                                                                                                                                    | Remove any duplicate signers                                                                                                                          |
| SEQUENCE\_NONCE\_INVALID                                        |                                                                                                                                                                                                                                     The sequence nonce in the transaction is invalid (too new, too old, or already used).                                                                                                                                                                                                                                     | N/A                                                                                                                                                   |
| CHAIN\_ACCOUNT\_INFO\_DOES\_NOT\_EXIST                          |                                                                                                                                                                                                                                             There was an error when accessing chain-specific account information.                                                                                                                                                                                                                                             | N/A                                                                                                                                                   |
| MODULE\_ADDRESS\_DOES\_NOT\_MATCH\_SENDER                       |                                                                                                                                                                                                                                         the module publisher is not the account that will eventually hold the module.                                                                                                                                                                                                                                         | Confirm the module address in the move contract matches the sender of the transaction                                                                 |
| ZERO\_SIZED\_STRUCT                                             |                                                                                                                                                                                                                                                            Reported when a struct has zero fields.                                                                                                                                                                                                                                                            | N/A                                                                                                                                                   |
| DUPLICATE\_MODULE\_NAME                                         |                                                                                                                                                                                                                                       The sender is trying to publish two modules with the same name in one transaction.                                                                                                                                                                                                                                      | Confirm every module has a unique name                                                                                                                |
| BACKWARD\_INCOMPATIBLE\_MODULE\_UPDATE                          |                                                                                                                                                                                                                                         The sender is trying to publish a module that breaks the compatibility checks.                                                                                                                                                                                                                                        | Confirm your new modules being published don't break backwards compatibility                                                                          |
| CYCLIC\_MODULE\_DEPENDENCY                                      |                                                                                                                                                                                                                                     The updated module introduces a cyclic dependency (i.e., A uses B and B also uses A).                                                                                                                                                                                                                                     | Check for loops in your module dependencies in the modules being published                                                                            |
| INVALID\_FRIEND\_DECL\_WITH\_SELF                               |                                                                                                                                                                                                                                                           Cannot mark the module itself as a friend.                                                                                                                                                                                                                                                          | Confirm no module has itself marked as a friend in the modules being published                                                                        |
| INVALID\_FRIEND\_DECL\_WITH\_MODULES\_OUTSIDE\_ACCOUNT\_ADDRESS |                                                                                                                                                                                                                                                 Cannot declare modules outside of account address as friends.                                                                                                                                                                                                                                                 | Confirm all friends are in the same account address in the modules being published                                                                    |
| INVALID\_FRIEND\_DECL\_WITH\_MODULES\_IN\_DEPENDENCIES          |                                                                                                                                                                                                                                                 Cannot declare modules that this module depends on as friends.                                                                                                                                                                                                                                                | Check friend declarations of the modules being published                                                                                              |
| CYCLIC\_MODULE\_FRIENDSHIP                                      |                                                                                                                                                                                                                                  The updated module introduces a cyclic friendship (i.e., A friends B and B also friends A).                                                                                                                                                                                                                                  | Check friend declarations of the modules being published                                                                                              |
| INVALID\_PHANTOM\_TYPE\_PARAM\_POSITION                         |                                                                                                                                                                                                                                                  A phantom type parameter was used in a non-phantom position.                                                                                                                                                                                                                                                 | Confirm phantom types are used only with generics                                                                                                     |
| LOOP\_MAX\_DEPTH\_REACHED                                       |                                                                                                                                                                                                                                                                  Loops are too deeply nested.                                                                                                                                                                                                                                                                 | Check for many nested loops                                                                                                                           |
| TYPE\_RESOLUTION\_FAILURE                                       |                                                                                                                                                                                                                                             Failed to resolve type due to linking being broken after verification.                                                                                                                                                                                                                                            | N/A                                                                                                                                                   |
| RESOURCE\_DOES\_NOT\_EXIST                                      |                                                                                                                                                                                                                                              We tried to access a resource that does not exist under the account.                                                                                                                                                                                                                                             | Check the contract and possibly change it to handle resources that don't exist                                                                        |
| RESOURCE\_ALREADY\_EXISTS                                       |                                                                                                                                                                                                                                       We tried to create a resource under an account where that resource already exists.                                                                                                                                                                                                                                      | Check the contract and possibly change it to handle resources that already exist                                                                      |
| UNKNOWN\_STATUS                                                 |                                                                                                                                                                                                         A reserved status to represent an unknown vm status. This is std::u64::MAX, but we can't pattern match on that, so put the hardcoded value in.                                                                                                                                                                                                        | N/A                                                                                                                                                   |
| LINKER\_ERROR                                                   |                                                                                                                            This may be due to the function has not been published on chain or by trying to call an invalid function as the result of either an incorrect account address, module name, or function name. This might not happen locally if the sources are available locally but have yet to be published on-chain.                                                                                                                            | There are many reasons, but you should check your account addresses, module names, and function names to determine that they're correct and published |
| FAILED\_TO\_DESERIALIZE\_ARGUMENT                               | This error in deserializing argument is triggered by one of the following validation checks. 1) It exceeds the limit on the number of nested or unpacked structs (including in a vector). The maximum overall args equals to depth \* number of args. The max depth is currently 10. 2) The nested struct exceeds the aforementioned max depth. 3) The serialized arguments to constructor contained extra data. 4) It was derializing utf8 but struct\_constructors are disabled. 5) The string argument is too long. 6) BCS deserialization fails for utf8. | N/A                                                                                                                                                   |

## Move Standard Library (stdlib)

| Error               |                                             Meaning                                             |
| ------------------- | :---------------------------------------------------------------------------------------------: |
| INVALID\_ARGUMENT   |                        Caller specified an invalid argument (HTTP: 400).                        |
| OUT\_OF\_RANGE      |                 An input or result of a computation is out of range (HTTP: 400).                |
| INVALID\_STATE      |          The system is not in a state where the operation can be performed (HTTP: 400).         |
| UNAUTHENTICATED     | Request not authenticated due to missing, invalid, or expired authentication token (HTTP: 401). |
| PERMISSION\_DENIED  |                   The client does not have sufficient permission (HTTP: 403).                   |
| NOT\_FOUND          |                          A specified resource is not found (HTTP: 404).                         |
| ABORTED             |              Concurrency conflict, such as read-modify-write conflict (HTTP: 409).              |
| ALREADY\_EXISTS     |              The resource that a client tried to create already exists (HTTP: 409).             |
| RESOURCE\_EXHAUSTED |                         Out of gas or other forms of quota (HTTP: 429).                         |
| CANCELLED           |                           Request cancelled by the client (HTTP: 499).                          |
| INTERNAL            |                                   Internal error (HTTP: 500).                                   |
| NOT\_IMPLEMENTED    |                               Feature not implemented (HTTP: 501).                              |
| UNAVAILABLE         | The service is currently unavailable. Indicates that a retry could solve the issue (HTTP: 503). |

## Aptos accounts

| Error                                    |                                                                Meaning                                                                | Possible Resolution                                                              |
| ---------------------------------------- | :-----------------------------------------------------------------------------------------------------------------------------------: | -------------------------------------------------------------------------------- |
| EACCOUNT\_ALREADY\_EXISTS                |                                                        Account already exists.                                                        | N/A                                                                              |
| EACCOUNT\_DOES\_NOT\_EXIST               |                                                        Account does not exist.                                                        | Create the account first                                                         |
| ESEQUENCE\_NUMBER\_TOO\_BIG              |                                          Sequence number exceeds the maximum value for a u64.                                         | Provide a smaller sequence number                                                |
| EMALFORMED\_AUTHENTICATION\_KEY          |                                         The provided authentication key has an invalid length.                                        | Check your authentication key; it should be a 32-byte vector                     |
| ECANNOT\_RESERVED\_ADDRESS               |                                           Cannot create account because address is reserved.                                          | N/A                                                                              |
| EOUT\_OF\_GAS                            |                                              Transaction exceeded its allocated max gas.                                              | Increase the max gas amount                                                      |
| EWRONG\_CURRENT\_PUBLIC\_KEY             |                                              Specified current public key is not correct.                                             | Confirm the public key matches the account                                       |
| EINVALID\_PROOF\_OF\_KNOWLEDGE           |                          Specified proof of knowledge required to prove ownership of a public key is invalid.                         | Check your proof of knowledge in key rotation to ensure it has proper signatures |
| ENO\_CAPABILITY                          |                          The caller does not have a digital-signature-based capability to call this function.                         | Confirm you have the capability for the called functions                         |
| EINVALID\_ACCEPT\_ROTATION\_CAPABILITY   |                           The caller does not have a valid rotation capability offer from the other account.                          | Confirm the account being rotated is correct                                     |
| ENO\_VALID\_FRAMEWORK\_RESERVED\_ADDRESS |                                 Address to create is not a valid reserved address for Aptos framework.                                | N/A                                                                              |
| EINVALID\_SCHEME                         | Specified scheme required to proceed with the smart contract operation - can only be ED25519\_SCHEME(0) OR MULTI\_ED25519\_SCHEME(1). | Confirm the transaction was signed correctly when creating the account           |
| EINVALID\_ORIGINATING\_ADDRESS           |             Abort the transaction if the expected originating address is different from the originating address on-chain.             | Confirm you are rotating the correct account's key                               |
| ENO\_SUCH\_SIGNER\_CAPABILITY            |                                       The signer capability doesn't exist at the given address.                                       | Confirm the address is correct                                                   |

## Aptos coins

| Error                                  |                                                 Meaning                                                | Possible Resolution                                                       |
| -------------------------------------- | :----------------------------------------------------------------------------------------------------: | ------------------------------------------------------------------------- |
| ECOIN\_INFO\_ADDRESS\_MISMATCH         | Address of account which is used to initialize a coin `CoinType` doesn't match the deployer of module. | Create the coin using a `CoinType` in the same account creating the coin. |
| ECOIN\_INFO\_ALREADY\_PUBLISHED        |                              `CoinType` is already initialized as a coin.                              | N/A                                                                       |
| ECOIN\_INFO\_NOT\_PUBLISHED            |                              `CoinType` hasn't been initialized as a coin.                             | Create the coin with `CoinType` first before using it                     |
| ECOIN\_STORE\_ALREADY\_PUBLISHED       |                       Account already has `CoinStore` registered for `CoinType`.                       | N/A                                                                       |
| ECOIN\_STORE\_NOT\_PUBLISHED           |                          Account hasn't registered `CoinStore` for `CoinType`.                         | Register the account for the `CoinType`                                   |
| EINSUFFICIENT\_BALANCE                 |                                Not enough coins to complete transaction.                               | Transfer less coins, or acquire more coins prior to the transfer          |
| EDESTRUCTION\_OF\_NONZERO\_TOKEN       |                                     Cannot destroy non-zero coins.                                     | N/A                                                                       |
| EZERO\_COIN\_AMOUNT                    |                                       Coin amount cannot be zero.                                      | Don't burn coins or conduct other actions with zero coins                 |
| EFROZEN                                |                      CoinStore is frozen. Coins cannot be deposited or withdrawn.                      | Account is frozen for this token; talk to the coin owner                  |
| ECOIN\_SUPPLY\_UPGRADE\_NOT\_SUPPORTED |                  Cannot upgrade the total supply of coins to different implementation.                 | N/A                                                                       |
| ECOIN\_NAME\_TOO\_LONG                 |                                      Name of the coin is too long.                                     | Coin name must be less than or equal to 32 characters                     |
| ECOIN\_SYMBOL\_TOO\_LONG               |                                     Symbol of the coin is too long.                                    | Coin symbol must be less than or equal to 10 characters                   |

## Aptos tokens

| Error                                              |                             Meaning                            |
| -------------------------------------------------- | :------------------------------------------------------------: |
| EALREADY\_HAS\_BALANCE                             |        The token has balance and cannot be initialized.        |
| ECOLLECTIONS\_NOT\_PUBLISHED                       |         There isn't any collection under this account.         |
| ECOLLECTION\_NOT\_PUBLISHED                        |          Cannot find collection in creator's account.          |
| ECOLLECTION\_ALREADY\_EXISTS                       |                 The collection already exists.                 |
| ECREATE\_WOULD\_EXCEED\_COLLECTION\_MAXIMUM        |     Exceeds the collection's maximal number of token\_data.    |
| EINSUFFICIENT\_BALANCE                             |                   Insufficient token balance.                  |
| EINVALID\_TOKEN\_MERGE                             |      Cannot merge the two tokens with different token IDs.     |
| EMINT\_WOULD\_EXCEED\_TOKEN\_MAXIMUM               |             Exceed the token data maximal allowed.             |
| ENO\_BURN\_CAPABILITY                              |                       No burn capability.                      |
| ETOKEN\_DATA\_ALREADY\_EXISTS                      |                    TokenData already exists.                   |
| ETOKEN\_DATA\_NOT\_PUBLISHED                       |                    TokenData not published.                    |
| ETOKEN\_STORE\_NOT\_PUBLISHED                      |                    TokenStore doesn't exist.                   |
| ETOKEN\_SPLIT\_AMOUNT\_LARGER\_THAN\_TOKEN\_AMOUNT |     Cannot split token to an amount larger than its amount.    |
| EFIELD\_NOT\_MUTABLE                               |                    The field is not mutable.                   |
| ENO\_MUTATE\_CAPABILITY                            |                    Not authorized to mutate.                   |
| ENO\_TOKEN\_IN\_TOKEN\_STORE                       |                  Token not in the token store.                 |
| EUSER\_NOT\_OPT\_IN\_DIRECT\_TRANSFER              |               User didn't opt-in direct transfer.              |
| EWITHDRAW\_ZERO                                    |                    Cannot withdraw 0 token.                    |
| ENFT\_NOT\_SPLITABLE                               |          Cannot split a token that only has 1 amount.          |
| ENO\_MINT\_CAPABILITY                              |                       No mint capability                       |
| ECOLLECTION\_NAME\_TOO\_LONG                       |                The collection name is too long.                |
| ENFT\_NAME\_TOO\_LONG                              |                    The NFT name is too long.                   |
| EURI\_TOO\_LONG                                    |                      The URI is too long.                      |
| ENO\_DEPOSIT\_TOKEN\_WITH\_ZERO\_AMOUNT            |              Cannot deposit a token with 0 amount.             |
| ENO\_BURN\_TOKEN\_WITH\_ZERO\_AMOUNT               |                      Cannot burn 0 token.                      |
| EWITHDRAW\_PROOF\_EXPIRES                          |                     Withdraw proof expires.                    |
| EOWNER\_CANNOT\_BURN\_TOKEN                        |                 Token is not burnable by owner.                |
| ECREATOR\_CANNOT\_BURN\_TOKEN                      |                Token is not burnable by creator.               |
| ECANNOT\_UPDATE\_RESERVED\_PROPERTY                | Reserved fields for token contract. Cannot be updated by user. |
| EURI\_TOO\_SHORT                                   |                         URI too short.                         |
| ETOKEN\_OFFER\_NOT\_EXIST                          |                   Token offer doesn't exist.                   |

# Aptos Fungible Asset (FA) Standard

> Learn about the Aptos Fungible Asset standard for creating and managing fungible tokens on Aptos blockchain with enhanced security and functionality.

import { ThemedImage } from '~/components/ThemedImage';

import { Aside } from '@astrojs/starlight/components';

The Aptos Fungible Asset Standard (also known as ‚ÄúFungible Asset‚Äù or ‚ÄúFA‚Äù) provides a standard, type-safe way to define fungible assets in the Move ecosystem. It is a modern replacement for the `coin` module that allows for seamless minting, transfer, and customization of fungible assets for any use case.

This standard is important because it allows fungible assets on Aptos (such as Currencies and Real World Assets (RWAs)) to represent and transfer ownership in a consistent way dApps can recognize. This standard also allows for more extensive customization than the `coin` module did by leveraging [Move Objects](/build/smart-contracts/objects) to represent fungible asset data.

The FA standard provides all the functionality you need to create, mint, transfer, and burn fungible assets (as well as automatically allowing recipients of the fungible asset to store and manage any fungible assets they receive).

It does so by using two Move Objects:

1. `Object<Metadata>` - This represents details about the fungible asset itself, including information such as the `name`, `symbol`, and `decimals`.
2. `Object<FungibleStore>` - This stores a count of fungible asset units owned by this account. Fungible assets are interchangeable with any other fungible asset that has the same metadata. An account _may_ own more than one `FungibleStore` for a single Fungible Asset, but that is only for advanced use cases.

The diagram below shows the relationship between these Objects. The `Metadata` Object is owned by the Fungible Asset creator, then referenced in FA holders' `FungibleStore`s to indicate which FA is being tracked:

<ThemedImage
  alt="FA Object Relationship"
  sources={{
light: '~/images/fa-diagram-light.png',
dark: '~/images/fa-diagram-dark.png',
}}
/>

[This implementation](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/fungible_asset.move) is an improvement on the `coin` Standard because Move Objects are more customizable and extensible via smart contract. See the advanced guides on writing [Move Objects](/build/smart-contracts/objects) for more details.
The FA standard also automatically handles tracking how much of a fungible asset an account owns, as opposed to requiring the recipient to register a `CoinStore` resource separate from the transfer.

## Creating a new Fungible Asset (FA)

At a high level, this is done by:

1. Creating a non-deletable Object to own the newly created Fungible Asset `Metadata`.
2. Generating `Ref`s to enable any desired permissions.
3. Minting Fungible Assets and transferring them to any account you want to.

To start with, the Fungible Asset standard is implemented using Move Objects. Objects by default are transferable, can own multiple resources, and can be customized via smart contract. For full details on Objects and how they work, please read [this guide](/build/smart-contracts/objects).

To create an FA, first you need to create a **non-deletable Object** since destroying the metadata for a Fungible Asset while there are active balances would not make sense. You can do that by either calling `object::create_named_object(caller_address, NAME)` or `object::create_sticky_object(caller_address)` to create the Object on-chain.

When you call these functions, they will return a `ConstructorRef`. `Ref`s allow Objects to be customized immediately after they are created. You can use the `ConstructorRef` to generate other permissions that may be needed based on your use case.

<Aside type="note">
  Note that the `ConstructorRef` cannot be stored and is destroyed by the end of the transaction used to create this Object, so any `Ref`s must be generated during Object creation.
</Aside>

One use for the `ConstructorRef` is to generate the FA `Metadata` Object. The standard provides a generator function called `primary_fungible_store::create_primary_store_enabled_fungible_asset` which will allow your fungible asset to be transferred to any account. This method makes it so the primary `FungibleStore` for recipients is automatically created or re-used so you don't need to create or index the store directly.

This is what `create_primary_store_enabled_fungible_asset` looks like:

```move filename="example.move"
public fun create_primary_store_enabled_fungible_asset(
    constructor_ref: &ConstructorRef,
    // This ensures total supply does not surpass this limit - however,
    // Setting this will prevent any parallel execution of mint and burn.
    maximum_supply: Option<u128>,
    // The fields below here are purely metadata and have no impact on-chain.
    name: String,
    symbol: String,
    decimals: u8,
    icon_uri: String,
    project_uri: String,
)
```

<Aside type="note">
  Alternatively, you can use `add_fungibility` which uses the same parameters, but requires recipients to keep track of their `FungibleStore` addresses to keep track of how many units of your FA they have.
</Aside>

Once you have created the Metadata, you can also use the `ConstructorRef` to generate additional `Ref`s. In addition to the usual [Object Refs](/build/smart-contracts/object/creating-objects), FAs define three additional permissions you can generate:

1. `MintRef` offers the capability to mint new FA units.
2. `TransferRef` offers the capability to freeze accounts from transferring this FA, or to bypass an existing freeze. (This can be important when trying to be compliant with some regulations).
3. `BurnRef` offers the capability to burn or delete FA units.

<Aside type="caution">
  Note: All `Ref`s must be generated when the Object is created as that is the only time you can generate an Object's `ConstructorRef`.
</Aside>

To generate an Object with all FA permissions, you could deploy a contract like this:

```move filename="example.move"
module my_addr::my_fungible_asset_example {
    use aptos_framework::fungible_asset::{Self, MintRef, TransferRef, BurnRef, Metadata, FungibleAsset};
    use aptos_framework::object::{Self, Object};
    use aptos_framework::primary_fungible_store;
    use std::error;
    use std::signer;
    use std::string::utf8;
    use std::option;

  const ASSET_SYMBOL: vector<u8> = b"FA";

	// Make sure the `signer` you pass in is an address you own.
	// Otherwise you will lose access to the Fungible Asset after creation.
  entry fun initialize(admin: &signer) {
    // Creates a non-deletable object with a named address based on our ASSET_SYMBOL
    let constructor_ref = &object::create_named_object(admin, ASSET_SYMBOL);

    // Create the FA's Metadata with your name, symbol, icon, etc.
    primary_fungible_store::create_primary_store_enabled_fungible_asset(
        constructor_ref,
        option::none(),
        utf8(b"FA Coin"), /* name */
        utf8(ASSET_SYMBOL), /* symbol */
        8, /* decimals */
        utf8(b"http://example.com/favicon.ico"), /* icon */
        utf8(b"http://example.com"), /* project */
    );

    // Generate the MintRef for this object
    // Used by fungible_asset::mint() and fungible_asset::mint_to()
    let mint_ref = fungible_asset::generate_mint_ref(constructor_ref);

    // Generate the TransferRef for this object
    // Used by fungible_asset::set_frozen_flag(), fungible_asset::withdraw_with_ref(),
    // fungible_asset::deposit_with_ref(), and fungible_asset::transfer_with_ref().
    let transfer_ref = fungible_asset::generate_transfer_ref(constructor_ref);

    // Generate the BurnRef for this object
    // Used by fungible_asset::burn() and fungible_asset::burn_from()
    let burn_ref = fungible_asset::generate_burn_ref(constructor_ref);

    // Add any other logic required for your use case.
    // ...
  }
}
```

<Aside type="note">
  For a full example of how to create your own Fungible Asset module, please see [fa\_coin.move](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/move-examples/fungible_asset/fa_coin/sources/FACoin.move).
  Alternatively, you can explore the collection of [FA example code here](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/move-examples/fungible_asset).
</Aside>

Now you can use the `MintRef` to mint via:

```move filename="example.move"
public fun mint(ref: &MintRef, amount:u64): FungibleAsset
```

Or burn FA units using the `BurnRef` like so:

```move filename="example.move"
public fun burn(ref: &BurnRef, fa: FungibleAsset)
```

At this point, you can mint, transfer, and burn Fungible Assets using the `Ref`s you generated. See the above example Move scripts for how to implement those entry functions.

## Reference Docs

You can find the complete set of functions that the Fungible Asset Standard provides [here](/move-reference/mainnet/aptos-framework/fungible_asset). {/* TODO: Update the Move Reference link once we migrate that page */}

The basic features owners of Fungible Assets can use include the following.

### Withdraw

An owner can withdraw FA from their primary store by calling:

```move filename="withdraw"
public fun primary_fungible_store::withdraw<T: key>(owner: &signer, metadata: Object<T>, amount:u64): FungibleAsset
```

This function will emit a `WithdrawEvent`.

### Deposit

An owner can deposit FA to their primary store by calling:

```move filename="deposit"
public fun primary_fungible_store::deposit(owner: address, fa: FungibleAsset)
```

This function will emit a `DepositEvent`.

### Transfer

An owner can deposit FA from their primary store to that of another account by calling:

```move filename="transfer"
public entry fun primary_fungible_store::transfer<T: key>(sender: &signer, metadata: Object<T>, recipient: address, amount:u64)
```

This will emit both `WithdrawEvent` and `DepositEvent` on the respective `FungibleStore`s.

### Check Balance

To check the balance of a primary store, call:

```move filename="check_balances"
public fun primary_fungible_store::balance<T: key>(account: address, metadata: Object<T>): u64
```

### Check Frozen Status

To check whether the given account's primary store is frozen, call:

```move filename="is_frozen"
public primary_fungible_store::fun is_frozen<T: key>(account: address, metadata: Object<T>): bool
```

### Events

FAs have three events emitted from the above basic functions:

1. `Deposit`: Emitted when FAs are deposited into a store.

```move filename="deposit_event"
struct Deposit has drop, store {
    store: address,
    amount: u64,
}
```

2. `Withdraw`: Emitted when FAs are withdrawn from a store.

```move filename="withdraw_event"
struct Withdraw has drop, store {
    store: address,
    amount: u64,
}
```

3. `Frozen`: Emitted when the frozen status of a fungible store is updated.

```move filename="frozen_event"
struct Frozen has drop, store {
    store: address,
    frozen: bool,
}
```

## Dispatchable Fungible Asset (Advanced)

Aside from the default managed fungible asset functionality provided by the Aptos Framework, fungible asset issuers can implement their own deposit/withdraw logic using the dispatchable fungible asset standard. This is done by registering custom hook functions to be invoked at withdrawal/deposit time. These hook functions are stored in the metadata of a fungible asset class, and the Aptos Framework will automatically invoke them instead of the default logic. This allows issuers to implement complex logic, such as customized access control. For more details, refer to the corresponding [AIP](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-73.md).

### Implementing the Hook Function

To implement a custom hook function, build a module with functions that have the following signature:

```move filename="example.move"
module my_addr::my_fungible_asset_example {
    // ...
    public fun withdraw<T: key>(
        store: Object<T>,
        amount: u64,
        transfer_ref: &TransferRef,
    ): FungibleAsset {
        // Your custom logic here
    }

    public fun deposit<T: key>(
        store: Object<T>,
        fa: FungibleAsset,
        transfer_ref: &TransferRef,
    ) {
        // Your custom logic here
    }
    // ...
}
```

### Limitations

- **Reentrancy Prevention**: Only call `with_ref` APIs in your custom hooks for deposit/withdraw operations.
  - Use `fungible_asset::deposit_with_ref` instead of `fungible_asset::deposit`.
  - Use `fungible_asset::withdraw_with_ref` instead of `fungible_asset::withdraw`.
- Avoid calling functions defined in `dispatchable_fungible_asset` and `primary_fungible_store`, _except_ for inline functions, to prevent errors during transfers.
- Note that calling `fungible_asset::withdraw` and `fungible_asset::deposit` will NOT work for assets with registered hooks. See more information in Interacting with dispatchable fungible asset.

For more details on these limitations, refer to the [AIP](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-73.md).

### Registering the Hook Function

Once the functions are implemented, use the API defined in `dispatchable_fungible_asset::register_dispatch_functions` to bind the functions with your fungible asset.

```move filename="register_dispatch"
module 0x1::dispatchable_fungible_asset {
    public fun register_dispatch_functions(
        constructor_ref: &ConstructorRef,
        withdraw_function: Option<FunctionInfo>,
        deposit_function: Option<FunctionInfo>,
        derived_balance_function: Option<FunctionInfo>,
    )
}
```

<Aside type="note">
  The `register_dispatch_functions` function takes `Option<FunctionInfo>` as input to specify whether to use custom or default logic for withdraw/deposit/balance operations. If `option::none()` is passed, the default logic is used.
  A `FunctionInfo` identifies the function to be used as a custom hook.
  The `constructor_ref` is a reference for the metadata object of your fungible asset.
</Aside>

To construct a `FunctionInfo`, use either of:

```move filename="new_function_info"
module 0x1::function_info {
    public fun new_function_info(module_signer: &signer, module_name: String, function_name: String): FunctionInfo
    // or if you do not have the signer:
    public fun new_function_info_from_address(module_address: address, module_name: String, function_name: String): FunctionInfo
}
```

The registration can look like this:

```move filename="example.move"
module my_addr::my_fungible_asset_example {
    use aptos_framework::string;
    use aptos_framework::object;
    use aptos_framework::primary_fungible_store;
    use aptos_framework::dispatchable_fungible_asset;
    use aptos_framework::function_info;

    fun create_fungible_asset(module_signer: &signer, /* ... */) {
        // Make the deposit override function info
        let deposit_override = function_info::new_function_info(
            module_signer,
            string::utf8(b"my_fungible_asset_example"),
            string::utf8("deposit")
        );

        // Create the fungible asset
        let constructor_ref = object::create_sticky_object( /* ... */);

        primary_fungible_store::create_primary_store_enabled_fungible_asset(&constructor_ref, ...);
        // or below if not having primary stores
        // fungible_asset::add_fungibility(&constructor_ref, /* ... */);

        // Override default functionality for deposit
        dispatchable_fungible_asset::register_dispatch_functions(
            &constructor_ref,
            option::none(),
            option::some(deposit_override),
            option::none()
        );

        // ...
    }

    // ...
}
```

### Interacting with dispatchable fungible asset

For users using `primary_fungible_store` to manage assets, no changes are required to interact with assets with dispatchable hooks. The Aptos Framework automatically invokes the dispatch logic if a hook is set up.

For users using secondary `FungibleStore` to interact with assets, use `dispatchable_fungible_asset::withdraw/deposit` instead of `fungible_asset::withdraw/deposit` to handle assets with registered hooks.

The `dispatchable_fungible_asset::withdraw/deposit` functions are replacements, and also work with functions that do not have hooks registered.

## Managing Stores (Advanced)

Behind the scenes, the Fungible Asset Standard needs to manage how the asset balances are stored on each account. In the vast majority of circumstances, users will store all FA balances in their Primary `FungibleStore`. Sometimes though, additional ‚ÄúSecondary Stores‚Äù can be created for advanced DeFi applications.

- Each account owns only one non-deletable primary store for each type of FA, the address of which is derived in a deterministic manner from the account address and metadata object address. If primary store does not exist, it will be created if FA is going to be deposited by calling functions defined in `primary_fungible_store.move`
- Secondary stores do not have deterministic addresses and are deletable when empty. Users are able to create as many secondary stores as they want using the provided functions but there is a caveat that addressing secondary stores on-chain may be more complex.

You can look up a primary store via the following function:

```move filename="primary_store"
public fun primary_store<T: key>(owner: address, metadata: Object<T>): Object<FungibleStore>
```

And if you want to create a primary store manually you can use this function:

```move filename="create_primary_store"
public fun create_primary_store<T: key>(owner_addr: address, metadata: Object<T>): Object<FungibleStore>
```

The primary reason to use a secondary store is for assets managed by a smart contract. For example, an asset pool may have to manage multiple fungible stores for one or more types of FA.

To create a secondary store, you must:

1. Create an Object to get its `ConstructorRef`.
2. Call:

```move filename="create_store"
public fun create_store<T: key>(constructor_ref: &ConstructorRef, metadata: Object<T>): Object<FungibleStore>
```

This will create a secondary store owned by the newly created Object. Sometimes an object can be reused as a store. For example, a metadata object can also be a store to hold some FA of its own type or a liquidity pool object can be a store of the issued liquidity pool's coin.

It is crucial to set the correct owner of a `FungibleStore` object for managing the FA stored inside. By default, the owner of a newly created object is the creator whose `signer` is passed into the creation function. For `FungibleStore` objects managed by smart contract itself, the owner should usually be an Object address controlled by the contract. For those cases, those objects should keep their `ExtendRef` at the proper place to create `signer` as needed to modify the `FungibleStore` via contract logic.

## Migration from `Coin` to the Fungible Asset Standard

### Smart Contract Migration

**Projects utilizing the `coin` module do not need to modify their contracts.** The `coin` module has been enhanced to handle migration automatically. Whenever a paired FA is required for a `coin`, it will be automatically created if it doesn't already exist. The mapping between coins and FAs is immutable and stored in an on-chain table:

```move filename="coin_conversion"
struct CoinConversionMap has key {
    coin_to_fungible_asset_map: Table<TypeInfo, address>,
}
```

A `#[view]` function is available to retrieve metadata for the paired FA if it exists:

```move filename="paired_metadata"
#[view]
public fun paired_metadata<CoinType>(): Option<Object<Metadata>>
```

Similarly, a function exists for reverse lookup:

```move filename="paired_coin"
#[view]
public fun paired_coin(metadata: Object<Metadata>): Option<TypeInfo>
```

### Off-chain Migration

There are two changes needed for off-chain services:

1. Balances should reflect that a user may have **both** a `coin` balance and a paired FA balance.
2. Event listeners should listen for both `coin` and FA events.

Since a user may possess **both** a `coin` balance and a paired FA balance, off-chain applications should be updated to reflect the **sum** of both the `coin` balance and its paired FA balance.

- For Aptos Indexer users, you may utilize the table called `current_fungible_asset_balances` to obtain the latest sum of coin balance and FA balance representing the same asset type. If the FA has a paired coin type, the asset type would be set to the coin type, such as `0x1::aptos_coin::AptosCoin`. Otherwise, for FA not paired from a coin, the asset type would be the metadata address. Users could filter by this field to get the FA balance of their interest.
- For users employing Node API or other customized indexing, they should add the balance of the paired FA in users' `FungibleStore` and `ConcurrentFungibleBalance` if any of them exist to the coin balance.

To retrieve the balance of the `PrimaryFungibleStore` for a paired FA to an existing `coin` of type `CoinType`:

1. Call `paired_metadata<CoinType>()` to obtain the paired FA metadata object address (the address is immutable).
2. Retrieve the balance of the paired FA:
   - Call [getCurrentFungibleAssetBalances](https://github.com/aptos-labs/aptos-ts-sdk/blob/c01a26ff899235fac1c31c6cc3fe504b764e5b91/src/api/fungibleAsset.ts#L115).
   - Alternatively, determine the address of the primary `FungibleStore`, which can be deterministically calculated with the following formula:
     - `sha3_256(32-byte account address | 32-byte metadata object address | 0xFC)`
   - Then use that address to obtain the `FungibleStore` resource to fetch the balance.
     - If the balance is non-zero, this is the final balance of this FA.
     - Otherwise, try to get `ConcurrentFungibleBalance` resource at the same address and get the balance there instead.
     - If neither exist, the FA balance for this account is 0.

**Post-migration, both coin events and FA events could be emitted for an activity, depending on whether the user has migrated or not.** Dapps relying on events should update their business logic accordingly.

### Migration FAQs

<details>
  <summary><span className="font-bold">What is the Aptos Fungible Asset (FA) standard?</span></summary>

  <div className="p-8">
    The FA standard introduces a new way to represent fungible tokens as [Move objects](/build/smart-contracts/objects), replacing the legacy Coin resource model. Fungible Assets are more composable and developer-friendly compared to legacy Coins.

    APT will be migrated starting on June 30, 2025.
  </div>
</details>

<details>
  <summary><span className="font-bold">How exactly does the new FA standard differ from legacy Coins?</span></summary>

  <div className="p-8">
    With legacy Coins, each account directly holds a `CoinStore\<CoinType>` resource that tracks balances (in u64), includes flags like "frozen," and emits basic events on deposits or withdrawals. Transfers, mints, and burns are performed via `0x1::coin` module functions.

    Under the FA Standard, token balances are held in FungibleStore objects (instead of each account directly holding a CoinStore resource). Each asset has metadata that defines its properties (name, symbol, etc.). For any account that owns that token, the balance lives in a FungibleStore object belonging to that account and linked to the Metadata object.

    The primary way an account holds a fungible asset is via a primary fungible store; the address of this object is deterministically derived from the user's account address and the token's metadata address.

    FAs come in two flavors:

    1. **Vanilla FA**: Tokens that primarily manage simple balance updates.

    2. **Dispatchable FA (DFA)**: Tokens that embed custom Move logic automatically executed upon transfers.
  </div>
</details>

<details>
  <summary><span className="font-bold">How will this migration impact me?</span></summary>

  <div className="p-8">
    As an end user, you don't need to do anything. Your tokens remain safe, exactly where they should be in their new form. The migration does not affect ownership or usability in any way.

    If you're a developer, your existing smart contract code remains functional, but you should immediately start using the FA SDK for all new work. Existing coin API calls will continue working by silently routing to FA. After the migration, the coin module will be kept as it is, with minimal maintenance. Please note that you will no longer be able to look up coin balance by resource. Move to the `0x1::coin::balance` view function, or the balance REST API instead.
  </div>
</details>

<details>
  <summary><span className="font-bold">What is the migration timeline?</span></summary>

  <div className="p-8">
    All tokens on Aptos will begin migrating automatically from Coin v1 to the FA standard.
    All the coins except APT will be migrated from June 23 to 30. APT will transition from June 30 to July 8, 2025.
    The process involves continuously running batched transactions until every valid CoinStore has been fully converted into the new FungibleStore.
  </div>
</details>

<details>
  <summary><span className="font-bold">Why is the upgrade to the Fungible Asset standard necessary?</span></summary>

  <div className="p-8">
    Short answer: It unlocks powerful functionalities that the legacy Coin module simply cannot support.

    Modern DeFi and RWA apps increasingly demand sophisticated features like automated yield claims, custom fee structures, and built-in compliance checks. These are difficult to implement on legacy Coins. Attempting to bolt these capabilities onto the old standard rapidly creates composability issues, integration headaches and rising complexity.

    Beyond functionality, builders can also use a unified asset standard across all tokens, including stablecoins. Imagine designing a payment kiosk: if it accepts only digital payments, you avoid the complexity of cash slots, coin dispensers, and change mechanisms altogether. Similarly, adopting a single streamlined token standard reduces complexity in platform development. It improves developer productivity and delivers more consistent user experience.

    In short, the FA standard is clean and elegant. Developers can launch tokens that immediately integrate seamlessly across wallets, explorers, and DeFi applications from day one.
  </div>
</details>

<details>
  <summary><span className="font-bold">What are some new and unique functionalities I can build with Fungible Assets?</span></summary>

  <div className="p-8">
    Fungible Assets open the door to a range of advanced features that weren't possible with the legacy Coin model. Some notable capabilities include:

    - Tokens that automatically collect fees (like a percentage charge on transfers).

    - Interest-bearing tokens that accrue yield directly to the holders without manual claims.

    - Tokens with built-in vesting or time-locks that automatically release funds when certain conditions are met, a la escrow.

    - Tokens that dispense loyalty points on-chain when they're spent.

    - Tokens that can dynamically adjust supply; burning or minting based on usage patterns.

    The possibilities are endless.

    A great real-world example is xLPT from [Thala Labs](https://www.thalalabs.xyz/), which uses built-in DFA hooks to automate staking & unstaking LP tokens, updating positions and rewards automatically upon each transfer, without any user intervention.
  </div>
</details>

<details>
  <summary><span className="font-bold">We know there is always a paired FA of a coin type. How can we query the supply and balance of this asset after the migration?</span></summary>

  <div className="p-8">
    After the migration, querying resource `0x1::coin::CoinStore<0x1::aptos_coin::AptosCoin>` at account address will be unavailable. Instead, you can query the account balance by the following three ways:

    1. [Balance Node API](/build/apis/fullnode-rest-api#tag/accounts/GET/accounts/%7Baddress%7D/balance/%7Basset_type%7D), the asset\_type can be either coin\_type, such as 0x1::aptos\_coin::AptosCoin or FA metadata address such as 0xa, either way should return the same value.

    2. `#[view] function primary_fungible_store::balance<T: key>(account: address, metadata: Object<T>): u64`

    3. `#[view] function balance<CoinType>(owner: address): u64`. This method is deprecated and not applicable to pure FA tokens (e.g., USDt); it applies only to migrated coins such as APT. Due to its limitations and higher gas costs, it is not recommended.
  </div>
</details>

<details>
  <summary><span className="font-bold">Before migration, I could query all the assets a user has by getting all the resources at their address using API. How do I do it after migration?</span></summary>

  <div className="p-8">
    You can [use the Indexer API](/build/indexer/indexer-api/indexer-reference#current_fungible_asset_balances) to query all the fungible assets the user owns.

    Querying raw resources to get the asset balance and types is not recommended and will not be well-supported by fullnode API.
  </div>
</details>

<details>
  <summary><span className="font-bold">What if I have more questions?</span></summary>

  <div className="p-8">
    Join the [Aptos Discord](https://discord.com/invite/aptosnetwork)! Aptos Labs engineers will be available throughout migration week to answer questions and offer support.
  </div>
</details>

# Aptos Move Lint

> Learn about linter for Move smart contract development on Aptos blockchain.

The "Aptos Move Lint" tool runs on a Move package to find and warn about common issues in Move programs, helping improve your Move code.

You can run it with the aptos CLI command: `aptos move lint`.

If you find any issues, please submit [bugs and feedback](https://github.com/aptos-labs/aptos-core/issues/new?title=%5Blinter%5D%20%3CDescriptive%20Title%3E\&body=%3CDetailed%20description%20of%20the%20issue%20or%20feature%20request%3E\&labels=move-linter\&projects=aptos-labs/16). Also, we are tracking ideas and prioritization requests for new lint rules [here](https://github.com/aptos-labs/aptos-core/issues/15221), we welcome your contributions.

## Lint Checks

### `aborting_overflow_checks`

Checks for patterns that look like overflow checks done in a C style:

```move
// Overflow check
if (x > x + y) {
  abort 1;
};

// Underflow check
if (x < x - y) {
  abort 1;
};
```

This pattern in Move does not make sense, as it either aborts immediately or is always true/false.

### `almost_swapped`

Checks for expression patterns that look like a failed swap attempt and notifies the user. These patterns are likely erroneous code. This currently only detects simple access patterns such as assignments to a variable or a field of a struct. Examples include:

- `a = b; b = a;` which can be correctly swapped with `(a, b) = (b, a);`
- `a.x = b.x; b.x = a.x;` which can be correctly swapped with `(a.x, b.x) = (b.x, a.x);`

### `assert_const`

Checks for trivial assertions, i.e. `assert!(false)` and `assert!(true)`. The latter is equivalent to a no-op, so can be removed entirely, while the former can be replaced by an abort.

### `avoid_copy_on_identity_comparison`

Checks for identity comparisons (`==` or `!=`) between copied values of type `vector` or `struct` (i.e., types for which copy can be expensive). It instead suggests to use reference-based identity comparison instead (i.e., use `&x == &y` instead of `x == y`, when the above mentioned conditions meet).

[This recommendation](/build/smart-contracts/book/equality#avoid-extra-copies) is also given in the Move book. Due to automatic copy inference, it may not be obvious when a copy is being made while using `==` or `!=` on values with types that have the `copy` ability. This lint identifies cases where extra copies on vectors or structs could be skipped by using reference-based identity comparisons.

### `blocks_in_conditions`

Checks for use of blocks in conditions (e.g., in `if`, `match`, and `while` conditions), which can make code hard to read. An example coding pattern caught by this lint is:

```move
if ({let x = foo(); !x}) { // uses a block in condition
  bar();
}
```

Such code can usually be rewritten to hoist the block out and above the condition, usually making it more readable.

It is a common Move pattern to provide inline specifications in conditions, especially loop invariants, which requires creating blocks in conditions. We exclude this pattern in the lint check to continue to allow for this specification pattern.

Note that an `assert!` is translated to a conditional abort, so blocks in `assert!` condition also are reported by this lint.

### `empty_if`

Checks for `if` statements that have no body, which is likely a mistake. For example:

```move
if (x) {
}
```

### `equal_operands_in_bin_op`

Checks for binary operations where both operands are the same, which is likely a mistake. For example `x % x`, `x ^ x`,  `x > x`, `x >= x`, `x == x`, `x | x`, `x & x`, `x / x`, and `x != x` are all caught by this lint. The lint suggests replacing these with a more appropriate value or expression, such as `0`, `true`, or `false`.

This lint does not catch cases where the operands are vector access.

### `empty_range`

Checks for empty ranges in `for` loops, such as `for i in 0..0 { ... }`, which do not execute the loop body. This can happen when the start of the range is greater than or equal to the end of the range, resulting in an empty iteration.

### `find_unnecessary_casts`

Checks for unnecessary type casts where the source expression already has the same type as the target type. These casts are redundant and can be removed to improve code readability.

For example:

```move
let x: u64 = 42;
let y = x as u64; // unnecessary cast, x is already u64
```

The above can be simplified to:

```move
let x: u64 = 42;
let y = x; // cast removed
```

### `infinite_recursion`

Checks for functions or groups of functions that recurse infinitely. Note that the linter cannot detect _conditional_ infinite recursion, only inconditional, so a flag is a definite error in the program.

### `known_to_abort`

Checks for expressions that will always abort at runtime due to known constant values that violate runtime constraints. This lint helps identify code that will deterministically fail before it reaches production.

The following cases are detected:

- **Bit shifts with excessive shift amounts**: `x << n` or `x >> n` where `n` is a constant that is greater than or equal to the bit width of `x`'s type. For example, `value << 64` when `value` is of type `u64` will always abort.
- **Division or modulo by zero**: `x / 0` or `x % 0` operations will always abort at runtime.
- **Out-of-range type casting**: `constant as type` where the `constant` value is outside the representable range of the target `type`. For example, `300 as u8` will abort since `u8` can only represent values 0-255.

### `needless_bool`

Checks for patterns of the form (where `x` is any arbitrary boolean expression):

- `if (x) true else false`, which can be replaced with just `x`.
- `if (x) false else true`, which can be replaced with just `!x`.
- `if (x) { return true } else { return false }`, which can be replaced with just `return x`.
- `if (x) { return false } else { return true }`, which can be replaced with just `return !x`.
- `if (x) true else true` or `if (x) false else false`, which should be rewritten to remove the redundant branch.

### `needless_deref_ref`

Checks for patterns where references taken are immediately dereferenced, and suggests removing the pair of dereference-reference operators:

- `*&x.f` can be simplified to `x.f`
- `*&mut x.f` can be simplified to `x.f`
- `*&mut x.f = 5;` can be simplified to `x.f = 5;`

### `needless_loops`

Checks for loops that always exit on their first iteration, making the loop construct unnecessary. This lint detects loops that immediately return, abort, or break without performing any meaningful iteration.

The linter identifies these patterns:

- Loops where the first instruction is `return`, `abort`, or `break`
- Loops where the first instruction is a conditional branch where both paths immediately exit the loop

Examples of needless loops:

```move
// Always returns on first iteration
loop {
    return 42;
}

// Always aborts on first iteration
loop {
    abort 1;
}
```

These can be simplified by removing the loop construct entirely and using just the exit statement directly.

This lint uses conservative analysis to avoid false positives, only flagging cases where the exit behavior is immediately obvious from the loop's structure.

### `needless_mutable_reference`

Checks for mutable references or borrows (currently: mutable reference parameters, mutable borrow of locals, `borrow_global_mut`) that are not used mutably, and suggests to use the immutable reference or borrow instead.

For example, in the function `foo` below, `&mut` can be replaced by `&` because the reference is not mutably used.

```move
fun foo(x: u64): u64 {
  let y = &mut x;
  *y
}

```

### `needless_ref_deref`

Checks for patterns where immutable reference are taken for a dereference, and suggests removing the pair of reference-dereference operators: `&*x` can be simplified to `x`.

### `needless_ref_in_field_access`

Checks for patterns where there are needless references taken when accessing a field of a struct or an enum, and suggests removing the explicit reference taken:

- `(&s).f` can be simplified to `s.f`
- `(&mut s).f = 42;` can be simplified to `s.f = 42;`

### `needless_return`

Checks for unnecessary `return` statements in functions that can be simplified. This lint identifies cases where a `return` statement is used to return a value that can be directly returned without the `return` keyword.
For example, the following function:

```move
public fun foo(): bool {
  // ...
  return true;
}
```

This pattern can be simplified to:

```move
public fun foo(): bool {
  // ...
  true
}
```

### `nested_if`

Checks for nested if statements that can be simplified using the `&&` operator. This lint identifies patterns where an inner if statement with no else branch is contained within an outer if statement that also has no else branch.

```move
if (a) {
    if (b) {
        // some code
    }
}
```

This pattern can be simplified to:

```move
if (a && b) {
    // some code
}
```

The simplified version is more readable and avoids unnecessary nesting while maintaining the same logical behavior.

### `nonminimal_bool`

Check for boolean expressions that can be simplified when a boolean literal (either `true` or `false`) is part of a binary or unary boolean operator. Examples:

- `x && true` is logically equivalent to `x`
- `x || true` is logically equivalent to `true`
- `x => false` is logically equivalent to `!x`
- `x <==> true` is logically equivalent to `x`
- `! true` is logically equivalent to `false`

Does NOT consider side-effects/short-circuiting in the recommended simplifications. Example:

- `1/0 || true` is logically equivalent to `true`, but applying this simplification affects program semantics.

### `no_op`

Checks for statements that can be removed without changing program behavior. Examples:

- `42;`
- `*(&mut 0) = /*...*/;`
- `x << 4;`

Note that the linter does not take into account possible aborts due to arithmetic errors. If a statement is flagged it's almost definitely a programmer mistake, but you should evaluate the code in question to understand the intent. Sometimes the proper fix is to remove the statement, sometimes the statement should be changed.

### `random_modulo`

Checks for expressions of the form `u{8|16|32|64|128|256}_integer() % x`. Getting the remainder of a division where the dividend is a random number results in a non-uniform distribution, which could affect the fairness of a contract's behavior, depending on how the value is used. For example, the result of `u8_integer() % 255` is twice as likely to be 0 than 1. Instead of wrapping with modulo, `u{8|16|32|64|128|256}_range(0, x)` can be used, which produces a uniform distribution.

### `self_assignment`

Checks for patterns where a variable or a field of a struct is assigned to itself and suggests removing the assignment. These assignments do not affect the state of the program. Examples include:

- `let x = x;`
- `x = x;`
- `a.x = a.x;`

### `simpler_bool_expression`

Checks for boolean patterns that can be simplified through different boolean algebra laws. Examples include:

- Absorption law:
  - `a && b || a` can be simplified to `a`
  - `a || a && b` can be simplified to `a`
- Idempotence:
  - `a && a` can be simplified to `a`
  - `a || a` can be simplified to `a`
- Contradiction
  - `a && !a` can be simplified to `false`
  - `!a && a` can be simplified to `false`
- Tautology:
  - `a || !a` can be simplified to `true`
  - `!a || a` can be simplified to `true`
- Distributive law:
  - `(a && b) || (a && c)` can be simplified to `a && (b || c)`
  - `(a || b) && (a || c)` can be simplified to `a || (b && c)`

Where `a`, `b` and `c` can either be simple or composed expressions.

### `simpler_numeric_expression`

Checks for various patterns where a simpler numeric expression can be used instead. In all these cases, the code must already type check, and `x` can be any numeric expression.

- `x & 0`, `x * 0`, `0 & x`, `0 * x`, `0 << x`, `0 >> x`, `x % 1` can all be replaced with just `0`.
- `x | 0`, `x ^ 0`, `x >> 0`, `x << 0`, `x + 0`, `x - 0`, `x / 1`, `x * 1`, `0 | x`, `0 ^ x`, `0 + x`, `1 * x` can all be replaced with just `x`.

### `unnecessary_boolean_identity_comparison`

Checks for boolean identity comparisons of the form:

- `x == true`, `true == x`, which can be replaced with just `x`.
- `x == false`, `false == x`, which can be replaced with just `!x`.

In all these cases, `x` can be any arbitrary boolean expression.

### `unnecessary_numerical_extreme_comparison`

Checks if there are any numerical comparisons with extreme values (i.e., min and max value representable by that numeric type) that are unnecessary or can be made more precise and clear. Depending on the comparison, various recommendations are made.

Consider the following example expressions that are caught by the lint, and the corresponding recommendations made (in all these cases, `x` is a place holder for a numerical expression of type `u8`, `u16`, `u32`, `u64`, `u128`, or `u256`, and `MAX` is a place holder for the max value representable for that numeric type):

- `x < 0`, `0 > x`, `x > MAX`, `MAX < x`, are always false, rewrite code to remove this comparison
- `x >= 0`, `0 <= x`, `x <= MAX`, `MAX >= x`, are always true, rewrite code to remove this comparison
- `x <= 0`, `0 >= x`, `x >= MAX`, `MAX <= x`, can all be simplified to use `==` instead
- `x > 0`, `0 < x`, `x < MAX`, `MAX > x`, can all be clarified to use `!=` instead

### `redundant_comparison`

Checks for redundant, contradictory, and tautological numerical comparisons over the same variable in boolean expressions combined with `&&` and `||`. This lint identifies logic errors in conditional statements that can lead to unreachable code or always-true/false conditions.

Examples of patterns caught by this lint:

- **Redundant with `&&`**: `x <= 400 && x < 500` - the second condition is redundant since it's always satisfied when the first is true
- **Contradictory with `&&`**: `x <= 400 && x > 500` - these conditions can never both be true, making the expression always false
- **Redundant with `||`**: `x > 10 || x >= 5` - the first condition is redundant since the second covers more cases
- **Tautology with `||`**: `x < 5 || x >= 5` - this expression is always true for any value of x

The lint only triggers when comparisons are on the same variable and can detect constants on either side of the comparison operator.

### `while_true`

Checks for `while (true) { .... }` patterns and suggests using the more explicit `loop { .... }` construct instead.

## Suppressing Lint Warnings

To suppress one or more lint checks named `check1`, `check2`, ... (and so on), you can add the attribute `#[lint::skip(check1, check2, ...)]` to a function or a module. The linter will then not perform the checks named `check1`, `check2`, ... (and so on) for that function or module.

For example, the function below would usually get a warning from the linter about a `needless_bool`, but due to the attribute on the function, the linter does not emit a warning.

```move
#[lint::skip(needless_bool)]
fun violation(): bool {
    if (foo()) true else false
}
```

## Security Checks

### `contains_in_table`

Checks for unsafe usage of table operations that could lead to runtime errors. This lint helps prevent common mistakes when working with tables by detecting:

1. **Unsafe `table::borrow` calls**: Borrowing from a table without first checking if the key exists using `table::contains`. This can cause runtime errors if the key doesn't exist.

2. **Unsafe `table::add` calls**: Adding to a table without ensuring the key doesn't already exist. This can cause runtime errors if the key already exists.

The lint analyzes control flow to understand when keys are known to exist or not exist based on `table::contains` checks.

**Examples of patterns caught by this lint:**

```move
// Unsafe borrow - no contains check
table::borrow(&table, key); // Error: might fail if key doesn't exist

// Unsafe add - no contains check
table::add(&mut table, key, value); // Error: might fail if key already exists

// Wrong key check
if (table::contains(&table, key1)) {
    table::borrow(&table, key2); // Error: checked key1 but borrowing key2
}

// Wrong branch usage
if (!table::contains(&table, key)) {
    table::borrow(&table, key); // Error: key is known NOT to exist
}
```

**Recommended solutions:**

- For `table::borrow`: Use `table::contains` first to check if the key exists
- For `table::add`: Use `table::upsert` instead, or check with `table::contains` that the key doesn't exist first

### `return_signer`

This security check detects when a public function returns a `signer` value, which can leak authority and is usually a security risk. Returning a `signer` from a public function allows callers to obtain signer capabilities that they shouldn't have access to, potentially leading to unauthorized operations.

**Examples of patterns caught by this lint:**

```move
// Direct signer return - security risk
public fun get_signer(): signer {
    // ... code that returns a signer
}

// Signer in vector - security risk
public fun get_signers(): vector<signer> {
    // ... code that returns signers
}

// Signer in tuple - security risk
public fun get_data(): (u64, signer) {
    // ... code that returns a tuple with signer
}
```

### `zero_address`

This security check detects the use of `address` parameters in external functions that are not checked for being zero before being used. This could lead to loss of funds or other security issues.‚èé

### `return_constructor_ref`

Checks for public functions that return an `ConstructorRef`. Constructor references confer the authority to create an object, and returning them from functions can leak privileged capability. This lint helps prevent accidental exposure of sensitive object creation authority.

**Examples of patterns caught by this lint:**

```move
// Public function returning ConstructorRef - security risk
public fun create_object_ref(): ConstructorRef {
    // ... code that returns ConstructorRef
}

// Public function returning a struct containing ConstructorRef
public fun get_authority(): MyStruct<ConstructorRef> {
    // ... code that returns struct with ConstructorRef
}

// Public function returning vector containing ConstructorRef
public fun get_refs(): vector<ConstructorRef> {
    // ... code that returns vector with ConstructorRef
}
```

## Experimental Checks

### `cyclomatic_complexity`

Cyclomatic complexity measures the number of linearly independent execution paths through a function. A high value generally correlates with code that is harder to test and maintain.

This linter performs an approximation while traversing the Move expression tree:

1. The complexity score starts at **1**.
2. The score is incremented for each control-flow decision point found:
   - +1 for each `if`
   - +1 for each `else if`
   - +1 for each `loop`, `while`, or `for`
   - +1 for each `break` or `continue`
   - +1 for each `return` statement that is not the final expression in the function
   - +n where n = (number of match arms - 1)

When the accumulated score exceeds the default threshold (currently **10**), the linter emits a diagnostic suggesting that the function be simplified or decomposed.

# Maps

> Learn about maps for Move smart contract development on Aptos blockchain.

There are multiple different implementations of key-value maps inside the framework, suited for different usecases.
We will go over their differences and similarities, and how to choose which one to use.

## Aptos Blockchain performance and gas cost considerations

Aptos Blockchain state is kept in **storage slots**.
Furthermore, transaction performance and gas cost is heavily influenced by how these **slots** are read and written.
Breaking down the gas costs further, we have:

1. Storage fee, which are determined by the number and size of **slots** (i.e., writing to a new **slot** incurs the highest storage fee, whereas deleting an existing **slot** provides the largest refund.)
2. IO gas costs ‚Äîgenerally much lower‚Äî which depend on the number and size of resources read and modified.
3. execution gas costs are based on the computation needed, and are generally in the similar scale as io gas costs.

Transactions that modify the same **slot** cannot be executed concurrently (with some exceptions, like aggregators and resources as a part of the same resource group), as they conflict with one another.

One useful analogy is thinking about each **slot** being a file on a disk,
then performance of smart contract would correlate well to a program that
operates on files in the same way.

## Different Map implementations

| Implementation    | Size Limit                          | Storage Structure                                                                                                                               | Key Features                                                                                                                                                                                                  |
| ----------------- | ----------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `OrderedMap`      | Bounded (fits in a single **slot**) | Stored entirely within the resource that contains it                                                                                            | Supports ordered access (front/back, prev/next), implemented as sorted vector, but operations are effectively O(log(n)) due to internal optimizations                                                         |
| `Table`           | Unbounded                           | Each (key, value) stored in a separate **slot**                                                                                                 | Supports basic operations, like `add`, `remove`, `contains`, but **not iteration**, and **cannot be destroyed**; useful for large/unbounded keys/values and where high-concurrency is needed                  |
| `TableWithLength` | Unbounded                           | same as `Table`                                                                                                                                 | Variant of `Table`, with additional length tracking, which adds `length`, `empty`, and `destroy_empty` methods; Adding or removing elements **cannot** be done concurrently, modifying existing elements can. |
| `BigOrderedMap`   | Unbounded                           | Combines multiple keys into a single **slot**, initially stored within resource that contains it, and grows into multiple **slots** dynamically | Implemented as B+ tree; **opportunistically concurrent** for non-adjacent keys; supports ordered access (front/back, prev/next); configurable node capacities to balance storage and performance              |

Note:

- `SimpleMap` has been deprecated, and replaced with `OrderedMap`.
- `SmartTable` has been deprecated, and replaced with `BigOrderedMap`.

#### Performance comparison

We measured performance at small scale, measuring microseconds taken for a single pair of `insert` + `remove` operation, into a map of varied size.

| num elements | OrderedMap | BigOrderedMap max\_degree>10000 | BigOrderedMap max\_degree=16 |
| ------------ | ---------- | ------------------------------- | ---------------------------- |
| 10           | 65         | 123                             | 123                          |
| 100          | 85         | 146                             | 455                          |
| 1000         | 105        | 168                             | 567                          |
| 10000        | 142        | 210                             | 656                          |

You can see that overhead of `BigOrderedMap` compared to `OrderedMap`, when both are in the single **slot**, is around 1.5-2x.
So you can generally used `BigOrdredMap` when it is unknown if data will be too large to be stored in a single **slot**.

## Common map operations:

Most maps above support the same set of functions (for actual signatures and restrictions, check out the corresponding implementations):

#### Creating Maps

- `new<K, V>(): Self`: creates an empty map

#### Destroying Maps

- `destroy_empty<K, V>(self: Self<K, V>)`: Destroys an empty map. (**not** supported by `Table`)
- `destroy<K, V>(self: Self<K, V>, dk: |K|, dv: |V|)`: Destroys a map with given functions that destroy corresponding elements. (**not** supported by `Table` and `TableWithLength`)

#### Managing Entries

- `add<K, V>(self: &mut Self<K, V>, key: K, value: V)`: Adds a key-value pair to the map.
- `remove<K, V>(self: &mut Self<K, V>, key: K): V`: Removes and returns the value associated with a key.
- `upsert<K, V>(self: &mut Self<K, V>, key: K, value: V): Option<V>`: Inserts or updates a key-value pair.
- `add_all<K, V>(self: &mut Self<K, V>, keys: vector<K>, values: vector<V>)`: Adds multiple key-value pairs to the map. (**not** supported by `Table` and `TableWithLength`)

#### Retrieving Entries

- `contains<K, V>(self: &Self<K, V>, key: &K): bool`: Checks whether key exists in the map.
- `borrow<K, V>(self: &Self<K, V>, key: &K): &V`: Returns an immutable reference to the value associated with a key.
- `borrow_mut<K: drop, V>(self: &mut Self<K, V>, key: K): &mut V`: Returns a mutable reference to the value associated with a key.
  (`BigOrderedMap` only allows `borrow_mut` when value type has a static constant size, due to modification being able to break it's invariants otherwise. Use `remove()` and `add()` combination instead)

#### Order-dependant functions

These set of functions are only implemented by `OrderedMap` and `BigOrderedMap`.

- `borrow_front<K, V>(self: &Self<K, V>): (&K, &V)`
- `borrow_back<K, V>(self: &Self<K, V>): (&K, &V)`
- `pop_front<K, V>(self: &mut Self<K, V>): (K, V)`
- `pop_back<K, V>(self: &mut Self<K, V>): (K, V)`
- `prev_key<K: copy, V>(self: &Self<K, V>, key: &K): Option<K>`
- `next_key<K: copy, V>(self: &Self<K, V>, key: &K): Option<K>`

#### Utility Functions

- `length<K, V>(self: &Self<K, V>): u64`: Returns the number of entries in the map. (not supported by `Table`)

#### Traversal Functions

These set of functions are not implemented by `Table` and `TableWithLength`.

- `keys<K: copy, V>(self: &Self<K, V>): vector<K>`

- `values<K, V: copy>(self: &Self<K, V>): vector<V>`

- `to_vec_pair<K, V>(self: Self<K, V>): (vector<K>, vector<V>)`

- `for_each_ref<K, V>(self: &Self<K, V>, f: |&K, &V|)`

- `to_ordered_map<K, V>(self: &BigOrderedMap<K, V>): OrderedMap<K, V>`: Converts `BigOrderedMap` into `OrderedMap`

## Example Usage

### Creating and Using a OrderedMap

```move filename="map_usage.move"
module 0x42::map_usage {
    use aptos_framework::ordered_map;

    public entry fun main() {
        let map = ordered_map::new<u64, u64>();
        map.add(1, 100);
        map.add(2, 200);

        let length = map.length();
        assert!(length == 2, 0);

        let value1 = map.borrow(&1);
        assert!(*value1 == 100, 0);

        let value2 = map.borrow(&2);
        assert!(*value2 == 200, 0);

        let removed_value = map.remove(&1);
        assert!(removed_value == 100, 0);

        map.destroy_empty();
    }
}
```

## Additional details for `BigOrderedMap`

Its current implementation is B+ tree, which is chosen as it is best suited for the onchain storage layout - where the majority of cost comes from loading and writing to storage items, and there is no partial read/write of them.

Implementation has few characteristics that make it very versatile and useful across wide range of usecases:

- When it has few elements, it stores all of them within the resource that contains it, providing comparable performance to OrderedMap itself, while then dynamically growing to multiple resources as more and more elements are added
- It reduces amount of conflicts: modifications to a different part of the key-space can be generally done concurrently, and it provides knobs for tuning between concurrency and size
- All operations have guaranteed upper-bounds on performance (how long they take, as well as how much execution and io gas they consume), allowing for safe usage across a variety of use cases.
  - One caveat, is refundable storage fee. By default, operation that requires map to grow to more resources needs to pay for storage fee for it. Implementation here has an option to pre-pay for storage slots, and to reuse them as elements are added/removed, allowing applications to achieve fully predictable overall gas charges, if needed.
- If key/value is within the size limits map was configured with, inserts will never fail unpredictably, as map internally understands and manages maximal **slot** size limits.

### `BigOrderedMap` structure

`BigOrderedMap` is represented as a tree, where inner nodes split the "key-space" into separate ranges for each of it's children, and leaf nodes contain the actual key-value pairs.
Internally it has `inner_max_degree` representing largest number of children an inner node can have, and `leaf_max_degree` representing largest number of key-value pairs leaf node can have.

#### Creating `BigOrderedMap`

Because it's layout affects what can be inserted and performance, there are a few ways to create and configure it:

- `new<K, V>(): Self<K, V>`: Returns a new `BigOrderedMap` with the default configuration. Only allowed to be called with constant size types. For variable sized types, another constructor is needed, to explicitly select automatic or specific degree selection.
- `new_with_type_size_hints<K, V>(avg_key_bytes: u64, max_key_bytes: u64, avg_value_bytes: u64, max_value_bytes: u64): Self<K, V>`: Returns a map that is configured to perform best when keys and values are of given `avg` sizes, and guarantees to fit elements up to given `max` sizes.
- `new_with_config<K, V>(inner_max_degree: u16, leaf_max_degree: u16, reuse_slots: bool): Self<K, V>`: Returns a new `BigOrderedMap` with the provided max degree consts (the maximum # of children a node can have, both inner and leaf). If 0 is passed for either, then it is dynamically computed based on size of first key and value, and keys and values up to 100x times larger will be accepted.
  If non-0 is passed, sizes of all elements must respect (or their additions will be rejected):

  - `key_size * inner_max_degree <= MAX_NODE_BYTES`
  - `entry_size * leaf_max_degree <= MAX_NODE_BYTES`

  `reuse_slots` means that removing elements from the map doesn't free the storage slots and returns the refund.
  Together with `allocate_spare_slots`, it allows to preallocate slots and have inserts have predictable gas costs.
  (otherwise, inserts that require map to add new nodes, cost significantly more, compared to the rest)

## Source Code

- [ordered\_map.move](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/datastructures/ordered_map.move)
- [table.move](https://github.com/aptos-labs/aptos-core/blob/6f5872b567075fe3615e1363d35f89dc5eb45b0d/aptos-move/framework/aptos-stdlib/sources/table.move)
- [table\_with\_length.move](https://github.com/aptos-labs/aptos-core/blob/6f5872b567075fe3615e1363d35f89dc5eb45b0d/aptos-move/framework/aptos-stdlib/sources/table.move)
- [big\_ordered\_map.move](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/datastructures/big_ordered_map.move)

## Additional details of (deprecated) SmartTable

The Smart Table is a scalable hash table implementation based on linear hashing.
This data structure aims to optimize storage and performance by utilizing linear hashing, which splits one bucket at a time instead of doubling the number of buckets, thus avoiding unexpected gas costs.
Unfortunately, it's implementation makes every addition/removal be a conflict, making such transactions fully sequential.
The Smart Table uses the SipHash function for faster hash computations while tolerating collisions. Unfortunately, this also means that collisions are predictable, which means that if end users can control the keys being inserted, it can have large number of collisions in a single bucket.

### SmartTable Structure

The `SmartTable` struct is designed to handle dynamic data efficiently:

- `buckets`: A table with a length that stores vectors of entries.
- `num_buckets`: The current number of buckets.
- `level`: The number of bits representing `num_buckets`.
- `size`: The total number of items in the table.
- `split_load_threshold`: The load threshold percentage that triggers bucket splits.
- `target_bucket_size`: The target size of each bucket, which is not strictly enforced.

### SmartTable usage examples

- [Move Spiders Smart Table](https://movespiders.com/courses/modules/datastructures/lessonId/7)
- [Move Spiders Querying Smart Table via FullNode APIs](https://movespiders.com/courses/modules/datastructures/lessonId/9)
- [Move Spiders Querying Smart Table via View Function](https://movespiders.com/courses/modules/datastructures/lessonId/10)

# Modules on Aptos

> Learn about modules on aptos for Move smart contract development on Aptos blockchain.

import { Aside } from '@astrojs/starlight/components';

Aptos allows for permissionless publishing of [modules](/build/smart-contracts/book/modules-and-scripts)
within a [package](/build/smart-contracts/book/packages) as well as [upgrading](/build/smart-contracts/book/package-upgrades)
those that have appropriate compatibility policy set.

A module contains several structs and functions, much like Rust.

During package publishing time, a few constraints are maintained:

- Both Structs and public function signatures are published as immutable.
- The `init_module` function plays a crucial role in module initialization:
  - When a module is published for the first time (i.e., the module does not exist on-chain), the VM will search for and execute the `init_module(account: &signer)` function.
  - When upgrading an existing module that is already on-chain, the `init_module` function will NOT be called.
  - The signer of the account that is publishing the module is passed into the `init_module` function.
  - **This function must be private and not return any value.**
  - The `init_module` function can have at most one parameter, and its type must be `&signer`
  - The `init_module` function should not have generic parameters
  - The `init_module` function is commonly used to initialize module-specific data structures or set initial states.

<Aside type="note">
  `init_module` is optional. You only need to implement it if you want to:

  - Initialize module data when publishing a module for the first time
  - Set up initial states or configurations
  - Create resource accounts or other module-specific setup tasks
</Aside>

<Aside type="tip">
  Remember: The `init_module` function will only be called once in a module's lifecycle - when it is first published.
  Subsequent upgrades to the module will not trigger the `init_module` function again.
</Aside>

# Move Reference

> Learn about move reference for Move smart contract development on Aptos blockchain.

{/* <MoveReference /> */}

# Move Security Guidelines

> Learn about move security guidelines for Move smart contract development on Aptos blockchain.

import { Aside } from '@astrojs/starlight/components';

The Move language is designed with security and inherently offers several features including a type system and a linear logic. Despite this, its novelty and the intricacies of some business logic mean that developers might not always be familiar with Move's secure coding patterns, potentially leading to bugs.

This guide addresses this gap by detailing common anti-patterns and their secure alternatives. It provides practical examples to illustrate how security issues can arise and recommends best practices for secure coding. This guide aims to sharpen developers' understanding of Move's security mechanisms and ensure the robust development of smart contracts.

## Access Control

### Object Ownership Check

Every `Object<T>` can be accessed by anyone, which means any `Object<T>` can be passed to any function, even if the caller doesn't own it.
It's important to verify that the `signer` is the rightful owner of the object.

#### Example Insecure Code

In this module, a user must purchase a subscription before performing certain actions. The user invokes the registration function to acquire an `Object<Subscription>`, which they can later use to execute operations.

```move filename="object_example.move"
module 0x42::example {

    struct Subscription has key {
        end_subscription: u64
    }

    entry fun registration(user: &signer, end_subscription: u64) {
        let price = calculate_subscription_price(end_subscription);
        payment(user,price);

        let user_address = address_of(user);
        let constructor_ref = object::create_object(user_address);
        let subscription_signer = object::generate_signer(&constructor_ref);
        move_to(&subscription_signer, Subscription { end_subscription });
    }

    entry fun execute_action_with_valid_subscription(
        user: &signer, obj: Object<Subscription>
    ) acquires Subscription {
        let object_address = object::object_address(&obj);
        let subscription = borrow_global<Subscription>(object_address);
        assert!(subscription.end_subscription >= aptos_framework::timestamp::now_seconds(), 1);
        // Use the subscription
        [...]
    }
}
```

In this insecure example, `execute_action_with_valid_subscription` does not verify if the user owns the `obj` passed to it. Consequently, anyone can use another person's subscription, bypassing the payment requirement.

#### Example Secure Code

Ensure that the signer owns the object.

```move filename="object_example.move"
module 0x42::example {

    struct Subscription has key {
        end_subscription: u64
    }

    entry fun registration(user: &signer, end_subscription: u64) {
        let price = calculate_subscription_price(end_subscription);
        payment(user,price);

        let user_address = address_of(user);
        let constructor_ref = object::create_object(user_address);
        let subscription_signer = object::generate_signer(&constructor_ref);
        move_to(&subscription_signer, Subscription { end_subscription });
    }

    entry fun execute_action_with_valid_subscription(
        user: &signer, obj: Object<Subscription>
    ) acquires Subscription {
        //ensure that the signer owns the object.
        assert!(object::owner(&obj) == address_of(user), ENOT_OWNWER);
        let object_address = object::object_address(&obj);
        let subscription = borrow_global<Subscription>(object_address);
        assert!(subscription.end_subscription >= aptos_framework::timestamp::now_seconds(), 1);
        // Use the subscription
        [...]
    }
}
```

### Global Storage Access Control

Accepting a `&signer` is not always sufficient for access control purposes. Be sure to assert that the signer is the expected account, especially when performing sensitive operations.

Users without proper authorization can execute privileged actions.

#### Example Insecure Code

This code snippet allows any user invoking the `delete` function to remove an `Object`, without verifying that the caller has the necessary permissions.

```move filename="global_storage_insecure.move"
module 0x42::example {
  struct Object has key{
    data: vector<u8>
  }

  public fun delete(user: &signer, obj: Object) {
    let Object { data } = obj;
  }
}
```

#### Example Secure Code

A better alternative is to use the global storage provided by Move, by directly borrowing data off of `signer::address_of(signer)`. This approach ensures robust access control, as it exclusively accesses data contained within the address of the signer of the transaction. This method minimizes the risk of access control errors, ensuring that only the data owned by the `signer` can be manipulated.

```move filename="global_storage_secure.move"
module 0x42::example {
  struct Object has key{
    data: vector<u8>
  }

  public fun delete(user: &signer) {
    let Object { data } = move_from<Object>(signer::address_of(user));
  }
}
```

### Function visibility

Adhere to the principle of least privilege:

- Always start with private functions, change their visibility as it is needed by the business logic.
- Utilize `entry` for functions intended for use solely from the Aptos CLI or SDK.
- Utilize `friend` for functions that can only be accessible by specific modules.
- Utilize the `#[view]` decorator with functions that read data from storage without altering state. #\[view] functions can be invoked indirectly and in this case they might change the storage.

Function visibility determines who can call a function. It's a way to enforce access control and is critical for smart contract security:

- private functions are only callable within the module they are defined in. They're not accessible from other modules or from the CLI/SDK, which prevents unintended interactions with contract internals.

```move filename="private_function.move"
module 0x42::example {
  fun sample_function() { /* ... */ }
}
```

- `public(friend)` functions expand on this by allowing specified _friends_ modules to call the function, enabling controlled interaction between different contracts while still restricting general access.

```move filename="friend_function.move"
module 0x42::example {
  friend package::mod;

  public(friend) fun sample_function() { /* ... */ }
}
```

- `public` functions are callable by any published module or script.

```move filename="public_function.move"
module 0x42::example {
  public fun sample_function() { /* ... */ }
}
```

- `#[view]` decorated functions cannot alter storage; they only read data, providing a safe way to access information without risking state modification.

```move filename="view_function.move"
module 0x42::example {
  #[view]
  public fun read_only() { /* ... */ }
}
```

- The `entry` modifier in Move is used to indicate entry points for transactions. Functions with the `entry` modifier serve as the starting point of execution when a transaction is submitted to the blockchain.

```move filename="entry_function.move"
module 0x42::example {
  entry fun f(){}
}
```

To summarize:

|                | Module itself | Other Modules                | Aptos CLI/SDK |
| -------------- | ------------- | ---------------------------- | ------------- |
| private        | ‚úÖ             | ‚õî                            | ‚õî             |
| public(friend) | ‚úÖ             | ‚úÖ if friend<br />‚õî otherwise | ‚õî             |
| public         | ‚úÖ             | ‚úÖ                            | ‚õî             |
| entry          | ‚úÖ             | ‚õî                            | ‚úÖ             |

This layered visibility ensures that only authorized entities can execute certain functions, greatly reducing the risk of bugs or attacks that compromise contract integrity.

Note that it‚Äôs possible to combine `entry` with `public` or `public(friend)`

```move filename="friend_entry_function.move"
module 0x42::example {
  public(friend) entry fun sample_function() { /* ... */ }
}
```

In this case `sample_function` can be called by both the Aptos CLI/SDK by any module declared as a friend.

#### Impact

Adhering to this principle ensures that functions are not over-exposed, restricting the scope of function access to only what is necessary for the business logic.

## Types and Data Structures

### Generics type check

Generics can be used to define functions and structs over different input data types. When using them, ensure that the generic types are valid and what‚Äôs expected. [Read more](/build/smart-contracts/book/generics) about generics.

Unchecked generics can lead to unauthorized actions or transaction aborts, potentially compromising the integrity of the protocol.

#### Example Insecure Code

The code below outlines a simplified version of a flash loan.

In the `flash_loan<T>` function, a user can borrow a given amount of coins type **`T`** along with a `Receipt` that records the borrowed amount plus a fee that should be returned to the protocol before the end of the transaction.

The `repay_flash_loan<T>` function accepts a `Receipt` and a `Coin<T>` as parameters. The function extracts the repayment amount from the `Receipt` and asserts that the value of the returned `Coin<T>` is greater than or equal to the amount specified in the `Receipt`, however there‚Äôs no check to ensure that the `Coin<T>` returned is the same as the `Coin<T>`that was initially loaned out, giving the ability to repay the loan with a coin of lesser value.

```move filename="flash_loan_insecure.move"
module 0x42::example {
  struct Coin<T> {
    amount: u64
  }

  struct Receipt {
    amount: u64
  }

  public fun flash_loan<T>(user: &signer, amount: u64): (Coin<T>, Receipt) {
    let (coin, fee) = withdraw(user, amount);
    ( coin, Receipt {amount: amount + fee} )
  }

  public fun repay_flash_loan<T>(rec: Receipt, coins: Coin<T>) {
    let Receipt{ amount } = rec;
    assert!(coin::value<T>(&coins) >= rec.amount, 0);
    deposit(coins);
  }
}
```

#### Example Secure Code

The Aptos Framework sample below creates a key-value table consisting of two generic types `K` and `V` . Its related `add` functions accepts as parameters a `Table<K, V>` object, a `key`, and a `value` of types `K` and `V` . The `phantom` syntax ensures that the key and value types cannot be different than those in the table, preventing type mismatches. [Read more](/build/smart-contracts/book/generics#phantom-type-parameters) about `phantom` type parameters.

```move filename="table_secure.move"
module 0x42::example {
  struct Table<phantom K: copy + drop, phantom V> has store {
    handle: address,
  }

  public fun add<K: copy + drop, V>(table: &mut Table<K, V>, key: K, val: V) {
    add_box<K, V, Box<V>>(table, key, Box { val })
  }
}
```

Given the by-design type checking provided by the Move language, we can refine the code of our flash loan protocol. The code below ensures that the coins passed to `repay_flash_loan` match the originally-loaned coins.

```move filename="flash_loan_secure.move"
module 0x42::example {
  struct Coin<T> {
    amount: u64
  }
  struct Receipt<phantom T> {
    amount: u64
  }

  public fun flash_loan<T>(_user: &signer, amount:u64): (Coin<T>, Receipt<T>) {
    let (coin, fee) = withdraw(_user, amount);
    (coin,Receipt { amount: amount + fee})
  }

  public fun repay_flash_loan<T>(rec: Receipt<T>, coins: Coin<T>) {
    let Receipt{ amount } = rec;
    assert!(coin::value<T>(&coins) >= rec.amount, 0);
    deposit(coins);
  }
}
```

### Resource management and Unbounded Execution

Effective resource management and unbounded execution prevention are important for maintaining security and gas efficiency in protocol. It's essential to consider these aspects in contract design:

1. Avoid iterating over a publicly accessible structure that allows for unlimited entries, where any number of users can contribute without constraints.
2. Store user-specific assets, such as coins and NFTs, within individual user accounts.
3. Keep module or package-related information within Objects, separate from user data.
4. Instead of combining all user operations in a single shared global space, separating them by individual users.

#### Impact

The negligence of these aspects allowing an attacker to deplete the gas and abort the transaction. This can block application functionalities.

#### Example Insecure Code

The code below shows a loop iterating over every open order and could potentially be blocked by registering many orders:

```move filename="order_insecure.move"
module 0x42::example {
  public fun get_order_by_id(order_id: u64): Option<Order> acquires OrderStore {
    let order_store = borrow_global_mut<OrderStore>(@admin);
    let i = 0;
    let len = vector::length(&order_store.orders);
    while (i < len) {
      let order = vector::borrow<Order>(&order_store.orders, i);
      if (order.id == order_id) {
        return option::some(*order)
      };
      i = i + 1;
    };
    return option::none<Order>()
  }
  //O(1) in time and gas operation.
  public entry fun create_order(buyer: &signer) { /* ... */ }
}
```

#### Example Secure Code

It's recommended to structure the order management system in a way that each user's orders are stored in their respective account rather than in a single global order store. This approach not only enhances security by isolating user data but also improves scalability by distributing the data load. Instead of using **`borrow_global_mut<OrderStore>(@admin)`** which accesses a global store, the orders should be accessed through the individual user's account.

```move filename="order_secure.move"
module 0x42::example {
  public fun get_order_by_id(user: &signer, order_id: u64): Option<Order> acquires OrderStore {
    let order_store = borrow_global_mut<OrderStore>(signer::address_of(user));
    if (smart_table::contains(&order_store.orders, order_id)) {
      let order = smart_table::borrow(&order_store.orders, order_id);
      option::some(*order)
    } else {
      option::none<Order>()
    }
  }
}
```

It is also advisable to utilize efficient data structures tailored to the specific needs of the operations being performed. For instance, a **`SmartTable`** can be particularly effective in this context.

### Move Abilities

Move's abilities are a set of permissions that control the possible actions on data structures within the language. Smart contract developers must handle these capabilities with care, ensuring they're only assigned where necessary and understanding their implications to prevent security vulnerabilities.

| Ability | Description                                                                                                            |
| ------- | ---------------------------------------------------------------------------------------------------------------------- |
| copy    | Permits the duplication of values, allowing them to be used multiple times within the contract.                        |
| drop    | Allows values to be discarded from memory, which is necessary for controlling resources and preventing leaks.          |
| store   | Enables data to be saved in the global storage, critical to persist data across transactions.                          |
| key     | Grants data the ability to serve as a key in global storage operations, important for data retrieval and manipulation. |

[Read more](/build/smart-contracts/book/abilities) about abilities.

Incorrect usage of abilities can lead to security issues such as unauthorized copying of sensitive data (`copy`), resource leaks (`drop`), and global storage mishandling (`store`).

#### Example Insecure Code

```move filename="abilities_insecure.move"
module 0x42::example {
  struct Token has copy { }
  struct FlashLoan has drop { }
}
```

- `copy` capability for a `Token` allows tokens to be replicated, potentially enabling double-spending and inflation of the token supply, which could devalue the currency.
- Allowing the `drop` capability in a `FlashLoan` struct could permit borrowers to get out of their loan by destroying it before repayment.

## Arithmetic Operations

***

### Division Precision

Arithmetic operations that decrease precision by rounding down could lead protocols to underreport the outcome of these computations.

Move includes six unsigned integer data types: `u8`, `u16`, `u32`, `u64`, `u128`, and `u256`. Division operations in Move truncate any fractional part, effectively rounding down to the nearest whole number, potentially causing protocols to underrepresent the result of such calculations.

Rounding errors in calculations can have wide-ranging impacts, potentially causing financial imbalances, data inaccuracies, and flawed decision-making processes. These errors can result in a loss of revenue, give undue benefits, or even pose safety risks, depending on the context. Accurate and precise computation is essential to maintain system reliability and user confidence.

#### Example Insecure Code

```move filename="division_insecure.move"
module 0x42::example {
  public fun calculate_protocol_fees(size: u64): (u64) {
    return size * PROTOCOL_FEE_BPS / 10000
  }
}
```

If `size` is less than `10000 / PROTOCOL_FEE_BPS`, the fee will round down to 0, effectively enabling a user to interact with the protocol without incurring any fees.

#### Example Secure Code

The following examples outlines two distinct strategies to mitigate the issue in the code:

- Set a minimum order size threshold that is greater than `10000 / PROTOCOL_FEE_BPS`, ensuring that the fee will never round down to zero.

```move filename="division_secure_min.move"
module 0x42::example {
  const MIN_ORDER_SIZE: u64 = 10000 / PROTOCOL_FEE_BPS + 1;

  public fun calculate_protocol_fees(size: u64): (u64) {
    assert!(size >= MIN_ORDER_SIZE, 0);
    return size * PROTOCOL_FEE_BPS / 10000
  }
}
```

- Check that fees are non-zero and handle the situation specifically, for example by set a minimum fee or rejecting the transaction.

```move filename="division_secure_check.move"
module 0x42::example {
  public fun calculate_protocol_fees(size: u64): (u64) {
    let fee = size * PROTOCOL_FEE_BPS / 10000;
    assert!(fee > 0, 0);
    return fee;
  }
}
```

### Integer Considerations

In Move, the security around integer operations is designed to prevent overflow and underflow which can cause unexpected behavior or vulnerabilities. Specifically:

- Additions (`+`) and multiplications (`*`) cause the program to abort if the result is too large for the integer type. An abort in this context means that the program will terminate immediately.
- Subtractions (`-`) abort if the result is less than zero.
- Division (`/`) abort if the divisor is zero.
- Left Shift (`<<`), uniquely, does not abort in the event of an overflow. This means if the shifted bits exceed the storage capacity of the integer type, the program will not terminate, resulting in incorrect values or unpredictable behavior.

[Read more](/build/smart-contracts/book/integers#operations) about operations.

Bad operations could unexpectedly alter the correct execution of the smart contract, either by causing an unwanted abort or by calculating inaccurate data.

## Aptos Objects

***

### ConstructorRef leak

When creating objects ensure to never expose the object‚Äôs `ConstructorRef` as it allows adding resources to an object. A `ConstructorRef` can also be used to generate other capabilities (or "Refs") that are used to alter or transfer the ownership the object. [Read more](/build/smart-contracts/object/creating-objects) about Objects capabilities.

#### Example Vulnerable code

For example, if a `mint` function returns the `ConstructorRef` for an NFT, it can be transformed to a `TransferRef`, stored in global storage, and can allow the original owner to transfer the NFT back after it‚Äôs being sold.

```move filename="constructor_ref_vulnerable.move"
module 0x42::example {
  use std::string::utf8;

  public fun mint(creator: &signer): ConstructorRef {
    let constructor_ref = token::create_named_token(
        creator,
        string::utf8(b"Collection Name"),
        string::utf8(b"Collection Description"),
        string::utf8(b"Token"),
        option::none(),
        string::utf8(b"https://mycollection/token.jpeg"),
    );
    constructor_ref
  }
}
```

#### Example Secure Code

Don‚Äôt return `CostructorRef` in the `mint` function:

```move filename="constructor_ref_secure.move"
module 0x42::example {
  use std::string::utf8;

  public fun mint(creator: &signer) {
    let constructor_ref = token::create_named_token(
        creator,
        string::utf8(b"Collection Name"),
        string::utf8(b"Collection Description"),
        string::utf8(b"Token"),
        option::none(),
        string::utf8(b"https://mycollection/token.jpeg"),
    );
  }
}
```

### Object Accounts

In the Aptos Framework, multiple `key`-able resources can be stored at a single object account.

However, objects should be isolated to different account, otherwise modifications to one object within an account can influence the entire collection.

For example, transferring one resource implies the transfer of all group members, since the transfer function operates on `ObjectCore`, which is essentially a general tag for all resources at the account.

[Read more](/build/smart-contracts/objects) about Aptos Objects.

#### Example Insecure Code

The `mint_two` function lets `sender` create a `Monkey` for themselves and send a `Toad` to `recipient`.

As `Monkey` and `Toad` belong to the same object account the result is that both objects‚Äô are now owned by the `recipient`.

```move filename="object_accounts_insecure.move"
module 0x42::example {
  #[resource_group(scope = global)]
  struct ObjectGroup { }

  #[resource_group_member(group = 0x42::example::ObjectGroup)]
  struct Monkey has store, key { }

  #[resource_group_member(group = 0x42::example::ObjectGroup)]
  struct Toad has store, key { }

  fun mint_two(sender: &signer, recipient: &signer) {
    let constructor_ref = &object::create_object_from_account(sender);
    let sender_object_signer = object::generate_signer(constructor_ref);
    let sender_object_addr = object::address_from_constructor_ref(constructor_ref);

    move_to(sender_object_signer, Monkey{});
    move_to(sender_object_signer, Toad{});
    let monkey_object: Object<Monkey> = object::address_to_object<Monkey>(sender_object_addr);
    object::transfer<Monkey>(sender, monkey_object, signer::address_of(recipient));
  }
}
```

#### Example Secure Code

In this example, objects should be stored at separate object accounts:

```move filename="object_accounts_secure.move"
module 0x42::example {
  #[resource_group(scope = global)]
  struct ObjectGroup { }

  #[resource_group_member(group = 0x42::example::ObjectGroup)]
  struct Monkey has store, key { }

  #[resource_group_member(group = 0x42::example::ObjectGroup)]
  struct Toad has store, key { }

  fun mint_two(sender: &signer, recipient: &signer) {
    let sender_address = signer::address_of(sender);

    let constructor_ref_monkey = &object::create_object(sender_address);
    let constructor_ref_toad = &object::create_object(sender_address);
    let object_signer_monkey = object::generate_signer(&constructor_ref_monkey);
    let object_signer_toad = object::generate_signer(&constructor_ref_toad);

    move_to(object_signer_monkey, Monkey{});
    move_to(object_signer_toad, Toad{});

    let object_address_monkey = signer::address_of(&object_signer_monkey);

    let monkey_object: Object<Monkey> = object::address_to_object<Monkey>(object_address_monkey);
    object::transfer<Monkey>(sender, monkey_object, signer::address_of(recipient));
  }
}
```

## Business logic

### Front-running

Front-running involves executing transactions ahead of others by exploiting knowledge of future actions already made by others. This tactic gives front-runners an unfair advantage, as they can anticipate and benefit from the outcomes of these pending transactions.

Front-running can undermine the fairness and integrity of a decentralized application. It can lead to loss of funds, unfair advantages in games, manipulation of market prices, and a general loss of trust in the platform

#### Example Insecure Code

In a lottery scenario, users participate by selecting a number from 1 to 100. At a certain point, the game administrator invokes the function `set_winner_number` to set the winning number. Subsequently, in a separate transaction, the administrator reviews all player bets to determine the winner via `evaluate_bets_and_determine_winners`.

A front-runner observing the winning number set by `set_winner_number` could attempt to submit a late bet or modify an existing bet to match the winning number before `evaluate_bets_and_determine_winners` executes.

```move filename="front_running_insecure.move"
module 0x42::example {
  struct LotteryInfo {
    winning_number: u8,
    is_winner_set: bool,
  }

  struct Bets { }

  public fun set_winning_number(admin: &signer, winning_number: u8) {
    assert!(signer::address_of(admin) == @admin, 0);
    assert!(winning_number < 10, 0);
    let lottery_info = LotteryInfo { winning_number, is_winner_set: true };
    move_to<LotteryInfo>(admin, lottery_info);
  }

  public fun evaluate_bets_and_determine_winners(admin: &signer) acquires LotteryInfo, Bets {
    assert!(signer::address_of(admin) == @admin, 0);
    let lottery_info = borrow_global<LotteryInfo>(admin);
    assert(lottery_info.is_winner_set, 1);

    let bets = borrow_global<Bets>(admin);
    let winners: vector<address> = vector::empty();

    let winning_bets_option = smart_table::borrow_with_default(&bets.bets, lottery_info.winning_number, &vector::empty());

    vector::iter(winning_bets_option, |bet| {
       vector::push_back(&mut winners, bet.player);
    });
    distribute_rewards(&winners);
  }
}
```

#### Example Secure Code

An effective strategy to avoid front-running could be implementing a `finalize_lottery` function that reveals the answer and concludes the game within a single transaction, and making the other functions private. This approach guarantees that as soon as the answer is disclosed, the system no longer accepts any new answers, thereby eliminating the chance for front-running.

```move filename="front_running_secure.move"
module 0x42::example {
  public fun finalize_lottery(admin: &signer, winning_number: u64) {
    set_winner_number(admin, winning_number);
    evaluate_bets_and_determine_winners(admin);
  }

  fun set_winning_number(admin: &signer, winning_number: u64) { }

  fun evaluate_bets_and_determine_winners(admin: &signer) acquires LotteryInfo, Bets { }
}
```

### Price Oracle Manipulation

In Defi applications, price oracles that utilize the liquidity ratio of tokens in a pair to determine prices for transactions can be vulnerable to manipulation. This susceptibility arises from the fact that the liquidity ratio can be influenced by market participants who hold a significant amount of tokens. When these participants strategically increase or decrease their token holdings, it can impact the liquidity ratio and consequently affect the prices determined by the price oracle, potentially draining the pool.

We recommend to use multiple oracles to determine prices.

#### Secure Code Example

Thala, for example, utilizes a tiered-oracle design. The system has a primary and a secondary oracle. Should one of the oracles fail, the other one serves as a backup based on a sophisticated switching logic. The system is designed with adversarial situations in mind, and strives to provide highly accurate price feeds with minimal governance interaction all the time.

For more in-depth information, refer to [Thala's documentation](https://docs.thala.fi/thala-protocol-design/move-dollar-mod/oracles).

### Token Identifier Collision

When dealing with tokens, ensure that the method for comparing token structs to establish a deterministic ordering does not lead to collisions. Concatenating the address, module, and struct names into a vector is insufficient, as it does not differentiate between similar names that should be treated as unique.

As a consequence, the protocol may erroneously reject legitimate swap pairs due to collisions in token struct comparisons. This oversight could compromise the integrity of swap operations, leading to a loss of funds.

#### Example Insecure Code

The `get_pool_address` function creates a unique address for a liquidity pool associated with trading pairs of fungible assets. It generates and returns an address that serves as a distinct identifier for the liquidity pool of the specified two tokens.

However, users have the freedom to create an `Object<Metadata>` with any symbol they choose. This flexibility could lead to the creation of `Object<Metadata>` instances that mimic other existing instances. This issue might result in a seed collision, which in turn could cause a collision in the generation of the pool address.

```move filename="token_collision_insecure.move"
module 0x42::example {
  public fun get_pool_address(token_1: Object<Metadata>, token_2: Object<Metadata>): address {
    let token_symbol = string::utf8(b"LP-");
    string::append(&mut token_symbol, fungible_asset::symbol(token_1));
    string::append_utf8(&mut token_symbol, b"-");
    string::append(&mut token_symbol, fungible_asset::symbol(token_2));
    let seed = *string::bytes(&token_symbol);
    object::create_object_address(&@swap, seed)
  }
}
```

#### Example Secure Code

`object::object_address` returns an unique identifier for each `Object<Metadata>`

```move filename="token_collision_secure.move"
module 0x42::example {
  public fun get_pool_address(token_1: Object<Metadata>, token_2: Object<Metadata>): address {
    let seeds = vector[];
    vector::append(&mut seeds, bcs::to_bytes(&object::object_address(&token_1)));
    vector::append(&mut seeds, bcs::to_bytes(&object::object_address(&token_2)));
    object::create_object_address(&@swap, seeds)
  }
}
```

## Operations

***

### Pausing functionality

Protocols should have the ability to pause operations effectively. For immutable protocols, a built-in pause functionality is necessary. Upgradable protocols can achieve pausing either through smart contract functionality or via protocol upgrades. Teams should be equipped with automation for the quick and efficient execution of this process.

The absence of a pausing mechanism can lead to prolonged exposure to vulnerabilities, potentially resulting in significant losses. An efficient pausing functionality allows for prompt response to security threats, bugs, or other critical issues, minimizing the risk of exploitation and ensuring the safety of user assets and protocol integrity.

#### Example Secure Code

Example of how to integrate a pause functionality

```move filename="pause_functionality.move"
module 0x42::example {
  struct State {
    is_paused: bool,
  }

  public entry fun pause_protocol(admin: &signer) {
    assert!(signer::address_of(admin) == @protocol_address, ERR_NOT_ADMIN);
    let state = borrow_global_mut<State>(@protocol_address);
    state.is_paused = true;
  }

  public entry fun resume_protocol(admin: &signer) {
    assert!(signer::address_of(admin) == @protocol_address, ERR_NOT_ADMIN);
    let state = borrow_global_mut<State>(@protocol_address);
    state.is_paused = false;
  }

  public fun main(user: &signer) {
    let state = borrow_global<State>(@protocol_address);
    assert!(!state.is_paused, 0);
    // ...
  }
}
```

### Smart contract publishing key management

Using the same account for testnet and mainnet poses a security risk, as testnet private keys, often stored in less secure environments (ex. laptops), can be more easily exposed or leaked. An attacker that can obtain the private key for the testnet smart contract would be able to upgrade the mainnet one.

## Randomness

For more information on randomness and why it is crucial for preventing the predictability of random numbers, please refer to this page: [Randomness Guide](/build/smart-contracts/randomness).

***

### Randomness - test-and-abort

> At Aptos, We are always security-first. During compilation, we ensure that no randomness API is invoked from a public function. However, we still allow users to make this choice by adding the attribute `#[lint::allow_unsafe_randomness]` to the public function.

If a `public` function directly or indirectly invokes the randomness API, a malicious user can abuse the composability of this function and abort the transaction if the result is not as desired. This allows the user to keep trying until they achieve a beneficial outcome, undermining the randomness.

#### Example Vulnerable code

```move filename="randomness_example.move"
module user::lottery {
    fun mint_to_user(user: &signer) {
        move_to(user, WIN {});
    }

    #[lint::allow_unsafe_randomness]
    public entry fun play(user: &signer) {
        let random_value = aptos_framework::randomness::u64_range(0, 100);
        if (random_value == 42) {
            mint_to_user(user);
        }
    }
}
```

In this example, the `play` function is `public`, allowing it to be composed with other modules. A malicious user can invoke this function and then check if they have won. If they have not won, they can abort the transaction and try again.

```move filename="randomness_example.move"
module attacker::exploit {
    entry fun exploit(attacker: &signer) {
        @user::lottery::play(attacker);
        assert!(exists<@user::lottery::WIN>(address_of(attacker)));
    }
}
```

To resolve the possible issue, is sufficient to set the visibility of all functions that invoke the randomness API, either directly or indirectly, to `entry` rather than `public` or `public entry`.

#### Example Secure Code

```move filename="randomness_example.move"
module user::lottery {
    fun mint_to_user(user: &signer) {
        move_to(user, WIN {});
    }

    #[lint::allow_unsafe_randomness]
    entry fun play(user: &signer) {
        let random_value = aptos_framework::randomness::u64_range(0, 100);
        if (random_value == 42) {
            mint_to_user(user);
        }
    }
}
```

### Randomness - undergasing

When different code paths in a function consume different amounts of gas, an attacker can manipulate the gas limit to bias the outcome. Let's look at an example of how different paths can consume different amounts of gas.

#### Example Vulnerable code

```move filename="randomness_example.move"
module user::lottery {

    //transfer 10 aptos from admin to user
    fun win(user: &signer) {
        let admin_signer = &get_admin_signer();
        let aptos_metadata = get_aptos_metadata();
        primary_fungible_store::transfer(admin_signer, aptos_metadata, address_of(user),10);
    }

    //transfer 10 aptos from user to admin, then 1 aptos from admin to fee_admin
    fun lose(user: &signer) {

        //user to admin
        let aptos_metadata = get_aptos_metadata();
        primary_fungible_store::transfer(user, aptos_metadata, @admin, 10);

        //admin to fee_admin
        let admin_signer = &get_admin_signer();
        primary_fungible_store::transfer(admin_signer, aptos_metadata, @fee_admin, 1);
    }

    #[randomness]
    entry fun play(user: &signer) {
        let random_value = aptos_framework::randomness::u64_range(0, 100);
        if (random_value == 42) {
            win(user);
        } else {
            lose(user);
        }
    }
}
```

In this lottery-example, `win` and `lose` consume different amounts of gas.
The `lose` function consumes more gas than the `win` function. An attacker can set the max gas limit that is sufficient for `win` but not for `lose`. This forces the transaction to abort when the `lose` path is taken, ensuring that the user will never execute the `lose` path. Then, the user can call the function repeatedly until they win.

#### Example Secure Code

There are different ways to secure the code:

1. Ensure better outcomes use more or the same gas as worse outcomes.
2. Allow only admin addresses to invoke the randomness API.
3. Ensure entry functions work regardless of random outcomes. This can be handled by committing the random result, then using the random result to provide the action in a different transaction. Avoid immediate actions based on randomness for consistent gas use.

> We will be providing more functionality in the future, to allow for more complex code to be able to be safe against undergasing attacks.

## Reentrancy

A **reentrancy attack** occurs when a contract performs an external call that can invoke the original contract again _before it finishes updating its state_. This can let an attacker repeat state-dependent actions (e.g., multiple withdrawals) against **stale state**.

Historically, Move prevented reentrancy. With the introduction of **function values**, certain forms of reentrancy are now possible under specific conditions. By contrast, **dispatchable fungible assets** remain protected against reentrancy.

<Aside type="note" emoji="‚ÑπÔ∏è" title="Dispatchable Fungible Assets">
  **No reentrancy permitted.** All native dispatchable functions are **locked against re-entering an active module** (a module already invoked within the current transaction).
</Aside>

***

## Function Values

Since language version **2.2**, Move supports **function values** (first-class functions). Function values can be stored, and passed around like any other value.

<Aside type="caution" emoji="üö®">
  Function values are **not** locked against reentrancy. Callbacks via function values can re-enter the original module.
</Aside>

```mermaid
graph LR
  %% Stable: no quotes, no parentheses, no double colons, no special edge labels.

  %% Left (no function values)
  A[Without Function Values]
  m1a[m1]
  m2a[m2]
  noteA[acyclic usage -> no reentrancy]
  A --- m1a
  m1a --> m2a
  m2a --- noteA

  %% Right (with function values)
  B[With Function Values]
  m1b[m1]
  call1[call m2.f passing FV]
  m2b[m2]
  cb1[callback to m1 via FV]
  noteB[closure dynamic dispatch -> reentrancy possible]
  B --- m1b
  m1b --> call1 --> m2b
  m2b -.-> cb1 -.-> m1b
  m2b --- noteB
```

***

### Resource Locking

To preserve Move‚Äôs reference semantics and suppress side effects from reentrancy, **re-entered modules cannot access their own resources** during dynamic dispatch through a closure. Attempts to borrow or move such resources **abort**.

Examples that will abort on re-entry:

- `borrow_global<m::R>(addr)`
- `move_from<m::R>(addr)`

[Read more](/build/smart-contracts/book/functions#reentrancy-check) about the function-value reentrancy checks.

### Time-of-Check vs Time-of-Use (TOCTOU)

Function values (FVs) can be stored inside wrapper structs and moved to global storage. Because FVs can **capture local variables**, scenarios arise where a value is **checked now** but **used later** (after state changes), leading to TOCTOU bugs.

```move filename="function_value_struct.move"
module example::function_value_struct {
    struct S {
        fn: |u64| u64
    }
}
```

**Guidance:**

- If an **amount** (or any state-derived value) is validated before creating the FV, **re-validate it at invocation time**‚Äîespecially if the FV (or a struct containing it) is stored in global storage and called later.
- There is **no guarantee** that the state captured by an FV remains unchanged by the time the FV executes (or that it executes at all).

**Safer pattern‚Äîcapture a concrete resource:**

Capturing a concrete value whose identity is stable and which has the `store` ability is generally safer for long-lived function values‚Äîespecially when the function value must be stored in global storage. This avoids relying on state-derived values that can change between time-of-check and time-of-use.

Important: `FungibleAsset` does not have the `store` ability. Any function value that captures a `FungibleAsset` therefore cannot itself be storable. If you need a storable function value, capture a separate, concrete resource that records the intended action (for example, a voucher/grant) and then perform the FA operation at invocation time.

This approach assumes that the FA is acquired and stored under a controlled FungibleStore without any state changes. Only at the time of voucher use and destruction are state changes or operations performed.

Example: capturing a storable voucher resource, then currying a persistent function so the resulting function value is storable:

```move filename="voucher_example.move"
module example::vouchers {
    use std::signer;

    // Concrete resource with store ability; identity and contents are fixed at capture time
    struct Voucher has store {
        metadata: Object<Metadata>,
        amount: u64
    }

    // Persistent, via public, function so the resulting FV can have `store`
    public fun redeem(to: address, v: Voucher) {
        // Redeem using the fixed metadata/amount in the voucher
        // e.g., withdraw/deposit at this point
    }

    // Produces a storable FV that closes over a concrete Voucher
    public fun build_redeemer(v: Voucher): |address| {
        |to| redeem(to, v)
    }
}
```

Case: `FungibleAsset` (non-storable capture). If you capture a `FungibleAsset`, the function value cannot be stored, it must be invoked immediately in the same transaction. For persistence, capture a storable description (such as a voucher) instead of the FA itself.

```move filename="fungible_asset_case.move"
module example::fa_case {
    // Pattern B: Pass FA as an argument to a function value (no capture)
    public fun with_handler(
        owner: &signer,
        token: Object<Metadata>,
        amount: u64,
        handle: |FungibleAsset|
    ) {
        let fa = primary_fungible_store::withdraw(owner, token, amount);
        handle(fa);
    }
}
```

### Immutable Parameters

If a function value has captured or lifted arguments, those arguments are not going to be overridden at the time of invocation.
The following example demonstrates this intended behavior.

```move filename="immutable_parameters.move"
module example::example {
    use std::signer;
    use std::debug;

    fun foo(x: u64) {
        debug::print(&x);
    }

    public fun invoke(f: |u64|) {
        f(1); // The captured value (10) is not overridden at the time of invocation.
    }

    #[test(_att = @0x1337)]
    fun run(_att: &signer) {
        invoke(|_x| foo(10));
    }
}
```

To understand this behavior, we need to look at how closures are lifted into functions.

```text filename="lambda_assembly.masm"
__lambda__1__run(_x: u64) /* def_idx: 3 */ {
B0:
	0: LdU64(10) // load the value 10 into the stack
	1: Call foo(u64)
	2: Ret
}
```

You can see that the resulting function fixes the first argument to 10. So `x` is not overridden at the time of invocation.

### Arbitrary Function Value

Passing one or a chain of functions as a parameter to another function, or storing FVs in a table, e.g. to be used as custom hooks, are patterns that can lead to reentrancy.

**Example Vulnerable code:**

In this example, the `withdraw_operations` acts as a proxy to call into a series of functions.
As `Grant` is not part of `0x42::example`, any operation on it is **allowed** during closure dynamic dispatch.

```move filename="reentrancy_example.move"
module example::account {
    use std::signer;
    friend example::example;

    const ENOT_ENOUGH_BALANCE: u64 = 1;

    public struct Grant has drop {}

    public(friend) fun grant(): Grant {
        Grant {}
    }

    public(friend) fun balance(_account: address): u64 {
        1_000
    }

    public(friend) fun transfer(
        _from: address, _to: address, _amount: u64
    ) {}

    public(friend) fun has_grant(_g: &Grant): bool {
        true
    }
}

module example::example {
    use std::signer::address_of;
    use std::option::{Self as option, Option};
    use example::account;

    const EGRANT_NOT_FOUND: u64 = 2;
    const ENOT_ENOUGH_BALANCE: u64 = 3;

    public fun withdraw_operations(
        user: &signer,
        recipient: Option<address>,
        amount: u64,
        f: |address, Option<address>, &account::Grant, u64|
    ) {
        let account_addr = address_of(user);
        let bal = account::balance(account_addr);
        assert!(bal >= amount, ENOT_ENOUGH_BALANCE);
        let g = account::grant();
        f(account_addr, recipient, &g, amount);
    }

    public fun withdraw(
        account_addr: address,
        recipient: Option<address>,
        grant: &account::Grant,
        amount: u64
    ) {
        assert!(account::has_grant(grant), EGRANT_NOT_FOUND);
        let r = recipient;
        if (option::is_some(&r)) {
            account::transfer(account_addr, option::destroy_some(r), amount);
        } else {
            option::destroy_none(r);
        };
        account::transfer(account_addr, account_addr, amount);
    }
}
```

An attacker can exploit this by calling `withdraw_operations` with a function value that calls `withdraw` and passes the `Grant` as a parameter.
By altering, or [prefixing](/build/smart-contracts/move-security-guidelines#immutable-parameters), the amount of the transfer, which if pulled from a shared pool of funds, allows the attacker to overdraw the balance of the account.

```move filename="attacker.move"
module attacker::exploit {
    use 0x42::example;
    entry fun start(attacker: &signer) {
        example::withdraw_operations(
            attacker,
            None,
            10,
            |account, recipient, grant, amount| example::withdraw(
                attacker, recipient, grant, 100_000_000
            )
        );
    }
}
```

**Example Secure code:**

We've introduced the amount field into the grant structure to fix the amount at a specific moment. At the same time, we've finalized the status update. This can be thought of as a bank transfer that the bank is simply waiting to execute but has already recorded.

```move filename="reentrancy_secure.move"
module example::account {
    use std::signer;
    friend example::example;

    const ENOT_ENOUGH_BALANCE: u64 = 1;

    // Notice that the grant is not droppable to ensure it used, but we can allow it to be stored.
    public struct Grant {
        account: address,
        amount: u64
    } // might capture other information like the asset type.

    public(friend) fun grant(account: address, amount: u64): Grant {
        update_balance_withdraw(account, amount);
        Grant { account, amount }
    }

    fun update_balance_withdraw(account: address, amount: u64) { /* retrieve the account and update the balance */ } // The state update is done here.

    public(friend) fun balance(_account: address): u64 {
        1_000
    }

    public(friend) fun transfer(_to: address, _grant: Grant) {
        /* transfer the amount of the grant to the recipient and destroy the grant */
    }

    public(friend) fun has_grant(_g: &Grant): bool {
        true
    }
}

module example::example {
    use std::signer::address_of;
    use std::option::{Self as option, Option};
    use example::account;

    const EGRANT_NOT_FOUND: u64 = 2;
    const ENOT_ENOUGH_BALANCE: u64 = 3;

    public fun withdraw_operations(
        user: &signer,
        recipient: Option<address>,
        amount: u64,
        f: |address, account::Grant|
    ) {
        let account_addr = address_of(user);
        let bal = account::balance(account_addr);
        assert!(bal >= amount, ENOT_ENOUGH_BALANCE);
        let g = account::grant(account_addr, amount); // When the grant is created, the amount is fixed and verified to be available.
        if (option::is_some(&recipient)) {
            f(option::destroy_some(recipient), g); // By the time the function value is invoked, the state update is done, so reentrancy is not a problem.
        } else {
            f(account_addr, g);
        };
    }

    public fun withdraw(recipient: address, grant: account::Grant) {
        assert!(account::has_grant(&grant), EGRANT_NOT_FOUND);
        account::transfer(recipient, grant);
    }
}
```

# Move VSCode Extension

> Learn about move vscode extension for Move smart contract development on Aptos blockchain.

import { Aside } from '@astrojs/starlight/components';

# Move on Aptos Language Extension

This is the official Visual Studio Code (and Cursor) extension for [developing smart contracts in the Move language on the Aptos blockchain](/build/smart-contracts).

Built from the ground up, it delivers a modern and performant development experience, offering essential features like semantic highlighting, real-time diagnostics, auto-formatting and seamless integration with the rest of the Aptos toolchain - all designed to help developers build and test Move contracts with ease and confidence.

Actively maintained by the Aptos team, this extension is designed to evolve alongside the Move language and supports both developers who are new to Move, and those building more complex applications.

## Features

- Semantic Highlighting
- Go to Definition
- Find All References & Symbol Renaming
- Type and Documentation on Hover
- Contextual Auto-Completion
- Inlay Hints for Types and Function Parameters

![Inlay hints](~/images/move-vscode-extension/inlay_hints.png)

- Real-Time Diagnostics
- [Code suggestions](#code-suggestions-with-fixes)
- `movefmt` Integration

![Formatting with movefmt](~/images/move-vscode-extension/format.gif)

- Run `#[test]` functions
- Check modules and functions with Move Prover

## Installation

We publish releases both on [VSCode Marketplace](https://marketplace.visualstudio.com/items?itemName=AptosLabs.move-on-aptos) and [OpenVSX](https://open-vsx.org/extension/aptoslabs/move-on-aptos).

We also publish `nightly` pre-releases, which are built from `main` branch every night. To use those, select **Switch to Pre-Release Version** from your editor's Extensions View.

![Pre-releases selection](~/images/move-vscode-extension/pre-releases.png)

### Build from sources

Clone the repo, then run:

```
cargo run -p xtask -- install --server --client
```

(or just `cargo xtask install --server --client`, see [https://github.com/matklad/cargo-xtask](https://github.com/matklad/cargo-xtask))

The command builds `move-on-aptos.vsix` extension file and installs it into your VSCode.
Then it runs `cargo install` to build and install language server.

Put

```
"move-on-aptos.server.path": "~/.cargo/bin/aptos-language-server",
```

to your `settings.json` to point the extension to your locally built language server.

### Build from sources: Cursor AI editor

If you use [https://www.cursor.com/](https://www.cursor.com/) AI editor, you need to do a bit more work.

Run the installation command above. The result would be a `./editors/code/move-on-aptos.vsix` vscode extension package.
Then install it from the editor using the `"Install from VSIX..."` command.

## Configuration

<Aside type="note">
  Extension by itself won't download your dependencies from the network.

  If you see `unresolved reference` errors on the `AptosFramework` imports -
  try running `aptos move compile` once on your project to download your remote dependencies.
</Aside>

This extension provides configurations through VSCode's configuration settings.
All configurations are under `move-on-aptos.*`.

### Recommended configuration for the Move package directories

LSP is somewhat limited in what it can actually do, so some of the settings need to be specified manually.

#### Mark Move Library sources read-only

Add the following to your `settings.json`:

```json5
    "files.readonlyInclude": {
        "**/build/*/sources/**/*.move": true,
        "**/.move/**/*.move": true,
    }
```

#### Auto-close `b"` and `x"` properly

```json5
    "[move]": {
        "editor.wordSeparators": "`~!@#$%^&*()-=+[{]}\\|;:'\",.<>/?bx",
    },
```

A bunch of symbols in the config value are the defaults, we're adding `b` and `x` symbols for the string prefixes.

#### Set `Organize Imports` command to a keyboard shortcut

```json5
    {
        "key": "ctrl+alt+o",
        "command": "move-on-aptos.organizeImports",
        "when": "editorTextFocus && !editorReadonly"
    }
```

## AdvancedConfiguration

### Diagnostics

Extension provides a number of diagnostics, from hard errors like "unresolved reference" to style lints.
Some of those might be less useful than others for different coding styles, so there's an escape hatch to disable those:

```json5
{
    "move-on-aptos.diagnostics.disabled": [],
}
```

where values are diagnostic codes from the error messages, like `unused-variable` here:

![Diagnostic code example](~/images/move-vscode-extension/diag_code.png)

### Inlay hints

Type hints for the let statements and lambda parameters are supported.

```move
module 0x1::m {
    fun main() {
        let a/*: integer*/ = 1;
        let f: |u8| u8 = |e/*: u8*/| e;
    }
}
```

To disable those, use:

```json5
{
    "move-on-aptos.inlayHints.typeHints.enable": false,
}
```

### Formatting (works with `movefmt` >= 1.2.1)

Specify a path to the `movefmt` executable and extra args (like a `--config-path`) if necessary:

```json5
{
    "move-on-aptos.movefmt.path": "~/code/movefmt/target/release/movefmt",
    "move-on-aptos.movefmt.extraArgs": [],
}
```

Formatting on Save can be enabled in VSCode with

```json5
{
    "editor.formatOnSave": true,
}
```

## Debugging

It's useful to enable INFO logging level, it's not very chatty and could provide with a valuable information to debug:

```
    "move-on-aptos.server.extraEnv": { "RA_LOG": "info" },
```

## Additional commands

### `aptos-language-server diagnostics`

Run server diagnostics on the file (or package directory). If `--apply-fixes` is provided, automatically applies available autofixes:

[See available diagnostics with auto-fixes](#code-suggestions-with-fixes)

```shell
  $ aptos-language-server diagnostics --apply-fixes replace-with-method-call ./aptos-stdlib/sources/cryptography/keyless.move 
processing package 'aptos-stdlib', file: /home/mkurnikov/code/aptos-core/aptos-move/framework/aptos-stdlib/sources/cryptography/keyless.move
note[replace-with-method-call]: Can be replaced with method call
   ‚îå‚îÄ /home/mkurnikov/code/aptos-core/aptos-move/framework/aptos-stdlib/sources/cryptography/keyless.move:67:17
   ‚îÇ
67 ‚îÇ         assert!(string::bytes(&iss).length() <= MAX_ISSUER_UTF8_BYTES_LENGTH, error::invalid_argument(E_INVALID_ISSUER_UTF8_BYTES_LENGTH));
   ‚îÇ                 ^^^^^^^^^^^^^^^^^^^
   ‚îÇ
   ‚îå‚îÄ /home/mkurnikov/code/aptos-core/aptos-move/framework/aptos-stdlib/sources/cryptography/keyless.move:67:17
   ‚îÇ
67 ‚îÇ         assert!(iss.bytes().length() <= MAX_ISSUER_UTF8_BYTES_LENGTH, error::invalid_argument(E_INVALID_ISSUER_UTF8_BYTES_LENGTH));
   ‚îÇ                 ^^^^^^^^^^^ after fix


```

## Code suggestions (with fixes)

### Use method call notation

**Code**: `replace-with-method-call`

![Replace with method call](~/images/move-vscode-extension/replace_with_method_call.gif)

### Use compound assignment expression

**Code**: `replace-with-compound-expr`

![Compound assignment expression](~/images/move-vscode-extension/compound_expr.gif)

### Use vector index expr

**Code**: `replace-with-index-expr`

Detects expressions of form `*vector::borrow(&some_vector, index)` and `*some_vector.borrow(index)`,
which can be converted to `some_vector[index]`.

![Vector index expression](~/images/move-vscode-extension/vector_index_expr.gif)

### Use field initialization shorthand

**Code**: `use-struct-lit-field-shorthand`, `use-struct-pat-field-shorthand`, `use-schema-lit-field-shorthand`

Detects struct literal fields which could be written in shorthand form.

![Field initialization shorthand](~/images/move-vscode-extension/field_shorthand.gif)

### Redundant integer type cast

**Code**: `remove-redundant-cast`

Detects expressions like `number as u8`, where `number` is already of type it's being casted to.

![Redundant integer type cast](~/images/move-vscode-extension/redundant_cast.gif)

### Add `_` prefix to the variable name

**Code**: `rename-with-underscore-prefix`

Prefixes unused variable with `_`.

![Rename with underscore prefix](~/images/move-vscode-extension/rename_fix.gif)

## Roadmap

- More error highlighting:
  - Implement more errors from the Aptos Move compiler (like ability checking)
  - Implement lints from the `aptos move lint` with extension-provided quickfixes.

- Working with imports:
  - Detect unused imports and remove them with "Organize Imports" VSCode feature.
  - Show completion items not imported in the current module, create `use` statements for those automatically.

- Integration with the `aptos-cli` commands: compile packages, publishing modules and executing transactions.

- `Move.toml` support.

- AI integration (via MCP server).

# Creating objects

> Master object creation patterns, ownership models, and lifecycle management in Aptos Move development.

import { Aside } from '@astrojs/starlight/components';

Creating an Object involves two steps:

1. Creating the `ObjectCore` resource group (which has an address you can use to refer to the Object later).
2. Customizing how the Object will behave using permissions called `Ref`s.

<Aside type="note">
  Configuring an Object by generating `Ref`s has to happen in the same
  transaction you create it. Later on it is impossible to change those settings.
</Aside>

## Creating an Object

There are three types of Object you can create:

1. A **normal Object.** This type is deletable and has a random address. You can create it using: `0x1::object::create_object(owner_address: address)`. For example:

```move filename="object_playground.move"
module my_addr::object_playground {
  use std::signer;
  use aptos_framework::object;

  entry fun create_my_object(caller: &signer) {
    let caller_address = signer::address_of(caller);
    let constructor_ref = object::create_object(caller_address);
    // ...
  }
}
```

2. A **named Object.** This type is **not** deletable and has a deterministic address. You can create it by using: `0x1::object::create_named_object(creator: &signer, seed: vector<u8>)`. For example:

```move filename="object_playground.move"
module my_addr::object_playground {
  use std::signer;
  use aptos_framework::object;

  /// Seed for my named object, must be globally unique to the creating account
  const NAME: vector<u8> = b"MyAwesomeObject";

  entry fun create_my_object(caller: &signer) {
    let caller_address = signer::address_of(caller);
    let constructor_ref = object::create_named_object(caller, NAME);
    // ...
  }

  #[view]
  fun has_object(creator: address): bool {
    let object_address = object::create_object_address(&creator, NAME);
    object::object_exists<0x1::object::ObjectCore>(object_address)
  }
}
```

3. A **sticky Object.** This type is also **not** deletable and has a random address. You can create it by using `0x1::object::create_sticky_object(owner_address: address)`. For example:

```move filename="object_playground.move"
module my_addr::object_playground {
  use std::signer;
  use aptos_framework::object;

  entry fun create_my_object(caller: &signer) {
    let caller_address = signer::address_of(caller);
    let constructor_ref = object::create_sticky_object(caller_address);
    // ...
  }
}
```

## Customizing Object Features

Once you create your object, you will receive a `ConstructorRef` you can use to generate additional `Ref`s. `Ref`s can be used in future to enable / disable / execute certain Object functions such as transferring resources, transferring the object itself, or deleting the Object.

The following sections will walk through commonly used `Ref`s and the features they enable.

<Aside type="note">
  Note: The `ConstructorRef` cannot be stored. It is destroyed at the end of the
  transaction used to create the Object, so any other `Ref`s **must** be
  generated during Object creation.
</Aside>

### Adding Resources

You can use the `ConstructorRef` with `object::generate_signer` to create a signer that allows you to transfer resources onto the Object. This uses `move_to`, the same function as for adding resources to an account.

```move filename="Example.move"
module my_addr::object_playground {
  use std::signer;
  use aptos_framework::object;

  #[resource_group_member(group = aptos_framework::object::ObjectGroup)]
  struct MyStruct has key {
    num: u8
  }

  entry fun create_my_object(caller: &signer) {
    let caller_address = signer::address_of(caller);

    // Creates the object
    let constructor_ref = object::create_object(caller_address);

    // Retrieves a signer for the object
    let object_signer = object::generate_signer(&constructor_ref);

    // Moves the MyStruct resource into the object
    move_to(&object_signer, MyStruct { num: 0 });

    // ...
  }
}
```

### Adding Extensibility (`ExtendRef`)

Sometimes you want an Object to be editable later on. In that case, you can generate an `ExtendRef` with `object::generate_extend_ref`. This ref can be used to generate a signer for the object.

You can control who has permission to use the `ExtendRef` via smart contract logic like in the below example.

```move filename="Example.move"
module my_addr::object_playground {
  use std::signer;
  use std::string::{Self, String};
  use aptos_framework::object::{Self, Object};

  /// Caller is not the owner of the object
  const E_NOT_OWNER: u64 = 1;
  /// Caller is not the publisher of the contract
  const E_NOT_PUBLISHER: u64 = 2;

  #[resource_group_member(group = aptos_framework::object::ObjectGroup)]
  struct MyStruct has key {
    num: u8
  }

  #[resource_group_member(group = aptos_framework::object::ObjectGroup)]
  struct Message has key {
    message: string::String
  }

  #[resource_group_member(group = aptos_framework::object::ObjectGroup)]
  struct ObjectController has key {
    extend_ref: object::ExtendRef,
  }

  entry fun create_my_object(caller: &signer) {
    let caller_address = signer::address_of(caller);

    // Creates the object
    let constructor_ref = object::create_object(caller_address);

    // Retrieves a signer for the object
    let object_signer = object::generate_signer(&constructor_ref);

    // Moves the MyStruct resource into the object
    move_to(&object_signer, MyStruct { num: 0 });

    // Creates an extend ref, and moves it to the object
    let extend_ref = object::generate_extend_ref(&constructor_ref);
    move_to(&object_signer, ObjectController { extend_ref });
    // ...
  }

  entry fun add_message(
    caller: &signer,
    object: Object<MyStruct>,
    message: String
  ) acquires ObjectController {
    let caller_address = signer::address_of(caller);
    // There are a couple ways to go about permissions

    // Allow only the owner of the object
    assert!(object::is_owner(object, caller_address), E_NOT_OWNER);
    // Allow only the publisher of the contract
    assert!(caller_address == @my_addr, E_NOT_PUBLISHER);
    // Or any other permission scheme you can think of, the possibilities are endless!

    // Use the extend ref to get a signer
    let object_address = object::object_address(&object);
    let extend_ref = &borrow_global<ObjectController>(object_address).extend_ref;
    let object_signer = object::generate_signer_for_extending(extend_ref);

    // Extend the object to have a message
    move_to(&object_signer, Message { message });
  }
}
```

### Disabling / Toggling Transfers (`TransferRef`)

By default, all Objects are transferable. This can be changed via a `TransferRef` which you can generate with `object::generate_transfer_ref`.

The example below shows how you could generate and manage permissions for determining whether an Object is transferrable.

```move filename="Example.move"
module my_addr::object_playground {
  use std::signer;
  use aptos_framework::object::{Self, Object};

  /// Caller is not the publisher of the contract
  const E_NOT_PUBLISHER: u64 = 1;

  #[resource_group_member(group = aptos_framework::object::ObjectGroup)]
  struct ObjectController has key {
    transfer_ref: object::TransferRef,
  }

  entry fun create_my_object(
    caller: &signer,
    transferrable: bool,
    controllable: bool
  ) {
    let caller_address = signer::address_of(caller);

    // Creates the object
    let constructor_ref = object::create_object(caller_address);

    // Retrieves a signer for the object
    let object_signer = object::generate_signer(&constructor_ref);

    // Creates a transfer ref for controlling transfers
    let transfer_ref = object::generate_transfer_ref(&constructor_ref);

    // We now have a choice, we can make it so the object can be transferred
    // and we can decide if we want to allow it to change later.  By default, it
    // is transferrable
    if (!transferrable) {
      object::disable_ungated_transfer(&transfer_ref);
    };

    // If we want it to be controllable, we must store the transfer ref for later
    if (controllable) {
      move_to(&object_signer, ObjectController { transfer_ref });
    }
    // ...
  }

  /// In this example, we'll only let the publisher of the contract change the
  /// permissions of transferring
  entry fun toggle_transfer(
    caller: &signer,
    object: Object<ObjectController>
  ) acquires ObjectController {
    // Only let the publisher toggle transfers
    let caller_address = signer::address_of(caller);
    assert!(caller_address == @my_addr, E_NOT_PUBLISHER);

    // Retrieve the transfer ref
    let object_address = object::object_address(&object);
    let transfer_ref = &borrow_global<ObjectController>(
      object_address
    ).transfer_ref;

    // Toggle it based on its current state
    if (object::ungated_transfer_allowed(object)) {
      object::disable_ungated_transfer(transfer_ref);
    } else {
      object::enable_ungated_transfer(transfer_ref);
    }
  }
}
```

### One-Time Transfers (`LinearTransferRef`)

Additionally, if the creator wants to control all transfers, a `LinearTransferRef` can be created from the `TransferRef` to provide a one time use transfer functionality. This can be used to create ‚Äúsoulbound‚Äù objects by having a one-time transfer from the Object creator to the recipient. The `LinearTransferRef` must be used by the owner of the Object.

```move filename="Example.move"
module my_addr::object_playground {
  use std::signer;
  use aptos_framework::object::{Self, Object};

  /// Caller is not the publisher of the contract
  const E_NOT_PUBLISHER: u64 = 1;

  #[resource_group_member(group = aptos_framework::object::ObjectGroup)]
  struct ObjectController has key {
    transfer_ref: object::TransferRef,
  }

  entry fun create_my_object(
    caller: &signer,
  ) {
    let caller_address = signer::address_of(caller);

    // Creates the object
    let constructor_ref = object::create_object(caller_address);

    // Retrieves a signer for the object
    let object_signer = object::generate_signer(&constructor_ref);

    // Creates a transfer ref for controlling transfers
    let transfer_ref = object::generate_transfer_ref(&constructor_ref);

    // Disable ungated transfer
    object::disable_ungated_transfer(&transfer_ref);
    move_to(&object_signer, ObjectController {
      transfer_ref,
    });
    // ...
  }

  /// In this example, we'll only let the publisher of the contract change the
  /// permissions of transferring
  /// Now only owner can transfer exactly once
  entry fun transfer(
    caller: &signer,
    object: Object<ObjectController>,
    new_owner: address
  ) acquires ObjectController {
    // Only let the publisher toggle transfers
    let caller_address = signer::address_of(caller);
    assert!(caller_address == @my_addr, E_NOT_PUBLISHER);

    let object_address = object::object_address(&object);

    // Retrieve the transfer ref
    let transfer_ref = &borrow_global<ObjectController>(
      object_address
    ).transfer_ref;

    // Generate a one time use `LinearTransferRef`
    let linear_transfer_ref = object::generate_linear_transfer_ref(
      transfer_ref
    );

    object::transfer_with_ref(linear_transfer_ref, new_owner);
  }
}
```

## Allowing Deletion of an Object (`DeleteRef`)

For Objects created with the default method (allowing deletion) you can generate a `DeleteRef` which can be used later. This can help remove clutter as well as receive a storage refund.

You cannot create a `DeleteRef` for a non-deletable Object.

```move filename="Example.move"
module my_addr::object_playground {
  use std::signer;
  use aptos_framework::object::{Self, Object};

  /// Caller is not the owner of the object
  const E_NOT_OWNER: u64 = 1;

  #[resource_group_member(group = aptos_framework::object::ObjectGroup)]
  struct ObjectController has key {
    delete_ref: object::DeleteRef,
  }

  entry fun create_my_object(
    caller: &signer,
    _transferrable: bool,
    _controllable: bool
  ) {
    let caller_address = signer::address_of(caller);

    // Creates the object
    let constructor_ref = object::create_object(caller_address);

    // Retrieves a signer for the object
    let object_signer = object::generate_signer(&constructor_ref);

    // Creates and store the delete ref
    let delete_ref = object::generate_delete_ref(&constructor_ref);
    move_to(&object_signer, ObjectController {
      delete_ref
    });
    // ...
  }

  /// Now only let the owner delete the object
  entry fun delete(
    caller: &signer,
    object: Object<ObjectController>,
  ) acquires ObjectController {
    // Only let caller delete
    let caller_address = signer::address_of(caller);
    assert!(object::is_owner(object, caller_address), E_NOT_OWNER);

    let object_address = object::object_address(&object);

    // Retrieve the delete ref, it is consumed so it must be extracted
    // from the resource
    let ObjectController {
      delete_ref
    } = move_from<ObjectController>(
      object_address
    );

    // Delete the object forever!
    object::delete(delete_ref);
  }
}
```

## Making an Object Immutable

An object can be made immutable by making the contract associated immutable, and removing any ability to extend or mutate the object. By default, contracts are not immutable, and objects can be extended with an `ExtendRef`, and resources can be mutated if the contract allows for it.

## Further Reading

You can find documentation for all possible `Refs` by looking at the Move reference docs for `0x1::object` [here](/move-reference/mainnet/aptos-framework/object).

You can also explore how to use Objects once they are constructed [here](/build/smart-contracts/object/using-objects).

# Using objects

> Learn how to interact with and manipulate Aptos Objects in smart contracts for composable applications.

import { Aside } from '@astrojs/starlight/components';

Once you've created your Object, you can use it in Move entry functions, structs, transfer it, and modify it using any refs you generated during [Object construction](/build/smart-contracts/object/creating-objects). Below are various ways to utilize, manage, and interact with Objects in Move.

## Using an Object as an entry function argument

Objects in move functions have the type `Object<T>`, where `T` is the type of a resource owned by the Object. All Objects have an `ObjectCore` type which contains the metadata for the Object.

To use an Object parameter, users can pass in the Object address or a reference to the Object. At runtime the contract will verify that the Object exists at that address, and has a resource of type T before executing the function.

```move filename="Example.move"
module my_addr::object_playground {
  use aptos_framework::object::{Object, ObjectCore};

  struct MyAwesomeStruct has key {}

  /// This will fail if the object doesn't have MyAwesomeStruct stored
  entry fun do_something(object: Object<MyAwesomeStruct>) {
    // ...
  }

  /// All Objects have ObjectCore, so this will only fail if the
  /// address is not an object
  entry fun do_something_to_object_core(object: Object<ObjectCore>) {
    // ...
  }
}
```

To let the user of the entry function specify the type of resource, you can keep the generic type `T` like so:

```move filename="Example.move"
module my_addr::object_playground {
  use aptos_framework::object::Object;

  /// This will fail if the object doesn't have the generic `T` stored
  entry fun do_something<T>(object: Object<T>) {
    // ...
  }
}
```

### Object types

You can refer to an Object by any type of resource that is owned by the Object. For convenience, you can convert an address to an Object, or convert an Object between types as long as the resources are available using `address_to_object` and `convert` like so:

```move filename="Example.move"
module my_addr::object_playground {
  use aptos_framework::object::{Self, Object, ObjectCore};

  struct MyAwesomeStruct has key {}

  fun convert_type(object: Object<ObjectCore>): Object<MyAwesomeStruct> {
    object::convert<ObjectCore, MyAwesomeStruct>(object)
  }

  fun address_to_type(object_address: address): Object<MyAwesomeStruct> {
    object::address_to_object<MyAwesomeStruct>(object_address)
  }
}
```

<Aside type="note">
  Objects can be owned by any address, including Objects, Accounts, and Resource accounts. This allows composability between objects and complex relationships between them.
</Aside>

## Using an Object as type of a field in struct

Objects can help represent complicated types by using them in structs. For example,

```move filename="Example.move"
module my_addr::object_playground {
  use aptos_framework::object::{Self, Object};
  use aptos_framework::fungible_asset::Metadata;
  use aptos_framework::primary_fungible_store;
  use std::signer;
  use std::option;
  use std::string::utf8;

  struct MyStruct has key {
    fungible_asset_object: Object<Metadata>
  }

  entry fun create_fungible_asset(creator: &signer) {
    let fa_obj_constructor_ref = &object::create_sticky_object(@my_addr);
    let fa_obj_signer = object::generate_signer(fa_obj_constructor_ref);
    let fa_obj_addr = signer::address_of(&fa_obj_signer);
    primary_fungible_store::create_primary_store_enabled_fungible_asset(
        fa_obj_constructor_ref, 
        option::none(),
        utf8(b"Asset name"),
        utf8(b"Asset symbol"),
        2,
        utf8(b"Icon uri"),
        utf8(b"Project uri")
    );
    move_to(creator, MyStruct {
      fungible_asset_object: object::address_to_object(fa_obj_addr)
    });
  }
}
```

## Looking up who owns an Object

When writing contracts for Objects, it is often important to verify ownership before modifying the Object. Because an Object can be owned by any address, verifying ownership needs to account for whether the owner is an Account, a Resource Account or another Object like so:

```move filename="Example.move"
module my_addr::object_playground {
  use std::signer;
  use aptos_framework::object::{Self, Object};

  // Not authorized!
  const E_NOT_AUTHORIZED: u64 = 1;

  fun check_owner_is_caller<T: key>(caller: &signer, object: Object<T>) {
    assert!(
      object::is_owner(object, signer::address_of(caller)),
      E_NOT_AUTHORIZED
    );
  }

  fun check_is_owner_of_object<T: key>(addr: address, object: Object<T>) {
    assert!(object::owner(object) == addr, E_NOT_AUTHORIZED);
  }

  fun check_is_nested_owner_of_object<T: key, U: key>(
    caller: &signer,
    outside_object: Object<T>,
    inside_object: Object<U>
  ) {
    // Ownership expected
    // Caller account -> Outside object -> inside object

    // Check outside object owns inside object
    let outside_address = object::object_address(&outside_object);
    assert!(object::owns(inside_object, outside_address), E_NOT_AUTHORIZED);

    // Check that the caller owns the outside object
    let caller_address = signer::address_of(caller);
    assert!(object::owns(outside_object, caller_address), E_NOT_AUTHORIZED);

    // Check that the caller owns the inside object (via the outside object)
    // This can skip the first two calls (and even more nested)
    assert!(object::owns(inside_object, caller_address), E_NOT_AUTHORIZED);
  }
}
```

## Transfer of ownership

By default, all Objects are transferrable. Some Objects are configured to disable `ungated_transfer`s when they are constructed (see Constructing Objects for more details).

You can transfer an Object like so:

```move filename="Example.move"
module my_addr::object_playground {
  use aptos_framework::object::{Self, Object};

  /// Transfer to another address, this can be an object or account
  fun transfer<T: key>(owner: &signer, object: Object<T>, destination: address) {
    object::transfer(owner, object, destination);
  }

  /// Transfer to another object
  fun transfer_to_object<T: key, U: key>(
    owner: &signer,
    object: Object<T>,
    destination: Object<U>
  ) {
    object::transfer_to_object(owner, object, destination);
  }
}
```

<Aside type="caution">
  If `ungated_transfer` is **disabled**, then all transfers need to use a special permission given by a `TransferRef` or `LinearTransferRef`.
</Aside>

## Events

By default, Objects only have a `TransferEvent` which triggers whenever the Object is transferred.

Objects can be extended to have additional events.

You can use the following functions to create event handles for Objects:

```move filename="example.move"
module 0x1::object {
  /// Create a guid for the object, typically used for events
  public fun create_guid(object: &signer): guid::GUID {}

  /// Generate a new event handle.
  public fun new_event_handle<T: drop + store>(object: &signer): event::EventHandle<T> {}
}
```

Generated event handles can be transferred to the Object as long as you have the Object's `SignerRef`. For example:

```move filename="example.move"
module 0x42::example {
  use aptos_framework::event;
  use aptos_framework::fungible_asset::Metadata;
  use aptos_framework::object::{Self, Object};

  #[resource_group_member(group = aptos_framework::object::ObjectGroup)]  
  struct LiquidityPoolResourceGroup has key {
    pool: LiquidityPool,
    event_store: LiquidityPoolEventStore,
  }

  struct LiquidityPool has store {
    metadata_token_a: Object<Metadata>,
    metadata_token_b: Object<Metadata>,
    reserves_a: u128,
    reserves_b: u128,
  }

  struct LiquidityPoolEventStore has store {
    create_events: event::EventHandle<CreateLiquidityPoolEvent>,
  }

  #[event]
  struct CreateLiquidityPoolEvent has store, drop {
    token_a: address,
    token_b: address,
    reserves_a: u128,
    reserves_b: u128,
  }

  public entry fun create_liquidity_pool_with_events(
        account_signer: &signer,
        metadata_token_a: Object<Metadata>,
        metadata_token_b: Object<Metadata>,
        reserves_a: u128,
        reserves_b: u128
  ) {
    let liquidity_pool_constructor_ref = &object::create_object_from_account(
      account_signer
    );
    let liquidity_pool_signer = &object::generate_signer(
      liquidity_pool_constructor_ref
    );
    let event_handle = object::new_event_handle<CreateLiquidityPoolEvent>(
      liquidity_pool_signer
    );

    event::emit_event<CreateLiquidityPoolEvent>(&mut event_handle, CreateLiquidityPoolEvent {
      token_a: object::object_address(&metadata_token_a),
      token_b: object::object_address(&metadata_token_b),
      reserves_a,
      reserves_b,
    });

    move_to(liquidity_pool_signer, LiquidityPoolResourceGroup {
      pool: LiquidityPool {
        metadata_token_a,
        metadata_token_b,
        reserves_a,
        reserves_b
      },
      event_store: LiquidityPoolEventStore {
        create_events: event_handle
      }
    });
  }
}
```

## Modifying Objects after creation

In general, Objects can only be modified with `Refs` generated during construction. See [Creating and Configuring Objects](/build/smart-contracts/object/creating-objects) for more details on what `Refs` are available, how to generate them, and how to use them. This is how you add additional resources to an Object, delete it, and extend it.

## Example contracts

Here are three real-world code snippets which use Objects:

- [Digital Asset Marketplace Example](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/move-examples/marketplace)
- [Digital Assets Examples](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/move-examples/token_objects)
- [Fungible Asset Examples](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/move-examples/fungible_asset)

# Building with Objects

> Learn about objects for Aptos Objects in smart contract development.

In Move, Objects group resources together so they can be treated as a single entity on chain.

Objects have their own address and can own resources similar to an account. They are useful for representing more complicated data types on-chain as Objects can be used in entry functions directly, and can be transferred as complete packages instead of one resource at a time.

Here's an example of creating an Object and transferring it:

```move filename="Example.move"
module my_addr::object_playground {
  use std::signer;
  use std::string::{Self, String};
  use aptos_framework::object::{Self, ObjectCore};

  struct MyStruct1 has key {
    message: String,
  }

  struct MyStruct2 has key {
    message: String,
  }

  entry fun create_and_transfer(caller: &signer, destination: address) {
    // Create object
    let caller_address = signer::address_of(caller);
    let constructor_ref = object::create_object(caller_address);
    let object_signer = object::generate_signer(&constructor_ref);

    // Set up the object by creating 2 resources in it
    move_to(&object_signer, MyStruct1 {
      message: string::utf8(b"hello")
    });
    move_to(&object_signer, MyStruct2 {
      message: string::utf8(b"world")
    });

    // Transfer to destination
    let object = object::object_from_constructor_ref<ObjectCore>(
      &constructor_ref
    );
    object::transfer(caller, object, destination);
  }
}
```

During construction, Objects can be configured to be transferrable and extensible.

For example, you could use an Object to represent a soulbound NFT by making it only transferrable once, and have it own resources for an image link and metadata. Objects can also own other Objects, so you could implement your own NFT collection Object by transferring several of the soulbound NFTs to it.

## Learn how to

- [Create and configure a new Object.](/build/smart-contracts/object/creating-objects)
- [Use Objects you created.](/build/smart-contracts/object/using-objects)

## Examples with Object contracts

- [Digital Asset Marketplace Example](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/move-examples/marketplace)
- [Digital Assets Examples](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/move-examples/token_objects)
- [Fungible Asset Examples](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/move-examples/fungible_asset)

# Move Prover Overview

> Explore prover in Move Prover for formal verification of smart contracts.

The Move Prover supports formal [specification](/build/smart-contracts/prover/spec-lang) and
[verification](/build/smart-contracts/prover/prover-guide) of Move code. The Move Prover can
automatically validate logical properties of Move smart contracts while offering
a user experience similar to a type checker or linter.

The Move Prover exists to make contracts more _trustworthy_; it:

- Protects massive assets managed by the Aptos blockchain from smart contract bugs
- Protects against well-resourced adversaries
- Anticipates justified regulator scrutiny and compliance requirements
- Allows domain experts with a mathematical background, but not necessarily a
  software engineering background, to understand what smart contracts do

For more information, refer to the documentation:

- [Installation](/build/cli/setup-cli/install-move-prover)
- [Move Prover User Guide](/build/smart-contracts/prover/prover-guide)
- [Move Specification Language](/build/smart-contracts/prover/spec-lang)
- [Move Prover Supporting Resources](/build/smart-contracts/prover/supporting-resources)

# Move Prover User Guide

> Comprehensive guide to using Move Prover for formal verification, specifications, and contract correctness.

This is the user guide for the Move Prover. This document accompanies the
[Move specification language](/build/smart-contracts/prover/spec-lang). See the sections below for details.

## Running the Move Prover

The Move Prover is invoked via the [Aptos CLI](/build/cli). In order
to call the CLI, you must have a [_Move package_](/build/smart-contracts/book/packages) in place.
In the simplest case, a Move package is defined by a directory with a set of
`.move` files in it and a manifest of the name `Move.toml`. You can create a new
Move package at a given location by running the command:
`aptos move init --name <name>`

Once the package exists, call the Move Prover from the directory to be tested or
by supplying its path to the `--package-dir` argument:

- Prove the sources of the package in the current directory:
  ```shellscript filename="Terminal"
  aptos move prove
  ```
- Prove the sources of the package in a specific directly:
  ```shellscript filename="Terminal"
  aptos move prove --package-dir <path>
  ```

See example output and other available options in the
[Proving Move](/build/cli/working-with-move-contracts#6-optional-formally-verifying-move-scripts)
section of Use Aptos CLI.

### Target filtering

By default, the `aptos move prove` command verifies all files of a package.
During iterative development of larger packages, it is often more effective to
focus verification on particular files with the `-f` (`--filter`) option, like so:

```shellscript filename="Terminal"
aptos move prove -f coin
```

In general, if the string provided to the `-f` option is contained somewhere in
the file name of a source, that source will be included for verification.

> NOTE: the Move Prover ensures there is no semantic difference between
> verifying modules one-by-one or all at once. However, if your goal is to
> verify all modules, verifying them in a single `aptos move prove` run will be
> significantly faster than sequentially.

### Prover options

The Move Prover has a number of options (such as the filter option above) that
you pass with an invocation of: `aptos move prove <options>`. The most commonly
used option is the `-t` (`--trace`) option that causes the Move Prover to
produce richer diagnosis when it encounters errors:

```shellscript filename="Terminal"
aptos move prove -f coin -t
```

To see the list of all command line options, run: `aptos move prove --help`

### Prover configuration file

You can also create a Move Prover configuration file named `Prover.toml` that
lives side-by-side with the `Move.toml` manifest file in the root of the package
directory. For example, to enable tracing by default for a package, add a
`Prover.toml` file with the following configuration:

```toml
[prover]
auto_trace_level = "VerifiedFunction"
```

Find the most commonly used options in the example `.toml` below, which you can
cut and paste and adopt for your needs (adjusting the defaults shown in the
displayed values as needed):

```toml
# Verbosity level
# Possible values: "ERROR", "WARN", "INFO", "DEBUG". Each level subsumes the output of the previous one.
verbosity_level = "INFO"

[prover]
# Set auto-tracing level, which enhances the diagnosis the Move Prover produces on verification errors.
# Possible values: "Off", "VerifiedFunction", "AllFunctions"
auto_trace_level = "Off"

# Minimal severity level for diagnosis to be reported.
# Possible values: "Error", "Warning", "Note"
report_severity = "Warning"

[backend]
# Timeout in seconds for the solver backend. Note that this is a soft timeout and may not always
# be respected.
vc_timeout = 40

# Random seed for the solver backend. Different seeds can result in different verification run times,
# as the solver uses heuristics.
random_seed = 1

# The number of processor cores to assume for concurrent check of verification conditions.
proc_cores = 4
```

> HINT: For local verification, you may want to set `proc_cores` to an
> aggressive number (your actual cores) to speed up the turnaround cycle.

## Prover diagnosis

When the Move Prover finds a verification error, it prints diagnosis to standard
output in a style similar to a compiler or a debugger. We explain the different
types of diagnoses below, based on the following evolving example:

```move
module 0x42::m {
  struct Counter has key {
    value: u8,
  }

  public fun increment(a: address) acquires Counter {
    let r = borrow_global_mut<Counter>(a);
    r.value = r.value + 1;
  }

  spec increment {
    aborts_if !exists<Counter>(a);
    ensures global<Counter>(a).value == old(global<Counter>(a)).value + 1;
  }
}
```

We will modify this example as we demonstrate different types of diagnoses.

### Unexpected abort

If we run the Move Prover on the example immediately above, we get the following
error:

```shellscript filename="Terminal"
error: abort not covered by any of the `aborts_if` clauses
   ‚îå‚îÄ m.move:11:5
   ‚îÇ
 8 ‚îÇ           r.value = r.value + 1;
   ‚îÇ                             - abort happened here with execution failure
   ¬∑
11 ‚îÇ ‚ï≠     spec increment {
12 ‚îÇ ‚îÇ         aborts_if !exists<Counter>(a);
13 ‚îÇ ‚îÇ         ensures global<Counter>(a).value == old(global<Counter>(a)).value + 1;
14 ‚îÇ ‚îÇ     }
   ‚îÇ ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ^
   ‚îÇ
   =     at m.move:6: increment
   =         a = 0x29
   =     at m.move:7: increment
   =         r = &mmm.Counter{value = 255u8}
   =     at m.move:8: increment
   =         ABORTED

{
  "Error": "Move Prover failed: exiting with verification errors"
}
```

The Move Prover has generated an example counter that leads to an overflow when
adding 1 to the value of 255 for an `u8`. This overflow occurs if the function
specification calls for abort behavior, but the condition under which the
function is aborting is not covered by the specification. And in fact, with
`aborts_if !exists<Counter>(a)`, we only cover the abort caused by the absence
of the resource, but not the abort caused by the arithmetic overflow.

Let's fix the above and add the following condition:

```move
module 0x42::m {
  spec increment {
    aborts_if global<Counter>(a).value == 255;
    // ...
  }
}
```

With this, the Move Prover will succeed without any errors.

### Post-condition failure

Let us inject an error into the `ensures` condition of the above example:

```move
module 0x42::m {
  spec increment {
    ensures global<Counter>(a).value == /*old*/(global<Counter>(a).value) + 1;
  }
}
```

With this, the Move Prover will produce the following diagnosis:

```shellscript filename="Terminal"
error: post-condition does not hold
   ‚îå‚îÄ m.move:14:9
   ‚îÇ
14 ‚îÇ         ensures global<Counter>(a).value == /*old*/(global<Counter>(a).value) + 1;
   ‚îÇ         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   ‚îÇ
   =     at m.move:6: increment
   =         a = 0x29
   =     at m.move:7: increment
   =         r = &mmm.Counter{value = 0u8}
   =     at m.move:8: increment
   =     at m.move:9: increment
   =     at m.move:12: increment (spec)
   =     at m.move:15: increment (spec)
   =     at m.move:13: increment (spec)
   =     at m.move:14: increment (spec)

{
  "Error": "Move Prover failed: exiting with verification errors"
}
```

While we know what the error is (as we just injected it), this is not
particularly obvious in the output This is because we don't directly see on
which values the `ensures` condition was actually evaluated. To see this, use
the `-t` (`--trace`) option; this is not enabled by default because it makes the
verification problem slightly harder for the solver.

Instead or in addition to the `--trace` option, you can use the built-in
function `TRACE(exp)` in conditions to explicitly mark expressions whose values
should be printed on verification failures.

> NOTE: Expressions that depend on quantified symbols cannot be traced. Also,
> expressions appearing in specification functions can not currently be traced.

## Debugging the Move Prover

The Move Prover is an evolving tool with bugs and deficiencies. Sometimes it
might be necessary to debug a problem based on the output the Move Prover passes
to the underlying backends. If you pass the option `--dump`, the Move Prover
will output the original Move bytecode, as well as the Move Prover bytecode,
as the former is transformed during compilation.

# Move Specification Language

> Learn the Move specification language for formal verification, invariants, and contract properties.

This document describes the _Move specification language (MSL)_, a subset of the
[Move](/build/smart-contracts) language that supports specification of the
behavior of Move programs. MSL works together with the [Move Prover](/build/smart-contracts/prover),
a tool that can statically verify the correctness of MSL specifications against
Move programs. In contrast to traditional testing, verification of MSL is
exhaustive and holds for all possible inputs and global states of a
[Move module](/network/glossary#move-module) or
[Move script](/network/glossary#move-script). At the
same time, this verification of MSL is fast and automated enough that it can be
used at a similar place in the developer workflow where tests are typically
conducted (for example, for qualification of pull requests in continuous
integration).

While the Move programming language at this point is stable, the subset
represented by MSL should be considered evolving. This has no impact on platform
stability, since MSL is not running in production; yet MSL is used for offline
quality assurance where it is continuously improved for evolving objectives.

This document describes the language only; see [Use the Move Prover](/build/smart-contracts/prover/prover-guide)
for instructions. The reader is expected to have basic knowledge of the Move
language, as well as basic principles of pre- and post-condition specifications.
(See for example the [Design by contract](https://en.wikipedia.org/wiki/Design_by_contract)).
For examples of specifications, we refer to the [Aptos framework](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/doc/overview.md)
documentation, which has specifications embedded.

# Expressions

Expressions in MSL are a subset of Move program expressions plus a set of
additional constructs, as discussed in the following sections.

## Type System

The type system of MSL is similar to that of Move, with the following differences:

- There are two types of encodings for integer types: `num` and `bv` (bit vector).
  If an integer (either a constant or a variable) is not involved in any bitwise operations directly or indirectly,
  regardless of its type in Move (`u8`, `u16`, `u32`, `u64`, `u128` and `u256`), it is treated as the same type. In
  specifications, this type is called `num`, which is an arbitrary precision _signed_ integer type.
  When MSL refers to a Move name that represents an `u8` or such, it will be automatically widened
  to `num`. This allows writing MSL expressions like `x + 1 <= MAX_U128` or `x - y >= 0` without
  needing to worry about overflow or underflow.
  Different from `num`, `bv` cannot and does not need to be explicitly used in specifications: if an integer is involved in bitwise operations such as `&`, `|` or `^`, it will be automatically encoded as `bv`at the backend.
  Moreover, a `bv` integer has a fixed precision, which is consistent with its precision in Move (`bv8`, `bv16`, `bv32`, `bv64`, `bv128` and `bv256`).
  Note that, in general using `bv` is not so efficient as `num` in the [SMT](https://en.wikipedia.org/wiki/Satisfiability_modulo_theories) solver such as [Z3](https://github.com/Z3Prover/z3). Consequently,
  the Move Prover has some restrictions when using bitwise operations, which are stated in detail below.
- The Move types `&T`, `&mut T`, and `T` are considered equivalent for MSL. Equality is interpreted
  as value equality. There is no need to worry about dereferencing a reference from the Move
  program: these are automatically dereferenced as needed. This simplification is possible because
  MSL cannot modify values from a Move program, and the program cannot directly reason about
  reference equality (which eliminates the need for doing so in MSL). (Note there is also a
  restriction in expressiveness coming with this, namely
  for [functions which return `&mut T`](#expressiveness). However, this is rarely hit in practice,
  and there are workarounds).
- There is the additional type `type`, which is the type of all types. It can be used only in
  quantifiers.
- There is the additional type `range`, which represents an integer range (and the notation `n..m` to
  denote a value).

## Naming

Name resolution in MSL works similar to the Move language. `use` declarations can introduce aliases for
imported names. MSL functions and variable names must start with a lowercase letter. Schema names
are treated like types and must start with a capital letter. ([Schemas](#schemas) are a named construct
discussed later).

Move functions, MSL functions, Move types, and schemas all share the same namespace and are
therefore unambiguous if aliased via a Move `use` clause. Because of the common name space, an MSL
function cannot have the same name as a Move function. This is often handled via the convention to
prefix MSL functions as in `spec_has_access` when the related Move function is called `has_access`.

## Operators

All Move operators are supported in MSL, except `&`, `&mut`, and `*` (dereference).

In addition to the existing operators, vector subscript `v[i]`, slicing `v[i..j]`, and range
construction `i..j` are supported (the type of integer ranges is a new builtin type called `range`). Moreover, boolean implication `p ==> q` is supported as a more intuitive form than `!p || q`.

## Function calls

In MSL expressions, functions can be called like in Move. However, the callee must either be
an [MSL helper function](#helper-functions) or a **pure** Move function.

Move functions are considered pure if they do not modify global state and do not use Move expression
features that are not supported in MSL expressions (as defined in this document).

There is one extension. If a Move function definition contains a direct `assert`, this will be
ignored when it is called from an MSL expression, and the function will be considered pure. For
example:

```move
module 0x42::m {
  fun get(addr: address): &T {
    assert(exists<T>(addr), ERROR_CODE);
    borrow_global<T>(addr)
  }
}
```

This function is pure and can be called from an MSL expression. The assertion will be ignored, and
the function will be interpreted as:

```move
module 0x42::m {
  spec fun get(addr: address): T { global<T>(addr) }
}
```

This is justified by that MSL having [_partial semantics_](#partial-semantics).

## Statements

Limited sequencing of the form `{ let x = foo(); x + x }` is supported, as well as if-then-else.
Other statement forms of the Move language are not supported.

## Pack and unpack

Pack expressions are supported. Unpack expressions are currently _not_ supported.

## Quantifiers

Universal and existential quantification is supported. The general form is:

```move
forall <binding>, ..., <binding> [ where <exp> ] : <exp>
exists <binding>, ..., <binding> [ where <exp> ] : <exp>
```

- Bindings can either be of the form `name: <type>` or `name in <exp>`. For the second form, the
  expression must either be a `range` or a vector.
- The optional constraint `where <exp>` allows to restrict the quantified range. `forall x: T where p: q`
  is equivalent to `forall x: T : p ==> q` and `exists x: T where p: q` is equivalent to `exists x: T : p && q`.

## Choice operator

The choice operator allows selecting a value that satisfies a predicate:

```move
choose a: address where exists<R>(a) && global<R>(a).value > 0
```

If the predicate is not satisfiable, the result of the choice will be undetermined. (See [partial semantics](#partial-semantics)).

The choice also comes in a form to select the _minimal_ value from a set of integers, as in:

```move
choose min i: num where in_range(v, i) && v[i] == 2
```

## Cast operator

In the specification language, we can use the same syntax `(e as T)` to cast an expression `e` with one integer type to `T`, an integer type of another size.

## Shift operator

Shift operators `<<` and `>>` are supported in the specification language, and both of them have the same semantics with the Move language. As for abort, if a value `v` has width `n`, then `v << m` or `v >> m` will abort if `m >= n`.

## Bitwise operators

Move programs using bitwise operators `&`, `|` and `^` can be verified in the prover, and these operators are also supported in the specification language.
Due to encoding and efficiency issues, using bitwise operators has more caveats:

- Integers involved in bitwise operations are encoded as `bv` types at the backend, and two encodings of integers are not compatible. For instance, if a variable `v` is involved in a bitwise operation such as `v & 2` or `v = a ^ b`, then when it is used in an arithmetic operation `v * w` or a shift operation `v << w`, `w` will be implicitly cast to a `bv` type in the Move program.
  However, the specification language does not support implicit type cast so users must explicitly use the built-in function `int2bv` in the specification: `v << int2bv(w)`.
  Not that since each `bv` type has a fixed length (from 8 to 256), values with type `num` cannot be converted into `bv`.

- Verification of `bv` types is not efficient and may lead to timeout. As a result, users may prefer isolating bitwise operations from other operations and not using `int2bv` if possible. Moreover, users need to use pragmas to explicitly specify which integer-typed function arguments or struct fields will be used in bitwise computations:

```move
module 0x42::m {
  struct C has drop {
    a: u64,
    b: u64
  }
  spec C {
    // b, the second field of C, will be of bv type
    pragma bv = b"1";
  }
  public fun foo_generic<T>(i: T): T {
    i
  }

  spec foo_generic {
    // The first parameter will be of bv type if T is instantiated as a number type
    pragma bv = b"0";
    // The first return value will be of bv type if T is instantiated as a number type
    pragma bv_ret = b"0";
  }

  public fun test(i: C): u64 {
    let x1 = foo_generic(C.b);
    x1 ^ x1
  }

  spec test {
    // Explicit type cast is mandatory for generating correct boogie program
    ensures result == (0 as u64);
  }
}
```

Note that if arguments or fields of a generic function or struct are specified with `bv` types,
they will be of `bv` types in all instances of the function or the struct when the instantiated type is an integer type.

- Values with integer types in vectors and tables can be encoded as `bv` types; indices and keys in tables cannot be `bv` types for now. Using other types will lead to internal errors.

## Built-in functions

MSL supports a number of built-in constants and functions. Most of them are not available in the Move
language:

- `MAX_U8: num`, `MAX_U64: num`, `MAX_U128: num` returns the maximum value of the corresponding
  type.
- `exists<T>(address): bool` returns true if the resource T exists at address.
- `global<T>(address): T` returns the resource value at address.
- `len<T>(vector<T>): num` returns the length of the vector.
- `update<T>(vector<T>, num, T>): vector<T>` returns a new vector with the element replaced at the
  given index.
- `vec<T>(): vector<T>` returns an empty vector.
- `vec<T>(x): vector<T>` returns a singleton vector.
- `concat<T>(vector<T>, vector<T>): vector<T>` returns the concatenation of the parameters.
- `contains<T>(vector<T>, T): bool` returns true if element is in vector.
- `index_of<T>(vector<T>, T): num` returns the index of the element in the vector, or the length of
  the vector if it does not contain it.
- `range<T>(vector<T>): range` returns the index range of the vector.
- `in_range<T>(vector<T>, num): bool` returns true if the number is in the index range of the
  vector.
- `in_range<T>(range, num): bool` returns true if the number is in the range.
- `update_field(S, F, T): S` updates a field in a struct, preserving the values of other fields,
  where `S` is some struct, `F` the name of a field in `S`, and `T` a value for this field.
- `old(T): T` delivers the value of the passed argument at point of entry into a Move function. This
  is allowed in
  `ensures` post-conditions,
  inline spec blocks (with additional restrictions), and
  certain forms of invariants, as discussed later.
- `TRACE(T): T` is semantically the identity function and causes visualization of the argument's
  value in error messages created by the prover.
- `int2bv(v)` explicitly converts an integer `v` into its `bv` representation.
- `bv2int(b)` explicitly converts a 'bv' integer 'b' into the `num` representation. However, it is not encouraged to use it due to efficiency issue.

Built-in functions live in an unnamed outer scope of a module. If the module defines a function `len`,
then this definition will shadow that of the according built-in function. To access the built-in
function in such a situation, one can use the notation `::len(v)`.

## Partial semantics

In MSL, expressions have partial semantics. This is in contrast to Move program expressions, which
have total semantics, since they either deliver a value or abort.

An expression `e[X]` that depends on some variables `X` may have a known interpretation for
some assignments to variables in `X` but is unknown for others. An unknown interpretation for a
sub-expression causes no issue if its value is not needed for the overall expression result.
Therefore, it does not matter if we say `y != 0 && x / y > 0`
or `x / y > 0 && y != 0`: boolean operators are commutative.

This basic principle inherits to higher-level language constructs. For example, in specifications,
it does not matter in which order conditions are supplied: `aborts_if y != 0; ensures result == x / y;` is the same as
`ensures result == x / y; aborts_if y != 0;`. Also, `aborts_if P; aborts_if Q;` is the same
as `aborts_if Q || P`
.

Moreover, the principle of partial semantics is inherited to [specification helper functions](#helper-functions), which behave transparently. Specifically, inlining those functions is equivalent to calling them (call-by-expression parameter passing semantics).

# Specifications

Specifications are contained in so-called _specification blocks_ (abbreviated **spec block**) that
can appear as module members and inside Move functions. The various types of spec blocks are shown
below, and will be discussed in subsequent sections.

```move
module addr::M {
  struct Counter has key {
    value: u8,
  }

  public fun increment(a: address) acquires Counter {
    let r = borrow_global_mut<Counter>(a);
    spec {
      // spec block targeting this code position
      // ...
    };
    r.value = r.value + 1;
  }

  spec increment {
    // spec block targeting function increment
    // ...
  }

  spec Counter {
    // spec block targeting struct Counter
    // ...
  }

  spec schema Schema {
    // spec block declaring a schema
    // ...
  }

  spec fun f(x: num): num {
    // spec block declaring a helper function
    // ...
  }

  spec module {
    // spec block targeting the whole module
    // ...
  }
}
```

Apart from spec blocks inside Move functions, the textual position of spec block is irrelevant. Also,
a spec block for a struct, function, or module can be repeated multiple times, accumulating the
content.

## Separating specifications

Instead of putting specifications into the same module as the regular Move definitions, one can also
put them into a separate "specification" module, which can live in the same or a different file:

```move
module addr::M {
    //...
}
spec addr::M {
    spec increment { /* ... */ }
}
```

The syntax of a specification module is the same as for a regular module; however, Move functions
and structures are not allowed.

A specification module must be compiled together with the Move module it is targeting and cannot be
compiled and verified standalone.

In case Move definitions are far apart (e.g., in different files), it is possible to augment the
specification of a Move function with a signature of this function to give sufficient context to
understand the specification. This syntax is optionally enabled in regular and in specification
modules:

```move
module 0x42::m {
  public fun increment(a: address) acquires Counter { /* ... */ }
  // ...
  spec increment(a: address) { /* ... */ }
}
```

## Pragmas and properties

Pragmas and properties are a generic mechanism to influence interpretation of specifications. They
are also an extension point to experiment with new concepts before they become part of the mainstream
syntax. Here we give a brief introduction into their general syntax; individual instances are
discussed later.

The general form of a pragma is:

```move
module 0x42::m {
  spec item {
    pragma <name> = <literal>;
  }
}
```

The general form of a property is:

```move
module 0x42::m {
  spec item {
  <directive> [<name> = <literal>] <content>; // ensures, aborts_if, include, etc..
  }
}
```

The `<literal>` can be any value supported by MSL (or the Move language). A value assignment can
also be omitted, in which case a default is used. For example, it is common to use `pragma option;`
as a shortcut for `pragma option = true;`.

Instead of a single pragma or property, a list can also be provided, as in `invariant [global, isolated] P`.

### Pragma inheritance

A pragma in a module spec block sets a value that applies to all other spec blocks in the module. A
pragma in a function or struct spec block can override this value for the function or struct.
Furthermore, the default value of some pragmas can be defined via the prover configuration.

As an example, we look at the `verify` pragma. This pragma is used to turn verification on or off.

```move
module 0x42::m {
  spec module {
    pragma verify = false; // By default, do not verify specs in this module ...
  }

  spec increment {
    pragma verify = true; // ... but do verify this function.
    // ...
  }
}
```

### General pragmas and properties

A number of pragmas control general behavior of verification. Those are listed in the table below.

| Name                       | Description                                                                                                                                                             |
| -------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `verify`                   | Turns on or off verification.                                                                                                                                           |
| `intrinsic`                | Marks a function to skip the Move implementation and use a prover native implementation. This makes a function behave like a native function even if it not so in Move. |
| `timeout`                  | Sets a timeout (in seconds) for function or module. Overrides the timeout provided by command line flags.                                                               |
| `verify_duration_estimate` | Sets an estimate (in seconds) for how long the verification of function takes. If the configured `timeout` is less than this value, verification will be skipped.       |
| `seed`                     | Sets a random seed for function or module. Overrides the seed provided by command line flags.                                                                           |

The following properties control general behavior of verification:

| Name            | Description                                          |
| --------------- | ---------------------------------------------------- |
| `[deactivated]` | Excludes the associated condition from verification. |

## Pre and post state

Multiple conditions in spec blocks work with a _pre_ and _post_ state, relating them to each other.
Function specifications are one example of this: in the `ensures P` condition, the pre-state (at
function entry) and the post-state (at function exit) are related via the predicate `P`. However,
the concept is more general and also applied for invariants, where the pre-state is before and
post-state after a global update.

In contexts where a pre/post-state is active, expressions are evaluated implicitly in the
post-state. To evaluate an expression in a pre-state, one uses the built-in function `old(exp)`,
which evaluates its parameter in the pre-state and returns its value. It is important to understand
that every sub-expression in `exp` is computed in the pre-state as well, including calls to helper
functions.

The 'state' in question here consists of assignments to global resource memory, as well as to any
parameters of the function of type `&mut T`. Examples:

```move
module 0x42::m {
  fun increment(counter: &mut u64) { *counter = *counter + 1 }
  spec increment {
    ensures counter == old(counter) + 1;
  }

  fun increment_R(addr: address) {
    let r = borrow_global_mut<R>(addr);
    r.value = r.value + 1;
  }
  spec increment_R {
    ensures global<R>(addr).value == old(global<R>(addr).value) + 1;
  }
}
```

## Helper functions

MSL allows defining helper functions. Those functions can then be used in expressions.

Helper functions are defined using the following syntax:

```move
module 0x42::m {
  spec fun exists_balance<Currency>(a: address): bool { exists<Balance<Currency>>(a) }
}
```

As seen in the example, helper functions can be generic. Moreover, they can access global state.

Definitions of helper functions are neutral regarding whether they apply to
a [pre- or post-state](#pre-and-post-state). They are evaluated in the currently active state. For
instance, in order to see whether a balance existed in the pre-state, one
uses `old(exists_balance<Currency>(a))`. Consequently, the expression `old(..)` is not allowed
within the definition of a helper function.

Helper functions are partial functions; see the discussion of [partial semantics](#partial-semantics).

### Uninterpreted functions

A helper function can be defined as **uninterpreted** by simply omitting its body:

```move
module 0x42::m {
  spec fun something(x: num): num;
}
```

An uninterpreted function is one of the prover is allowed to assign some arbitrary meaning to, as long
as it is consistent within a given verification context. Uninterpreted functions are a useful tool
for abstraction in specifications (see also [abstract specifications](#abstract-specifications)).

### Axioms

The meaning of helper functions can be further constrained by using **axioms**. Currently, axioms
must be contained in module spec blocks:

```move
module 0x42::m {
  spec module {
    axiom forall x: num: something(x) == x + 1;
  }
}
```

Axioms should be used with care as they can introduce unsoundness in the specification logic via
contradicting assumptions. The Move Prover supports a smoke test for detecting unsoundness via
the `--check-inconsistency` flag.

## Let bindings

A spec block can contain let bindings that introduce names for expressions:

```move
module 0x42::m {
  fun get_R(account: signer): R { /* ... */ }
  spec get_R {
    let addr = signer::spec_address_of(account);
    aborts_if addr != ROOT;
    ensures result == global<R>(addr);
  }
}
```

In a spec block that has a pre-state and post-state (like a function specification), the `let name = e`
form will evaluate `e` in the pre-state. In order to evaluate an expression in the post-state, use `let post name = e`. In the rhs expression of this form, one can use `old(..)` to refer to the
pre-state.

## Aborts\_if condition

The `aborts_if` condition is a spec block member that can appear only in a function context. It
specifies conditions under which the function aborts.

In the following example, we specify that the function `increment` aborts if the `Counter` resource
does not exist at address `a` (recall that `a` is the name of the parameter of `increment`).

```move
module 0x42::m {
  spec increment {
    aborts_if !exists<Counter>(a);
  }
}
```

If a function has more than one `aborts_if` condition, those conditions are or-ed with each other.
The evaluation of the combined aborts condition (or-ed from each individual condition) depends on
the value of the pragma `aborts_if_is_partial`. If this value is false (the default), the function
aborts _if and only if_ the combined aborts condition is true. In this case, the above aborts
specification for `increment` will lead to a verification error, since there are additional
situations where `increment` can abort, namely if incrementing `Counter.value` would lead to an
overflow. To fix this, the specification can be completed like this:

```move
module 0x42::m {
  spec increment {
    pragma aborts_if_is_partial = false; // This is the default, but added here for illustration.
    aborts_if !exists<Counter>(a);
    aborts_if global<Counter>(a).value == 255;
  }
}
```

If the value of `aborts_if_is_partial` is true, the combined aborts condition (the or-ed individual
conditions) only _implies_ that the function aborts. Formally, if `A` is the combined aborts condition, then
with `aborts_if_is_partial = true`, we have `A ==> function_aborts`; otherwise we have
`A <==> function_aborts`. Therefore, the following does verify:

```move
module 0x42::m {
  spec increment {
    pragma aborts_if_is_partial = true;
    aborts_if !exists<Counter>(a);
  }
}
```

<a name="risk-aborts-if-is-partial" />

> Note that there is a certain risk in setting `aborts_if_is_partial` to true, and best practice is to avoid it in specifications of public functions and Move scripts once those are considered finalized. This is because changing the code after finalization of the spec can add new (non-trivial, undesired) abort situations the original specification did not anticipate yet will nevertheless silently pass verification.

If no aborts condition is specified for a function, abort behavior is unspecified. The function may
or may not abort, and verification will not raise any errors, whether `aborts_if_is_partial` is set
or not. In order to state that a function never aborts, use `aborts_if false`. One can use the
pragma `aborts_if_is_strict` to change this behavior; this is equivalent to an `aborts_if false` being added to each function that does not have an explicit `aborts_if` clause.

### Aborts\_if condition with code

The `aborts_if` condition can be augmented with code:

```move
module 0x42::m {
  fun get_value(addr: address): u64 {
    aborts(exists<Counter>(addr), 3);
    borrow_global<Counter>(addr).value
  }
  spec get_value {
    aborts_if !exists<Counter>(addr) with 3;
  }
}
```

It is a verification error if the above function does not abort with code `3` under the given
condition.

In order to specify a direct VM abort, one can use the special constant `EXECUTION_FAILURE`:

```move
module 0x42::m {
  fun get(addr: address): &Counter acquires Counter {
    borrow_global<Counter>(addr)
  }
  spec get {
    aborts_if !exists<Counter>(addr) with EXECUTION_FAILURE;
  }
}
```

This same constant can be used for all other VM failures (division by zero, overflow, etc.).

## Aborts\_with condition

The `aborts_with` condition allows specifying with which codes a function can abort, independent
under which condition. It is similar to a 'throws' clause in languages like Java.

```move
module 0x42::m {
  fun get_one_off(addr: address): u64 {
    aborts(exists<Counter>(addr), 3);
    borrow_global<Counter>(addr).value - 1
  }
  spec get_one_off {
    aborts_with 3, EXECUTION_FAILURE;
  }
}
```

If the function aborts with any other or none of the specified codes, a verification error will be
produced.

The `aborts_with` condition can be combined with `aborts_if` conditions. In this case, the `aborts_with`
specifies any other codes with which the function may abort, in addition to the ones given in the `aborts_if`:

```move
module 0x42::m {
  spec get_one_off {
    aborts_if !exists<Counter>(addr) with 3;
    aborts_with EXECUTION_FAILURE;
  }
}
```

## Requires condition

The `requires` condition is a spec block member that postulates a pre-condition for a function. The
Move Prover will produce verification errors for functions that are called with violating
pre-conditions.

A `requires` is different from an `aborts_if`: in the latter case, the function can be called, and
any aborts it produces will be propagated to the caller context. In the `requires` case, the Move Prover
will not allow the function to be called in the first place. Nevertheless, the function can _still
be called at runtime_ if verification is skipped. Because of this, `requires` are rare in Move
specifications, and `aborts_if` are more common. Specifically, `requires` should be avoided for public APIs.

An example of `requires` is:

```move
module 0x42::m {
  spec increment {
    requires global<Counter>(a).value < 255;
  }
}
```

## Ensures condition

The `ensures` condition postulates a post-condition for a function that must be satisfied when the
function terminates successfully (i.e., does not abort). The Move Prover will verify each `ensures` to
this end.

An example for the `ensures` condition is the following:

```move
module 0x42::m {
  spec increment {
    ensures global<Counter>(a) == old(global<Counter>(a)) + 1;
  }
}
```

Within the expression for the `ensures` condition, one can use the `old` function, as discussed in
[Pre and post state](#pre-and-post-state).

## Modifies condition

The `modifies` condition is used to provide permissions to a function to modify global storage. The
annotation itself comprises a list of global access expressions. It is specifically used together
with [opaque function specifications](#opaque-specifications).

```move
module 0x42::m {
  struct S has key {
    x: u64
  }

  fun mutate_at(addr: address) acquires S {
    let s = borrow_global_mut<S>(addr);
    s.x = 2;
  }
  spec mutate_at {
    pragma opaque;
    modifies global<S>(addr);
  }
}
```

In general, a global access expression has the form `global<type_expr>(address_expr)`. The
address-valued expression is evaluated in the pre-state of the annotated function.

```move
module 0x42::m {
  fun read_at(addr: address): u64 acquires S {
    let s = borrow_global<S>(addr);
    s.x
  }

  fun mutate_S_test(addr1: address, addr2: address): bool acquires T {
    assert(addr1 != addr2, 43);
    let x = read_at(addr2);
    mutate_at(
      addr1
    ); // Note we are mutating a different address than the one read before and after
    x == read_at(addr2)
  }
  spec mutate_S_test {
    aborts_if addr1 == addr2;
    ensures result == true;
  }
}
```

In the function `mutate_S_test`, the assertion in the spec block is expected to hold. A benefit of
the modifies specification on `mutate_at` is that this assertion can be proved whether `mutate_at` is inlined.

If the modifies annotation is omitted on a function, then that function is deemed to have all
possible permissions for those resources it may modify during its execution. The set of all
resources that may be modified by a function is obtained via an interprocedural analysis of the
code. In the example above, `mutate_S_test` does not have a modifies specification and modifies
resource `S` via the call to `mutate_at`. Therefore, it is considered to have modified `S` at any
possible address. Instead, if the programmer adds `modifies global<S>(addr1)`
to the specification of `mutate_S_test`, then the call to `mutate_at` is checked to make sure that
modify permissions granted to `mutate_S_test` cover the permissions it grants to `mutate_at`.

## Invariant condition

The invariant condition can be applied on structs and on global level.

### Function invariants

The `invariant` condition on a function is simply a shortcut for a `requires` and `ensures` with the
same predicate.

Thus, the following spec block:

```move
module 0x42::m {
  spec increment {
    invariant global<Counter>(a).value < 128;
  }
}
```

... is equivalent to:

```move
module 0x42::m {
  spec increment {
    requires global<Counter>(a).value < 128;
    ensures global<Counter>(a).value < 128;
  }
}
```

### Struct invariants

When the `invariant` condition is applied to a struct, it expresses a well-formedness property of
the struct data. Any instance of this struct that is currently not mutated will satisfy this
property (with exceptions as outlined below).

For example, we can postulate an invariant on our counter that it never must exceed the value of
127:

```move
module 0x42::m {
  spec Counter {
    invariant value < 128;
  }
}
```

A struct invariant is checked by the Move Prover whenever the struct value is constructed (packed). While
the struct is mutated (e.g., via a `&mut Counter`) the invariant does _not_ hold (but see exception
below). In general, we consider mutation as an implicit unpack, and end of mutation as a pack.

The Move language semantics unambiguously identifies the point when mutation ends and starts. This
follows from the borrow semantics of Move and includes mutation via an enclosing struct.
(The mutation of an inner struct ends when the mutation of the root struct where mutation started
ends).

There is one exception to this rule. When a mutable reference to a struct declared in module M is
passed into a _public_ function of M which does by itself _not_ return any other mutable reference (which could be borrowed from the input parameter), we treat this parameter as "packed". That means, on function entry, we will unpack it and on function exit we will pack again, enforcing the invariant. This reflects that in Move, struct data can be mutated only within the module that declares the struct; so for an outside caller of the public function, the mutable reference can actually not be mutated unless by calling public functions of module M again. It is a significant simplification of the verification problem to exploit this in the semantics.

### Global invariants

A global invariant appears as a member of module. It can express a condition over the global state
of the Move program, as represented by resources stored in memory. For example, the below invariant
states that a `Counter` resource stored at any given address can never be zero:

```move
module addr::M {
    invariant forall a: addr where exists<Counter>(a): global<Counter>(a).value > 0;
}
```

A global invariant is assumed to hold when data is read from the global state, and is asserted (and
may fail to verify) at the moment the state is updated. For example, the below function will never abort with arithmetic underflow because the counter value is always greater than zero; however, it will create a verification error since the counter can drop to zero:

```move
module 0x42::m {
  fun decrement_ad(addr: address) acquires Counter {
    let counter = borrow_global_mut<Counter>(addr);
    let new_value = counter.value - 1;   // Will not abort because counter.value > 0
    *counter.value = new_value;          // Fails verification since value can drop to zero
  }
}
```

Notice that type parameters are supported in global invariants. For example, the invariant above can be rewritten into the below one if `Counter` is generic:

```move
module addr::M {
    invariant<T> forall a: addr where exists<Counter<T>>(a): global<Counter<T>>(a).value > 0;
}
```

#### Disabling invariants

There are times when a global invariant holds almost everywhere, except for a brief interval inside a function. In current Move code, this often occurs when something (e.g., an account) is being set up and
several structs are published together. Almost everywhere, an invariant holds that all the structs are published or none of them are. But the code that publishes the structs must do so sequentially. While the structs are being published, there will be a point where some are published and others are not.

In order to verify invariants that hold except during small regions, there is a feature to allow users to disable invariants temporarily. Consider the following code fragment:

```move
module 0x42::m {
  fun setup() {
    publish1();
    publish2();
  }
}
```

where `publish1` and `publish2` publish two different structs, `T1` and `T2` at address `a`.

```move
module addr::M {
    invariant [global] exists<T1>(a) == exists<T2>(a)
}
```

As written, the Move Prover will report that the invariant is violated after the call to `publish1` and before the call to `publish2`. If either of `publish1` or `publish2` is without the other, the Move Prover
will also report a violation of the invariant.

By default, a global invariant is checked immediately after the instruction `I` that touches the resources mentioned in the global invariant. The `[suspendable]` attribute (at the invariant side) together with two pragmas (specified in function spec block) provide fine-grained control on where we hope this invariant to be checked:

- `disable_invariants_in_body`: the invariant will be checked at the end of the function where `I` resides.
- `delegate_invariants_to_caller`: the invariant will be checked by all callers of the function where `I` resides.

For the example above, we can add the pragma `disable_invariants_in_body`:

```move
module 0x42::m {
  spec setup {
    pragma disable_invariants_in_body;
  }
}
```

which says that invariants are not required to hold while `setup` is executing but are assumed to hold on entry to and exit from `setup`.

This pragma changes the Move Prover's behavior. The invariants are assumed on entry to `setup` but not proved during or after `publish1` and `publish2`. Instead, all invariants that could be invalidated in the
body of `setup` are asserted and proved at the point of return from `setup`. A consequence of this processing is that the user may need to provide stronger post-conditions on `publish1` and `publish2` to
make it possible to prove the invariants on exit from `setup`.

Another consequence of this processing is that invariants cannot safely be assumed to hold during the execution of `publish1` and `publish2` (unless nothing in the body of `setup` changes state
mentioned in the invariant). Therefore, if proving a post-condition requires the invariant to be assumed, the post-condition will fail.

In the example, invariants hold at the call sites of `setup` but not in the body. For `publish1`, invariants don't necessarily hold at the call site _or_ in the body of the function. In the example, that
behavior is implied because `publish1` is called in a context where invariants are disabled.

When invariants are disabled in `setup` in the above example, the Move Prover cannot assume them on entry to `publish1` and `publish2` and should not try to prove them on exit from those functions. The Move Prover
would have the same behavior for any functions called by `publish1` or `publish2`. The Move Prover _automatically_ adopts this behavior when invariants are disabled in a calling function, but it is possible for the user to declare that a function be treated like `publish1`.

For example, if `publish2` is _only_ called from the setup function above, and we did _not_ disable invariants in `setup`, we could achieve a similar effect by using the pragma `delegate_invariants_to_caller`, instead.

```move
module 0x42::m {
  spec setup {
    pragma delegate_invariants_to_caller;
  }
}
```

This would be legal only if `setup` is a private or `public (friend)` function. The difference between this and disabling invariants in `setup` is that the invariants would not be assumed at the beginning of `setup` and would be proved after `setup` returns at each site where it is called.

While both pragmas disable invariants in the body of a function, the difference is that `disable_invariants_in_body` assumes invariants on entry and proves them on exit, while `delegate_invariants_to_caller` does neither.

There are some limitations on how these pragmas can be used. `disable_invariants_in_body` cannot be declared for functions where invariants are delegated to a caller, either explicitly via the pragma
or implicitly because the function is called in a context where invariants have been disabled. (This restriction is to ensure consistent processing, because on pragma assumes that invariants hold
in the calling context and the other does not). Second, it is illegal for a public or script function to delegate invariant checking to its callers (since the Move Prover does not know all the call sites), _unless_ the function cannot possibly invalidate an invariant because it doesn't change any of the state mentioned in `exists` and `global` expressions appearing in the invariant.

#### Update invariants

The `update` form of a global invariant allows to express a relation between [pre-state and post-state](#pre-and-post-state) of a global state update. For example, the following invariant states that the counter must decrease monotonically whenever it is updated:

```move
module addr::M {
    invariant update [global] forall a: addr where old(exists<Counter>(a)) && exists<Counter>(addr):
        global<Counter>(a).value <= old(global<Counter>(a));
}
```

#### Isolated global invariants

A global invariant can be marked as `[isolated]` to indicate that it is not relevant for proving
other properties of the program. An isolated global invariant will not be assumed when the related
global state is read. It will only be assumed before the state is updated to help prove that the
invariant still holds after the update. This feature is for improving performance in situations
where there are many global invariants, but they have no direct influence on verification.

#### Modular verification and global invariants

Certain usage of global invariants leads to verification problems that cannot be checked in a modular fashion. "Modular" here means that a module can be verified standalone and proven to be universally correct in all usage contexts (if preconditions are met).

A non-modular verification problem may arise if a global invariant refers to state from multiple modules. Consider a situation where module `M1` uses module `M2`, and `M1` contains the following invariant, with the helper function `condition` referring to global state of each respective module:

```move
module addr::M1 {
    invariant M1::condition() ==> M2::condition();
}
```

When we verify `M1` standalone, the Move Prover will determine that it also needs to verify functions in `M2`, namely those which update the M2 memory such that the invariant in M1 can fail.

## Assume and assert conditions in code

A spec block might also occur anywhere an ordinary Move statement block can occur.
Here is an example:

```move
module 0x42::m {
  fun simple1(x: u64, y: u64) {
    let z;
    y = x;
    z = x + y;
    spec {
      assert x == y;
      assert z == 2 * x;
    }
  }
}
```

In such inline spec blocks, only a subset of conditions are permitted:

- `assume` and `assert` statements are allowed in any code locations.
- loop `invariant` statements are allowed only in code locations that represent loop headers.

An assert statement inside a spec block indicates a condition that must hold when control reaches
that block. If the condition does not hold, an error is reported by the Move Prover. An `assume`
statement, on the other hand, blocks executions violating the condition in the statement. The
function `simple2` shown below is verified by the Move Prover. However, if the first spec block
containing the assume statement is removed, Move Prover will show a violation to the `assert`
statement in the second spec block.

```move
module 0x42::m {
  fun simple2(x: u64, y: u64) {
    let z: u64;
    spec {
      assume x > y;
    };
    z = x + y;
    spec {
      assert z > 2 * y;
    }
  }
}
```

### Loop invariants

An `invariant` statement encodes a loop invariant and must be placed at a loop head, as in the
following example:

```move
module 0x42::m {
  fun simple3(n: u64) {
    let x = 0;
    loop {
      spec {
        invariant x <= n;
      };
      if (x < n) {
        x = x + 1
      } else {
        break
      }
    };
    spec {
      assert x == n;
    }
  }
}
```

A loop invariant is translated into two `assert` statements and one `assume` statement to facilitate the inductive reasoning of properties about the loop. In break down, a loop invariant is translated to:

- An `assert` statement that confirms the invariant holds when the loop is first encountered in the
  execution -- establishing the base case.
- An `assume` statement that encodes the property that the invariant holds at loop iteration `I`.
- An `assert` statement that checks whether the invariant continues to hold at loop iteration `I+1`.

### Referring to pre-state

Occasionally, we would like to refer to the pre-state of a mutable function argument in inline spec
blocks. In MSL, this can be done with the `old(T)` expression. Similar to the semantics of `old(..)`
in post conditions, an `old(T)` expression in an `assume` or `assert` statement always yields the
value of `T` at the function entry point. Here is an example that illustrate the use of
`old(..)` in an inline spec block:

```move
module 0x42::m {
  fun swap(x: &mut u64, y: &mut u64) {
    let t = *x;
    *x = *y;
    *y = t;
    spec {
      assert x == old(y);
      assert y == old(x);
    };
  }
}
```

The above example is trivial as the same property can be expressed with post conditions
(i.e., `ensures`) too. But there are cases where we must use `old(..)` to refer to the pre-state, especially in the specification of loop invariants. Consider the following example
where we verify that the `vector_reverse` function properly reverses the order of all elements
in a vector:

```move
module 0x42::m {
  fun verify_reverse<Element>(v: &mut vector<Element>) {
    let vlen = vector::length(v);
    if (vlen == 0) return;

    let front_index = 0;
    let back_index = vlen - 1;
    while ({
      spec {
        assert front_index + back_index == vlen - 1;
        assert forall i in 0..front_index: v[i] == old(v)[vlen - 1 - i];
        assert forall i in 0..front_index: v[vlen - 1 - i] == old(v)[i];
        assert forall j in front_index..back_index + 1: v[j] == old(v)[j];
        assert len(v) == vlen;
      };
      (front_index < back_index)
    }) {
      vector::swap(v, front_index, back_index);
      front_index = front_index + 1;
      back_index = back_index - 1;
    };
  }
  spec verify_reverse {
    aborts_if false;
    ensures forall i in 0..len(v): v[i] == old(v)[len(v) - 1 - i];
  }
}
```

Note the usage of `old(v)` in the loop invariants. Without them, it is hard to express the
invariant that the vector is partially reversed while the loop is iterating and the rest
remain unchanged.

However, unlike the `old(T)` expressions in `ensures` conditions where `T` can be any valid
expression (e.g., `old(v[i])` is allowed), the `old(T)` expressions in `assert` and `assumes`
statements accept only a single variable as `T` and that variable must be a function argument of
a mutable reference type. In the above example, `old(v[i])` is not allowed, and we should use
`old(v)[i]` instead.

## Specification variables

MSL supports _spec variables_, also called _ghost variables_ in the verification community. These
variables are used only in specifications and represent information derived from the global state of
resources. An example use case is to compute the sum of all coins available in the system and
specify that the sum can be changed only in certain scenarios.

We illustrate this feature by introducing a spec variable that maintains the sum of all `Counter`
resources from our running example. First, a spec variable is introduced via spec module block as
follows:

```move
module 0x42::m {
  spec module {
    global sum_of_counters: num;
  }
}
```

This value is going to be updated whenever a `Counter` is packed or unpacked. (Recall that mutation
is interpreted as an implicit unpack and pack):

```move
module 0x42::m {
  spec Counter {
    invariant pack sum_of_counters = sum_of_counters + value;
    invariant unpack sum_of_counters = sum_of_counters - value;
  }
}
```

> TODO: `invariant pack` and `invariant unpack` are currently not implemented

Now we may for example want to specify that the sum of all Counter instances in the global state
should never exceed a particular value. We can do this as follows:

```move
module 0x42::m {
  spec module {
    invariant [global] sum_of_counters < 4711;
  }
}
```

Note that spec variables can also be referenced from helper functions. Moreover, spec variables can
be generic:

```move
module 0x42::m {
  spec module {
    global some_generic_var<T>: num;
  }
}
```

When using such a spec variable, a type parameter must be provided, as in `some_generic_var<u64>`. Effectively, a generic spec variable is like a family of variables indexed by types.

## Schemas

Schemas are a means for structuring specifications by grouping properties together. Semantically,
they are just syntactic sugar that expand to conditions on functions, structs, or modules.

### Basic Schema Usage

Schemas are used as such:

```move
module 0x42::m {
  spec schema IncrementAborts {
    a: address;
    aborts_if !exists<Counter>(a);
    aborts_if global<Counter>(a).value == 255;
  }

  spec increment {
    include IncrementAborts;
  }
}
```

Each schema may declare a number of typed variable names and a list of conditions over those
variables. All supported condition types can be used in schemas. The schema can then be included in
another spec block:

- If that spec block is for a function or a struct, all variable names the schema declares must be
  matched against existing names of compatible type in the context.
- If a schema is included in another schema, existing names are matched and must have the same type,
  but non-existing names will be added as new declarations to the inclusion context.

When a schema is included in another spec block, it will be checked whether the conditions it
contains are allowed in this block. For example, including the schema `IncrementAborts` into a
struct spec block will lead to a compile-time error.

When a schema is included, the names it declares can also bound by expressions. For example, one can
write `include IncrementAborts{a: some_helper_address()}`. Effectively, not providing a binding is
equivalent to writing `IncrementAborts{a: a}` if `a` is an existing name in scope.

Schemas can be generic. Generic schemas must be fully instantiated where they are included; type
inference is not available for schemas.

### Schema expressions

When a schema is included, one can use a limited set of Boolean operators as follows:

- `P ==> SchemaExp`: all conditions in the schema will be prefixed with `P ==> ..`. Conditions that
  are not based on Boolean expressions will be rejected.
- `if (P) SchemaExp1 else SchemaExp2`: this is treated similar to including both
  `P ==> SchemaExp1` and `!P ==> SchemaExp2`.
- `SchemaExp1 && SchemaExp2`: this is treated as two includes for both schema expressions.

### Schema apply operation

One of the main use cases for schemas is to be able to name a group of properties and then apply
those to a set of functions. This is achieved by the `apply` operator. The `apply` spec block member
can appear only in module spec blocks.

The general form of the apply operator is `apply Schema to FunctionPattern, .. except FunctionPattern, ..`. Here, `Schema` can be a schema name or a schema name plus formal type arguments. `FunctionPatterns` consists of an optional visibility modifier `public` or `internal` (if not provided, both visibilities will match), a name pattern in the style of a shell file pattern ( e.g., `*`, `foo*`, `foo*bar`, etc.), and finally an optional type argument list. All type arguments provided to `Schema` must be bound
in this list and vice versa.

The `apply` operator includes the given schema in all function spec blocks that match the patterns,
except those excluded via the `except` patterns.

A typical use of the `apply` operator is to provide common pre-conditions and post-conditions to all functions in
a module with some exceptions. Example:

```move
module 0x42::m {
  spec schema Unchanged {
    let resource = global<R>(ADDR);
    ensures resource == old(resource);
  }

  spec module {
    // Enforce Unchanged for all functions except the initialize function.
    apply Unchanged to * except initialize;
  }
}
```

Notice that while with [global invariants](#global-invariants) we can express similar things, we _cannot_
express the restriction of the invariant to only specific functions.

## Opaque specifications

With the pragma `opaque`, a function is declared to be solely defined by its specification at caller
sides. In contrast, if this pragma is not provided, then the function's implementation will be used
as the basis to verify the caller.

Using `opaque` requires the specification to be sufficiently complete for the verification problem at hand. Without `opaque`, the Move Prover will use the implementation as the source of truth for the definition of the function. But with `opaque`, if there is an aspect of the function definition unspecified, an arbitrary meaning will be assumed. For example, with the specification below, the `increment` function can abort under arbitrary conditions:

```move
module 0x42::m {
  spec increment {
    pragma opaque;
    // aborts_if !exists<Counter>(a);  // We need to add this to make the function not abort arbitrarily
    ensures global<Counter>(a) == old(global<Counter>(a)) + 1;
  }
}
```

In general, `opaque` functions enable modular verification, as they abstract from the implementation
of functions, resulting in much faster verification.

If an `opaque` function modifies state, it is advised to use the [`modifies` condition](#modifies-condition) in its specification. If this is omitted, verification of the state changes will fail.

## Abstract specifications

The `[abstract]` property allows specifying a function such that abstract semantics are used at the
caller side that is different from the actual implementation. This is useful if the implementation
is too complex for verification, and abstract semantics are sufficient for verification goals.
The `[concrete]` property, in turn, still allows specifying conditions that are verified against
the implementation but not used at the caller side.

Consider the following example of a hash function. The actual value of the hash is not relevant for
verification of callers, and we use an [uninterpreted helper function](#uninterpreted-functions) delivering an arbitrary value chosen by the Move Prover. We can still specify the concrete implementation and verify its correctness:

```move
module 0x42::m {
  fun hash(v: vector<u8>): u64 {
    <<sum up values>>(v)
  }
  spec hash {
    pragma opaque;
    aborts_if false;
    ensures [concrete] result == << sum up values >> (v);
    ensures [abstract] result == spec_hash_abstract(v);
  }
  spec fun abstract_hash(v: vector<u8>): u64; // uninterpreted function
}
```

The soundness of the abstraction is the responsibility of the specifier and not verified by the
Move Prover.

> NOTE: The abstract/concrete properties should only be used with opaque specifications, but the Move Prover will currently not generate an error message even though they are not used with opaque specifications.

> NOTE: The `modifies` clause does not currently support abstract/concrete. Also, if no modifies is given, the modified state will be computed from the implementation anyway, possibly conflicting with `[abstract]` properties.

## Documentation generation

The organization of specification blocks in a file is relevant for documentation generation -- even
though it is not for the semantics.

# Expressiveness

The Move specification language is expressive enough to represent the full Move language semantics (formal argument outstanding) with one exception: functions that return a `&mut T` type.

Consider the following code:

```move
module 0x42::m {
  struct S { x: u64, y: u64 }

  fun x_or_y(b: bool, s: &mut S): &mut u64 {
    if (b) &mut s.x else &mut s.y
  }
  spec x_or_y {
    ensures b ==> result == s.x;
    ensures !b ==> result == s.y;
  }
}
```

We are not able to specify the _full_ semantics of `x_or_y` in MSL because we cannot capture the
semantics of mutable references. While we can say something about the value behind the reference at
function exit, subsequent effects as in `*x_or_y(b, &mut s) = 2` cannot be specified.

However, the Move Prover _does_ understand the meaning of such functions -- the restriction is only
in what we can specify. Practically, this means we cannot make the function `x_or_y` opaque and must
let verification rely on that the Move Prover directly works with the implementation. Specifically, we
can verify the following (which can then be opaque):

```move
module 0x42::m {
  fun x_or_y_test(s: S): S {
    *x_or_y(true, &mut s) = 2;
    s
  }
  spec x_or_y_test {
    pragma opaque;
    ensures result.x == 2;
    ensures result.y == s.y;
  }
}
```

## Supporting resources

- [Design by contract PRE\_POST\_REFERENCE](https://en.wikipedia.org/wiki/Design_by_contract)
- [APTOS\_FRAMEWORK](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/doc/overview.md)

# Supporting Resources

> Access supporting resources, documentation, and tools for Move Prover formal verification workflow.

## Standard Library and Framework Specifications

- [Move Stdlib](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/framework/move-stdlib)
- [Aptos Stdlib](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/framework/aptos-stdlib)
- [Aptos Framework](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/framework/aptos-framework)
- [Diem Framework](https://github.com/move-language/move/tree/main/language/documentation/examples/diem-framework/move-packages/DPN)

## Examples

- [`hello_prover` example](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/move-examples/hello_prover)
- [`basic-coin` example](https://github.com/move-language/move/tree/main/language/documentation/examples/experimental/basic-coin)
- [`math-puzzle` example](https://github.com/move-language/move/tree/main/language/documentation/examples/experimental/math-puzzle)
- [`rounding-error` example](https://github.com/move-language/move/tree/main/language/documentation/examples/experimental/rounding-error)
- [`verify-sort` example](https://github.com/move-language/move/tree/main/language/documentation/examples/experimental/verify-sort)
- [Move Prover Examples by Zellic](https://github.com/zellic/move-prover-examples)

## Tutorials

- [The Move Tutorial, steps 7 and 8](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/move-examples/move-tutorial#step-7--use-the-move-prover)
- [Verify Smart Contracts in Aptos with the Move Prover by MoveBit](https://www.movebit.xyz/blog/post/move-prover-tutorial-part-1.html)
- [The Move Prover: A Practical Guide by OtterSec](https://osec.io/blog/2022-09-16-move-prover)
- [Formal Verification, the Move Language, and the Move Prover by Certik](https://www.certik.com/resources/blog/2wSOZ3mC55AB6CYol6Q2rP-formal-verification-the-move-language-and-the-move-prover)
- [The Move Prover: Quality Assurance of Formal Verification by Certik](https://www.certik.com/resources/blog/1NygvVeqIwhbUk1U1q3vJF-the-move-prover-quality-assurance-of-formal-verification)

## Presentations

- [Verifying Smart Contracts with Move Prover by Wolfgang Grieskamp (video)](https://drive.google.com/file/d/1DpI-rQ25Kq1jqMGioLgVrG3YuCqJHVMm/view?usp=share_link)
- [Formal verification of Move programs for the Libra blockchain by David Dill (video)](https://www.fields.utoronto.ca/talks/Formal-verification-Move-programs-Libra-blockchain)
- [Move Prover - Best Practices & Tricks - A User‚Äôs Perspective by Xu-Dong@MoveBit (slides)](https://docs.google.com/presentation/d/1SuV0m5gGxSN9SaLdj9lLmTjspJ2xN1TOWgnwvdWbKEY/edit?usp=sharing)

## Conference papers

- Zhong, Jingyi Emma, Kevin Cheang, Shaz Qadeer, Wolfgang Grieskamp,
  Sam Blackshear, Junkil Park, Yoni Zohar, Clark Barrett, and David L. Dill.
  "The move prover." In _International Conference on Computer Aided Verification_,
  pp. 137-150. Springer, Cham, 2020.Harvard
  - [https://research.facebook.com/publications/the-move-prover/](https://research.facebook.com/publications/the-move-prover/)
- Dill, David, Wolfgang Grieskamp, Junkil Park, Shaz Qadeer, Meng Xu, and Emma
  Zhong. "Fast and reliable formal verification of smart contracts with the Move
  prover." In _International Conference on Tools and Algorithms for the
  Construction and Analysis of Systems_, pp. 183-200. Springer, Cham, 2022.Harvard
  - [https://research.facebook.com/publications/fast-and-reliable-formal-verification-of-smart-contracts-with-the-move-prover/](https://research.facebook.com/publications/fast-and-reliable-formal-verification-of-smart-contracts-with-the-move-prover/)
- Park, Junkil, Teng Zhang, Wolfgang Grieskamp, Meng Xu, Gerardo Di Giacomo, Kundu Chen, Yi Lu, and Robert Chen. "Securing Aptos framework with formal verification." In _5th International Workshop on Formal Methods for Blockchains (FMBC 2024)_. Schloss Dagstuhl‚ÄìLeibniz-Zentrum f√ºr Informatik, 2024.
  - [https://drops.dagstuhl.de/storage/01oasics/oasics-vol118-fmbc2024/OASIcs.FMBC.2024.9/OASIcs.FMBC.2024.9.pdf](https://drops.dagstuhl.de/storage/01oasics/oasics-vol118-fmbc2024/OASIcs.FMBC.2024.9/OASIcs.FMBC.2024.9.pdf)

# Randomness API

> Learn about randomness for Move smart contract development on Aptos blockchain.

import { Aside } from '@astrojs/starlight/components';

## What does it do: a quick example

### How random numbers have been obtained, insecurely/awkwardly

Building a lottery system and pick a random winner from `n` participants is trivial, at least in the centralized world with a trusted server:
the backend simply calls a random integer sampling function
(`random.randint(0, n-1)` in python, or `Math.floor(Math.random() * n)` in JS).

Unfortunately, without an equivalent of `random.randint()` in Aptos Move, building a dApp version of it was actually much harder.

One may have written a contract where the random numbers are sampled insecurely (e.g., from the blockchain timestamp):

```move
module module_owner::lottery {
    // ...

    struct LotteryState {
        players: vector<address>,
        winner_idx: std::option::Option<u64>,
    }

    fun load_lottery_state_mut(): &mut LotteryState {
        // ...
    }

    entry fun decide_winner() {
        let lottery_state = load_lottery_state_mut();
        let n = std::vector::length(&lottery_state.players);
        let winner_idx = aptos_framework::timestamp::now_microseconds() % n;
        lottery_state.winner_idx = std::option::some(winner_idx);
    }
}
```

The implementation above is insecure in multiple ways:

- a malicious user may bias the result by picking the transaction submission time;
- a malicious validator can bias the result easily by selecting which block the `decide_winner` transaction goes to.

Other dApps may have chosen to use an external secure randomness source
(e.g., [drand](https://drand.love/)), which is typically a complicated flow:

1. The participants agree on using a future randomness seed promised by the randomness source to determine the winner.
2. Once the randomness seed is revealed, the clients fetch it and derive the winner locally.
3. One of the participants submits the seed and the winner on chain.

```move
module module_owner::lottery {
    // ...

    struct LotteryState {
        players: vector<address>,
        /// public info about the "future randomness", tyipcally a VRF public key and an input.
        seed_verifier: vector<u8>,
        winner_idx: std::option::Option<u64>,
    }

    fun load_lottery_state_mut(): &mut LotteryState {
        // ...
    }

    fun is_valid_seed(seed_verifier: vector<u8>, seed: vector<u8>): bool {
        // ...
    }

    fun derive_winner(n: u64, seed: vector<u8>): u64 {
        // ...
    }

    entry fun update_winner(winner_idx: u64, seed: vector<u8>) {
        let lottery_state = load_lottery_state_mut();
        assert!(is_valid_seed(lottery_state.seed_verifier, seed), ERR_INVALID_SEED);
        let n = std::vector::length(players);
        let expected_winner_idx = derive_winner(n, seed);
        assert!(expected_winner_idx == winner_idx, ERR_INCORRECT_DERIVATION);
        lottery_state.winner_idx = std::option::some(winner_idx);
    }
}
```

### Achieve simplicity + security with Aptos randomness API

Using Aptos randomness API, the implementation will look like this:

```move
module module_owner::lottery {
    // ...
    use aptos_framework::randomness;

    struct LotteryState {
        players: vector<address>,
        winner_idx: std::option::Option<u64>,
    }

    fun load_lottery_state_mut(): &mut Lottery {
        // ...
    }

    #[randomness]
    entry fun decide_winner() {
        let lottery_state = load_lottery_state_mut();
        let n = vector::length(&lottery_state.players);
        let winner_idx = aptos_framework::randomness::u64_range(0, n);
        lottery_state.winner_idx = std::option::some(winner_idx);
    }
}
```

where:

- `let winner_idx = aptos_framework::randomness::u64_range(0, n);` is the randomness API call that returns an u64 integer in range `[0, n)` uniformly at random.
- `#[randomness]` is a required attribute to enable the API call at runtime.

<Aside type="note">
  ### Security Considerations

  Compiler helps with test and abort attacks, requiring functions using randomness to be private.  However, the randomness API currently does not prevent undergasing attacks.  The smart contract will need to be written in a certain way to avoid it.
</Aside>

## How to use Aptos randomness API

### Prerequisites

Ensure you have the latest [aptos-cli](/build/cli) installed.

### Keep undergasing attacks in mind

<Aside type="caution">
  **The randomness API currently does not prevent undergasing attacks.** Carefully read the undergasing section to understand about undergasing attacks and how to prevent them. As a dApp developer, you will need to design applications using randomness with safety in mind.
</Aside>

### Identify randomness-dependent entry functions and make them compliant

For safety (discussed with more details later), randomness API calls are only allowed from an entry function that is:

- private, and
- annotated with `#[randomness]`.

It's now a good time to think about what user actions need randomness API, write them down, and make sure they are private and have the right attribute, as shown in the example below.

```move
module module_owner::lottery {
    // ...

    #[randomness]
    entry fun decide_winner() {
        // ...
    }
}
```

At runtime, when randomness API is called, the VM checks whether the outermost of the callstack is a private entry function with `#[randomness]` attribute.
**If not, the entire transaction is aborted.**

<Aside type="note">
  NOTE: It also means randomness API calls are supported only in entry function-based transactions.
  (For example, using randomness API in a Move script is impossible.)
</Aside>

### Call the API

The APIs are public functions under `0x1::randomness` and can be referenced directly, as demonstrated in the lottery example above.

```move
module module_owner::lottery {
    // ...
    use aptos_framework::randomness;

    #[randomness]
    entry fun decide_winner() {
        // ...
        let winner_idx = aptos_framework::randomness::u64_range(0, n);
        lottery_state.winner_idx = std::option::some(winner_idx);
    }
}
```

The above example uses function `u64_range()` but many other basic types are also supported.
Here's a quick overview of all the API, where `T` can be one of `u8, u16, u32, u64, u128, u256`.

```move
module aptos_framework::randomness {
    /// Generates an number uniformly at random.
    fun u8_integer(): u8 {}

    /// Generates an number uniformly at random.
    fun u16_integer(): u16 {}

    // fun u32_integer(), fun u64_integer() ...

    /// Generates a number `[min_incl, max_excl)` uniformly at random.
    fun u8_range(min_incl: u8, max_excl: u8): u8 {}

    /// Generates a number `[min_incl, max_excl)` uniformly at random.
    fun u16_range(min_incl: u16, max_excl: u16): u16 {}

    // fun u32_range(), fun u64_range() ...

    /// Generates a sequence of bytes uniformly at random
    /// n is the number of bytes
    /// If n is 0, returns the empty vector.
    fun bytes(n: u64): vector<u8> {}

    /// Generate a permutation of `[0, 1, ..., n-1]` uniformly at random.
    /// n is the number of bytes
    /// If n is 0, returns the empty vector.
    fun permutation(n: u64): vector<u64> {}
}
```

The full API function list and documentation can be found [here](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/doc/randomness.md).

## Security considerations

Randomness API is powerful in many ways: it unlocks new dApp designs;
but if used incorrectly, it may leave your dApps open to attacks!
Below are some common mistakes you should avoid.

### Randomness API calls in public functions

As your dApp gets more complicated, you may have multiple entry functions that need to share the same randomness-dependent logic, and want to pull the logic out as a separate helper function.

While this is supported as shown below, extra care must be taken.

```move
module module_owner::lottery {
    // ...
    use aptos_framework::randomness;

    #[randomness]
    entry fun decide_winner_v0() {
        // ...
        decide_winner_internal(lottery_state);
    }

    #[randomness]
    entry fun decide_winner_v1() {
        // ...
        decide_winner_internal(lottery_state);
    }

    // A private helper function
    fun decide_winner_internal(lottery_state: &mut lottery_state) {
        let n = std::vector::length(&lottery_state.players);
        let winner_idx = aptos_framework::randomness::u64_range(0, n);
        lottery_state.winner_idx = std::option::some(winner_idx);
    }
}
```

If `decide_winner_internal()` were accidentally marked public,
malicious players can deploy their own contract to:

1. call`decide_winner_internal()`;
2. read the lottery result (assuming the `lottery` module has some getter functions for the result);
3. abort if the result is not in their favor.
   By repeatedly calling their own contract until a txn succeeds,
   malicious users can bias the uniform distribution of the winner (dApp developer's initial design).
   This is referred to as a [test-and-abort attack](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-41.md#test-and-abort-attacks).

The Aptos Move compiler has been updated to prevent this attack for your contract safety:
a randomness-dependent public function is treated as a compile error.
If you have finished the steps in the ["build Aptos CLI"](/build/cli) section,
then your Aptos CLI are equipped with the updated compiler.

```move
module module_owner::lottery {
    // Compile error!
    public fun decide_winner_internal(lottery_state: &mut lottery_state) {
        let n = std::vector::length(&lottery_state.players);
        let winner_idx = aptos_framework::randomness::u64_range(0, n);
        lottery_state.winner_idx = std::option::some(winner_idx);
    }
}
```

Not recommended, but if you intend to expose such a randomness-dependent function to the public, you can bypass the compiler check by annotating your function with `#[lint::allow_unsafe_randomness]`.

```move
module module_owner::lottery {
    // Can compile, but use it at your own risk!
    #[lint::allow_unsafe_randomness]
    public fun decide_winner_internal(lottery_state: &mut lottery_state) {
        let n = std::vector::length(&lottery_state.players);
        let winner_idx = aptos_framework::randomness::u64_range(0, n);
        lottery_state.winner_idx = std::option::some(winner_idx);
    }
}
```

### Undergasing attacks, and how to prevent

Imagine such a dApp. It defines a private entry function for a user to:

1. toss a coin (gas cost: 9), then
2. get a reward (gas cost: 10) if coin=1, or do some cleanup (gas cost: 100) otherwise.

A malicious user can control its account balance, so it covers at most 108 gas units (or set transaction parameter `max_gas=108`),
and the cleanup branch (total gas cost: 110) will always abort with an out-of-gas error.
The user then repeatedly call the entry function until it gets the reward.

Formally, this is referred to as an [undergasing attack](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-41.md#undergasing-attacks),
where an attacker can control how much gas is left for the entry function to execute,
and so can arbitrarily decide to abort paths that cost more gas,
biasing the outcome (i.e., effectively changing the distribution of random numbers).

<Aside type="caution">
  **WARNING: randomness API currently does not prevent undergasing attacks.**
  As a dApp developer, you need to be very careful in your design to avoid this type of attack.
  Here are some ideas of how to prevent undergasing attack generally.

  - Make your entry function gas independent from the randomness outcome.
    The simplest example is to not "act" on the randomness outcome, i.e., read it and store it for later. Note that calling any other functions  can have variable gas costs. For example, when calling randomness to decide which player should win, and then depositing the winnings to the winner might seem like a fixed gas cost. But, `0x1::coin::transfer` / `0x1::fungible_asset::transfer` can have a variable cost based on the user's on-chain state.
  - If your dApp involves a trusted admin/admin group, only allow the trusted to execute randomness transaction (i.e., require an admin signer).
  - Make the path that is most beneficial have the highest gas (as attacker can only abort paths with gas above a threshold he chooses.
    NOTE: that this can be tricky to get right, and gas schedule can change, and is even harder to get right when there are more than 2 possible outcomes.

  Note that everything that does not fall in above categories can be susceptible to undergasing attack in a subtle ways. Reach out if you need help.

  We will be providing more functionality in the future, to allow for more complex code to be able to be safe against undergasing attacks.
</Aside>

### It's random, but not a secret

While the randomness API mimics the standard libraries you use to implement a private centralized server,
keep in mind that **the seed is public, and so is your transaction execution**,
and not every randomness-dependent logic in your private centralized server can be transferred on chain safely,
**especially when it involves a secret that only the server should see**.

For example, in your contract, DO NOT try to do the following.

- Use randomness API to generate an asymmetric key pair, discard the private key, then think the public key is safe.
- Use randomness API to shuffle some opened cards, veil them, and think no one knows the permutation.

## Read more

[Aptogotchi Random Mint](https://github.com/aptos-labs/aptogotchi-random-mint/tree/main) is an official demo dApp built to demonstrate the use of randomness API.

The full API function list and documentation can be found [here](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/doc/randomness.md).

You can also find the partial implementation of the API functions and example unit tests [here](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/randomness.move).

See [AIP-41](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-41.md) for the API design,
and [AIP-79](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-79.md) if you are interested in system-level/cryptography details.

# Resource Accounts

> Learn about resource accounts for Move smart contract development on Aptos blockchain.

[Object Code Deployment](/build/smart-contracts/deployment) is the preferred method for deploying and upgrading smart contracts in Aptos. Resource accounts require developers to generate seeds
each time a resource account is created, and upgrading contracts requires specific steps which is prone to error.

A [resource account](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/resource_account.move)
is a developer feature used to manage resources independent of an account
managed by a user, specifically publishing modules and providing on-chain-only
access control, e.g., signers.

Typically, a resource account is used for two main purposes:

- Store and isolate resources; a module creates a resource account just to host
  specific resources.
- Publish module as a standalone (resource) account, a building block in a
  decentralized design where no private keys can control the resource account. The
  ownership (SignerCap) can be kept in another module, such as governance.

## Restrictions

In Aptos, a resource account is created based upon the SHA3-256 hash of the
source's address and additional seed data. A resource account can be created
only once; for a given source address and seed, there can be only one resource
account. That is because the calculation of the resource account address is
fully determined by the former.

An entity may call `create_account` in an attempt to claim an account ahead of
the creation of a resource account. But if a resource account is found, Aptos
will transition ownership of the account over to the resource account. This is
done by validating that the account has yet to execute any transactions and that
the `Account::signer_capbility_offer::for` is none. The probability of a
collision where someone has legitimately produced a private key that maps to a
resource account address is improbably low.

## Setup

The easiest way to set up a resource account is by:

1. Using Aptos CLI: `aptos account create-resource-account` creates a resource
   account, and `aptos move create-resource-account-and-publish-package` creates a
   resource account and publishes the specified package under the resource account's
   address.
2. Writing custom smart contracts code: in the `resource_account.move` module,
   developers can find the resource account creation functions
   `create_resource_account`, `create_resource_account_and_fund`, and
   `create_resource_account_and_publish_package`. Developers can then call those
   functions to create resource accounts in their smart contracts.

Each of those options offers slightly different functionality:

- `create_resource_account` - merely creates the resource account but doesn't
  fund it, retaining access to the resource account's signer until explicitly
  calling `retrieve_resource_account_cap`.
- `create_resource_account_and_fund` - creates the resource account and funds it,
  retaining access to the resource account's signer until explicitly calling
  `retrieve_resource_account_cap`.
- `create_resource_account_and_publish_package` - creates the resource account
  and results in loss of access to the resource account by design, because
  resource accounts are used to make contracts autonomous and immutable.

In this example, you will [initialize](https://github.com/aptos-labs/aptos-core/blob/2e9d8ee759fcd3f6e831034f05c1656b1c48efc4/aptos-move/move-examples/mint_nft/sources/minting.move#L73) the `mint_nft` module and retrieve
the signer capability from both the resource account and module account. To do
so, call `create_resource_account_and_publish_package` to publish the module
under the resource account's address.

1. Initialize the module as shown in the [`minting.move`](https://github.com/aptos-labs/aptos-core/blob/2e9d8ee759fcd3f6e831034f05c1656b1c48efc4/aptos-move/move-examples/mint_nft/sources/minting.move#L73) example.
2. Call `create_resource_account_and_publish_package` to publish the module
   under the resource account's address, such as in the [`mint_nft.rs`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/e2e-move-tests/src/tests/mint_nft.rs#L62)
   end-to-end example.
3. Retrieve the signer cap from the resource account + module account as shown
   in the [`minting.move`](https://github.com/aptos-labs/aptos-core/blob/2e9d8ee759fcd3f6e831034f05c1656b1c48efc4/aptos-move/move-examples/mint_nft/sources/minting.move#L83) example.

Note, if the above `resource_account` signer is **not** already set up as a
resource account, retrieving the signer cap will fail. The `source_addr` field
in the `retrieve_resource_account_cap` function refers to the address of the
source account, or the account that creates the resource account.

For an example, see the `SignerCapability` employed by the `mint_nft` function
in [`minting.move`](https://github.com/aptos-labs/aptos-core/blob/2e9d8ee759fcd3f6e831034f05c1656b1c48efc4/aptos-move/move-examples/mint_nft/sources/minting.move#L143-L181).

For more details, see the "resource account" references in [`resource_account.move`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/resource_account.move)
and [`account.move`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/account/account.move).

# Building with Move Scripts

> Guide to scripts in Move scripts for Aptos blockchain operations.

Move Scripts are a way to run multiple public functions on Aptos in a single
transaction. This is similar to deploying a helper module that would do common
tasks, but allows for the flexibility of not having to deploy beforehand.

An example would be a function to transfer a half of a user's balance to another
account. This is something that is easily programmable, but likely would not
need a module deployed for it:

```move
script {
  use std::signer;
  use aptos_framework::coin;
  use aptos_framework::aptos_account;

  fun transfer_half<Coin>(caller: &signer, receiver_address: address) {
    // Retrieve the balance of the caller
    let caller_address: address = signer::address_of(caller);
    let balance: u64 = coin::balance<Coin>(caller_address);

    // Send half to the receiver
    let half = balance / 2;
    aptos_account::transfer_coins<Coin>(caller, receiver_address, half);
  }
}
```

# Learn more about using Move Scripts

- [Writing scripts](/build/smart-contracts/scripts/writing-scripts)
- [Compiling scripts](/build/smart-contracts/scripts/compiling-scripts)
- [Running scripts](/build/smart-contracts/scripts/running-scripts)

# More details

For more details on Move Scripts, checkout:

- [Move Book on Scripts](/build/smart-contracts/book/modules-and-scripts)
- [Tutorial on Scripts](/build/smart-contracts/scripts/script-tutorial)

# Compiling Move Scripts

> Understand how to compile Move scripts with proper configuration and deployment preparation.

Move scripts can be compiled with the already existing Aptos Move compiler in
the Aptos CLI. For more on how to install and use the Aptos CLI with Move contracts, go to the [Working With Move Contracts](/build/cli/working-with-move-contracts) page.

Once you have the Aptos CLI installed, you can compile a script by running the following command from within the script package:

```shellscript filename="Terminal"
aptos move compile
```

There will then be compiled bytecode files under `build/` with the same name as
the function in Move.

For example this script in package `transfer_half`, would compile
to `build/transfer_half/bytecode_scripts/transfer_half.mv`

```move
script {
  use std::signer;
  use aptos_framework::coin;
  use aptos_framework::aptos_account;

  fun transfer_half<Coin>(caller: &signer, receiver_address: address) {
    // Retrieve the balance of the caller
    let caller_address: address = signer::address_of(caller);
    let balance: u64 = coin::balance<Coin>(caller_address);

    // Send half to the receiver
    let half = balance / 2;
    aptos_account::transfer_coins<Coin>(caller, receiver_address, half);
  }
}
```

Additionally, there is a convenience function for a package with exactly one
script with the below command:

```shellscript filename="Terminal"
aptos move compile-script
```

Providing output like below returning the exact location of the script and a
hash for convenience

```shellscript filename="Terminal"
Compiling, may take a little while to download git dependencies...
UPDATING GIT DEPENDENCY https://github.com/aptos-labs/aptos-framework.git
INCLUDING DEPENDENCY AptosFramework
INCLUDING DEPENDENCY AptosStdlib
INCLUDING DEPENDENCY MoveStdlib
BUILDING transfer_half
{
  "Result": {
    "script_location": "/opt/git/developer-docs/apps/docusaurus/static/move-examples/scripts/transfer_half/script.mv",
    "script_hash": "9b57ffa952da2a35438e2cf7e941ef2120bb6c2e4674d4fcefb51d5e8431a148"
  }
}
```

# Running Move Scripts

> Learn how to execute Move scripts on Aptos blockchain for one-time operations and complex transactions.

import { Aside } from '@astrojs/starlight/components';

Move scripts are supported in the Aptos TypeScript SDK, Aptos Wallet Adapter,
and in the Aptos CLI.

## Running scripts with the TypeScript SDK

To use a script with the TypeScript SDK, add the `bytecode` directly to the
transaction in place of an entry function name.

```typescript
import { readFileSync } from "fs";
import { Aptos, Account, AccountAddress } from "@aptos-labs/ts-sdk";

// Setup client, and account to sign
const aptos = new Aptos();
const account = Account.generate();

// Load script bytecode
const buffer = readFileSync("./transfer_half.mv", "buffer");
const bytecode = new Uint8Array.from(buffer);

// Build a transaction with the bytecode of the script
const transaction = await aptos.transaction.build.simple({
  sender: account.accountAddress,
  data: {
    bytecode,
    typeArguments: [parseTypeTag("0x1::aptos_coin::AptosCoin")],
    functionArguments: [AccountAddress.from("0x1")],
  },
});

// Submit and wait for the transaction to complete
const pendingTxn = await aptos.signAndSubmitTransaction({
  signer: account,
  transaction,
});
await aptos.waitForTransaction({ transactionHash: pendingTxn.hash });
```

## Running scripts with the Aptos Wallet Adapter

<Aside type="caution">
  Not all wallets support scripts, but when the wallet supports scripts, it can be
  provided as below
</Aside>

Similar to the TypeScript SDK, the same inputs are accepted as a transaction
type on the wallet adapter. Just simply load the bytecode as a hex `string` or
a `uint8array`.

```typescript
import { useWallet } from "@aptos-labs/wallet-adapter-react";

//...

// Load the bytecode either as a uint8array or a hex encoded string
const BYTECODE_IN_HEX = "0xa11ceb0b...78979";

export default function App() {
  const { signAndSubmitTransaction } = useWallet();

  function submitScript() {
    signAndSubmitTransaction({
      data: {
        bytecode: BYTECODE_IN_HEX,
        typeArguments: [parseTypeTag("0x1::aptos_coin::AptosCoin")],
        functionArguments: [AccountAddress.from("0x1")],
      },
    });
  }

  // ...
}
```

## Running scripts with the CLI

Running scripts with the CLI can be run with the command

```shellscript filename="Terminal"
aptos move run-script
```

There are two ways to run it, with a pre-compiled script, or it will compile the
script in-place similar to the compile step.

If you already have a compiled script, you can run it
with `--compiled-script-path` like the example below:

```shellscript filename="Terminal"
aptos move run-script --compiled-script-path /opt/git/developer-docs/apps/docusaurus/static/move-examples/scripts/transfer_half/script.mv
```

Similarly, if it's not compiled, just use `--script-path`

```shellscript filename="Terminal"
aptos move run-script --script-path ./sources/transfer_half.move
```

# Move Scripts Tutorial

> Step-by-step tutorial for creating and deploying Move scripts with practical examples and best practices.

import { FileTree } from '@astrojs/starlight/components';

This tutorial explains how to write and execute a [Move script](/build/smart-contracts/book/modules-and-scripts). You can use Move scripts to execute a series of commands across published Move module interfaces.

For more information about scripts, see the [Move scripts docs](/build/smart-contracts/scripts)

## Example use case

The following example calls functions on the [aptos\_coin.move](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/aptos_coin.move) module to confirm the balance of the destination account is less than `desired_balance`, and if so, tops it up to `desired_balance`.

```move
script {
    use std::signer;
    use aptos_framework::aptos_account;
    use aptos_framework::aptos_coin;
    use aptos_framework::coin;

    fun main(src: &signer, dest: address, desired_balance: u64) {
        let src_addr = signer::address_of(src);

        addr::my_module::do_nothing();

        let balance = coin::balance<aptos_coin::AptosCoin>(src_addr);
        if (balance < desired_balance) {
            aptos_account::transfer(src, dest, desired_balance - balance);
        };
    }
}
```

## Execution

Now that you know what you would like to accomplish, you need to determine:

- Where do I put these files?
- What do I name them?
- Do I need a `Move.toml`?
- How do I run my script with the CLI?

Let us run through how to execute a Move script with a step-by-step example using the [Aptos CLI](/build/cli/working-with-move-contracts).

1. Make a new directory for your work:

   ```shellscript filename="Terminal"
   mkdir testing
   cd testing
   ```

2. Set up the Aptos CLI and [create an account](/build/cli/setup-cli):

   ```shellscript filename="Terminal"
   aptos init --network devnet
   ```

   You may reuse an existing private key (which looks like this: `0xbd944102bf5b5dfafa7fe865d8fa719da6a1f0eafa3cd600f93385482d2c37a4`), or it can generate a new one for you, as part of setting up your account. Let's say your account looks like the example below:

   ```shellscript filename="Terminal"
   ---
   profiles:
     default:
       private_key: "0xbd944102bf5b5dfafa7fe865d8fa719da6a1f0eafa3cd600f93385482d2c37a4"
       public_key: "0x47673ec83bb254cc9a8bfdb31846daacd0c96fe41f81855462f5fc5306312b1b"
       account: cb265645385819f3dbe71aac266e319e7f77aed252cacf2930b68102828bf615
       rest_url: "https://api.devnet.aptoslabs.com"
       faucet_url: "https://faucet.devnet.aptoslabs.com"
   ```

3. From this same directory, initialize a new Move project:

   ```shellscript filename="Terminal"
   aptos move init --name run_script
   ```

4. Create a `my_script.move` file containing the example script above in a `sources/` subdirectory of your `testing/` directory. Also, create a `my_module.move` file as seen in the example below:

   ```move
   module addr::my_module {
       public entry fun do_nothing() { }
   }
   ```

   This results in the following file structure:

<FileTree>
  - testing/
    - Move.toml
    - sources/
      - my\_script.move
      - my\_module.move
</FileTree>

5. Compile the script:

   ```shellscript filename="Terminal"
   $ aptos move compile --named-addresses addr=cb265645385819f3dbe71aac266e319e7f77aed252cacf2930b68102828bf615
   Compiling, may take a little while to download git dependencies...
   INCLUDING DEPENDENCY AptosFramework
   INCLUDING DEPENDENCY AptosStdlib
   INCLUDING DEPENDENCY MoveStdlib
   BUILDING run_script
   {
     "Result": [
       "cb265645385819f3dbe71aac266e319e7f77aed252cacf2930b68102828bf615::my_module"
     ]
   }
   ```

   Note how we use the `--named-addresses` argument. This is necessary because in the code we refer to this named address called `addr`. The compiler needs to know what this refers to. Instead of using this CLI argument, you could put something like this in your `Move.toml`:

   ```toml
   [addresses]
   addr = "cb265645385819f3dbe71aac266e319e7f77aed252cacf2930b68102828bf615"
   ```

6. Run the compiled script:
   ```shellscript filename="Terminal"
   $ aptos move run-script --compiled-script-path build/run_script/bytecode_scripts/main.mv --args address:b078d693856a65401d492f99ca0d6a29a0c5c0e371bc2521570a86e40d95f823 --args u64:5
   Do you want to submit a transaction for a range of [17000 - 25500] Octas at a gas unit price of 100 Octas? [yes/no] >
   yes
   {
     "Result": {
       "transaction_hash": "0xa6ca6275c73f82638b88a830015ab81734a533aebd36cc4647b48ff342434cdf",
       "gas_used": 3,
       "gas_unit_price": 100,
       "sender": "cb265645385819f3dbe71aac266e319e7f77aed252cacf2930b68102828bf615",
       "sequence_number": 4,
       "success": true,
       "timestamp_us": 1683030933803632,
       "version": 3347495,
       "vm_status": "Executed successfully"
     }
   }
   ```

Note that the path of the compiled script is under `build/run_script/`, not `build/my_script/`. This is because it uses the name of the project contained in `Move.toml`, which is `run_script` from when we ran `aptos move init --name run_script`.

See the [code](https://github.com/banool/move-examples/tree/main/run_script) used for this document. The full example explains how to use a Move script that relies on a user-created Move module as well.

See also how to do this with the [Rust SDK](https://github.com/aptos-labs/aptos-developer-discussions/discussions/24) instead of the Aptos CLI in Aptos Developer Discussions.

## Advanced

You may execute a script in a more streamlined fashion; instead of running `aptos move compile` and then `aptos move run-script --compiled-script-path` separately, you can just do this:

```shellscript filename="Terminal"
$ aptos move run-script --script-path sources/my_script.move --args address:b078d693856a65401d492f99ca0d6a29a0c5c0e371bc2521570a86e40d95f823 --args u64:5
```

This will conduct both steps with a single CLI command yet has [issues](https://github.com/aptos-labs/aptos-core/issues/5733). For this reason, we recommend using the previous two-step approach for now.

# How can I write Move Scripts?

> Learn how to write Move scripts for batch operations, administrative tasks, and complex transaction flows.

import { FileTree } from '@astrojs/starlight/components';

Move scripts can be written in tandem with Move contracts, but it's highly
suggested to use a separate Move package for it. This will make it easier for
you to determine which bytecode file comes from the script.

## Package layout

The package needs a Move.toml and a sources directory, similar to code modules.

For example, we may have a directory layout like:

<FileTree>
  - my\_project/
    - Move.toml
    - sources/
      - my\_script.move
</FileTree>

## Script syntax

Scripts can be written exactly the same as modules on Aptos. Imports can be used
for any dependencies in the Move.toml file, and all public functions, including
entry functions, can be called from the contract. There are a few limitations:

- There must be only one function in the contract, it will compile to that name.
- Input arguments can only be one of
  \[`u8`, `u16`, `u32`, `u64`, `u256`, `address`, `bool`, `signer`, `&signer`, `vector<u8>`].
  There is no support for vectors of other types, or structs.

An example below:

```move
script {
  use std::signer;
  use aptos_framework::coin;
  use aptos_framework::aptos_account;

  fun transfer_half<Coin>(caller: &signer, receiver_address: address) {
    // Retrieve the balance of the caller
    let caller_address: address = signer::address_of(caller);
    let balance: u64 = coin::balance<Coin>(caller_address);

    // Send half to the receiver
    let half = balance / 2;
    aptos_account::transfer_coins<Coin>(caller, receiver_address, half);
  }
}
```

For more specific details see:
[Move Book on Scripts](/build/smart-contracts/book/modules-and-scripts)

# Smart Table

> Learn about smart table for Move smart contract development on Aptos blockchain.

The Smart Table is a scalable hash table implementation based on linear hashing.
This data structure aims to optimize storage and performance by utilizing linear hashing, which splits one bucket at a time instead of doubling the number of buckets, thus avoiding unexpected gas costs.
The Smart Table uses the SipHash function for faster hash computations while tolerating collisions.

## Core Features of SmartTable

### Structure

The `SmartTable` struct is designed to handle dynamic data efficiently:

- `buckets`: A table with a length that stores vectors of entries.
- `num_buckets`: The current number of buckets.
- `level`: The number of bits representing `num_buckets`.
- `size`: The total number of items in the table.
- `split_load_threshold`: The load threshold percentage that triggers bucket splits.
- `target_bucket_size`: The target size of each bucket, which is not strictly enforced.

### Constants

The following constants define various error codes used within the module:

- `ENOT_FOUND`: 1
- `EZERO_CAPACITY`: 2
- `ENOT_EMPTY`: 3
- `EALREADY_EXIST`: 4
- `EINVALID_LOAD_THRESHOLD_PERCENT`: 5
- `EINVALID_TARGET_BUCKET_SIZE`: 6
- `EEXCEED_MAX_BUCKET_SIZE`: 7
- `EINVALID_BUCKET_INDEX`: 8
- `EINVALID_VECTOR_INDEX`: 9

### API Overview

#### Creating Tables

- `new<K: copy + drop + store, V: store>(): SmartTable<K, V>`: Creates an empty table with default configurations.
- `new_with_config<K: copy + drop + store, V: store>(num_initial_buckets: u64, split_load_threshold: u8, target_bucket_size: u64): SmartTable<K, V>`: Creates an empty table with custom configurations.

#### Destroying Tables

- `destroy_empty<K, V>(table: SmartTable<K, V>)`: Destroys an empty table.
- `destroy<K: drop, V: drop>(table: SmartTable<K, V>)`: Destroys a table and its elements.
- `clear<K: drop, V: drop>(table: &mut SmartTable<K, V>)`: Clears all elements from the table.

#### Managing Entries

- `add<K, V>(table: &mut SmartTable<K, V>, key: K, value: V)`: Adds a key-value pair to the table.
- `add_all<K, V>(table: &mut SmartTable<K, V>, keys: vector<K>, values: vector<V>)`: Adds multiple key-value pairs to the table.
- `remove<K: copy + drop, V>(table: &mut SmartTable<K, V>, key: K): V`: Removes and returns the value associated with a key.
- `upsert<K: copy + drop, V: drop>(table: &mut SmartTable<K, V>, key: K, value: V)`: Inserts or updates a key-value pair.

#### Retrieving Entries

- `borrow<K: drop, V>(table: &SmartTable<K, V>, key: K): &V`: Returns an immutable reference to the value associated with a key.
- `borrow_with_default<K: copy + drop, V>(table: &SmartTable<K, V>, key: K, default: &V): &V`: Returns the value associated with a key or a default value if the key is not found.
- `borrow_mut<K: drop, V>(table: &mut SmartTable<K, V>, key: K): &mut V`: Returns a mutable reference to the value associated with a key.
- `borrow_mut_with_default<K: copy + drop, V: drop>(table: &mut SmartTable<K, V>, key: K, default: V): &mut V`: Inserts a key-value pair if the key is not found, then returns a mutable reference to the value.

#### Utility Functions

- `length<K, V>(table: &SmartTable<K, V>): u64`: Returns the number of entries in the table.
- `load_factor<K, V>(table: &SmartTable<K, V>): u64`: Returns the load factor of the table.
- `update_split_load_threshold<K, V>(table: &mut SmartTable<K, V>, split_load_threshold: u8)`: Updates the split load threshold.
- `update_target_bucket_size<K, V>(table: &mut SmartTable<K, V>, target_bucket_size: u64)`: Updates the target bucket size.
- `to_simple_map<K: store + copy + drop, V: store + copy>(table: &SmartTable<K, V>): SimpleMap<K, V>`: Converts the smart table to a simple map.

## Example Usage

### Creating and Using a SmartTable

```move filename="smart_table.move"
module 0x42::smart_table_usage {
    use aptos_std::smart_table;

    public entry fun main() {
        let table = smart_table::new<u64, u64>();
        smart_table::add(&mut table, 1, 100);
        smart_table::add(&mut table, 2, 200);

        let length = smart_table::length(&table);
        assert!(length == 2, 0);

        let value1 = smart_table::borrow(&table, 1);
        assert!(*value1 == 100, 0);

        let value2 = smart_table::borrow(&table, 2);
        assert!(*value2 == 200, 0);

        let removed_value = smart_table::remove(&mut table, 1);
        assert!(removed_value == 100, 0);

        smart_table::destroy_empty(table);
    }
}
```

### Adding Multiple Entries to a SmartTable

```move filename="smart_table.move"
module 0x42::smart_table_usage {
    use aptos_std::smart_table;

    public fun add_multiple_entries() {
        let table = smart_table::new<u64, u64>();
        let keys = vector[1, 2, 3];
        let values = vector[100, 200, 300];

        smart_table::add_all(&mut table, keys, values);

        let length = smart_table::length(&table);
        assert!(length == 3, 0);

        let value1 = smart_table::borrow(&table, 1);
        assert!(*value1 == 100, 0);

        let value2 = smart_table::borrow(&table, 2);
        assert!(*value2 == 200, 0);

        let value3 = smart_table::borrow(&table, 3);
        assert!(*value3 == 300, 0);

        smart_table::destroy_empty(table);
    }
}
```

### Updating and Clearing Table

```move filename="smart_table.move"
module 0x42::smart_table_usage {
    use aptos_std::smart_table;

    public fun update_and_clear_table() {
        let table = smart_table::new<u64, u64>();
        smart_table::add(&mut table, 1, 100);
        smart_table::add(&mut table, 2, 200);

        smart_table::upsert(&mut table, 2, 300);
        let value2 = smart_table::borrow(&table, 2);
        assert!(*value2 == 300, 0);

        smart_table::clear(&mut table);
        let length = smart_table::length(&table);
        assert!(length == 0, 0);

        smart_table::destroy_empty(table);
    }
}
```

### Converting to Simple Map

```move filename="smart_table.move"
module 0x42::smart_table_usage {
    use aptos_std::smart_table;
    use aptos_std::simple_map;

    public fun convert_to_simple_map() {
        let table = smart_table::new<u64, u64>();
        smart_table::add(&mut table, 1, 100);
        smart_table::add(&mut table, 2, 200);

        let map = smart_table::to_simple_map(&table);
        let length = simple_map::length(&map);
        assert!(length == 2, 0);

        let value1 = simple_map::borrow(&map, &1);
        assert!(*value1 == 100, 0);

        let value2 = simple_map::borrow(&map, &2);
        assert!(*value2 == 200, 0);

        smart_table::destroy(table);
    }
}
```

## Source Code

- [smart\_table.move](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-stdlib/sources/data_structures/smart_table.move)

## Other Examples

- [Move Spiders Smart Table](https://movespiders.com/courses/modules/datastructures/lessonId/7)
- [Move Spiders Querying Smart Table via FullNode APIs](https://movespiders.com/courses/modules/datastructures/lessonId/9)
- [Move Spiders Querying Smart Table via View Function](https://movespiders.com/courses/modules/datastructures/lessonId/10)

# Smart Vector

> Learn about smart vector for Move smart contract development on Aptos blockchain.

The Smart Vector is a scalable vector implementation based on `tables`, where elements are grouped into buckets. This data structure allows for efficient handling of large data sets by combining the flexibility of small vectors with the scalability of larger structures.

## Core Features of `SmartVector`

### Structure

The `SmartVector` struct is designed to handle dynamic data with efficiency:

- `inline_vec`: A small vector that stores elements directly.
- `big_vec`: An optional large vector for scalable storage.
- `inline_capacity`: An optional value defining the capacity of `inline_vec`.
- `bucket_size`: An optional value defining the size of buckets in `big_vec`.

### Constants

The following constants define various error codes used within the module:

- `EINDEX_OUT_OF_BOUNDS`: 1
- `EVECTOR_NOT_EMPTY`: 2
- `EVECTOR_EMPTY`: 3
- `EZERO_BUCKET_SIZE`: 4
- `ESMART_VECTORS_LENGTH_MISMATCH`: 0x20005

## API Overview

### Creating Vectors

- `new<T: store>(): SmartVector<T>`: Creates an empty vector.
- `empty_with_config<T: store>(inline_capacity: u64, bucket_size: u64): SmartVector<T>`: Creates an empty vector with custom capacity and bucket size.
- `singleton<T: store>(element: T): SmartVector<T>`: Creates a vector with a single element.

### Destroying Vectors

- `destroy_empty<T>(v: SmartVector<T>)`: Destroys an empty vector.
- `destroy<T: drop>(v: SmartVector<T>)`: Destroys a vector and its elements.

### Managing Elements

- `push_back<T: store>(v: &mut SmartVector<T>, val: T)`: Adds an element to the end of the vector.
- `pop_back<T>(v: &mut SmartVector<T>): T`: Removes the last element from the vector.
- `remove<T>(v: &mut SmartVector<T>, i: u64): T`: Removes an element at a specific index.
- `swap_remove<T>(v: &mut SmartVector<T>, i: u64): T`: Swaps an element at a specific index with the last element and removes it.
- `borrow<T>(v: &SmartVector<T>, i: u64): &T`: Returns an immutable reference to an element at a specific index.
- `borrow_mut<T>(v: &mut SmartVector<T>, i: u64): &mut T`: Returns a mutable reference to an element at a specific index.

### Utility Functions

- `length<T>(v: &SmartVector<T>): u64`: Returns the number of elements in the vector.
- `is_empty<T>(v: &SmartVector<T>): bool`: Checks if the vector is empty.
- `clear<T: drop>(v: &mut SmartVector<T>)`: Clears all elements from the vector.
- `to_vector<T: store + copy>(v: &SmartVector<T>): vector<T>`: Converts a smart vector to a native vector.

## Example Usage

### Creating and Using a SmartVector

```move filename="smart_vector.move"
module 0x42::smart_vector_usage {
    use aptos_std::smart_vector;

    public entry fun main() {
        let v = smart_vector::new<u64>();
        smart_vector::push_back(&mut v, 10);
        smart_vector::push_back(&mut v, 20);
        let length = smart_vector::length(&v);
        assert!(length == 2, 0);
        let first_elem = smart_vector::borrow(&v, 0);
        assert!(*first_elem == 10, 0);
        let second_elem = smart_vector::borrow(&v, 1);
        assert!(*second_elem == 20, 0);
        let last_elem = smart_vector::pop_back(&mut v);
        assert!(last_elem == 20, 0);
        smart_vector::destroy_empty(v);
    }
}
```

### Appending Vectors

```move filename="smart_vector.move"
module 0x42::smart_vector_usage {
    use aptos_std::smart_vector;

    public fun append_vectors() {
        let v1 = smart_vector::new<u64>();
        let v2 = smart_vector::new<u64>();

        smart_vector::push_back(&mut v1, 1);
        smart_vector::push_back(&mut v1, 2);

        smart_vector::push_back(&mut v2, 3);
        smart_vector::push_back(&mut v2, 4);

        smart_vector::append(&mut v1, v2);

        let length = smart_vector::length(&v1);
        assert!(length == 4, 0);

        let first_elem = smart_vector::borrow(&v1, 0);
        assert!(*first_elem == 1, 0);

        let second_elem = smart_vector::borrow(&v1, 1);
        assert!(*second_elem == 2, 0);

        let third_elem = smart_vector::borrow(&v1, 2);
        assert!(*third_elem == 3, 0);

        let fourth_elem = smart_vector::borrow(&v1, 3);
        assert!(*fourth_elem == 4, 0);
    }
}
```

### Removing Elements

```move filename="smart_vector.move"
module 0x42::smart_vector_usage {
    use aptos_std::smart_vector;

    public fun remove_elements() {
        let v = smart_vector::new<u64>();

        smart_vector::push_back(&mut v, 1);
        smart_vector::push_back(&mut v, 2);
        smart_vector::push_back(&mut v, 3);

        let removed_elem = smart_vector::remove(&mut v, 1);
        assert!(removed_elem == 2, 0);

        let length = smart_vector::length(&v);
        assert!(length == 2, 0);

        let first_elem = smart_vector::borrow(&v, 0);
        assert!(*first_elem == 1, 0);

        let second_elem = smart_vector::borrow(&v, 1);
        assert!(*second_elem == 3, 0);
    }
}
```

### Clearing the Vector

```move filename="smart_vector.move"
module 0x42::smart_vector_usage {
    use aptos_std::smart_vector;

    public fun clear_vector() {
        let v = smart_vector::new<u64>();

        smart_vector::push_back(&mut v, 1);
        smart_vector::push_back(&mut v, 2);
        smart_vector::push_back(&mut v, 3);

        smart_vector::clear(&mut v);
        let length = smart_vector::length(&v);
        assert!(length == 0, 0);
    }
}
```

### Swapping Elements

```move filename="smart_vector.move"
module 0x42::smart_vector_usage {
    use aptos_std::smart_vector;

    public fun swap_elements() {
        let v = smart_vector::new<u64>();

        smart_vector::push_back(&mut v, 1);
        smart_vector::push_back(&mut v, 2);
        smart_vector::push_back(&mut v, 3);

        smart_vector::swap(&mut v, 0, 2);

        let first_elem = smart_vector::borrow(&v, 0);
        assert!(*first_elem == 3, 0);

        let third_elem = smart_vector::borrow(&v, 2);
        assert!(*third_elem == 1, 0);
    }
}
```

## Source Code

- [smart\_vector.move](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-stdlib/sources/data_structures/smart_vector.move)

## Other Examples

- [move spiders tutorial on smart vectors](https://movespiders.com/courses/modules/datastructures/lessonId/6)
- [move spiders tutorial on querying smart vectors](https://movespiders.com/courses/modules/datastructures/lessonId/9)

# Table

> Learn about table for Move smart contract development on Aptos blockchain.

The `Table` provides a flexible and efficient way to manage large amounts of data in a table format. Each table item is represented as a separate global state item, allowing for scalable storage solutions.

## Core Features of Table

### Structure

The `Table` struct is designed to handle large-scale storage with efficiency:

- `handle`: An address that uniquely identifies the table.

### Constants

The following constants define various error codes used within the module (these are implied but not explicitly stated in the provided code):

- `ENOT_FOUND`: Key not found in the table.
- `EALREADY_EXIST`: Key already exists in the table.
- `EINVALID_ARGUMENT`: Invalid argument passed to a function.

### API Overview

#### Creating Tables

- `new<K: copy + drop, V: store>(): Table<K, V>`: Creates a new table.

#### Managing Entries

- `add<K: copy + drop, V>(table: &mut Table<K, V>, key: K, val: V)`: Adds a key-value pair to the table. Aborts if the key already exists.
- `remove<K: copy + drop, V>(table: &mut Table<K, V>, key: K): V`: Removes and returns the value associated with a key. Aborts if the key is not found.
- `upsert<K: copy + drop, V: drop>(table: &mut Table<K, V>, key: K, value: V)`: Inserts or updates a key-value pair.

#### Retrieving Entries

- `borrow<K: copy + drop, V>(table: &Table<K, V>, key: K): &V`: Returns an immutable reference to the value associated with a key. Aborts if the key is not found.
- `borrow_with_default<K: copy + drop, V>(table: &Table<K, V>, key: K, default: &V): &V`: Returns the value associated with a key or a default value if the key is not found.
- `borrow_mut<K: copy + drop, V>(table: &mut Table<K, V>, key: K): &mut V`: Returns a mutable reference to the value associated with a key. Aborts if the key is not found.
- `borrow_mut_with_default<K: copy + drop, V: drop>(table: &mut Table<K, V>, key: K, default: V): &mut V`: Inserts a key-value pair if the key is not found, then returns a mutable reference to the value.

#### Utility Functions

- `contains<K: copy + drop, V>(table: &Table<K, V>, key: K): bool`: Checks if the table contains a key.

## Example Usage

### Creating and Using a Table

```move filename="table.move"
module 0x42::table_usage {
    use aptos_std::table;

    public entry fun main() {
        let table = table::new<u64, u64>();
        table::add(&mut table, 1, 100);
        table::add(&mut table, 2, 200);

        let value1 = table::borrow(&table, 1);
        assert!(*value1 == 100, 0);

        let value2 = table::borrow(&table, 2);
        assert!(*value2 == 200, 0);

        let removed_value = table::remove(&mut table, 1);
        assert!(removed_value == 100, 0);

        let contains_key = table::contains(&table, 2);
        assert!(contains_key, 0);

        // Note: A table must be stored in a resource at the end of a function
    }
}
```

### Adding and Upserting Multiple Entries

```move filename="table.move"
module 0x42::table_usage {
    use aptos_std::table;

    public fun add_and_upsert_entries() {
        let table = table::new<u64, u64>();
        table::add(&mut table, 1, 100);
        table::upsert(&mut table, 1, 200);
        table::upsert(&mut table, 2, 300);

        let value1 = table::borrow(&table, 1);
        assert!(*value1 == 200, 0);

        let value2 = table::borrow(&table, 2);
        assert!(*value2 == 300, 0);

        // Note: A table must be stored in a resource at the end of a function
    }
}
```

### Borrowing Mutable References

```move filename="table.move"
module 0x42::table_usage {
    use aptos_std::table;

    public fun borrow_mutable_references() {
        let table = table::new<u64, u64>();
        table::add(&mut table, 1, 100);

        let value_mut = table::borrow_mut(&mut table, 1);
        *value_mut = 200;

        let value = table::borrow(&table, 1);
        assert!(*value == 200, 0);

        // Note: A table must be stored in a resource at the end of a function
    }
}
```

## Source Code

- [table.move](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-stdlib/sources/table.move)

## Other Examples

- [Move Spiders Tables Tutorial](https://movespiders.com/courses/modules/datastructures/lessonId/4)
- [Move Spiders Query Table via FullNode](https://movespiders.com/courses/modules/datastructures/lessonId/9)
- [Move Spiders Query Table via View Function](https://movespiders.com/courses/modules/datastructures/lessonId/10)

# Third Party Dependencies

> Learn about third party dependencies for Move smart contract development on Aptos blockchain.

import { Aside, FileTree } from '@astrojs/starlight/components';

Third party dependencies are external [modules](/build/smart-contracts/book/modules-and-scripts) that a controlled module interacts with. Typically, these external modules exist under different accounts.

## Multi-DEX router example

A multi-DEX router actively utilizes third party dependencies. Instead of submitting multiple transactions to interact with different DEXs and their individual [entry](/build/smart-contracts/book/functions#entry-modifier) functions within a swap route, a module (or [script](/build/smart-contracts/book/modules-and-scripts#scripts)) can consolidate all independent DEX invocations into a single, atomic transaction. The multi-DEX router references and calls to functions present in each of the third party DEX modules to achieve this.

## Sources

Third party dependencies will have varying amounts of reliability and available information based on where they‚Äôre sourced from. Specifically, documentation for a few instances will be non-existant, as well as logic potentially being refactored.

Source code that is verified against the on-chain deployed module, like the [Git Repository](#git-repository) and [Local Source Code](#local-source-code), should always be preferred. If neither of those are available, there are other options to depend on usable code, like [decompiled code](#decompiled-code), [bytecode](#bytecode), and [ABI](#abi)-crafted code.

### Git Repository

The default `Move.toml` includes `AptosFramework` as a git repository dependency:

```toml filename="Move.toml"
  [dependencies.AptosFramework]
  git = "<https://github.com/aptos-labs/aptos-framework.git>"
  rev = "mainnet"
  subdir = "aptos-framework"
```

When Aptos CLI commands are ran, updates to the dependency are automatically retrieved and compiled against.

### Local Source Code

Third party source code can be included in the `sources` directory. Essentially treating it the same as custom code.

<FileTree>
  - third\_party\_dependency\_project/
    - source/
      - `{ControlledCode}.move`
      - `{ThirdPartyCode}.move`
    - Move.toml
</FileTree>

<Aside type="caution" emoji="‚ö†Ô∏è">
  Any upgrades to the Third Party dependency will need to be retrieved, manually.
</Aside>

### Decompiled code

Move code can be reconstructed by using the [Revela Compiler](https://aptoslabs.medium.com/move-revealed-the-revela-decompiler-b206eaf48b45#27ad) against a package‚Äôs bytecode:

```shellscript filename="Terminal"
aptos move decompile --package-path ./bytecode_modules
```

Corresponding `{ModuleName}.mv.move` files will be generated in `bytecode_modules`.

<FileTree>
  - third\_party\_dependency\_project/
    - byte\_modules/
      - `{ModuleName}.mv`
      - `{ModuleName}.mv.move`
    - Move.toml
</FileTree>

Reference it as a local source file after changing the file type to `{ModuleName}.move` and placing it in the workspace‚Äôs `sources` directory.

<FileTree>
  - third\_party\_dependency\_project/
    - sources/
      - `{ModuleName}.move`
    - Move.toml
</FileTree>

<Aside type="note" emoji="‚ÑπÔ∏è">
  Decompiled code will keep behaviors of on-chain execution, but will be refactored.
</Aside>

### Bytecode

The Aptos CLI allows for downloading a [package's](/build/smart-contracts/book/packages) bytecode.

```shellscript filename="Terminal"
aptos move download --account {account_addr} --bytecode --package {package_name}
```

Each bytecode dependency requires their own package, with a structure of:

- `Move.toml` file, with the package address pre-defined.
- `build/{ModuleName}/bytecode_modules` directory with the bytecode inside.
- Empty sources directory.

The controlled module can then reference the dependency, upon it's inclusion in the controlled package's `Move.toml`.

<details>
  <summary>Aptos Token example</summary>

  A controlled `invoking_code.move` module interacts with the external `aptos_token` module:

  ```move filename="invoking_code.move"
  module invoker::invoking_code {
      use aptos_token_objects_addr::aptos_token;

      public entry fun wrapper_add_property(): u64 {
          aptos_token::add_property(...);
      }
  }
  ```

  The below command retrieves the necessary [AptosTokenObjects package](https://explorer.aptoslabs.com/account/0x4/modules/code/aptos_token/mint?network=mainnet) bytecode from the Mainnet.

  ```shellscript filename="Terminal"
  aptos move download --account 0x4 \
  --bytecode --package AptosTokenObjects \
  --output-dir ./aptos_token_bytecode_output/
  ```

  <FileTree>
    - invoking\_code/
      - aptos\_token\_bytecode\_output/
        - byte\_modules/
          - aptos\_token.mv
      - sources/
        - invoking\_code.move
      - Move.toml
  </FileTree>

  The created dependency package structure and contents for `aptos_token` is:

  <FileTree>
    - aptos\_token\_objects\_addr/
      - build/
        - aptos\_token/
          - bytecode\_modules/
            - aptos\_token.mv
      - sources/
        - ...
      - Move.toml
    - invoking\_code/
      - aptos\_token\_bytecode\_output/
        - byte\_modules/
          - aptos\_token.mv
          - aptos\_token.mv.move
          - ...
      - sources/
        - invoking\_code.move
      - Move.toml
  </FileTree>

  ```toml filename="aptos_token_objects_addr/Move.toml"
  [package]
  name = "aptos_token"
  version = "0.0.0"
  [addresses]
  aptos_token_module_addr = "0x4"
  ```

  The dependency list from the controlled `invoking_code.move` module will include a local reference to the bytecode package, allowing for compilation.

  ```toml filename="invoking_code/Move.toml"
  [package]
  name = "invoking_code"
  [addresses]
  invoker = "_"
  [dependencies]
  aptos_token = { local = "../aptos_token_objects_addr" }
  ```
</details>

### ABI

Move interface code can be manually crafted by reading a package's ABI. Notably, while the function header is required to be exact, the logic within is not.

<Aside type="note" emoji="‚ÑπÔ∏è">
  All available public and entry methods are defined with their name, arguments, return values, and more, within the ABI. Structs and resources will also be included.
</Aside>

Afterwards, the interface code is treated equivalent to local source code.

<details>
  <summary>Aptos Token example</summary>

  Below is a portion of the `AptosTokenObjects` ABI, gathered from the [Aptos Explorer](https://explorer.aptoslabs.com/account/0x0000000000000000000000000000000000000000000000000000000000000004/modules/code/aptos_token?network=mainnet#:~:text=1114-,ABI,-%7B):

  ```json
  {
  "address": "0x4",
  "name": "aptos_token",
  "friends": [],
  "exposed_functions": [
      {
      "name": "add_property",
      "visibility": "public",
      "is_entry": true,
      "is_view": false,
      "generic_type_params": [
          {
          "constraints": [
              "key"
          ]
          }
      ],
      "params": [
          "&signer",
          "0x1::object::Object<T0>",
          "0x1::string::String",
          "0x1::string::String",
          "vector<u8>"
      ],
      "return": []
      },
      ...
  ]
  }
  ```

  An interface Move file can be handwritten and treated as a source file. Looking similar to:

  ```move
  module 0x4::aptos_token {
      // ...
      public entry fun add_property<T: key>(
          creator: &signer,
          token: Object<T>,
          key: String,
          type: String,
          value: vector<u8>,
      ) acquires AptosCollection, AptosToken {
          abort 0
      }
  }
  ```

  <FileTree>
    - third\_party\_dependency\_project/
      - source/
        - `{ControlledCode}.move`
        - aptos\_token.move
      - Move.toml
  </FileTree>
</details>

# Aptos Token Standard Overview

> Learn about tokens for Move smart contract development on Aptos blockchain.

The [Aptos Digital Asset Standard](/build/smart-contracts/digital-asset) defines the
canonical Non-fungible Token on Aptos. Aptos leverages composability to extend
the digital asset standard with features like fungibility via
the [Fungible Asset standard](/build/smart-contracts/fungible-asset). The concept of
composability comes from the underlying data model for these constructs:
the [Move object](/build/smart-contracts/objects) data model.

The rest of this document discusses how the Aptos token standards compare to the
standards on Ethereum and Solana.

## Data models

To understand tokens, we begin by comparing the data models across different
blockchains.

### Ethereum

Ethereum has two types of accounts:

- Externally-owned accounts which store a balance of Ether.
- Contract accounts which manage their underlying smart contracts and have an
  associated storage for persistent state, which can only be mutated by the
  associated contract.

In order to create a new NFT collection, a creator must deploy their own
contract to the blockchain, which in turn will create a collection and set of
NFTs within its storage.

### Solana

Unlike Ethereum or Aptos where data and code co-exist, Solana stores data and
programs in separate accounts. There are two types of accounts on the Solana
blockchain:

- Executable accounts only store contract code
- Non-executable accounts store data associated with and owned by executable
  accounts.

In order to create a new NFT collection, a creator calls an existing deployed
program to populate a new collection and set of NFTs.

### Aptos

The [accounts](/network/blockchain/accounts) in Aptos store both smart contracts
and data. Unlike Ethereum, the associated data of a smart contract is
distributed across the space of all accounts
in [resources](/network/blockchain/resources)
within [accounts](/network/blockchain/accounts)
or [objects](/build/smart-contracts/objects). For example, a collection and an
NFT within that collection are stored in distinct objects at different addresses
with the smart contract defining them at another address. A smart contract
developer could also store data associated with the NFT and collection at the
same address as the smart contract or in other objects.

There are two means to create NFTs on Aptos:

- The [no-code standard](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-22.md)
  allows creators to call into the contract to create new collections and tokens
  without deploying a new contract.
- Custom NFT contracts allow creators to customize their NFTs by extending the
  object model that can manage all aspects of their collection.

Aptos strikes a balance between the customizability offered by Ethereum with the
simplicity of creating new collections like Solana.

Like Ethereum, Aptos requires indexing to determine the set of all NFTs owned by
an account, while Solana has no need.

## Token standard comparison

The Fungible Token (FT) was initially introduced
by [EIP-20](https://eips.ethereum.org/EIPS/eip-20), and Non-Fungible Token (NFT)
was defined in [EIP-721](https://eips.ethereum.org/EIPS/eip-721).
Later, [EIP-1155](https://eips.ethereum.org/EIPS/eip-1155) combined FT and NFT
or even Semi-Fungible Token (SFT) into one standard.

The Ethereum token standards requires each token to deploy their own individual
contract code to distinguish collection of tokens. Solana account model enables
another pattern where code can be reused so that one generic program operates on
various data. To create a new token, you could create an account that can mint
tokens and more accounts that can receive them. The mint account itself uniquely
determines the token type instead of contract account, and these are all passed
as arguments to the one contract deployed to some executable account.

The collection of Aptos token standards shares some similarities with Solana,
especially how it covers FT, NFT and SFT into a common on-chain code. Instead of
deploying a new smart contract for each new token, a creator calls a function in
the contract with the necessary arguments. Depending on which function you call,
the token contract will mint/transfer/burn/... tokens.

### Token identification

Aptos identifies a token by its `Address` or `ObjectId`, a location within
global storage. Collections are stored at a location determined by the address
of the creator and the name of the collection.

In Ethereum, contracts are deployed on accounts determined by the account that
is deploying the contract. NFTs are then stored as indexes into data tables
within the contract.

In Solana, NFT data is stored under a mint account, independent of the program
account.

### Token metadata

Aptos token has metadata in its `Token` resource with the data most commonly
required by dapps to interact with tokens. Some examples include:

- `name`: The name of the token. It must be unique within a collection.
- `description`: The description of the token.
- `uri`: A URL pointer to off-chain for more information about the token. The
  asset could be media such as an image or video or more metadata in a JSON
  file.
- `collection`: A pointer to the ObjectId of the collection.

Additional fields can be stored in creator-defined resources or
the `PropertyMap` resource that defines a generalizable key-value map.

In Ethereum, only a small portion of such properties are defined as methods,
such as `name()`, `symbol()`, `decimals()`, `totalSupply()` of ERC-20;
or `name()` and `symbol()` and `tokenURI()` of the optional metadata extension
for ERC-721; ERC-1155 also has a similar method `uri()` in its own optional
metadata extension. Token metadata is not standardized so that dapps have to
take special treatment case by case.

In Solana, the Token Metadata program offers a Metadata Account defining
numerous metadata fields associated with a token as well, including `collection`
which is defined in `TokenDataId` in Aptos. Solana, however, does not offer
mutability for assets, unlike Aptos. Like Aptos, Token Metadata v1.1.0 offers
an `attribute` container for customized properties.

# Vector

> Master vector operations in Move for dynamic arrays, collections, and list manipulation in smart contracts.

The Vector in Move provides a flexible and dynamic array-like data structure that supports various operations such
as indexing, adding, and removing elements. Vectors in Move are growable and support 0-based indexing.

## Core Features of Vector

### Structure

The `vector` module provides various native and Move functions to manage dynamic arrays:

- `empty`: Creates an empty vector.
- `length`: Returns the length of the vector.
- `borrow`: Returns an immutable reference to an element at a given index.
- `push_back`: Adds an element to the end of the vector.
- `borrow_mut`: Returns a mutable reference to an element at a given index.
- `pop_back`: Removes and returns the last element of the vector.
- `destroy_empty`: Destroys an empty vector.
- `swap`: Swaps elements at two given indices.

### Constants

The following constants define various error codes used within the module:

- `EINDEX_OUT_OF_BOUNDS`: 0x20000

### API Overview

#### Creating Vectors

- `empty<Element>(): vector<Element>`: Creates an empty vector.
- `singleton<Element>(e: Element): vector<Element>`: Creates a vector with a single element.

#### Managing Elements

- `push_back<Element>(v: &mut vector<Element>, e: Element)`: Adds an element to the end of the vector.
- `pop_back<Element>(v: &mut vector<Element>): Element`: Removes and returns the last element from the vector.
- `remove<Element>(v: &mut vector<Element>, i: u64): Element`: Removes an element at a specific index and shifts subsequent elements.
- `swap_remove<Element>(v: &mut vector<Element>, i: u64): Element`: Swaps the element at the given index with the last element and removes it.

#### Retrieving Elements

- `borrow<Element>(v: &vector<Element>, i: u64): &Element`: Returns an immutable reference to an element at a given index.
- `borrow_with_default<Element>(v: &vector<Element>, i: u64, default: &Element): &Element`: Returns a reference to an element or a default value if the index is out of bounds.
- `borrow_mut<Element>(v: &mut vector<Element>, i: u64): &mut Element`: Returns a mutable reference to an element at a given index.

#### Utility Functions

- `length<Element>(v: &vector<Element>): u64`: Returns the number of elements in the vector.
- `is_empty<Element>(v: &vector<Element>): bool`: Checks if the vector is empty.
- `contains<Element>(v: &vector<Element>, e: &Element): bool`: Checks if the vector contains a given element.
- `index_of<Element>(v: &vector<Element>, e: &Element): (bool, u64)`: Returns the index of a given element if found.
- `reverse<Element>(v: &mut vector<Element>)`: Reverses the order of elements in the vector.
- `append<Element>(lhs: &mut vector<Element>, other: vector<Element>)`: Appends all elements of one vector to another.
- `for_each<Element>(v: vector<Element>, f: |Element|)`: Applies a function to each element in the vector.
- `for_each_ref<Element>(v: &vector<Element>, f: |&Element|)`: Applies a function to a reference of each element in the vector.
- `for_each_mut<Element>(v: &mut vector<Element>, f: |&mut Element|)`: Applies a function to a mutable reference of each element in the vector.
- `fold<Accumulator, Element>(v: vector<Element>, init: Accumulator, f: |Accumulator, Element|Accumulator): Accumulator`: Applies a function to accumulate a value over the elements of the vector.
- `map<Element, NewElement>(v: vector<Element>, f: |Element|NewElement): vector<NewElement>`: Maps a function over the elements of the vector, producing a new vector.
- `filter<Element: drop>(v: vector<Element>, p: |&Element|bool): vector<Element>`: Filters the vector using a predicate function.

## Example Usage

### Creating and Using a Vector

```move filename="vector.move"
module 0x42::vector_usage {
    use std::vector;

    public entry fun main() {
        let v = vector::empty<u64>();
        vector::push_back(&mut v, 10);
        vector::push_back(&mut v, 20);

        let length = vector::length(&v);
        assert!(length == 2, 0);

        let first_elem = vector::borrow(&v, 0);
        assert!(*first_elem == 10, 0);

        let second_elem = vector::borrow(&v, 1);
        assert!(*second_elem == 20, 0);

        let last_elem = vector::pop_back(&mut v);
        assert!(last_elem == 20, 0);

        vector::destroy_empty(v);
    }
}
```

### Appending Vectors

```move filename="vector.move"
module 0x42::vector_usage {
    use std::vector;

    public fun append_vectors() {
        let v1 = vector::empty<u64>();
        let v2 = vector::empty<u64>();

        vector::push_back(&mut v1, 1);
        vector::push_back(&mut v1, 2);

        vector::push_back(&mut v2, 3);
        vector::push_back(&mut v2, 4);

        vector::append(&mut v1, v2);

        let length = vector::length(&v1);
        assert!(length == 4, 0);

        let first_elem = vector::borrow(&v1, 0);
        assert!(*first_elem == 1, 0);

        let second_elem = vector::borrow(&v1, 1);
        assert!(*second_elem == 2, 0);

        let third_elem = vector::borrow(&v1, 2);
        assert!(*third_elem == 3, 0);

        let fourth_elem = vector::borrow(&v1, 3);
        assert!(*fourth_elem == 4, 0);
    }
}
```

### Removing Elements

```move filename="vector.move"
module 0x42::vector_usage {
    use std::vector;

    public fun remove_elements() {
        let v = vector::empty<u64>();

        vector::push_back(&mut v, 1);
        vector::push_back(&mut v, 2);
        vector::push_back(&mut v, 3);

        let removed_elem = vector::remove(&mut v, 1);
        assert!(removed_elem == 2, 0);

        let length = vector::length(&v);
        assert!(length == 2, 0);

        let first_elem = vector::borrow(&v, 0);
        assert!(*first_elem == 1, 0);

        let second_elem = vector::borrow(&v, 1);
        assert!(*second_elem == 3, 0);
    }
}
```

### Swapping Elements

```move filename="vector.move"
module 0x42::vector_usage {
    use std::vector;

    public fun swap_elements() {
        let v = vector::empty<u64>();

        vector::push_back(&mut v, 1);
        vector::push_back(&mut v, 2);
        vector::push_back(&mut v, 3);

        vector::swap(&mut v, 0, 2);

        let first_elem = vector::borrow(&v, 0);
        assert!(*first_elem == 3, 0);

        let third_elem = vector::borrow(&v, 2);
        assert!(*third_elem == 1, 0);
    }
}
```

## Source Code

- [vector.move](https://github.com/aptos-labs/aptos-core/blob/main/third_party/move/move-stdlib/sources/vector.move)

## Other Examples

- [Move Spiders Vector Tutorial](https://movespiders.com/courses/modules/datastructures/lessonId/1)
- [Move Spiders Vector Tutorial 2](https://movespiders.com/courses/modules/basics/lessonId/7)

# Why Move?

> Learn about why move for Move smart contract development on Aptos blockchain.

The Move programming language was originally created by a team of engineers at
Facebook for the Diem Payment Network. Move is designed to be a platform-agnostic
language to enable common libraries, tooling, and developer communities across
diverse blockchains with vastly different data and execution models.
At Aptos, we believe in building a strong developer community in Move and invite
them to build upon the Move on Aptos stack and contribute to the open source software.

Move is built upon the following principles:

| **Principle**            | **Explanation**                                                                                                                                                                                                                                                                               |
| ------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Secure by default**    | Financial systems are built to ensure users don't lose funds. Move was designed to prevent entire classes of attacks and bugs such as reentrancy attacks, double spends, and arithmetic overflow. Type safety and compile time checks are at the forefront of the security.                   |
| **Runtime Verification** | The bytecode can be verified at runtime to verify that nothing has gone wrong, providing extra safety and preventing malicious actors.                                                                                                                                                        |
| **Formal Verification**  | Move on Aptos provides a specification language to provide formal verification of contracts. This allows for proving invariants and assists with code auditing.                                                                                                                               |
| **Simplicity**           | The commands and bytecode are purposely simple. This allows for easy decompilation, runtime verification, and code inspection. Using regular programming languages for blockchains often requires to ignore large part of the language to make them suitable for smart contracts (e.g. Rust). |

## Why Move on Aptos?

Move on Aptos supports the full language built by the team at Facebook, with
additional extensions built to improve the security and the developer experience.

### Security

| **Advantages**          | **Explanation**                                                                                                                                         |
| ----------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Formal Verification** | Aptos framework is fully specified and formally verified with the Move Prover. This includes the core contracts involving governance, NFTs, and Tokens. |
| **Gas Coverage**        | Move VM has 100% gas coverage. Gas is charged based upon actual usage in the system (CPU, memory, storage, I/O). In other words, no gas exploits.       |
| **Security Redundancy** | Security redundancy provided by runtime safety checks.                                                                                                  |
| **Permission Controls** | Permission controls can flexibly be built at various levels. For example, token level permission controls exist by default to enable RWA tokenization.  |

### Developer Experience

| **Advantages**             | **Explanation**                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| -------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Move Development Tools** | - **Unit testing**: Move has built-in unit testing for all contracts. Aptos additionally provides test functionality in the framework to test different scenarios. <br /> - **Coverage**: Coverage tooling allows for both source and bytecode level coverage reporting. <br /> - **Decompiler**: For better security, on-chain bytecode can be disassembled or decompiled to provide visibility into the actual contracts. <br /> - **IDE Plugins**: Aptos has support for all major IDEs: [VSCode](https://marketplace.visualstudio.com/items?itemName=AptosLabs.move-on-aptos), [Cursor etc.](https://open-vsx.org/extension/aptoslabs/move-on-aptos) and [IntelliJ](https://plugins.jetbrains.com/plugin/14721-move-on-aptos). |
| **Data Model**             | Aptos has an accessible data model with the data definition stored on-chain. Objects and accounts can have multiple distinct structures in an easy-to-parse format.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |
| **Upgradability**          | Upgradability ensures that application interfaces cannot be broken and doesn't require explicit adoption from downstream applications. Contracts can simply be upgraded in-place to fix bugs.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
| **Cross-Interaction**      | Move allows for interaction between contracts by using type-safe structs.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
| **Code Storage**           | Aptos stores source code on-chain improving the ability to audit and ensure contract to bytecode correctness.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
| **Sponsored Transactions** | Native sponsored transaction support allows for having transactions be paid by other users with no special services or contract-specific code required.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |
| **Robust Token Standards** | The Digital Asset and Fungible Asset standards provide flexibility and a unified standard for diverse types of tokens and digital assets on-chain. These were influenced by existing standards such as ERC-20, ERC-721, ERC-1155 and Token-2022.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |
| **On-chain Randomness**    | Native on-chain unbiasable randomness provides a safe and consistent way of getting random numbers, with extra safety checks at compile time.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |

# ThemedImage Component

> A reusable Astro component that displays different images for light and dark themes, with automatic optimization using Astro's built-in Image component.

import { ThemedImage } from '~/components/ThemedImage';

## Features

- ‚úÖ Supports both light and dark mode images
- ‚úÖ Uses Astro's optimized Image component for performance
- ‚úÖ Supports the `~/images` alias path
- ‚úÖ Automatic image optimization and processing
- ‚úÖ TypeScript support with strict typing
- ‚úÖ Follows Starlight's theming conventions (`light:sl-hidden` and `dark:sl-block`)

## Live Demo

Try switching between light and dark mode to see the component in action:

<ThemedImage
  alt="Staking Flow"
  sources={{
light: '~/images/staking-light.svg',
dark: '~/images/staking-dark.svg',
}}
/>

## Usage

### Basic Usage

```astro
---
import ThemedImage from '~/components/ThemedImage';
---

<ThemedImage
  alt="Staking Flow"
  sources={{
    light: '~/images/staking-light.svg',
    dark: '~/images/staking-dark.svg',
  }}
/>
```

### With Custom Dimensions

<ThemedImage
  alt="Aptos Token Standard Flow"
  sources={{
light: '~/images/aptos-token-standard-flow.svg',
dark: '~/images/aptos-token-standard-flow-dark.svg',
}}
  width={600}
  height={400}
/>

```astro
<ThemedImage
  alt="Aptos Token Standard Flow"
  sources={{
    light: '~/images/aptos-token-standard-flow.svg',
    dark: '~/images/aptos-token-standard-flow-dark.svg',
  }}
  width={600}
  height={400}
/>
```

### With Custom CSS Class

<ThemedImage
  alt="Digital Asset"
  sources={{
light: '~/images/digital-asset-light.svg',
dark: '~/images/digital-asset-dark.svg',
}}
  class="rounded-lg shadow-md"
/>

```astro
<ThemedImage
  alt="Digital Asset"
  sources={{
    light: '~/images/digital-asset-light.svg',
    dark: '~/images/digital-asset-dark.svg',
  }}
  class="rounded-lg shadow-md"
/>
```

### Using Imported Images

```astro
---
import lightImage from '~/images/my-light-image.png';
import darkImage from '~/images/my-dark-image.png';
import ThemedImage from '~/components/ThemedImage';
---

<ThemedImage
  alt="My Image"
  sources={{
    light: lightImage,
    dark: darkImage,
  }}
/>
```

## Props

| Prop       | Type                                                                | Required | Default   | Description                                         |
| ---------- | ------------------------------------------------------------------- | -------- | --------- | --------------------------------------------------- |
| `alt`      | `string`                                                            | ‚úÖ        | -         | Alt text for the image (required for accessibility) |
| `sources`  | `{ light: string \| ImageMetadata, dark: string \| ImageMetadata }` | ‚úÖ        | -         | Object containing light and dark mode image sources |
| `width`    | `number`                                                            | ‚ùå        | -         | Image width in pixels                               |
| `height`   | `number`                                                            | ‚ùå        | -         | Image height in pixels                              |
| `loading`  | `'lazy' \| 'eager'`                                                 | ‚ùå        | `'lazy'`  | Image loading strategy                              |
| `decoding` | `'async' \| 'sync' \| 'auto'`                                       | ‚ùå        | `'async'` | Image decoding strategy                             |
| `class`    | `string`                                                            | ‚ùå        | `''`      | Additional CSS classes to apply                     |

## How It Works

The component renders two `<Image>` components:

1. **Light mode image**: Visible in light theme, hidden in dark theme (`light:sl-block dark:sl-hidden`)
2. **Dark mode image**: Hidden in light theme, visible in dark theme (`light:sl-hidden dark:sl-block`)

Both images use Astro's optimized `<Image>` component, which provides:

- Automatic image optimization
- WebP/AVIF format conversion
- Responsive image generation
- Lazy loading by default
- Cumulative Layout Shift (CLS) prevention

## Image Path Aliases

The component supports the `~/images` alias configured in your Astro project:

```javascript
// astro.config.mjs
export default defineConfig({
  vite: {
    resolve: {
      alias: {
        "~/images": fileURLToPath(new URL("./src/assets/images", import.meta.url)),
      },
    },
  },
});
```

This allows you to use paths like `~/images/my-image.svg` instead of relative paths.

## CSS Classes

The component uses Starlight's theming classes:

- `light:sl-block` - Shows element in light mode
- `dark:sl-hidden` - Hides element in dark mode
- `light:sl-hidden` - Hides element in light mode
- `dark:sl-block` - Shows element in dark mode

## More Examples

Here are additional examples showing different use cases:

<ThemedImage
  alt="Indexer Architecture"
  sources={{
light: '~/images/indexer-architecture-light.svg',
dark: '~/images/indexer-architecture-dark.svg',
}}
/>

<ThemedImage
  alt="GitHub Logo"
  sources={{
light: '~/images/github-light.svg',
dark: '~/images/github-dark.svg',
}}
  width={100}
  height={100}
/>

# LLMs.txt

> How to get tools like Cursor, GitHub Copilot, ChatGPT, and Claude to understand Aptos documentation.

## What is LLMs.txt?

We support [LLMs.txt](https://llmstxt.org/) files for making the Aptos documentation available to large language models
(LLMs). This feature helps AI tools better understand the Aptos blockchain, its Move language, SDKs, and development patterns.

## Available Routes

We provide the following LLMs.txt routes to help AI tools access our documentation:

- [llms.txt](/llms.txt) - Contains a structured overview of Aptos LLMs.txt files
- [llms-small.txt](/llms-small.txt) - Provides a condensed version of the documentation, optimized for smaller context windows
- [llms-full.txt](/llms-full.txt) - Provides the full comprehensive documentation for all Aptos concepts

## Usage with AI Tools

### Cursor

Use the `@Docs` feature in Cursor to include the LLMs.txt files in your project. This helps Cursor provide more accurate
code suggestions and documentation for Aptos development.

[Read more about @Docs in Cursor](https://docs.cursor.com/context/@-symbols/@-docs)

### GitHub Copilot

GitHub Copilot can leverage the information in these LLMs.txt files to provide better assistance when developing Aptos applications. You can reference these files in your GitHub Copilot Chat by using the following URLs:

```
https://aptos.dev/llms.txt
https://aptos.dev/llms-small.txt
https://aptos.dev/llms-full.txt
```

### Windsurf

Reference the LLMs.txt files using `@` or in your `.windsurfrules` files to enhance Windsurf's understanding of Aptos development.

[Read more about Windsurf Memories](https://docs.codeium.com/windsurf/memories#memories-and-rules)

### Other AI Tools

Any AI tool that supports LLMs.txt can use these routes to better understand Aptos. Simply point your tool to any of
the routes above.

# Aptos Blockchain

> Core concepts of the Aptos blockchain including architecture, consensus, and fundamental mechanisms

import { CardGrid, LinkCard } from '@astrojs/starlight/components';

Start here to get into the core concepts of the Aptos blockchain. Then review our [research papers](https://aptoslabs.com/research) and the Aptos source code found in the [Aptos-core](https://github.com/aptos-labs/aptos-core) repository of GitHub while continuing your journey through this site. The source contains READMEs and code comments invaluable to developing on Aptos.

<CardGrid>
  <LinkCard href="/network/blockchain/aptos-white-paper" title="Aptos White Paper" description="Explore the foundational white paper of Aptos." />

  <LinkCard href="/network/blockchain/blockchain-deep-dive" title="Aptos Blockchain Deep Dive" description="Dive deep into the mechanics and architecture of the Aptos blockchain." />

  <LinkCard href="/network/blockchain/move" title="Move - A Web3 Language and Runtime" description="Learn about Move, the smart-contract language designed for security and formal verification." />

  <LinkCard href="/network/blockchain/accounts" title="Accounts" description="Learn how accounts work on the Aptos blockchain." />

  <LinkCard href="/network/blockchain/resources" title="Resources" description="Discover how resources store data for smart contracts on chain." />

  <LinkCard href="/network/blockchain/events" title="Events" description="Learn how events are generated and used within Aptos." />

  <LinkCard href="/network/blockchain/txns-states" title="Transactions and States" description="Explore the relationship between transactions and state changes." />

  <LinkCard href="/network/blockchain/gas-txn-fee" title="Gas and Transaction Fees" description="Understand the gas model and how transaction fees are calculated." />

  <LinkCard href="/network/blockchain/base-gas" title="Computing Transaction Gas" description="Learn how gas costs are computed for transactions." />

  <LinkCard href="/network/blockchain/blocks" title="Blocks" description="Discover how Aptos groups transactions into blocks." />

  <LinkCard href="/network/blockchain/staking" title="Staking" description="Learn about the staking mechanism and its benefits." />

  <LinkCard href="/network/blockchain/governance" title="Governance" description="Understand how governance is handled on the Aptos blockchain." />
</CardGrid>

# Accounts

> Understand Aptos accounts, their addresses, authentication schemes, key rotation, sequence numbers, and how they control assets and resources on-chain.

import { Aside } from '@astrojs/starlight/components';

An account on the Aptos blockchain represents access control over a set of assets including on-chain currency and NFTs. In Aptos, these assets are represented by a Move language primitive known as a **resource** that emphasizes both access control and scarcity.

Each account on the Aptos blockchain is identified by a 32-byte account address. You can employ the Aptos Name Service at [www.aptosnames.com](https://www.aptosnames.com/) to secure .apt domains for key accounts to make them memorable and unique.

Different from other blockchains where accounts and addresses are implicit, accounts on Aptos are explicit and need to be created before they can execute transactions. The account can be created explicitly or implicitly by transferring Aptos tokens (APT) there. See the [Creating an account](#creating-an-account) section for more details. In a way, this is similar to other chains where an address needs to be sent funds for gas before it can send transactions.

Explicit accounts allow first-class features that are not available on other networks such as:

- Rotating authentication key. The account's authentication key can be changed to be controlled via a different private key. This is similar to changing passwords in the web2 world.
- Native multisig support. Accounts on Aptos support k-of-n multisig using both Ed25519 and Secp256k1 ECDSA signature schemes when constructing the authentication key.

There are three types of accounts on Aptos:

- _Standard account_ - This is a typical account corresponding to an address with a corresponding pair of public/private keys.
- [_Resource account_](/build/smart-contracts/resource-accounts) - An autonomous account without a corresponding private key used by developers to store resources or publish modules on-chain.
- [_Object_](/build/smart-contracts/objects) - A complex set of resources stored within a single address representing a single entity.

<Aside type="note">
  Account addresses are 32-bytes. They are usually shown as 64 hex characters, with each hex character a nibble.
  Sometimes the address is prefixed with a 0x. See the [Your First Transaction](/build/guides/first-transaction) for an example
  of how an address appears, reproduced below:
</Aside>

```text
Alice: 0xeeff357ea5c1a4e7bc11b2b17ff2dc2dcca69750bfef1e1ebcaccf8c8018175b
Bob: 0x19aadeca9388e009d136245b9a67423f3eee242b03142849eb4f81a4a409e59c
```

## Account address

Currently, Aptos supports only a single, unified identifier for an account. Accounts on Aptos are universally represented as a 32-byte hex string. A hex string shorter than 32-bytes is also valid; in those scenarios, the hex string can be padded with leading zeroes, e.g., `0x1` => `0x0000000000000...01`. While Aptos standards indicate leading zeroes may be removed from an Address, most applications attempt to eschew that legacy behavior and only support the removal of zeros for special addresses ranging from `0x0` to `0xa`.

## Creating an account

When a user requests to create an account, for example, by using the [Aptos SDK](/build/sdks/ts-sdk/account), the following steps are executed:

- Select the authentication scheme for managing the user's account, e.g., Ed25519 or Secp256k1 ECDSA.
- Generate a new private key, public key pair.
- Combine the public key with the public key's authentication scheme to generate a 32-byte authentication key and the account address.

The user should use the private key for signing the transactions associated with this account.

## Account sequence number

The sequence number for an account indicates the number of transactions that have been submitted and committed on-chain
from that account. Committed transactions either execute with the resulting state changes committed to the blockchain or
abort wherein state changes are discarded and only the transaction is stored.

Every transaction submitted must contain a unique sequence number for the given sender's account. When the Aptos
blockchain processes the transaction, it looks at the sequence number in the transaction and compares it with the
sequence number in the on-chain account. The transaction is processed only if the sequence number is equal to or larger
than the current sequence number. Transactions are only forwarded to other mempools or executed if there is a contiguous
series of transactions from the current sequence number. Execution rejects out of order sequence numbers, preventing
replay attacks of older transactions and guarantees ordering of future transactions.

<Aside type="note">
  Multi-agent transactions (transactions involving multiple signing accounts) only increase the sequence number of the
  primary signer (sender) account. The sequence number of the secondary signers (receivers) is not increased.
</Aside>

## Authentication key

The initial account address is set to the authentication key derived during account creation. However, the authentication key may subsequently change, for example, when you generate a new public-private key pair, public keys to rotate the keys. An account address never changes.

The Aptos blockchain supports the following authentication schemes:

1. [Ed25519](https://ed25519.cr.yp.to/)
2. [Secp256k1 ECDSA](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-49.md)
3. [K-of-N multi-signatures](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-55.md)
4. A dedicated, now legacy, MultiEd25519 scheme

<Aside type="note">
  The Aptos blockchain defaults to Ed25519 signature transactions.
</Aside>

### Ed25519 authentication

To generate an authentication key and the account address for an Ed25519 signature:

1. **Generate a key-pair**: Generate a fresh key-pair (`privkey_A`, `pubkey_A`). The Aptos blockchain uses the PureEdDSA scheme over the Ed25519 curve, as defined in RFC 8032.
2. **Derive a 32-byte authentication key**: Derive a 32-byte authentication key from the `pubkey_A`:
   ```text
   auth_key = sha3-256(pubkey_A | 0x00)
   ```
   where `|` denotes concatenation. The `0x00` is the 1-byte single-signature scheme identifier.
3. Use this initial authentication key as the permanent account address.

### MultiEd25519 authentication

With K-of-N multisig authentication, there are a total of N signers for the account, and at least K of those N signatures
must be used to authenticate a transaction.

To generate a K-of-N multisig account's authentication key and the account address:

1. **Generate key-pairs**: Generate `N` ed25519 public keys `p_1`, ..., `p_n`.
2. Decide on the value of `K`, the threshold number of signatures needed for authenticating the transaction.
3. **Derive a 32-byte authentication key**: Compute the authentication key as described below:
   ```text
   auth_key = sha3-256(p_1 | . . . | p_n | K | 0x01)
   ```
   The `0x01` is the 1-byte multisig scheme identifier.
4. Use this initial authentication key as the permanent account address.

### Generalized authentication

Generalized authentication supports both Ed25519 and Secp256k1 ECDSA. Like the
previous authentication schemes, these schemes contain a scheme value, `0x02`
and `0x03` for single and multikey respectively, but also each key contains a
prefix value to indicate its key type:

| Key type                          | Prefix byte |
| --------------------------------- | ----------- |
| Ed25519 generalized scheme        | `0x00`      |
| Secp256k1Ecdsa generalized scheme | `0x01`      |
| Secp256r1Ecdsa WebAuthn scheme    | `0x02`      |
| Keyless                           | `0x03`      |

For a single key Secp256k1 ECDSA account, using public key `pubkey`, the authentication key would be derived as follows:

```text
auth_key = sha3-256(0x01 | pubkey | 0x02)
```

Where

- the first entry, `0x01`, represents the use of a Secp256k1 ECDSA key;
- the last entry, `0x02`, represents the authentication scheme.

For a 1-of-2 multi-key account containing, a single Secp256k1 ECDSA public key, `pubkey_0`,
and a single Ed25519 public key, `pubkey_1`, where one signature suffices, the
authentication key would be derived as follows:

```text
auth_key = sha3-256(0x02 | 0x01 | pubkey_0 | 0x00 | pubkey_1 | 0x01 | 0x03)
```

Where

- the first entry, `0x02`, represents the total number of keys as a single byte;
- the second-to-last entry, `0x01`, represents the required number of signatures as a single byte;
- the last entry, `0x03`, represents the authentication scheme.

## Rotating the keys

An Account on Aptos can rotate keys so that potentially compromised keys cannot be used to access the accounts. Keys can be rotated via the `account::rotate_authentication_key` function.

Refreshing the keys is generally regarded as good hygiene in the security field. However, this presents a challenge for system integrators who are used to using a mnemonic to represent both a private key and its associated account. To simplify this for the system integrators, Aptos provides an on-chain mapping via aptos account lookup-address. The on-chain data maps an effective account address as defined by the current mnemonic to the actual account address.

For more information, see [`account.move`](https://github.com/aptos-labs/aptos-core/blob/a676c1494e246c31c5e96d3363d99e2422e30f49/aptos-move/framework/aptos-framework/sources/account.move#L274).

## State of an account

The state of each account comprises both the code (Move modules) and the data (Move resources). An account may contain an arbitrary number of Move modules and Move resources:

- **Move modules**: Move modules contain code, for example, type and procedure declarations; but they do not contain data. A Move module encodes the rules for updating the Aptos blockchain's global state.
- **Move resources**: Move resources contain data but no code. Every resource value has a type declared in a module published on the Aptos blockchain.

## Access control with signers

The sender of a transaction is represented by a signer. When a function in a Move module takes `signer` as an argument, the Aptos Move VM translates the identity of the account that signed the transaction into a signer in a Move module entry point. See the below Move example code with `signer` in the `initialize` and `withdraw` functions. When a `signer` is not specified in a function, for example, the below `deposit` function, then no signer-based access controls will be provided for this function:

```move filename="coin.move" /account: &signer/
module Test::Coin {
  struct Coin has key { amount: u64 }

  public fun initialize(account: &signer) {
    move_to(account, Coin { amount: 1000 });
  }

  public fun withdraw(account: &signer, amount: u64): Coin acquires Coin {
    let balance = &mut borrow_global_mut<Coin>(Signer::address_of(account)).amount;
    *balance = *balance - amount;
    Coin { amount }
  }

  public fun deposit(account: address, coin: Coin) acquires Coin {
      let balance = &mut borrow_global_mut<Coin>(account).amount;
      *balance = *balance + coin.amount;
      Coin { amount: _ } = coin;
  }
}
```

# Aptos White Paper

> Read the official Aptos blockchain white paper outlining the technical design, scalability principles, Move language integration, and architectural innovations.

import { CardGrid, LinkCard } from '@astrojs/starlight/components';

## Full PDF Versions

<CardGrid>
  <LinkCard href="https://aptosnetwork.com/whitepaper/aptos-whitepaper_en.pdf" title="üá∫üá∏ English (en-US) ‚Üó" description="Original Aptos White Paper PDF in English" target="_blank" />

  <LinkCard href="https://aptosnetwork.com/whitepaper/aptos-whitepaper_ko.pdf" title="üá∞üá∑ ÌïúÍµ≠Ïñ¥ Korean (ko-KR) ‚Üó" description="Aptos White Paper PDF translated to Korean" target="_blank" />

  <LinkCard href="https://aptosnetwork.com/whitepaper/aptos-whitepaper_ja.pdf" title="üáØüáµ Êó•Êú¨Ë™û Japanese (ja-JP) ‚Üó" description="Aptos White Paper PDF translated to Japanese" target="_blank" />

  <LinkCard href="https://aptosnetwork.com/whitepaper/aptos-whitepaper_es.pdf" title="üá™üá∏ Espa√±ol Spanish (es-ES) ‚Üó" description="Aptos White Paper PDF translated to Spanish" target="_blank" />
</CardGrid>

## Abstract

The rise of blockchains as a new Internet infrastructure has led to developers deploying tens of thousands of decentralized applications at rapidly growing rates.
Unfortunately, blockchain usage is not yet ubiquitous due to frequent outages, high costs, low throughput limits, and numerous security concerns. To enable mass adoption in the web3 era, blockchain infrastructure needs to follow the path of cloud infrastructure as a trusted, scalable, cost-efficient, and continually improving platform for building widely-used applications.

We present the Aptos blockchain, designed with scalability, safety, reliability, and upgradeability as key principles, to address these challenges. The Aptos blockchain has been developed over the past three years by over 350+ developers across the globe. It offers new and novel innovations in consensus, smart contract design, system security, performance, and decentralization. The combination of these technologies will provide a fundamental building block to bring web3 to the masses:

- First, the Aptos blockchain natively integrates and internally uses the Move language for fast and secure transaction execution. The Move prover, a formal verifier for smart contracts written in the Move language, provides additional safeguards for contract invariants and behavior. This focus on security allows developers to better protect their software from malicious entities.

- Second, the Aptos data model enables flexible key management and hybrid custodial options. This, alongside transaction transparency prior to signing and practical light client protocols, provides a safer and more trustworthy user experience.

- Third, to achieve high throughput and low latency, the Aptos blockchain leverages a pipelined and modular approach for the key stages of transaction processing. Specifically, transaction dissemination, block metadata ordering, parallel transaction execution, batch storage, and ledger certification all operate concurrently. This approach fully leverages all available physical resources, improves hardware efficiency, and enables highly parallel execution.

- Fourth, unlike other parallel execution engines that break transaction atomicity by requiring upfront knowledge of the data to be read and written, the Aptos blockchain does not put such limitations on developers. It can efficiently support atomicity with arbitrarily complex transactions, enabling higher throughput and lower latency for real-world applications and simplifying development.

- Fifth, the Aptos modular architecture design supports client flexibility and optimizes for frequent and instant upgrades. Moreover, to rapidly deploy new technology innovations and support new web3 use cases, the Aptos blockchain provides embedded on-chain change management protocols.

- Finally, the Aptos blockchain is experimenting with future initiatives to scale beyond individual validator performance: its modular design and parallel execution engine support internal sharding of a validator and homogeneous state sharding provides the potential for horizontal throughput scalability without adding additional complexity for node operators.

# Computing Transaction Gas

> Deep dive into Aptos gas computation including instruction gas, storage fees, payload costs, and optimization strategies for cost-effective transactions.

Aptos transactions by default charge a base gas fee, regardless of market conditions.
For each transaction, this "base gas" amount is based on three conditions:

1. Instructions.
2. Storage.
3. Payload.

The more function calls, branching conditional statements, etc. that a transaction requires, the more instruction gas it will cost.
Likewise, the more reads from and writes into global storage that a transaction requires, the more storage gas it will cost.
Finally, the more bytes in a transaction payload, the more it will cost.

As explained in the [optimization principles](#optimization-principles) section, storage gas has by far the largest effect on base gas. For background on the Aptos gas model, see [The Making of the Aptos Gas Schedule](https://aptoslabs.medium.com/the-making-of-the-aptos-gas-schedule-508d5686a350).

## Instruction gas

Basic instruction gas parameters are defined at [`instr.rs`] and include the following instruction types:

### No-operation

| Parameter | Meaning        |
| --------- | -------------- |
| `nop`     | A no-operation |

### Control flow

| Parameter  | Meaning                          |
| ---------- | -------------------------------- |
| `ret`      | Return                           |
| `abort`    | Abort                            |
| `br_true`  | Execute conditional true branch  |
| `br_false` | Execute conditional false branch |
| `branch`   | Branch                           |

### Stack

| Parameter           | Meaning                          |
| ------------------- | -------------------------------- |
| `pop`               | Pop from stack                   |
| `ld_u8`             | Load a `u8`                      |
| `ld_u16`            | Load a `u16`                     |
| `ld_u32`            | Load a `u32`                     |
| `ld_u64`            | Load a `u64`                     |
| `ld_u128`           | Load a `u128`                    |
| `ld_256`            | Load a `u256`                    |
| `ld_true`           | Load a `true`                    |
| `ld_false`          | Load a `false`                   |
| `ld_const_base`     | Base cost to load a constant     |
| `ld_const_per_byte` | Per-byte cost to load a constant |

### Local scope

| Parameter                   | Meaning                  |
| --------------------------- | ------------------------ |
| `imm_borrow_loc`            | Immutably borrow         |
| `mut_borrow_loc`            | Mutably borrow           |
| `imm_borrow_field`          | Immutably borrow a field |
| `mut_borrow_field`          | Mutably borrow a field   |
| `imm_borrow_field_generic`  |                          |
| `mut_borrow_field_generic`  |                          |
| `copy_loc_base`             | Base cost to copy        |
| `copy_loc_per_abs_val_unit` |                          |
| `move_loc_base`             | Move                     |
| `st_loc_base`               |                          |

### Calling

| Parameter                 | Meaning                         |
| ------------------------- | ------------------------------- |
| `call_base`               | Base cost for a function call   |
| `call_per_arg`            | Cost per function argument      |
| `call_per_local`          | Cost per local argument         |
| `call_generic_base`       |                                 |
| `call_generic_per_ty_arg` | Cost per type argument          |
| `call_generic_per_arg`    |                                 |
| `call_generic_per_local`  | Cost generic per local argument |

### Structs

| Parameter                  | Meaning                              |
| -------------------------- | ------------------------------------ |
| `pack_base`                | Base cost to pack a `struct`         |
| `pack_per_field`           | Cost to pack a `struct`, per field   |
| `pack_generic_base`        |                                      |
| `pack_generic_per_field`   |                                      |
| `unpack_base`              | Base cost to unpack a `struct`       |
| `unpack_per_field`         | Cost to unpack a `struct`, per field |
| `unpack_generic_base`      |                                      |
| `unpack_generic_per_field` |                                      |

### References

| Parameter                   | Meaning                            |
| --------------------------- | ---------------------------------- |
| `read_ref_base`             | Base cost to read from a reference |
| `read_ref_per_abs_val_unit` |                                    |
| `write_ref_base`            | Base cost to write to a reference  |
| `freeze_ref`                | Freeze a reference                 |

### Casting

| Parameter   | Meaning          |
| ----------- | ---------------- |
| `cast_u8`   | Cast to a `u8`   |
| `cast_u16`  | Cast to a `u16`  |
| `cast_u32`  | Cast to a `u32`  |
| `cast_u64`  | Cast to a `u64`  |
| `cast_u128` | Cast to a `u128` |
| `cast_u256` | Cast to a `u256` |

### Arithmetic

| Parameter | Meaning  |
| --------- | -------- |
| `add`     | Add      |
| `sub`     | Subtract |
| `mul`     | Multiply |
| `mod_`    | Modulo   |
| `div`     | Divide   |

### Bitwise

| Parameter | Meaning           |
| --------- | ----------------- |
| `bit_or`  | `OR`: `\|`        |
| `bit_and` | `AND`: `&`        |
| `xor`     | `XOR`: `^`        |
| `shl`     | Shift left: `<<`  |
| `shr`     | Shift right: `>>` |

### Boolean

| Parameter | Meaning      |
| --------- | ------------ |
| `or`      | `OR`: `\|\|` |
| `and`     | `AND`: `&&`  |
| `not`     | `NOT`: `!`   |

### Comparison

| Parameter              | Meaning                        |
| ---------------------- | ------------------------------ |
| `lt`                   | Less than: `<`                 |
| `gt`                   | Greater than: `>`              |
| `le`                   | Less than or equal to: `<=`    |
| `ge`                   | Greater than or equal to: `>=` |
| `eq_base`              | Base equality cost: `==`       |
| `eq_per_abs_val_unit`  |                                |
| `neq_base`             | Base not equal cost: `!=`      |
| `neq_per_abs_val_unit` |                                |

### Global storage

| Parameter                        | Meaning                                               |
| -------------------------------- | ----------------------------------------------------- |
| `imm_borrow_global_base`         | Base cost to immutably borrow: `borrow_global<T>()`   |
| `imm_borrow_global_generic_base` |                                                       |
| `mut_borrow_global_base`         | Base cost to mutably borrow: `borrow_global_mut<T>()` |
| `mut_borrow_global_generic_base` |                                                       |
| `exists_base`                    | Base cost to check existence: `exists<T>()`           |
| `exists_generic_base`            |                                                       |
| `move_from_base`                 | Base cost to move from: `move_from<T>()`              |
| `move_from_generic_base`         |                                                       |
| `move_to_base`                   | Base cost to move to: `move_to<T>()`                  |
| `move_to_generic_base`           |                                                       |

### Vectors

| Parameter                      | Meaning                                  |
| ------------------------------ | ---------------------------------------- |
| `vec_len_base`                 | Length of a vector                       |
| `vec_imm_borrow_base`          | Immutably borrow an element              |
| `vec_mut_borrow_base`          | Mutably borrow an element                |
| `vec_push_back_base`           | Push back                                |
| `vec_pop_back_base`            | Pop from the back                        |
| `vec_swap_base`                | Swap elements                            |
| `vec_pack_base`                | Base cost to pack a vector               |
| `vec_pack_per_elem`            | Cost to pack a vector per element        |
| `vec_unpack_base`              | Base cost to unpack a vector             |
| `vec_unpack_per_expected_elem` | Base cost to unpack a vector per element |

Additional storage gas parameters are defined in [`table.rs`], [`move_stdlib.rs`], and other assorted source files in [`aptos-gas-schedule/src/`].

## IO and Storage charges

The following gas parameters are applied (i.e., charged) to represent the costs associated with transient storage device resources, including disk IOPS and bandwidth:

In Move, one can read from the global state:

| Parameter                           | Meaning                                   |
| ----------------------------------- | ----------------------------------------- |
| storage\_io\_per\_state\_slot\_read | charged per item loaded from global state |
| storage\_io\_per\_state\_byte\_read | charged per byte loaded from global state |

For a committed transaction, various things will be written to the ledger history. Notice that the ledger history is subject to pruning and doesn't occupy permanent space on the disk, hence no storage fee charged for it.

| Parameter                                  | Meaning                                                                             |
| ------------------------------------------ | ----------------------------------------------------------------------------------- |
| storage\_io\_per\_state\_slot\_write       | charged per state write operation in the transaction output                         |
| storage\_io\_per\_state\_byte\_write       | charged per byte in all state write ops in the transaction output                   |
| storage\_io\_per\_event\_byte\_write       | charged per byte in all events in the transaction output                            |
| storage\_io\_per\_transaction\_byte\_write | charged per byte in the transaction itself which is also part of the ledger history |

The following storage fee parameters are applied (i.e., charged in absolute APT values) to represent the disk space and structural costs associated with using the [Aptos authenticated data structure](/network/glossary#merkle-trees) for storing items on the blockchain.

| Parameter                              | Meaning                                                                                                                                                                                                                                             |
| -------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| storage\_fee\_per\_state\_slot\_create | allocating a state slot, by `move_to()`, `table::add()`, etc                                                                                                                                                                                        |
| storage\_fee\_per\_state\_byte         | Notice this is charged every time the slot grows in size, not only at allocation time. (However, for simplicity, refunding is only at deletion time. See [AIP-65](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-65.md#specification)) |

### Vectors

Byte-wise fees are similarly assessed on vectors, which consume $\sum\_{i = 0}^{n - 1} e\_i + b(n)$ bytes, where:

- $n$ is the number of elements in the vector
- $e\_i$ is the size of element $i$
- $b(n)$ is a "base size" which is a function of $n$

See the [BCS sequence specification] for more information on vector base size (technically a `ULEB128`), which typically occupies just one byte in practice, such that a vector of 100 `u8` elements accounts for $100 + 1 = 101$ bytes.
Hence, per the item-wise read methodology described above, reading the last element of such a vector is treated as a 101-byte read.

## Payload gas

Payload gas is defined in [`transaction.rs`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/aptos-gas-schedule/src/gas_schedule/transaction.rs), which incorporates storage gas with several payload- and pricing-associated parameters:

| Parameter                       | Meaning                                                                                |
| ------------------------------- | -------------------------------------------------------------------------------------- |
| `min_transaction_gas_units`     | Minimum internal gas units for a transaction, charged at the start of execution        |
| `large_transaction_cutoff`      | Size, in bytes, above which transactions will be charged an additional amount per byte |
| `intrinsic_gas_per_byte`        | Internal gas units charged per byte for payloads above `large_transaction_cutoff`      |
| `maximum_number_of_gas_units`   | Upper limit on external gas units for a transaction                                    |
| `min_price_per_gas_unit`        | Minimum gas price allowed for a transaction                                            |
| `max_price_per_gas_unit`        | Maximum gas price allowed for a transaction                                            |
| `max_transaction_size_in_bytes` | Maximum transaction payload size in bytes                                              |
| `gas_unit_scaling_factor`       | Conversion factor between internal gas units and external gas units                    |

Here, "internal gas units" are defined as constants in source files like [`instr.rs`] and [`storage_gas.move`], which are more granular than "external gas units" by a factor of `gas_unit_scaling_factor`:
to convert from internal gas units to external gas units, divide by `gas_unit_scaling_factor`.
Then, to convert from external gas units to [octas](/network/glossary#octa), multiply by the "gas price", which denotes the number of octas per unit of external gas.

## Optimization principles

### Unit and pricing constants

As of the time of this writing, `min_price_per_gas_unit` in [`transaction.rs`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/aptos-gas-schedule/src/gas_schedule/transaction.rs) is defined as [`aptos_global_constants`]`::GAS_UNIT_PRICE` (which is itself defined as 100), with other noteworthy [`transaction.rs`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/aptos-gas-schedule/src/gas_schedule/transaction.rs) constants as follows:

| Constant                  | Value          |
| ------------------------- | -------------- |
| `min_price_per_gas_unit`  | 100            |
| `max_price_per_gas_unit`  | 10,000,000,000 |
| `gas_unit_scaling_factor` | 1,000,000      |

See [Payload gas](#payload-gas) for the meaning of these constants.

### Storage Fee

When the network load is low, the gas unit price is expected to be low, making most aspects of the transaction cost more affordable. However, the storage fee is an exception, as it's priced in terms of absolute APT value. In most instances, the transaction fee is the predominant component of the overall transaction cost. This is especially true when a transaction allocates state slots, writes to sizable state items, emits numerous or large events, or when the transaction itself is a large one. All of these factors consume disk space on Aptos nodes and are charged accordingly.

On the other hand, the storage refund incentivizes releasing state slots by deleting state items. The state slot fee is fully refunded upon slot deallocation, while the excess state byte fee is non-refundable. This will soon change by differentiating between permanent bytes (those in the global state) and relative ephemeral bytes (those that traverse the ledger history).

Some cost optimization strategies concerning the storage fee:

1. Minimize state item creation.
2. Minimize event emissions.
3. Avoid large state items, events, and transactions.
4. Clean up state items that are no longer in use.
5. If two fields are consistently updated together, group them into the same resource or resource group.
6. If a struct is large and only a few fields are updated frequently, move those fields to a separate resource or resource group.

### Instruction gas

As of the time of this writing, all instruction gas operations are multiplied by the `EXECUTION_GAS_MULTIPLIER` defined in [`meter.rs`], which is set to 20.
Hence, the following representative operations assume gas costs as follows (divide internal gas by scaling factor, then multiply by minimum gas price):

| Operation                    | Minimum [Octas](/network/glossary#octa) |
| ---------------------------- | --------------------------------------- |
| Table add/borrow/remove box  | 240                                     |
| Function call                | 200                                     |
| Load constant                | 130                                     |
| Globally borrow              | 100                                     |
| Read/write reference         | 40                                      |
| Load `u128` on stack         | 16                                      |
| Table box operation per byte | 2                                       |

(Note that per-byte table box operation instruction gas does not account for storage gas, which is assessed separately).

For comparison, reading a 100-byte item costs $r\_i + 100 \* r\_b = 3000 + 100 \* 3 = 3300$ [octas](/network/glossary#octa) at minimum, some 16.5 times as much as a function call, and in general, instruction gas costs are largely dominated by storage gas costs.

Notably, however, there is still technically an incentive to reduce the number of function calls in a program, but engineering efforts are more effectively dedicated to writing modular, decomposed code that is geared toward reducing storage gas costs, rather than attempting to write repetitive code blocks with fewer nested functions (in nearly all cases).

In extreme cases it is possible for instruction gas to far outweigh storage gas, for example if a looping mathematical function takes 10,000 iterations to converge; but again this is an extreme case and for most applications storage gas has a larger impact on base gas than does instruction gas.

### Payload gas

As of the time of this writing, [`transaction/mod.rs`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/aptos-gas-schedule/src/gas_schedule/transaction.rs) defines the minimum amount of internal gas per transaction as 1,500,000 internal units (15,000 [octas](/network/glossary#octa) at minimum), an amount that increases by 2,000 internal gas units (20 octas minimum) per byte for payloads larger than 600 bytes, with the maximum number of bytes permitted in a transaction set at 65536.
Hence, in practice, payload gas is unlikely to be a concern.

[#4540]: https://github.com/aptos-labs/aptos-core/pull/4540/files

[`aptos-gas-schedule/src/`]: https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/aptos-gas-schedule/src

[`aptos_global_constants`]: https://github.com/aptos-labs/aptos-core/blob/main/config/global-constants/src/lib.rs

[`base_8192_exponential_curve()`]: https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/doc/storage_gas.md#0x1_storage_gas_base_8192_exponential_curve

[BCS sequence specification]: https://github.com/diem/bcs#fixed-and-variable-length-sequences

[`meter.rs`]: https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/aptos-gas-meter/src/meter.rs

[`initialize()`]: https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/doc/storage_gas.md#0x1_storage_gas_initialize

[`instr.rs`]: https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/aptos-gas-schedule/src/gas_schedule/instr.rs

[`move_stdlib.rs`]: https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/aptos-gas-schedule/src/gas_schedule/move_stdlib.rs

[`on_reconfig()`]: https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/doc/storage_gas.md#@Specification_16_on_reconfig

[`storage_gas.md`]: https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/doc/storage_gas.md

[`storage_gas.move`]: https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/storage_gas.move

[`StorageGas`]: https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/doc/storage_gas.md#resource-storagegas

[`table.rs`]: https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/aptos-gas-schedule/src/gas_schedule/table.rs

[`transaction.rs`]: https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/aptos-gas-schedule/src/gas_schedule/transaction.rs

# Aptos Blockchain Deep Dive

> Take a comprehensive deep dive into Aptos blockchain architecture, transaction lifecycle, node components, and inter-component interactions for developers.

import { Aside } from '@astrojs/starlight/components';

For a deeper understanding of the lifecycle of an Aptos transaction (from an operational perspective), we will follow a transaction on its journey, from being submitted to an Aptos fullnode, to being committed to the Aptos blockchain. We will then focus on the logical components of Aptos nodes and take a look at how the transaction interacts with these components.

## Life of a Transaction

- Alice and Bob are two users who each have an [account](/network/glossary#account) on the Aptos blockchain.
- Alice's account has 110 Aptos Coins.
- Alice is sending 10 Aptos Coins to Bob.
- The current [sequence number](/network/glossary#sequence-number) of Alice's account is 5 (which indicates that 5 transactions have already been sent from Alice's account).
- There are a total of 100 validator nodes ‚Äî V<sub>1</sub> to V<sub>100</sub> on the network.
- An Aptos client submits Alice's transaction to a REST service on an Aptos Fullnode. The fullnode forwards this transaction to a validator fullnode which in turn forwards it to validator V<sub>1</sub>.
- Validator V<sub>1</sub> is a proposer/leader for the current round.

### The Journey

In this section, we will describe the lifecycle of transaction T<sub>5</sub>, from when the client submits it to when it is committed to the Aptos blockchain.

For the relevant steps, we've included a link to the corresponding inter-component interactions of the validator node. After you are familiar with all the steps in the lifecycle of the transaction, you may want to refer to the information on the corresponding inter-component interactions for each step.

```mermaid
graph LR
    subgraph Fullnodes
        direction TB
        REST_Service[REST Service]
    end

    Client(Client) -->|1| REST_Service

    subgraph Other_Validators[Other Validators]
        direction TB
    end

    subgraph Validators
        direction TB
        Mempool[Mempool]
        Consensus[Consensus]
        Consensus -->|7, 9| Execution
        Execution -->|11| Storage
        Execution -->|8| Virtual_Machine(Virtual Machine)
        Mempool --> Virtual_Machine
        Virtual_Machine --> Storage
    end

    Other_Validators <-->|6, 10| Consensus
    REST_Service -->|2, 3| Mempool
    Mempool <-->|4| Other_Validators(Other Validators)
    Consensus -->|5| Mempool
```

<Aside type="note">
  The arrows in all the visuals in this article originate on the component initiating an interaction/action and
  terminate on the component on which the action is being performed. The arrows do not represent data read,
  written, or returned.
</Aside>

The lifecycle of a transaction has five stages:

- **Accepting**: [Accepting the transaction](#accepting-the-transaction)
- **Sharing**: [Sharing the transaction with other validator nodes](#sharing-the-transaction-with-other-validator-nodes)
- **Proposing**: [Proposing the block](#proposing-the-block)
- **Executing and Consensus**: [Executing the block and reaching consensus](#executing-the-block-and-reaching-consensus)
- **Committing**: [Committing the block](#committing-the-block)

We've described what happens in each stage below, along with links to the corresponding Aptos node component interactions.

<Aside type="caution">
  Transactions are validated upon entering a mempool and prior to execution by consensus.
  The client only learns of validation results returned during the initial submission via the REST service.
  Transactions may silently fail to execute, especially in the case where the account has run out of utility
  token or changed its authentication key in the midst of many transactions. While this happens infrequently,
  there are ongoing efforts to improve the visibility in this space.
</Aside>

### Client submits a transaction

An Aptos **client constructs a raw transaction** (let's call it Traw<sub>5</sub>) to transfer 10 Aptos Coins from Alice‚Äôs account to Bob‚Äôs account. The Aptos client signs the transaction with Alice's private key. The signed transaction T<sub>5</sub> includes the following:

- The raw transaction.
- Alice's public key.
- Alice's signature.

The raw transaction includes the following fields:

| Fields                                                                               | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| ------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| [Account address](/network/glossary#account-address)                                 | Alice's account address                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |
| Payload                                                                              | Indicates an action or set of actions Alice's behalf. In the case this is a Move function, it directly calls into Move bytecode on the chain. Alternatively, it may be Move bytecode peer-to-peer [transaction script](/network/glossary#transaction-script). It also contains a list of inputs to the function or script. For this example, it is a function call to transfer an amount of Aptos Coins from Alice account to Bob's account, where Alice's account is implied by sending the transaction and Bob's account and the amount are specified as transaction inputs. |
| [Gas unit price](/network/glossary#gas-unit-price)                                   | The amount the sender is willing to pay per unit of gas, to execute the transaction. This is represented in [Octas](/network/glossary#octa).                                                                                                                                                                                                                                                                                                                                                                                                                                   |
| [Maximum gas amount](/network/glossary#maximum-gas-amount)                           | The maximum gas amount in APT Alice is willing to pay for this transaction. Gas charges are equal to the base gas cost covered by computation and IO multiplied by the gas price. Gas costs also include storage with an Apt-fixed priced storage model. This is represented in [Octas](/network/glossary#octa).                                                                                                                                                                                                                                                               |
| [Expiration time](/network/glossary#expiration-time)                                 | Expiration time of the transaction.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |
| [Sequence number](/network/glossary#sequence-number)                                 | The sequence number (5, in this example) for an account indicates the number of transactions that have been submitted and committed on-chain from that account. In this case, 5 transactions have been submitted from Alice‚Äôs account, including Traw<sub>5</sub>. Note: a transaction with sequence number 5 can only be committed on-chain if the account sequence number is 5.                                                                                                                                                                                              |
| [Chain ID](https://github.com/aptos-labs/aptos-core/blob/main/types/src/chain_id.rs) | An identifier that distinguishes the Aptos networks (to prevent cross-network attacks).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |

### Accepting the transaction

| Description                                                                                                                                                                                                                                                                                                                                                                                                                                                   | Aptos Node Component Interactions                                                   |
| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------- |
| 1. **Client ‚Üí REST service**: The client submits transaction T<sub>5</sub> to the REST service of an Aptos fullnode. The fullnode uses the REST service to forward the transaction to its own mempool, which then forwards the transaction to mempools running on other nodes in the network. The transaction will eventually be forwarded to a mempool running on a validator fullnode, which will send it to a validator node (V<sub>1</sub> in this case). | [1. REST Service](#1-client--rest-service)                                          |
| 2. **REST service ‚Üí Mempool**: The fullnode's mempool transmits transaction T<sub>5</sub> to validator V<sub>1</sub>'s mempool.                                                                                                                                                                                                                                                                                                                               | [2. REST Service](#2-rest-service--mempool), [1. Mempool](#1-rest-service--mempool) |
| 3. **Mempool ‚Üí Virtual Machine (VM)**: Mempool will use the virtual machine (VM) component to perform transaction validation, such as signature verification, account balance verification and replay resistance using the sequence number.                                                                                                                                                                                                                   | [4. Mempool](#4-mempool--vm), [3. Virtual Machine](#3-mempool--virtual-machine)     |

### Sharing the transaction with other validator nodes

| Description                                                                                                                                                                                                                                                         | Aptos Node Component Interactions               |
| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------- |
| 4. **Mempool**: The mempool will hold T<sub>5</sub> in an in-memory buffer. Mempool may already contain multiple transactions sent from Alice's address.                                                                                                            | [Mempool](#mempool)                             |
| 5. **Mempool ‚Üí Other Validators**: Using the shared-mempool protocol, V<sub>1</sub> will share the transactions (including T<sub>5</sub>) in its mempool with other validator nodes and place transactions received from them into its own (V<sub>1</sub>) mempool. | [2. Mempool](#2-mempool--other-validator-nodes) |

### Proposing the block

| Description                                                                                                                                                                                                                                            | Aptos Node Component Interactions                                          |
| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | -------------------------------------------------------------------------- |
| 6. **Consensus ‚Üí Mempool**: ‚Äî As validator V<sub>1</sub> is a proposer/leader for this transaction, it will pull a block of transactions from its mempool and replicate this block as a proposal to other validator nodes via its consensus component. | [1. Consensus](#1-consensus--mempool), [3. Mempool](#3-consensus--mempool) |
| 7. **Consensus ‚Üí Other Validators**: The consensus component of V<sub>1</sub> is responsible for coordinating agreement among all validators on the order of transactions in the proposed block.                                                       | [2. Consensus](#2-consensus--other-validators)                             |

### Executing the block and reaching consensus

| Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | Aptos Node Component Interactions                                                                            |
| -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------ |
| 8. **Consensus ‚Üí Execution**: As part of reaching agreement, the block of transactions (containing T<sub>5</sub>) is shared with the execution component.                                                                                                                                                                                                                                                                                                                                                                                                                                                      | [3. Consensus](#3-consensus--execution-consensus--other-validators), [1. Execution](#1-consensus--execution) |
| 9. **Execution ‚Üí Virtual Machine**: The execution component manages the execution of transactions in the VM. Note that this execution happens speculatively before the transactions in the block have been agreed upon.                                                                                                                                                                                                                                                                                                                                                                                        | [2. Execution](#2-execution--vm), [3. Virtual Machine](#3-mempool--virtual-machine)                          |
| 10. **Consensus ‚Üí Execution**: After executing the transactions in the block, the execution component appends the transactions in the block (including T<sub>5</sub>) to the [Merkle accumulator](/network/glossary#merkle-accumulator) (of the ledger history). This is an in-memory/temporary version of the Merkle accumulator. The necessary part of the proposed/speculative result of executing these transactions is returned to the consensus component to agree on. The arrow from "consensus" to "execution" indicates that the request to execute transactions was made by the consensus component. | [3. Consensus](#3-consensus--execution-consensus--other-validators), [1. Execution](#1-consensus--execution) |
| 11. **Consensus ‚Üí Other Validators**: V<sub>1</sub> (the consensus leader) attempts to reach consensus on the proposed block's execution result with the other validator nodes participating in consensus.                                                                                                                                                                                                                                                                                                                                                                                                     | [3. Consensus](#3-consensus--execution-consensus--other-validators)                                          |

### Committing the block

| Description                                                                                                                                                                                                                                                                                                                                                                                                                | Aptos Node Component Interactions                                                                                                                            |
| -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| 12. **Consensus ‚Üí Execution**, **Execution ‚Üí Storage**: If the proposed block's execution result is agreed upon and signed by a set of validators that have the quorum of votes, validator V<sub>1</sub>'s execution component reads the full result of the proposed block execution from the speculative execution cache and commits all the transactions in the proposed block to persistent storage with their results. | [4. Consensus](#4-consensus--execution), [3. Execution](#3-consensus--execution), [4. Execution](#4-execution--storage), [3. Storage](#3-execution--storage) |

Alice's account will now have 100 Aptos Coins, and its sequence number will be 6. If T<sub>5</sub> is replayed by Bob, it will be rejected as the sequence number of Alice's account (6) is greater than the sequence number of the replayed transaction (5).

## Aptos node component interactions

In the [Life of a Transaction](#life-of-a-transaction) section, we described the typical lifecycle of a transaction (from transaction submission to transaction commit). Now let's look at the inter-component interactions of Aptos nodes as the blockchain processes transactions and responds to queries. This information will be most useful to those who:

- Would like to get an idea of how the system works under the covers.
- Are interested in eventually contributing to the Aptos blockchain.

You can learn more about the different types of Aptos nodes here:

- [Validator nodes](/network/blockchain/validator-nodes)
- [Fullnodes](/network/blockchain/fullnodes)

For our narrative, we will assume that a client submits a transaction T<sub>N</sub> to a validator V<sub>X</sub>. For each validator component, we will describe each of its inter-component interactions in subsections under the respective component's section. Note that subsections describing the inter-component interactions are not listed strictly in the order in which they are performed. Most of the interactions are relevant to the processing of a transaction, and some are relevant to clients querying the blockchain (queries for existing information on the blockchain).

The following are the core components of an Aptos node used in the lifecycle of a transaction:

**Fullnode**

- [REST API Service](#rest-service)

**Validator node**

- [Mempool](#mempool)
- [Consensus](#consensus)
- [Execution](#execution)
- [Virtual Machine](#virtual-machine-vm)
- [Storage](#storage)

## REST Service

```mermaid
graph LR
    Client -->|1| REST_Service[REST Service]
    REST_Service -->|2| Mempool
    REST_Service -->|3| Storage
```

Any request made by a client goes to the REST Service of a fullnode first. Then, the submitted transaction is forwarded to the validator fullnode, which then sends it to the validator node V<sub>X</sub>.

### 1. Client ‚Üí REST Service

A client submits a transaction to the REST service of an Aptos fullnode.

### 2. REST Service ‚Üí Mempool

The REST service of the fullnode transfers the transaction to its mempool. After mempool does some initial checks, the REST Service will return a status to the client indicating whether the transaction was accepted or rejected. For example, out-of-date transactions will be rejected: mempool will accept the transaction T<sub>N</sub> only if the sequence number of T<sub>N</sub> is greater than or equal to the current sequence number of the sender's account.

### 3. Mempool -> Mempool

The mempool on the fullnode sends the transaction to the mempool of a validator fullnode, which then sends the transaction to validator node V<sub>X</sub>'s mempool. Note that the transaction will not be sent to the next mempool (or passed to consensus) until the sequence number matches the sequence number of the sender‚Äôs account. Furthermore, each mempool performs the same initial checks upon receiving a transaction, this may result in a transaction being discarded on its way to consensus. The current implementation of mempool does not provide any feedback if a transaction is discarded during this process.

### 4. REST Service ‚Üí Storage

When a client performs a read query on the Aptos blockchain (for example, to get the balance of Alice's account), the REST service interacts with the storage component directly to obtain the requested information.

## Virtual Machine (VM)

```mermaid
graph LR
    Mempool -->|3| Virtual_Machine[Virtual Machine]
    Virtual_Machine -->|2| Execution
    Virtual_Machine -->|1| Storage
```

The Move VM verifies and executes transaction scripts written in Move bytecode.

### 1. Virtual Machine ‚Üí Storage

When mempool requests the VM to validate a transaction via `VMValidator::validate_transaction()`, the VM loads the transaction sender's account from storage and performs verifications, some of which have been described in the list below.

- Checks that the input signature on the signed transaction is correct (to reject incorrectly signed transactions).
- Checks that the sender's account authentication key is the same as the hash of the public key (corresponding to the private key used to sign the transaction).
- Verifies that the sequence number for the transaction is greater than or equal to the current sequence number for the sender's account. Completing this check prevents the replay of the same transaction against the sender's account.
- Verifies that the program in the signed transaction is not malformed, as a malformed program cannot be executed by the VM.
- Verifies that the sender's account balance contains at least the maximum gas amount multiplied by the gas price specified in the transaction, which ensures that the transaction can pay for the resources it uses.

### 2. Execution ‚Üí Virtual Machine

The execution component utilizes the VM to execute a transaction via `ExecutorTask::execute_transaction()`.

It is important to understand that executing a transaction is different from updating the state of the ledger and persisting the results in storage. A transaction T<sub>N</sub> is first executed as part of an attempt to reach agreement on blocks during consensus. If agreement is reached with the other validators on the ordering of transactions and their execution results, the results are persisted in storage and the state of the ledger is updated.

### 3. Mempool ‚Üí Virtual Machine

When mempool receives a transaction from other validators via shared mempool or from the REST service, mempool invokes `VMValidator::validate_transaction()` on the VM to validate the transaction.

For implementation details refer to the [Move Virtual Machine README](https://github.com/move-language/move/tree/main/language/move-vm).

## Mempool

```mermaid
graph LR
    Mempool -->|2| Other_Validators[Other Validators]

    subgraph Fullnodes
        REST_Service[REST Service]
        Mempool[Mempool]
        Consensus[Consensus]
        Virtual_Machine[Virtual Machine]
    end

    REST_Service -->|1| Mempool
    Mempool -->|3| Consensus
    Mempool -->|4| Virtual_Machine
```

Mempool is a shared buffer that holds the transactions that are "waiting" to be executed. When a new transaction is added to the mempool, the mempool shares this transaction with other validator nodes in the system. To reduce network consumption in the "shared mempool," each validator is responsible for delivering its own transactions to other validators. When a validator receives a transaction from the mempool of another validator, the transaction is added to the mempool of the recipient validator.

### 1. REST Service ‚Üí Mempool

- After receiving a transaction from the client, the REST service sends the transaction to its own mempool, which then shares the transaction with the mempool of a validator fullnode. The mempool on the validator fullnode then shares the transaction with the mempool of a validator.
- The mempool for validator node V<sub>X</sub> accepts transaction T<sub>N</sub> for the sender's account only if the sequence number of T<sub>N</sub> is greater than or equal to the current sequence number of the sender's account.

### 2. Mempool ‚Üí Other validator nodes

- The mempool of validator node V<sub>X</sub> shares transaction T<sub>N</sub> with the other validators on the same network.
- Other validators share the transactions in their respective mempools with V<sub>X</sub>‚Äôs mempool.

### 3. Consensus ‚Üí Mempool

- When the transaction is forwarded to a validator node and once the validator node becomes the leader, its consensus component will pull a block of transactions from its mempool and replicate the proposed block to other validators. It does this to arrive at a consensus on the ordering of transactions and the execution results of the transactions in the proposed block.
- Note that just because a transaction T<sub>N</sub> was included in a proposed consensus block, it does not guarantee that T<sub>N </sub>will eventually be persisted in the distributed database of the Aptos blockchain.

### 4. Mempool ‚Üí VM

When mempool receives a transaction from other validators, mempool invokes `VMValidator::validate_transaction()` on the VM to validate the transaction.

## Consensus

```mermaid
graph TD
    subgraph Validators
        direction LR
            Consensus[Consensus] -->|1| Mempool[Mempool]
            Consensus -->|3, 4| Execution[Execution]
    end

    Other_Validators(Other Validators) <-->|2, 4| Consensus
```

The consensus component is responsible for ordering blocks of transactions and agreeing on the results of execution by participating in the [consensus protocol](/network/glossary#consensus-protocol) with other validators in the network.

### 1. Consensus ‚Üí Mempool

When validator V<sub>X</sub> is a leader/proposer, the consensus component of V<sub>X</sub> pulls a block of transactions from its mempool via: `Mempool::get_batch()`, and forms a proposed block of transactions.

### 2. Consensus ‚Üí Other Validators

If V<sub>X</sub> is a proposer/leader, its consensus component replicates the proposed block of transactions to other validators.

### 3. Consensus ‚Üí Execution, Consensus ‚Üí Other Validators

- To execute a block of transactions, consensus interacts with the execution component. Consensus executes a block of transactions via `BlockExecutorTrait::execute_block()` (Refer to [Consensus ‚Üí execution](#1-consensus--execution))
- After executing the transactions in the proposed block, the execution component responds to the consensus component with the result of executing these transactions.
- The consensus component signs the execution result and attempts to reach agreement on this result with other validators.

### 4. Consensus ‚Üí Execution

If enough validators vote for the same execution result, the consensus component of V<sub>X</sub> informs execution via `BlockExecutorTrait::commit_blocks()` that this block is ready to be committed.

## Execution

```mermaid
graph TD
    Consensus[Consensus] -->|1 and 3| Execution[Execution]
    Execution -->|2| Virtual_Machine[Virtual Machine]
    Execution -->|4| Storage[Storage]
```

The execution component coordinates the execution of a block of transactions and maintains a transient state that can be voted upon by consensus. If these transactions are successful, they are committed to storage.

### 1. Consensus ‚Üí Execution

- Consensus requests execution to execute a block of transactions via: `BlockExecutorTrait::execute_block()`.
- Execution maintains a "scratchpad," which holds in-memory copies of the relevant portions of the [Merkle accumulator](/network/glossary#merkle-accumulator). This information is used to calculate the root hash of the current state of the Aptos blockchain.
- The root hash of the current state is combined with the information about the transactions in the proposed block to determine the new root hash of the accumulator. This is done prior to persisting any data, and to ensure that no state or transaction is stored until agreement is reached by a quorum of validators.
- Execution computes the speculative root hash and then the consensus component of V<sub>X</sub> signs this root hash and attempts to reach agreement on this root hash with other validators.

### 2. Execution ‚Üí VM

When consensus requests execution to execute a block of transactions via `BlockExecutorTrait::execute_block()`, execution uses the VM to determine the results of executing the block of transactions.

### 3. Consensus ‚Üí Execution

If a quorum of validators agrees on the block execution results, the consensus component of each validator informs its execution component via `BlockExecutorTrait::commit_blocks()` that this block is ready to be committed. This call to the execution component will include the signatures of the validators to provide proof of their agreement.

### 4. Execution ‚Üí Storage

Execution takes the values from its "scratchpad" and sends them to storage for persistence via `DbWriter::save_transactions()`. Execution then prunes the old values from the "scratchpad" that are no longer needed (for example, parallel blocks that cannot be committed).

For implementation details refer to the [Execution README](https://github.com/aptos-labs/aptos-core/tree/main/execution).

## Storage

```mermaid
graph TD
    Virtual_Machine[Virtual Machine] -->|1| Storage[Storage]
    Execution[Execution] -->|2, 3| Storage
    REST_Service[REST Service] -->|4| Storage
```

The storage component persists agreed upon blocks of transactions and their execution results to the Aptos blockchain. A block of transactions (which includes transaction T<sub>N</sub>) will be saved via storage when there is agreement between more than a quorum (2f+1) of the validators participating in consensus. Agreement must include all the following:

- The transactions to include in the block
- The order of the transactions
- The execution results of the transactions in the block

Refer to [Merkle accumulator](/network/glossary#merkle-accumulator) for information on how a transaction is appended to the data structure representing the Aptos blockchain.

### 1. VM ‚Üí Storage

When mempool invokes `VMValidator::validate_transaction()` to validate a transaction, `VMValidator::validate_transaction()` loads the sender's account from storage and performs read-only validity checks on the transaction.

### 2. Execution ‚Üí Storage

When the consensus component calls `BlockExecutorTrait::execute_block()`, execution reads the current state from storage combined with the in-memory "scratchpad" data to determine the execution results.

### 3. Execution ‚Üí Storage

Once consensus is reached on a block of transactions, execution calls storage via `DbWriter::save_transactions()` to save the block of transactions and permanently record them. This will also store the signatures from the validator nodes that agreed on this block of transactions. The in-memory data in "scratchpad" for this block is passed to update storage and persist the transactions. When the storage is updated, every account that was modified by these transactions will have its sequence number incremented by one.

Note: The sequence number of an account on the Aptos blockchain increments by one for each committed transaction originating from that account.

### 4. REST Service ‚Üí Storage

For client queries that read information from the blockchain, the REST service directly interacts with storage to read the requested information.

For implementation details refer to the [Storage README](https://github.com/aptos-labs/aptos-core/tree/main/storage).

# Blocks

> Understand blocks on Aptos, including their role in the versioned database, system transactions, epochs, and how they structure blockchain data.

Aptos is a per-transaction versioned database. When transactions are executed, the resulting state of each transaction is stored separately and thus allows for more granular data access. This is different from other blockchains where only the resulting state of a block (a group of transactions) is stored.

Blocks are still a fundamental unit within Aptos. Transactions are batched and executed together in a block. In addition, the [proofs](/network/blockchain/txns-states#proofs) within storage are at the block-level granularity. The number of transactions within a block varies depending on network activity and a configurable maximum block size limit. As the blockchain becomes busier, blocks will likely contain more transactions.

## System transactions

Each Aptos block contains both user transactions and special system transactions to _mark_ the beginning and end of the transaction batch. Specifically, there are two system transactions:

1. `BlockMetadataTransaction` - is inserted at the beginning of the block. A `BlockMetadata` transaction can also mark the end of an [epoch](#epochs) and trigger reward distribution to validators.
2. `StateCheckpointTransaction` - is appended at the end of the block and is used as a checkpoint milestone.

## Epochs

In Aptos, epochs represent a longer period of time in order to safely synchronize major changes such as validator set additions/removals. An epoch is a fixed duration of time, currently defined as two hours on mainnet. The number of blocks in an epoch depends on how many blocks can execute within this period of time. It is only at the start of a new epoch that major changes such as a validator joining the validator set take effect among the validators.

# Delegated Staking

> Learn about delegated staking on Aptos, delegation pools, the owner-operator-voter-delegator model, and how to participate in staking without running a validator.

import { Aside } from '@astrojs/starlight/components';

<Aside type="note">
  We strongly recommend that you read about [Staking](/network/blockchain/staking) first.
</Aside>

Delegated staking is an extension of the staking protocol. A delegation pool abstracts the stake owner to an entity capable of collecting stake from delegators and adding it on their behalf to the native stake pool attached to the validator. This allows multiple entities to form a stake pool that achieves the minimum requirements for the validator to join the validator set. While delegators can add stake to an inactive pool, the delegation pool will not earn rewards until it is active.

<Aside type="caution">
  Delegation pools are permissionless and anyone can add stake. Delegation pools
  cannot be changed to stake pools once it's created or vice versa, though it
  can be removed from the validator set and assets withdrawn. For full details
  of the stake pool, see [Staking](/network/blockchain/staking)
</Aside>

For the full delegation pool smart contract, see [delegation\_pool.move](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/delegation_pool.move)

Unlike a stake pool, a delegation pool can be initialized with zero stake. When initialized, the delegated stake pool is owned indirectly via a resource account. This account will manage the stake of the underlying stake pool on behalf of the delegators by forwarding their stake-management operations to it (add, unlock, reactivate, withdraw) while the resource account cannot be directly accessed nor externally owned.

See full list of [Delegation Pool Operations](/network/nodes/validator-node/connect-nodes/delegation-pool-operations)

![Delegated Staking](~/images/delegated-staking/delegated-staking.png)

There are five entity types:

- Owner
- Operator
- Voter
- Delegator
- Beneficiary

Using this model, the owner does not have to stake on the Aptos blockchain in order to run a validator.

[How Validation on the Aptos blockchain works](/network/blockchain/staking#validation-on-the-aptos-blockchain)

### Owner

The delegation pool owner has the following capabilities:

1. Creates delegation pool
2. Assigns operator for the delegation pool
3. Sets operator commission percentage for the delegation pool
4. Assigns voter for the delegation pool

### Operator

A node operator is assigned by the pool owner to run the validator node. The operator has the following capabilities:

1. Join or leave the validator set once the delegation pool reaches 1M APT
2. Perform validating functions
3. Change the consensus key and network addresses. The consensus key is used to participate in the validator consensus process, i.e., to vote and propose a block. The operator is allowed to change ("rotate") this key in case this key is compromised.

The operator receives commission that is distributed automatically at the end of each epoch as rewards.

### Voter

An owner can designate a voter. This enables the voter to participate in governance. The voter will use the voter key to sign the governance votes in the transactions.

<Aside type="note">
  This document describes staking. See [Governance](/network/blockchain/governance) for how to
  participate in the Aptos on-chain governance using the owner-voter model.
</Aside>

### Delegator

A delegator is anyone who has stake in the delegation pool. Delegators earn rewards on their stake minus any commissions for the operator. Delegators can perform the following delegator operations:

1. Add stake
2. Unlock stake
3. Reactivate stake
4. Withdraw stake

### Beneficiary

A beneficiary is an address designated by the operator to receive operator commission rewards. Key aspects of the beneficiary role:

1. Each operator can set only one beneficiary address across all their delegation pools
2. The beneficiary can perform operations like unlock and withdraw for earned commission
3. When changing beneficiaries, any unpaid commission rewards will go to the new beneficiary
4. The operator can set or change the beneficiary using the `set_beneficiary_for_operator` function

## Validator flow

<Aside type="note">
  See [Delegation pool
  operations](/network/nodes/validator-node/connect-nodes/delegation-pool-operations)
  for the correct sequence of commands to run for the below flow.
</Aside>

1. [Operator deploys validator node](/network/nodes/validator-node)
2. [Run command to get delegation pool address](/network/nodes/validator-node/connect-nodes/delegation-pool-operations#prerequisites)
3. [Operator connects to the network using pool address derived in step 2](/network/nodes/validator-node/connect-nodes/connect-to-aptos-network)
4. [Owner initializes the delegation pool and sets operator](/network/nodes/validator-node/connect-nodes/delegation-pool-operations#initialize-a-delegation-pool)
5. Delegators can add stake at any time
6. When the delegation pool reaches 1M APT, the operator can call aptos node join-validator-set to join the active validator set. Changes will be effective in the next epoch.
7. Validator validates (proposes blocks as a leader-validator) and gains rewards. Rewards are distributed to delegators proportionally to stake amount. The stake will automatically be locked up for a fixed duration (set by governance) and automatically renewed at expiration.
8. At any point, if the operator wants to update the consensus key or validator network addresses, they can call aptos node update-consensus-key or aptos node update-validator-network-addresses. Similar to changes to stake, the changes to consensus key or validator network addresses are only effective in the next epoch.
9. Delegators can request to unlock their stake at any time. However, their stake will only become withdrawable when the delegation pool lockup expires.
10. Validator can either explicitly leave the validator set by calling aptos node leave-validator-set or if their stake drops below the min required, they would get removed at the end of the epoch.

## Joining the validator set

Participating as a delegation validator node on the Aptos network works like this:

1. Operator runs a validator node and configures the on-chain validator network addresses and rotates the consensus key.
2. Owner initializes the delegation pool.
3. The validator node cannot sync until the delegation pool becomes active. The delegation pool becomes active when it reaches 1M APT.
4. Operator validates and gains rewards.
5. The stake pool is automatically locked up for a fixed duration (set by the Aptos governance) and will be automatically renewed at expiration. Commissions are automatically distributed to the operator as rewards. The operator can unlock stake at any time, but cannot withdraw until the delegation pool‚Äôs lockup period expires.
6. Operator must wait until the new epoch starts before their validator becomes active.

<Aside type="note">
  For step-by-step instructions on how to join the validator set, see: [Joining
  Validator
  Set](/network/nodes/validator-node/connect-nodes/connect-to-aptos-network#join-the-validator-set).
</Aside>

### Automatic lockup duration

When the operator joins the validator set, the delegation pool's stake will automatically be locked up for a fixed duration that is set by the Aptos governance. Delegators will follow the delegation pool's lockup cycle.

### Automatic lockup renewal

When the lockup period expires, it will be automatically renewed, so that the validator can continue to validate and receive the rewards.

### Unlocking your stake

Delegators can unlock stake at any time. However, the stake will only become withdrawable after the delegation pool's lockup period expires. Unlocked stake will continue earning rewards until the stake becomes withdrawable.

### Resetting the lockup

Lockup cannot be reset.

## Rewards

Rewards for delegated staking are calculated by using:

1. The rewards\_rate, an annual percentage yield (APY), i.e., rewards accrue as a compound interest on your current staked amount.
2. Delegator stake
3. [Validator rewards performance](/network/blockchain/staking#rewards-formula)

See [Computing delegation pool rewards](/network/nodes/validator-node/connect-nodes/delegation-pool-operations#compute-delegation-pool-rewards-earned)

# Events

> Understand events on Aptos blockchain, including module events, EventHandle events (deprecated), and how to emit and query events in Move smart contracts.

Events are emitted during the execution of a transaction. Each Move module can define its own events and choose when to emit the events upon execution of the module. Aptos Move supports two form of events: module events and EventHandle events. Module events are the modern event mechanism and shipped in the framework release 1.7. EventHandle events are deprecated and shipped with the original framework. Because of how blockchains work, EventHandle events will likely never be fully removed from Aptos.

## Module Events

Module events are global event streams identified by a struct type. To define an event struct, add the attribute `#[event]` to a normal Move struct that has `drop` and `store` abilities. For example,

```move
/// 0xcafe::my_module_name
/// An example module event struct denotes a coin transfer.
#[event]
struct TransferEvent has drop, store {
    sender: address,
    receiver: address,
    amount: u64
}
```

And then create and emit the event:

```move
// Define an event.
let event = TransferEvent {
    sender: 0xcafe,
    receiver: 0xface,
    amount: 100
};
// Emit the event just defined.
0x1::event::emit(event);
```

Example module events are available [here](https://explorer.aptoslabs.com/txn/682252266/events?network=testnet). Indices 0, 1, 2 are three module events of
type `0x66c34778730acbb120cefa57a3d98fd21e0c8b3a51e9baee530088b2e444e94c::event::MyEvent`. For API compatibility, module events contain the fields `Account Address`, `Creation Number` and `Sequence Number` with all set to 0.

![Module event example](~/images/module-event.png "Module event example")

## Access in Tests

Events are stored in a separate merkle tree called event accumulator for each transaction. As it is ephemeral and hence independent of the state tree, MoveVM does not have read access to events when executing transaction in production. But in tests, Aptos Move supports two native functions that read emitted events for testing and debugging purposes:

```move
/// Return all emitted module events with type T as a vector.
# [test_only]
public native fun emitted_events<T: drop + store>(): vector<T>;

/// Return true iff `msg` was emitted.
# [test_only]
public fun was_event_emitted<T: drop + store>(msg: & T): bool
```

## API Access

There is support for querying both module events and EventHandle events using the [GraphQL API](/network/nodes/networks).

# Event-Handle Events (Deprecated)

As part of our legacy, Aptos inherited the Libra/Diem event streams derived from EventHandles. Where each EventHandle is identified by a globally unique value, GUID, and a per-event sequence number and stored within a resource. Each event within a stream has a unique sequence number derived from the EventHandle sequence number.

For example, during a [coin transfer](/build/guides/first-transaction), both the sender and receiver's accounts will emit `SentEvent` and `ReceivedEvent`, respectively. This data is stored within the ledger and can be queried via the REST interface's [Get events by event handle](https://api.devnet.aptoslabs.com/v1/spec#/operations/get_events_by_event_handle).

Assuming that an account `0xc40f1c9b9fdc204cf77f68c9bb7029b0abbe8ad9e5561f7794964076a4fbdcfd` had sent coins to another account, the following query could be made to the REST interface: `https://api.devnet.aptoslabs.com/v1/accounts/c40f1c9b9fdc204cf77f68c9bb7029b0abbe8ad9e5561f7794964076a4fbdcfd/events/0x1::coin::CoinStore<0x1::aptos_coin::AptosCoin>/withdraw_events`. The output would be all `WithdrawEvent`s stored on that account, it would look like

```json
[
  {
    "key": "0x0000000000000000caa60eb4a01756955ab9b2d1caca52ed",
    "sequence_number": "0",
    "type": "0x1::coin::WithdrawEvent",
    "data": {
      "amount": "1000"
    }
  }
]
```

Each registered event has a unique `key`. The key `0x0000000000000000caa60eb4a01756955ab9b2d1caca52ed` maps to the event `0x1::coin::CoinStore<0x1::aptos_coin::AptosCoin>/sent_events` registered on account `0xc40f1c9b9fdc204cf77f68c9bb7029b0abbe8ad9e5561f7794964076a4fbdcfd`. This key can then be used to directly make event queries, e.g., `https://api.devnet.aptoslabs.com/v1/events/0x0000000000000000caa60eb4a01756955ab9b2d1caca52ed`.

These represent event streams, or a list of events with each entry containing a sequentially increasing `sequence_number` beginning at `0`, a `type`, and `data`. Each event must be defined by some `type`. There may be multiple events defined by the same or similar `type`s especially when using generics. Events have associated `data`. The general principle is to include all data necessary to understand the changes to the underlying resources before and after the execution of the transaction that changed the data and emitted the event.

[coin_transfer]: https://github.com/aptos-labs/aptos-core/blob/bdd0a7fe82cd6aab4b47250e5eb6298986777cf7/aptos-move/framework/aptos-framework/sources/coin.move#L412

[get_events]: https://api.devnet.aptoslabs.com/v1/spec#/operations/get_events_by_event_handle

## Migration to Module Events

With the release of module events, EventHandle events are deprecated. To support migration to the module events, projects should emit a module event wherever they currently emit EventHandle events. Once external systems have sufficiently adopted module events, the legacy event may no longer need to be emitted.

Note, the EventHandle events cannot and will not be deleted and hence projects that are unable to upgrade will continue to be able to leverage them.

# Execution

> Explore transaction execution on Aptos, including deterministic processing, parallel execution with Block-STM, and performance optimizations for high throughput.

On Aptos, execution refers to the process where validators run and apply smart contract transactions
from an ordered block. The execution output is then applied to the blockchain state.

It is crucial for execution to be
[deterministic](https://en.wikipedia.org/wiki/Deterministic_algorithm), and all validators should
ideally agree on the same final state of the ledger. A majority of validators (more than 2/3 of the
validators) must agree on the final state of the ledger in order to come to a consensus. For more
detailed information on consensus properties, see the section on
[BFT](/network/glossary#byzantine-fault-tolerance-bft) and [consensus](/network/glossary#consensus).

Efficient execution, particularly parallel execution, is key to scaling blockchain performance and
throughput. The impact of this can be felt in the block time. As of December 2024, Aptos blocks close within 250ms.

## Why Parallel Execution?

![](https://miro.medium.com/v2/resize:fit:4800/format:webp/0*qG0KRe1KzsP8Odth)

The simplest approach for smart contract execution is to execute the transactions in a block
sequentially, one at a time. However, this does not scale well. Having a large number of sequential
transactions, especially with varying execution times, can cause the latency and throughput of the
blockchain to drop drastically.

To solve this problem, blockchains began to adopt parallel execution, or the ability to process
multiple transactions in parallel. The challenge with parallel execution, however, is that certain
transactions may read or write the same resource, causing conflicts.

### Static Parallelism

One approach to address the conflict issue in parallel execution is **static parallelism**, which
requires developers to specify the conflicts between transactions ahead of time. This, however,
brings a higher burden on the developer, and in many cases forces transactions that don't actually
conflict to be sequential.

### Dynamic Parallelism

**Dynamic parallelism** computes the execution ordering of transactions on-the-fly, dynamically
detecting dependencies and avoiding conflicts during execution. An additional property that is
important for dynamic parallelism on a blockchain is that the execution output is consistent with
executing transactions according to a preset order.

By not requiring developers to specify the conflicts ahead of time, dynamic parallelism allows
developers to flexibly write applications without facing the design constraints of statically
declaring transaction dependencies.

## Block-STM

Aptos uses a highly efficient, multi-threaded, in-memory parallel execution engine called Block-STM.
Block-STM leverages the preset order of transactions and combines Software Transactional Memory
techniques with a novel collaborative schedule.

Block-STM is the state-of-the-art dynamic parallelism execution engine developed by the Aptos Labs
team.

Since its release, [Polygon](https://polygon.technology/blog/innovating-the-main-chain-a-polygon-pos-study-in-parallelization), Sei,
[Starknet](https://www.starknet.io/blog/parallel-execution-and-v0-13-2/), and other blockchains have
adopted it to achieve parallel execution on their respective chains.

To learn more, see:

- [Block-STM blog post](https://medium.com/aptoslabs/block-stm-how-we-execute-over-160k-transactions-per-second-on-the-aptos-blockchain-3b003657e4ba)
- [Block-STM paper](https://arxiv.org/pdf/2203.06871)
- [a16z crypto research talk](https://www.youtube.com/watch?v=2SE5tqPzhyw)
- [Stark Spaces | Block-STM and Starknet](https://www.youtube.com/watch?v=y1kXOi39RX0)
- [Block-STM: Accelerating Smart-Contract Processing](https://blog.chain.link/block-stm/)

# Fullnodes Overview

> Discover how fullnodes work on Aptos, their role in verifying blockchain history, differences from validator nodes, and how they support the network ecosystem.

An Aptos node is an entity of the Aptos ecosystem that tracks the [state](/network/glossary#state) of the Aptos blockchain. Clients interact with the blockchain via Aptos nodes. There are two types of nodes:

- [Validator nodes](/network/blockchain/validator-nodes)
- Fullnodes

Each Aptos node comprises several logical components:

- [REST API service](/network/glossary#rest-api-service)
- [Mempool](/network/blockchain/validator-nodes#mempool)
- [Execution](/network/blockchain/validator-nodes#execution)
- [Virtual Machine](/network/blockchain/validator-nodes#virtual-machine)
- [Storage](/network/blockchain/validator-nodes#storage)
- [State synchronizer](/network/blockchain/validator-nodes#state-synchronizer)

The [Aptos-core](/network/glossary#aptos-core) software can be configured to run as a validator node or as a fullnode.

## Overview

Fullnodes can be run by anyone. Fullnodes verify blockchain history by either re-executing all transactions in the history of the Aptos blockchain or replaying each transaction's output. Fullnodes replicate the entire state of the blockchain by synchronizing with upstream participants, e.g., other fullnodes or validator nodes. To verify blockchain state, fullnodes receive the set of transactions and the [accumulator root hash](/network/glossary#accumulator-root-hash) of the ledger signed by the validators. In addition, fullnodes accept transactions submitted by Aptos clients and forward them directly (or indirectly) to validator nodes. While fullnodes and validators share the same code, fullnodes do not participate in consensus.

Depending on the fullnode upstream, a fullnode can be called as a validator fullnode, or a public fullnode:

- **Validator fullnode** state sync from a validator node directly.
- **Public fullnode** state sync from other fullnodes.

There's no difference in their functionality, only whether their upstream node is a validator or another fullnode. Read more details about network topology [here](/network/blockchain/node-networks-sync)

Third-party blockchain explorers, wallets, exchanges, and dapps may run a local fullnode to:

- Leverage the REST interface for blockchain interactions.
- Get a consistent view of the Aptos ledger.
- Avoid rate limitations on read traffic.
- Run custom analytics on historical data.
- Get notifications about particular on-chain events.

# Gas and Storage Fees

> Learn about gas fees and storage costs on Aptos, including execution costs, storage fees, gas pricing, and optimization strategies for efficient transactions.

import { Aside } from '@astrojs/starlight/components';

Any transaction execution on the Aptos blockchain requires a processing fee. As of today, this fee comprises two components:

1. Execution & IO costs

- This covers your usage of transient computation resources, such as processing your transactions and propagating the validated record throughout the distributed network of the mainnet.
- It is measured in Gas Units whose price may fluctuate according to the load of the network. This allows execution and IO costs to be low when the network is less busy.
- This portion of gas is burned permanently upon the execution of a transaction.

2. Storage fees

- This covers the cost to persistently store validated record in the distributed blockchain storage.
- It is measured in fixed APT prices, so the permanent storage cost stays stable even as the gas unit price fluctuates with the network's transient load.
- - The storage fee can be refunded when the allocated storage slot is deleted. Currently, the network is configured to refund the entirety of the storage fee paid over the lifetime of a state storage slot.
- To keep system implementation simple, this portion of gas is burned and minted again upon refund.

<Aside type="note">
  Conceptually, this fee can be thought of as quite similar to how we pay for our home electric or water utilities.
</Aside>

## Unit of gas

Transactions can range from simple and inexpensive to complicated based upon what they do. In the Aptos blockchain, a **unit of gas** represents a basic unit of consumption for transient resources, such as doing computation or accessing the storage. The latter should not be conflated with the long-term storage aspect of such operations, as that is covered by the storage fees separately.

See [How Base Gas Works](/network/blockchain/base-gas) for a detailed description of gas fee types and available optimizations.

<Aside type="note">
  üëâ A **unit of gas** is a dimensionless number or a unit that is not associated with any one item such as a coin, expressed as an integer. The total gas units consumed by your transaction depend on the complexity of your transaction. The **gas price**, on the other hand, is expressed in terms of Aptos blockchain‚Äôs native coin [APT](/network/glossary#apt) and its subunit [Octas](/network/glossary#octa). Also see [Transactions and States](/network/blockchain/txns-states) for how a transaction submitted to the Aptos blockchain looks like.
</Aside>

## The Fee Statement

As of Aptos Framework release 1.7, the breakdown of fee charges and refunds is emitted as a module event represented by struct `0x1::transaction_fee::FeeStatement`.

```move filename="transaction_fee.move"
#[event]
/// Breakdown of fee charge and refund for a transaction.
/// The structure is:
///
/// - Net charge or refund (not in the statement)
///    - total charge: total_charge_gas_units, matches `gas_used` in the on-chain `TransactionInfo`.
///      This is the sum of the sub-items below. Notice that there's potential precision loss when
///      the conversion between internal and external gas units and between native token and gas
///      units, so it's possible that the numbers don't add up exactly. -- This number is the final
///      charge, while the break down is merely informational.
///        - gas charge for execution (CPU time): `execution_gas_units`
///        - gas charge for IO (storage random access): `io_gas_units`
///        - storage fee charge (storage space): `storage_fee_octas`, to be included in
///          `total_charge_gas_unit`, this number is converted to gas units according to the user
///          specified `gas_unit_price` on the transaction.
///    - storage deletion refund: `storage_fee_refund_octas`, this is not included in `gas_used` or
///      `total_charge_gas_units`, the net charge / refund is calculated by
///      `total_charge_gas_units` * `gas_unit_price` - `storage_fee_refund_octas`.
///
/// This is meant to be emitted as a module event.
struct FeeStatement has drop, store {
    /// Total gas charge.
    total_charge_gas_units: u64,
    /// Execution gas charge.
    execution_gas_units: u64,
    /// IO gas charge.
    io_gas_units: u64,
    /// Storage fee charge.
    storage_fee_octas: u64,
    /// Storage fee refund.
    storage_fee_refund_octas: u64,
}
```

## Gas price and prioritizing transactions

In the Aptos network, the Aptos governance sets the absolute minimum gas unit price. However, the market determines how quickly a transaction with a particular gas unit price is processed. See [Ethereum Gas Tracker](https://etherscan.io/gastracker), for example, which shows the market price movements of Ethereum gas price.

By specifying a higher gas unit price than the current market price, you can **increase** the priority level for your transaction on the blockchain by paying a larger processing fee. As part of consensus, when the leader selects transactions from its mempool to propose as part of the next block, it will prioritize selecting transactions with a higher gas unit price. Please note that higher gas fees only prioritize transaction selection for the next block.

However, within a block, the order of transaction execution is determined by the system. This order is based on [transaction shuffling](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-27.md), which makes parallel execution more efficient by considering conflict patterns. While in most cases this is unnecessary, if the network is under load this measure can ensure your transaction is processed more quickly. See the `gas_unit_price` entry under [Estimating the gas units via simulation](#estimating-gas-consumption-via-simulation) for details.

<Aside type="caution">
  üëâ If you are increasing gas unit price, but have in-flight (uncommitted) transactions for the same account, you should resubmit all of those transactions with the higher gas unit price. This is because transactions within the same account always have to respect sequence number, so effectively the higher gas unit price transaction will increase priority only after the in-flight transactions are included in a block.
</Aside>

## Specifying gas fees within a transaction

When a transaction is submitted to the Aptos blockchain, the transaction must contain the following mandatory gas fields:

- `max_gas_amount`: The maximum number of gas units that the transaction sender is willing to spend to execute the transaction. This determines the maximum computational and storage resources that can be consumed by the transaction.
- `gas_price`: The price per gas unit the transaction sender is willing to pay. It is expressed in [Octas](/network/glossary#octa).

  During the transaction execution, the total gas amount, expressed as:

  ```text
  (total execution gas units consumed) + (total storage gas units consumed)
  ```

  must not exceed `max_gas_amount`, or else the transaction will abort the execution.

The transaction fee charged to the client will be at the most `gas_price * max_gas_amount`.

## Gas parameters set by governance

The following gas parameters are set by Aptos governance.

<Aside type="note">
  These on-chain gas parameters are published on the Aptos blockchain at `0x1::gas_schedule::GasScheduleV2`.
</Aside>

- `txn.maximum_number_of_gas_units`: Maximum number of gas units that can be spent (this is the maximum allowed value for the `max_gas_amount` gas parameter in the transaction). This is to ensure that the dynamic pricing adjustments do not exceed how much you are willing to pay in total.
- `txn.min_transaction_gas_units`: Minimum number of gas units that can be spent. The `max_gas_amount` value in the transaction must be set to greater than this parameter‚Äôs value.

There also exists some global per-category limits:

- `txn.max_execution_gas`: The maximum number of gas units a transaction can spend on execution.
- `txn.max_io_gas`: The maximum number of gas units a transaction can spend on IO.
- `txn.max_storage_fee`: The maximum amount of APT a transaction can spend on persistent storage.
  These limits help decouple one category from another, allowing us to set `txn.maximum_number_of_gas_units` generously without having to worry about abuses.

## Calculating Storage Fees

The storage fee for a transaction is charged according to the number of new slots allocated in the global state and the size increase in the existing slots.

There are some nuances with regard to price changing and legacy slots which didn't pay for the size of the slot below a historical "free quota". Refer to [AIP-65](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-65.md#specification) for more details.

It should also be noted that due to some backward compatibility reasons, the total storage fee of a transaction is currently presented to the client as part of the total `gas_used`. This means, this amount could vary based on the gas unit price even for the same transaction.

Here is an example. Suppose we have a transaction that costs `100` gas units in execution & IO, and `5000` [Octas](/network/glossary#octa) in storage fees. The network will show that you have used

- `100 + 5000 / 100 = 150` gas units if the gas unit price is `100`, or
- `100 + 5000 / 200 = 125` gas units if the unit price is `200`.

We are aware of the confusion this might create, and plan to present these as separate items in the future. However, this will require some changes to the transaction output format and downstream clients, so please be patient while we work hard to make this happen.

## Calculating Storage Deletion Refund

If a transaction deletes state items, a refund is issued to the transaction payer for the released storage slots. Currently, a full refund is issued -- that is, all storage fee paid for the slot and bytes of the item over the lifetime of it.

The refund amount is denominated in APT and is not converted to gas units or included in the total `gas_used`. Instead, this refund amount is specifically detailed in the `storage_fee_refund_octas` field of the [`FeeStatement`](#the-fee-statement). As a result, the transaction's net effect on the payer's APT balance is determined by `gas_used * gas_unit_price - storage_refund`. If the result is positive, there is a deduction from the account balance; if negative, there is a deposit.

## Examples

### Example 1: Account balance vs transaction fee

**The sender‚Äôs account must have sufficient funds to pay for the transaction fee.**

If, let's say, you transfer all the money out of your account so that you have no remaining balance to pay for the transaction fee. In such case the Aptos blockchain would let you know that the transaction will fail, and your transfer wouldn't succeed either.

### Example 2: Transaction amounts vs transaction fee

**Transaction fee is independent of transfer amounts in the transaction.**

In a transaction, for example, transaction A, you are transferring 1000 coins from one account to another account. In a second transaction B, with the same gas field values of transaction A, you now transfer 100,000 coins from one account to another one account. Assuming that both the transactions A and B are sent roughly at the same time, then the gas costs for transactions A and B would be near-identical.

## Estimating gas consumption via simulation

The gas used for a transaction can be estimated by simulating the transaction on chain as described here or locally via the gas profiling feature of the Aptos CLI. The results of the simulated transaction represent the **exact** amount that is needed at the **exact** state of the blockchain at the time of the simulation. These gas units used may change based on the state of the chain. For this reason, any amount coming out of the simulation is only an estimate, and when setting the max gas amount, it should include an appropriate amount of headroom based upon your comfort-level and historical behaviors. Setting the max gas amount too low will result in the transaction aborting and the account being charged for whatever gas was consumed.

To simulate transactions on chain, used the [`SimulateTransaction`](https://api.devnet.aptoslabs.com/v1/spec#/operations/simulate_transaction) API. This API will run the exact transaction that you plan to run.

To simulate the transaction locally, use the gas profiler, which is integrated into the Aptos CLI.
This will generate a web-based report to help you understand the precise gas usage of your transaction.
See [Gas Profiling](/build/cli/working-with-move-contracts/local-simulation-benchmarking-and-gas-profiling#gas-profiling) for more details.

<Aside type="note">
  Note that the `Signature` provided on the transaction must be all zeros. This is to prevent someone from using the valid signature.
</Aside>

To simulate the transaction, there are two flags:

1. `estimate_gas_unit_price`: This flag will estimate the gas unit price in the transaction using the same algorithm as the [`estimate_gas_price`](https://api.devnet.aptoslabs.com/v1/spec#/operations/estimate_gas_price) API.
2. `estimate_max_gas_amount`: This flag will find the maximum possible gas you can use, and it will simulate the transaction to tell you the actual `gas_used`.

### Simulation steps

The simulation steps for finding the correct amount of gas for a transaction are as follows:

1. Estimate the gas via simulation with both `estimate_gas_unit_price` and `estimate_max_gas_amount` set to `true`.
2. Use the `gas_unit_price` in the returned transaction as your new transaction‚Äôs `gas_unit_price`.
3. View the `gas_used * gas_unit_price` values in the returned transaction as the **lower bound** for the cost of the transaction.
4. To calculate the upper bound of the cost, take the **minimum** of the `max_gas_amount` in the returned transaction, and the `gas_used * safety factor`. In the CLI a value of `1.5` is used for `safety factor`. Use this value as `max_gas_amount` for the transaction you want to submit. Note that the **upper bound** for the cost of the transaction is `max_gas_amount * gas_unit_price`, i.e., this is the most the sender of the transaction is charged.
5. At this point you now have your `gas_unit_price` and `max_gas_amount` to submit your transaction as follows:
   1. `gas_unit_price` from the returned simulated transaction.
   2. `max_gas_amount` as the minimum of the `gas_used` \* `a safety factor` or the `max_gas_amount` from the transaction.
6. If you feel the need to prioritize or deprioritize your transaction, adjust the `gas_unit_price` of the transaction. Increase the value for higher priority, and decrease the value for lower priority.

<Aside type="note">
  Prioritization is based upon buckets of `gas_unit_price`. The buckets are defined in [`mempool_config.rs`](https://github.com/aptos-labs/aptos-core/blob/30b385bf38d3dc8c4e8ee0ff045bc5d0d2f67a85/config/src/config/mempool_config.rs#L8). The current buckets are `[0, 150, 300, 500, 1000, 3000, 5000, 10000, 100000, 1000000]`. Therefore, a `gas_unit_price` of 150 and 299 would be prioritized nearly the same.
</Aside>

<Aside type="note">
  Note that the `safety factor` only takes into consideration changes related to execution and IO. Unexpected creation of storage slots may not be sufficiently covered.
</Aside>

# On-Chain Governance

> Learn about Aptos on-chain governance, how to create and vote on proposals, and participate in blockchain upgrade decisions through the democratic process.

import { ThemedImage } from '~/components/ThemedImage';

The Aptos on-chain governance is a process by which the Aptos community members can create and vote on proposals that minimize the cost of blockchain upgrades. The following describes the scope of these proposals for the Aptos on-chain governance:

- Changes to the blockchain parameters, for example, the epoch duration, and the minimum required and maximum allowed validator stake.
- Changes to the core blockchain code.
- Upgrades to the Aptos Framework modules for fixing bugs or for adding or enhancing the Aptos blockchain functionality.
- Deploying new framework modules (at the address `0x1` - `0xa`).

## How a proposal becomes ready to be resolved

See below for a summary description of how a proposal comes to exist and when it becomes ready to be resolved:

<ThemedImage
  alt="Proposal voting flow"
  sources={{
light: '~/images/voting-resolution-flow.svg',
dark: '~/images/voting-resolution-flow-dark.svg',
}}
/>

- The Aptos community can suggest an Aptos Improvement Proposal (AIP) in the [Aptos Foundation AIP GitHub](https://github.com/aptos-foundation/AIPs).
- When appropriate, an on-chain proposal can be created for the AIP via the `aptos_governance` module.
- Voters can then vote on this proposal on-chain via the `aptos_governance` module. If there is sufficient support for a proposal, then it can be resolved.
- Governance requires a minimal number of votes to be cast by an expiration threshold. However, if sufficient votes, more than 50% of the total supply, are accumulated prior to that threshold, the proposal can be executed **without waiting for the full voting period**.

## Who can propose

- To either propose or vote, you must stake, but you are not required to run a validator node. However, we recommend that you run validator with a stake as part of the validator set to gain rewards from your stake.
- To create a proposal, the proposer's backing stake pool must have the minimum required proposer stake. The proposer's stake must be locked up for at least as long as the proposal's voting period. This is to avoid potential spam proposals.
- Proposers can create a proposal by calling [`aptos_governance::create_proposal`](https://github.com/aptos-labs/aptos-core/blob/27a255ebc662817944435349afc4ec33ea317e64/aptos-move/framework/aptos-framework/sources/aptos_governance.move#L183).

## Who can vote

- To vote, you must stake, though you are not required to run a validator node. Your voting power is derived from the backing stake pool.
- Voting power is calculated based on the current epoch's active stake of the proposer or voter's backing stake pool. In addition, the stake pool's lockup must be at least as long as the proposal's duration.
- Verify proposals before voting. Ensure each proposal is linked to its source code, and if there is a corresponding AIP, the AIP is in the title and description.

If you are a [staking pool](/network/blockchain/staking) voter, follow the instructions for voting [here](/network/nodes/validator-node/connect-nodes/staking-pool-voter).

If you are a [delegated staker](/network/blockchain/delegated-staking), follow the instructions for voting [here](/network/nodes/validator-node/connect-nodes/staking-pool-voter#delegation-pool-voter).

## Who can resolve

- Anyone can resolve an on-chain proposal that has passed voting requirements by using the `aptos governance execute-proposal` command from Aptos CLI.

## Aptos Improvement Proposals (AIPs)

AIPs are proposals created by the Aptos community or the Aptos Labs team to improve the operations and development of the Aptos chain.
To submit an AIP, create an issue in [`Aptos Foundation's GitHub repository`](https://github.com/aptos-foundation/AIPs/issues) using the [template](https://github.com/aptos-foundation/AIPs/blob/main/TEMPLATE.md)
To keep up with new AIPs, check the `#aip-announcements` channel on [Aptos' discord channel](https://discord.gg/aptosnetwork).
To view and vote on on-chain proposals, go to [`Aptos' Governance website`](https://governance.aptosfoundation.org/).

## Technical Implementation of Aptos Governance

The majority of the governance logic is in [`aptos_governance.move and voting.move`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources).
The `aptos_governance` module outlines how users can interact with Aptos Governance. It's the external-facing module of the Aptos on-chain governance process and contains logic and checks that are specific to Aptos Governance.
The `voting` module is the Aptos governance standard that can be used by DAOs on the Aptos chain to create their own on-chain governance process.

If you are thinking about creating a DAO on Aptos, you can refer to `aptos_governance`'s usage of the `voting` module as an example.
In `aptos_governance`, we rely on the `voting` module to create, vote on, and resolve a proposal.

- `aptos_governance::create_proposal` calls `voting::create_proposal` to create a proposal on-chain, when an off-chain AIP acquires sufficient importance.
- `aptos_governance::vote` calls `voting::vote` to record the vote on a proposal on-chain;
- `aptos_governance::resolve` can be called by anyone. It calls `voting::resolve` to resolve the proposal on-chain.

# Move - A Web3 Language and Runtime

> Explore Move programming language on Aptos, its safety features, comparison with other VMs, and unique capabilities for building secure Web3 applications.

The Aptos blockchain consists of validator nodes that run a consensus protocol. The consensus protocol agrees upon the ordering of transactions and their output when executed on the Move Virtual Machine (MoveVM). Each validator node translates transactions along with the current blockchain ledger state as input into the VM. The MoveVM processes this input to produce a changeset or storage delta as output. Once consensus agrees and commits to the output, it becomes publicly visible. In this guide, we will introduce you to core Move concepts and how they apply to developing on Aptos.

## What is Move?

Move is a safe and secure programming language for Web3 that emphasizes **scarcity** and **access control**. Any assets in Move can be represented by or stored within _resource_. **Scarcity** is enforced by default as structs cannot be accidentally duplicated or dropped. Only structs that have explicitly been defined at the bytecode layer as _copy_ can be duplicated and _drop_ can be dropped, respectively.

**Access control** comes from both the notion of accounts and module access privileges. A module in Move may either be a library or a program that can create, store, or transfer assets. Move ensures that only public module functions may be accessed by other modules. Unless a struct has a public constructor, it can only be constructed within the module that defines it. Similarly, fields within a struct can only be accessed and mutated within its module that or via public accessors and setters. Furthermore, structs defined with _key_ can be stored and read from global storage only within the module defines it. Structs with _store_ can be stored within another _store_ or _key_ struct inside or outside the module that defines that struct.

In Move, a transaction's sender is represented by a _signer_, a verified owner of a specific account. The signer has the highest level of permission in Move and is the only entity capable of adding resources into an account. In addition, a module developer can require that a signer be present to access resources or modify assets stored within an account.

## Comparison to other VMs

|                             | Aptos / Move                                                 | Solana / SeaLevel                                           | EVM                                                        | Sui / Move                            |
| --------------------------- | ------------------------------------------------------------ | ----------------------------------------------------------- | ---------------------------------------------------------- | ------------------------------------- |
| Data storage                | Stored at a global address or within the owner's account     | Stored within the owner's account associated with a program | Stored within the account associated with a smart contract | Stored at a global address            |
| Parallelization             | Capable of inferring parallelization at runtime within Aptos | Requires specifying all data accessed                       | Currently serial nothing in production                     | Requires specifying all data accessed |
| Transaction safety          | Sequence number                                              | Transaction uniqueness                                      | nonces, similar to sequence numbers                        | Transaction uniqueness                |
| Type safety                 | Module structs and generics                                  | Program structs                                             | Contract types                                             | Module structs and generics           |
| Function calling            | Static dispatch                                              | Static dispatch                                             | Dynamic dispatch                                           | Static dispatch                       |
| Authenticated Storage       | [Yes](/network/glossary#merkle-trees)                        | No                                                          | Yes                                                        | No                                    |
| Object global accessibility | Yes                                                          | Not applicable                                              | Not applicable                                             | No, can be placed in other objects    |

## Aptos Move features

Each deployment of the MoveVM has the ability to extend the core MoveVM with additional features via an adapter layer. Furthermore, MoveVM has a framework to support standard operations much like a computer has an operating system.

The Aptos Move adapter features include:

- [Move Objects](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-10.md) that offer an extensible programming model for globally access to heterogeneous set of resources stored at a single address on-chain.
- [Cryptography primitives](/build/smart-contracts/cryptography) for building scalable, privacy-preserving dapps.
- [Resource accounts](/build/smart-contracts/resource-accounts) that offer programmable accounts on-chain, which can be useful for DAOs (decentralized autonomous organizations), shared accounts, or building complex applications on-chain.
- [Tables](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-stdlib/sources/table.move) for storing key, value data within an account at scale.
- Parallelism via [Block-STM](https://medium.com/aptoslabs/block-stm-how-we-execute-over-160k-transactions-per-second-on-the-aptos-blockchain-3b003657e4ba) that enables concurrent execution of transactions without any input from the user.
- Multi-agent framework that enables a single transaction to be submitted with multiple distinct `signer` entities.

The Aptos framework ships with many useful libraries:

- An [Aptos Token Objects](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/framework/aptos-token-objects/sources) standard as defined in [AIP-11](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-11.md) and [AIP-22](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-22.md) that makes it possible to create interoperable NFTs with either lightweight smart contract development or none at all.
- A [Coin standard](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/coin.move) that makes it possible to create type-safe Coins by publishing a trivial module.
- A [Fungible asset standard](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/fungible_asset.move) as defined in [AIP-21](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-21.md) to modernize the coin concept with better programmability and controls.
- A [staking](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/staking_contract.move) and [delegation](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/delegation_pool.move) framework.
- A [`type_of`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-stdlib/sources/type_info.move) service to identify at run-time the address, module, and struct name of a given type.
- A [timestamp service](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/timestamp.move) that provides a monotonically increasing clock that maps to the actual current Unix time.

With updates frequently.

## More Resources

Developers can begin their journey in Move by heading over to our [Move developer page](/network/blockchain/move).

# Node Networking and State Synchronization

> Learn about the different Aptos node types, their network topology, and how nodes synchronize with each other to maintain blockchain state consistency.

Validator nodes and fullnodes form a hierarchical structure with validator nodes at the root and fullnodes everywhere else. The Aptos blockchain distinguishes two types of fullnodes: validator fullnodes and public fullnodes. Validator fullnodes connect directly to validator nodes and offer scalability alongside DDoS mitigation. Public fullnodes connect to validator fullnodes (or other public fullnodes) to gain low-latency access to the Aptos network.

![v-fn-network.svg](~/images/v-fn-network.svg)

## Node types

Aptos operates with these node types:

- [Validator nodes (VNs)](/network/blockchain/validator-nodes) - participates in consensus and drives [transaction processing](/network/blockchain/txns-states).
- Validator fullnodes (VFNs) - captures and keeps up-to-date on the state of the blockchain; run by the validator operator, so it can connect directly to the validator node and therefore serve requests from public fullnodes. Otherwise, it works like a public fullnode.
- [Public fullnodes (PFNs)](/network/blockchain/fullnodes) - run by someone who is not a validator operator, PFNs cannot connect directly to a validator node and therefore rely upon VFNs for synchronization.
- [Archival nodes (ANs)](/network/nodes/configure/state-sync#archival-pfns) - is a fullnode that contains all blockchain data since the start of the blockchain's history.

## Separate network stacks

The Aptos blockchain supports distinct networking stacks for various network topologies. For example, the validator network is independent of the fullnode network. The advantages of having separate network stacks include:

- Clean separation between the different networks.
- Better support for security preferences (e.g., bidirectional vs server authentication).
- Allowance for isolated discovery protocols (i.e., on-chain discovery for validator node's public endpoints vs. manual configuration for private organizations).

# Node synchronization

Aptos nodes synchronize to the latest state of the Aptos blockchain through two mechanisms: consensus or state synchronization. Validator nodes will use both consensus and state synchronization to stay up-to-date, while fullnodes use only state synchronization.

For example, a validator node will invoke state synchronization when it comes online for the first time or reboots (e.g., after being offline for a while). Once the validator is up-to-date with the latest state of the blockchain it will begin participating in consensus and rely exclusively on consensus to stay up-to-date. Fullnodes, however, continuously rely on state synchronization to get and stay up-to-date as the blockchain grows.

As of December 2024, the Aptos network's block time was under 250ms.

## State synchronizer

Each Aptos node contains a [State Synchronizer](/network/nodes/configure/state-sync) component which is used to synchronize the state of the node with its peers. This component has the same functionality for all types of Aptos nodes: it utilizes the dedicated peer-to-peer network to continuously request and disseminate blockchain data. Validator nodes distribute blockchain data within the validator node network, while fullnodes rely on other fullnodes (i.e., validator nodes or public fullnodes).

# Move Resources

> Learn about Resources in Move on Aptos, how they differ from instances, their permission models, and storage mechanisms for managing on-chain state.

On Aptos, on-chain state is organized into resources and modules. These are then stored within the individual accounts. This is different from other blockchains, such as Ethereum, where each smart contract maintains its own storage space. See [Accounts](/network/blockchain/accounts) for more details on accounts.

## Resources vs Instances

Move modules define struct definitions. Struct definitions may include the abilities such as `key` or `store`. Resources are struct instance with The `key` ability that are stored in global storage or directly in an account. The `store` ability allows struct instances to be stored within resources. An example here is how the APT coin is stored: CoinStore is the resource that contains the APT coin, while the Coin itself is an instance:

```move
/// A holder of a specific coin type and associated event handles.
/// These are kept in a single resource to ensure locality of data.
struct CoinStore<phantom CoinType> has key {
    coin: Coin<CoinType>,
}

/// Main structure representing a coin/token in an account's custody.
struct Coin<phantom CoinType> has store {
    /// Amount of coin this address has.
    value: u64,
}
```

The Coin instance can be taken out of CoinStore with the owning account's permission and easily transferred to another CoinStore resource. It can also be kept in any other custom resource, if the definition allows, for example:

```move
struct CustomCoinBox<phantom CoinType> has key {
    coin: Coin<CoinType>,
}
```

## Define resources and objects

All instances and resources are defined within a module that is stored at an address. For example `0x1234::coin::CoinStore<0x1234::coin::SomeCoin>` would be represented as:

```move
module 0x1234::coin {
    struct CoinStore<phantom CoinType> has key {
        coin: Coin<CoinType>,
    }

    struct SomeCoin { }
}
```

In this example, `0x1234` is the address, `coin` is the module, `CoinStore` is a struct that can be stored as a resource, and `SomeCoin` is a struct that is unlikely to ever be represented as an instance. The use of the phantom type allows for there to exist many distinct types of `CoinStore` resources with different `CoinType` parameters.

## Permissions of Instances including Resources

Permissions of resources and other instances are dictated by the module where the struct is defined. For example, an instance within a resource may be accessed and even removed from the resource, but the internal state cannot be changed without permission from the module where the instance's struct is defined.

Ownership, on the other hand, is signified by either storing a resource under an account or by logic within the module that defines the struct.

## Viewing a resource

Resources are stored within accounts. Resources can be located by searching within the owner's account for the resource at its full query path inclusive of the account where it is stored as well as its address and module. Resources can be viewed on the [Aptos Explorer](https://explorer.aptoslabs.com/) by searching for the owning account or directly fetched from a fullnode's API.

## How resources are stored

The module that defines a struct specifies how instances may be stored. For example, events for depositing a token can be stored in the receiver account where the deposit happens or in the account where the token module is deployed. In general, storing data in individual user accounts enables a higher level of execution efficiency as there would be no state read/write conflicts among transactions from different accounts, allowing for seamless parallel execution.

# Staking

> Understand staking on Aptos blockchain, including validator operations, rewards, lockup periods, and the owner-operator-voter model for network participation.

import { ThemedImage } from '~/components/ThemedImage';

import { Aside } from '@astrojs/starlight/components';

<Aside type="note">
  We strongly recommend that you read the consensus section of [Aptos Blockchain Deep Dive](/network/blockchain/blockchain-deep-dive#consensus) before proceeding further.
</Aside>

In a distributed system like blockchain, executing a transaction is distinct from updating the state of the ledger and persisting the results in storage. An agreement, i.e., consensus, must be reached by a quorum of validators on the ordering of transactions and their execution results before these results are persisted in storage and the state of the ledger is updated.

Anyone can participate in the Aptos consensus process, if they stake sufficient utility coin, i.e., place their utility coin into escrow. To encourage validators to participate in the consensus process, each validator's vote weight is proportional to the amount of validator's stake. In exchange, the validator is rewarded proportionally to the amount staked. Hence, the performance of the blockchain is aligned with the validator's interest, i.e., rewards.

<Aside type="note">
  Currently, slashing is not implemented.
</Aside>

The current on-chain data can be found in [`staking_config::StakingConfig`](https://api.mainnet.aptoslabs.com/v1/accounts/0x1/resource/0x1::staking_config::StakingConfig). The configuration set is defined in [`staking_config.move`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/configs/staking_config.move).

The rest of this document presents how staking works on the Aptos blockchain. See [Supporting documentation](#supporting-documentation) at the bottom for related resources.

## Staking on the Aptos blockchain

Below is a summary flow diagram of how staking on the Aptos blockchain works. The sections following the summary describe it in detail.

<ThemedImage
  alt="Staking Flow"
  sources={{
light: '~/images/staking-light.svg',
dark: '~/images/staking-dark.svg',
}}
/>

The Aptos staking module defines a capability that represents ownership.

<Aside type="note">
  See the `OwnerCapability` defined in [stake.move](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/stake.move).
</Aside>

The `OwnerCapability` resource can be used to control the stake pool. Three personas are supported:

- Owner
- Operator
- Voter

Using this owner-operator-voter model, a custodian can assume the owner persona and stake on the Aptos blockchain and participate in the Aptos governance. This model allows delegations and staking services to be built as it separates the account that is in control of the funds from the other accounts (operator, voter), hence allows secure delegations of responsibilities.

This section describes how this works, using Bob and Alice in the example.

### Owner

The owner is the owner of the funds. For example, Bob creates an account on the Aptos blockchain. Now Bob has the `OwnerCapability` resource. Bob can assign his account‚Äôs operator address to the account of Alice, a trusted node operator, to appoint Alice as a validator.

As an owner:

- Bob owns the funds that will be used for staking.
- Only Bob can add, unlock or withdraw funds.
- Only Bob can extend the lockup period.
- Bob can change the node operator Alice to some other node operator anytime Bob wishes to do so.
- Bob can set the operator commission percentage.
- The reward will be deposited into Bob's (owner's) account.

### Operator

A node operator is assigned by the fund owner to run the validator node and receives commission as set by the owner. The two personas, the owner and the operator, can be two separate entities or the same. For example, Alice (operator) runs the validator node, operating at the behest of Bob, the fund owner.

As an operator:

- Alice has permissions only to join or leave the validator set.
- As a validator, Alice will perform the validating function.
- Alice has the permissions to change the consensus key and network addresses. The consensus key is used by Alice to participate in the validator consensus process, i.e., to vote and propose a block. Alice is allowed to change ("rotate") this key in case this key is compromised.
- However, Alice cannot move funds (unless Alice is the owner, i.e., Alice has the `OwnerCapability` resource).
- The operator commission is deducted from the staker (owner) rewards and deposited into the operator account.

### Voter

An owner can designate a voter. This enables the voter to participate in governance. The voter will use the voter key to sign the governance votes in the transactions.

<Aside type="note">
  This document describes staking. See [Governance](/network/blockchain/governance) for how to participate in the Aptos on-chain governance using the owner-voter model.
</Aside>

## Validation on the Aptos blockchain

Throughout the duration of an epoch, the following flow of events occurs several times (thousands of times):

- A validator leader is selected by a deterministic formula based on the validator reputation determined by validator's performance (including whether the validator has voted in the past or not) and stake. **This leader selection is not done by voting.**
- The selected leader sends a proposal containing the collected quorum votes of the previous proposal and the leader's proposed order of transactions for the new block.
- All the validators from the validator set will vote on the leader's proposal for the new block. Once consensus is reached, the block can be finalized. Hence, the actual list of votes to achieve consensus is a subset of all the validators in the validator set. This leader validator is rewarded. **Rewards are given only to the leader validator, not to the voter validators.**
- The above flow repeats with the selection of another validator leader and repeating the steps for the next new block. Rewards are given at the end of the epoch.

## Validator state and stake state

States are defined for a validator and the stake.

- **Validator state:** A validator can be in any one of these four states. Moreover, the validator can go from inactive (not tracked in the validator set anywhere) state to any one of the other three states:
  - inactive
  - pending\_active.
  - active.
  - pending\_inactive.
- **Stake state:** A validator in pending\_inactive or active state, can have their stake in either of these four states:

  - inactive.
  - pending\_active.
  - active.
  - pending\_inactive.

  These stake states are applicable for the existing validators in the validator set adding or removing their stake.

### Validator states

<ThemedImage
  alt="Signed Transaction Flow"
  sources={{
light: '~/images/validator-state.svg',
dark: '~/images/validator-state-dark.svg',
}}
/>

There are two edge cases to call out:

1. If a validator's stake drops below the required [minimum](#minimum-and-maximum-stake), that validator will be moved from active state directly to the inactive state during an epoch change. This happens only during an epoch change.
2. Aptos governance can also directly remove validators from the active set. **Note that governance proposals will always trigger an epoch change.**

### Stake state

The state of stake has more granularity than that of the validator; additional stake can be added and a portion of stake removed from an active validator.

<ThemedImage
  alt="Signed Transaction Flow"
  sources={{
light: '~/images/stake-state.svg',
dark: '~/images/stake-state-dark.svg',
}}
/>

### Validator rules

The below rules is applicable during the changes of state:

- Voting power can change (increase or decrease) only on epoch boundary.
- A validator‚Äôs consensus key and the validator and validator fullnode network addresses can change only on epoch boundary.
- Pending inactive stake cannot be moved into inactive (and thus withdrawable) until before lockup expires.
- No validators in the active validator set can have their stake below the minimum required stake.

## Validator flow

<Aside type="note">
  See [Staking pool operations](/network/nodes/validator-node/connect-nodes/staking-pool-operations) for the correct sequence of commands to run for the below flow.
</Aside>

1. Owner initializes the stake pool with `aptos stake create-staking-contract`.
2. When the owner is ready to deposit the stake (or have funds assigned by a staking service in exchange for ownership capability), owner calls `aptos stake add-stake`.
3. When the validator node is ready, the operator can call `aptos node join-validator-set` to join the active validator set. Changes will be effective in the next epoch.
4. Validator validates (proposes blocks as a leader-validator) and gains rewards. The stake will automatically be locked up for a fixed duration (set by governance) and automatically renewed at expiration.
5. At any point, if the operator wants to update the consensus key or validator network addresses, they can call `aptos node update-consensus-key` or `aptos node update-validator-network-addresses`. Similar to changes to stake, the changes to consensus key or validator network addresses are only effective in the next epoch.
6. Validator can request to unlock their stake at any time. However, their stake will only become withdrawable when their current lockup expires. This can be at most as long as the fixed lockup duration.
7. After exiting, the validator can either explicitly leave the validator set by calling `aptos node leave-validator-set` or if their stake drops below the min required, they would get removed at the end of the epoch.
8. Validator can always rejoin the validator set by going through steps 2-3 again.
9. An owner can always switch operators by calling `aptos stake set-operator`.
10. An owner can always switch designated voter by calling `aptos stake set-delegated-voter`.

## Joining the validator set

Participating as a validator node on the Aptos network works like this:

1. Operator runs a validator node and configures the on-chain validator network addresses and rotates the consensus key.
2. Owner deposits her Aptos coins funds as stake, or have funds assigned by a staking service. The stake must be at least the minimum amount required.
3. **The validator node cannot sync until the stake pool becomes active.**
4. Operator validates and gains rewards.
5. The staked pool is automatically be locked up for a fixed duration (set by the Aptos governance) and will be automatically renewed at expiration. You cannot withdraw any of your staked amount until your lockup period expires. See [stake.move#L728](https://github.com/aptos-labs/aptos-core/blob/00a234cc233b01f1a7e1680f81b72214a7af91a9/aptos-move/framework/aptos-framework/sources/stake.move#L728).
6. Operator must wait until the new epoch starts before their validator becomes active.

<Aside type="note">
  For step-by-step instructions on how to join the validator set, see: [Joining Validator Set](/network/nodes/validator-node/connect-nodes/connect-to-aptos-network#join-the-validator-set).
</Aside>

### Minimum and maximum stake

You must stake the required minimum amount to join the validator set. Moreover, you can only stake up to the maximum stake amount. The current required minimum for staking is 1M APT tokens and the maximum is 50M APT tokens.

If at any time after joining the validator set, your current staked amount exceeds the maximum allowed stake (for example as the rewards are added to your staked amount), then your voting power and the rewards will be calculated only using the maximum allowed stake amount, and not your current staked amount.

The owner can withdraw part of the stake and leave their balance below the required minimum. In such case, their stake pool will be removed from the validator set when the next epoch starts.

### Automatic lockup duration

When you join the validator set, your stake will automatically be locked up for a fixed duration that is set by the Aptos governance.

### Automatic lockup renewal

When your lockup period expires, it will be automatically renewed, so that you can continue to validate and receive the rewards.

### Unlocking your stake

You can request to unlock your stake at any time. However, your stake will only become withdrawable when your current lockup expires. This can be at most as long as the fixed lockup duration. You will continue earning rewards on your stake until it becomes withdrawable.

The principal amount is updated when any of the following actions occur:

1. Operator [requests commission unlock](/network/nodes/validator-node/connect-nodes/staking-pool-operations#requesting-commission)
2. Staker (owner) withdraws funds
3. Staker (owner) switches operators

When the staker unlocks stake, this also triggers a commission unlock. The full commission amount for any staking rewards earned is unlocked. This is not proportional to the unlock stake amount. Commission is distributed to the operator after the lockup ends when `request commission` is called a second time or when staker withdraws (distributes) the unlocked stake.

### Resetting the lockup

When the lockup period expires, it is automatically renewed by the network. However, the owner can explicitly reset the lockup.

<Aside type="note">
  The lockup duration is decided by the Aptos governance, i.e., by the covenants that the Aptos community members vote on, and not by any special entity like the Aptos Labs.
</Aside>

## Epoch

An epoch in the Aptos blockchain is defined as a duration of time, in seconds, during which a number of blocks are voted on by the validators, the validator set is updated, and the rewards are distributed to the validators.

<Aside type="note">
  The Aptos mainnet epoch is set as 7200 seconds (two hours).
</Aside>

### Triggers at the epoch start

<Aside type="note">
  See the [Triggers at epoch boundary section of `stake.move`](https://github.com/aptos-labs/aptos-core/blob/256618470f2ad7d89757263fbdbae38ac7085317/aptos-move/framework/aptos-framework/sources/stake.move#L1036) for the full code.
</Aside>

At the start of each epoch, the following key events are triggered:

- Update the validator set by adding the pending active validators to the active validators set and by removing the pending inactive validators from the active validators set.
- Move any pending active stake to active stake, and any pending inactive stake to inactive stake.
- The staking pool's voting power in this new epoch is updated to the total active stake.
- Automatically renew a validator's lockup for the validators who will still be in the validator set in the next epoch.
- The voting power of each validator in the validator set is updated to be the corresponding staking pool's voting power.
- Rewards are distributed to the validators that participated in the previous epoch.

## Rewards

Rewards for staking are calculated by using:

1. The `rewards_rate`, an annual percentage yield (APY), i.e., rewards accrue as a compound interest on your current staked amount.
2. Your staked amount.
3. Your proposer performance in the Aptos governance.

<Aside type="note">
  The `rewards_rate` is set by the Aptos governance. Also see [Validation on the Aptos blockchain](#validation-on-the-aptos-blockchain).
</Aside>

### Rewards formula

See below the formula used to calculate rewards to the validator:

```text filename="Staking Rewards Formula"
Reward = staked_amount * rewards_rate per epoch * (Number of successful proposals by the validator / Total number of proposals made by the validator)
```

### Rewards paid every epoch

Rewards are paid every epoch. Any reward you (i.e., validator) earned at the end of current epoch is added to your staked amount. The reward at the end of the next epoch is calculated based on your increased staked amount (i.e., original staked amount plus the added reward), and so on.

### Rewards based on the proposer performance

The validator rewards calculation uses the validator's proposer performance. Once you are in the validator set, you can propose in every epoch. The more successfully you propose, i.e., your proposals pass, the more rewards you will receive.

Note that rewards are given only to the **leader-validators**, i.e., validators who propose the new block, and not to the **voter-validators** who vote on the leader's proposal for the new block. See [Validation on the Aptos blockchain](#validation-on-the-aptos-blockchain).

<Aside type="note">
  All the validator rewards are also subject to lockup period as they are added to the original staked amount.
</Aside>

## Leaving the validator set

<Aside type="note">
  See the Aptos Stake module in the Move language at [stake.move](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/stake.move).
</Aside>

- At any time you can call the following sequence of functions to leave the validator set:
  - Call `Stake::unlock` to unlock your stake amount, and
  - Either call `Stake::withdraw` to withdraw your staked amount at the next epoch, or call `Stake::leave_validator_set`.

## Rejoining the validator set

When you leave a validator set, you can rejoin by depositing the minimum required stake amount.

## Supporting documentation

- [Current on-chain data](https://api.mainnet.aptoslabs.com/v1/accounts/0x1/resource/0x1::staking_config::StakingConfig)
- [Staking Pool Operations](/network/nodes/validator-node/connect-nodes/staking-pool-operations)
- [Delegation Pool Operations](/network/nodes/validator-node/connect-nodes/delegation-pool-operations)
- [Configuration file `staking_config.move`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/configs/staking_config.move)
- [Contract file `staking_contract.move`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-framework/sources/staking_contract.move) covering requesting commissions
- [All staking-related \`.move files](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/framework/aptos-framework/sources)

# Transactions and States

> Understand how transactions modify the blockchain state on Aptos, including transaction types, execution states, and the versioned database model.

import { ThemedImage } from '~/components/ThemedImage';

import { Aside } from '@astrojs/starlight/components';

The Aptos blockchain stores three types of data:

- **Transactions**: Transactions represent an intended operation being performed by an account on the blockchain (e.g., transferring assets).
- **States**: The (blockchain ledger) state represents the accumulation of the output of execution of transactions, the values stored within all [resources](/network/blockchain/resources).
- [**Events**](/network/blockchain/events): Ancillary data published by the execution of a transaction.

<Aside type="note">
  Only transactions can change the ledger state.
</Aside>

## Transactions

Aptos transactions contain information such as the sender‚Äôs account address, authentication from the sender, the desired operation to be performed on the Aptos blockchain, and the amount of gas the sender is willing to pay to execute the transaction.

### Transaction states

A transaction may end in one of the following states:

- Committed on the blockchain and executed. This is considered as a successful transaction.
- Committed on the blockchain and aborted. The abort code indicates why the transaction failed to execute.
- Discarded during transaction submission due to a validation check such as insufficient gas, invalid transaction format, or incorrect key.
- Discarded after transaction submission but before attempted execution. This could be caused by timeouts or insufficient gas due to other transactions affecting the account.

The sender‚Äôs account will be charged gas for any committed transactions.

During transaction submission, the submitter is notified of successful submission or a reason for failing validations otherwise.

A transaction that is successfully submitted but ultimately discarded may have no visible state in any accessible Aptos node or within the Aptos network. A user can attempt to resubmit the same transaction to re-validate the transaction. If the submitting node believes that this transaction is still valid, it will return an error stating that an identical transaction has been submitted.

The submitter can try to increase the gas cost by a trivial amount to help make progress and adjust for whatever may have been causing the discarding of the transaction further downstream.

<Aside type="note">
  See [Aptos Blockchain Deep Dive](/network/blockchain/blockchain-deep-dive) for a comprehensive description of the Aptos transaction lifecycle.
</Aside>

### Contents of a Transaction

A signed transaction on the blockchain contains the following information:

- **Signature**: The sender uses a digital signature to verify that they signed the transaction (i.e., authentication).
- **Sender address**: The sender's [account address](/network/blockchain/accounts#account-address).
- **Sender public key**: The public authentication key that corresponds to the private authentication key used to sign the transaction.
- **Payload**: Indicates an action or set of actions Alice's behalf. In the case this is a Move function, it directly calls into Move bytecode on the chain. Alternatively, it may be Move bytecode peer-to-peer [transaction script](/network/glossary#transaction-script). It also contains a list of inputs to the function or script. For this example, it is a function call to transfer an amount of Aptos Coins from Alice account to Bob's account, where Alice's account is implied by sending the transaction and Bob's account and the amount are specified as transaction inputs.
- [**Gas unit price**](/network/glossary#gas-unit-price): The amount the sender is willing to pay per unit of gas, to execute the transaction. This is represented in [Octas](/network/glossary#octa).
- [**Maximum gas amount**](/network/glossary#maximum-gas-amount): The [maximum gas amount](/network/blockchain/gas-txn-fee#specifying-gas-fees-within-a-transaction) in APT the sender is willing to pay for this transaction. Gas charges are equal to the base gas cost covered by computation and IO multiplied by the gas price. Gas costs also include storage with an APT-fixed priced storage model. This is represented as [Octas](/network/glossary#octa).
- **Gas price** (in specified gas units): This is the amount the sender is willing to pay per unit of [gas](/network/blockchain/gas-txn-fee) to execute the transaction. [Gas](/network/blockchain/gas-txn-fee) is a way to pay for computation and storage. A gas unit is an abstract measurement of computation with no inherent real-world value.
- **Sequence number**: This is an unsigned integer that must be equal to the sender's account [sequence number](/network/blockchain/accounts#account-sequence-number) at the time of execution.
- **Expiration time**: A timestamp after which the transaction ceases to be valid (i.e., expires).

### Types of transaction payloads

Within a given transaction, the two most common types of payloads include:

- An entry point
- [A script (payload)](/build/smart-contracts/scripts)

Currently, the SDKs [Python](/build/sdks/python-sdk) and [Typescript](/build/sdks/ts-sdk) support both. This guide points out many of those entry points, such as `coin::transfer` and `aptos_account::create_account`.

All operations on the Aptos blockchain should be available via entry point calls. While one could submit multiple transactions calling entry points in series, many such operations may benefit from being called atomically from a single transaction. A script payload transaction can call any entry point or public function defined within any module.

<Aside type="note">
  See the tutorial on [Your First Transaction](/build/guides/first-transaction) for generating valid transactions.
</Aside>

<Aside type="note">
  The Aptos REST API supports generating BCS-encoded transactions from JSON. This is useful for rapid prototyping, but be cautious using it in Mainnet as this places a lot of trust on the fullnode generating the transaction.
</Aside>

## States

The Aptos blockchain's ledger state, or global state, represents the state of all accounts in the Aptos blockchain. Each validator node in the blockchain must know the latest version of the global state to execute any transaction.

Anyone can submit a transaction to the Aptos blockchain to modify the ledger state. Upon execution of a transaction, a transaction output is generated. A transaction output contains zero or more operations to manipulate the ledger state called **write sets** emitting a vector of resulting events, the amount of gas consumed, and the executed transaction status.

### Proofs

The Aptos blockchain uses proof to verify the authenticity and correctness of the blockchain data.

Data within the Aptos blockchain is replicated across the network. Each validator and fullnode's [storage](/network/blockchain/validator-nodes#storage) is responsible for persisting the agreed upon blocks of transactions and their execution results to the database.

The blockchain is represented as an ever-growing [Merkle tree](/network/glossary#merkle-trees), where each leaf appended to the tree represents a single transaction executed by the blockchain.

All operations executed by the blockchain and all account states can be verified cryptographically. These cryptographic proofs ensure that:

- The validator nodes agree on the state.
- The client does not need to trust the entity from which it is receiving data. For example, if a client fetches the last **n** transactions from an account, a proof can attest that no transactions were added, omitted or modified in the response. The client may also query for the state of an account, ask whether a specific transaction was processed, and so on.

### Versioned database

The ledger state is versioned using an unsigned 64-bit integer corresponding to the number of transactions the system has executed. This versioned database allows the validator nodes to:

- Execute a transaction against the ledger state at the latest version.
- Respond to client queries about ledger history at both current and previous versions.

## Transactions change ledger state

<ThemedImage
  alt="Signed Transaction Flow"
  sources={{
light: '~/images/transactions-and-state.svg',
dark: '~/images/transactions-and-state-dark.svg',
}}
/>

The above figure shows how executing transaction T<sub>_i_</sub> changes the state of the Aptos blockchain from S<sub>_i-1_</sub> to S<sub>_i_</sub>.

In the figure:

- Accounts **A** and **B**: Represent Alice's and Bob's accounts on the Aptos blockchain.
- **S<sub>_i-1_</sub>** : Represents the (_i-1_)-the state of the blockchain. In this state, Alice's account **A** has a balance of 110 APT (Aptos coins), and Bob's account **B** has a balance of 52 APT.
- **T<sub>_i_</sub>** : This is the _i_-th transaction executed on the blockchain. In this example, it represents Alice sending 10 APT to Bob.
- **Apply()**: This is a deterministic function that always returns the same final state for a specific initial state and a specific transaction. If the current state of the blockchain is **S<sub>_i-1_</sub>**, and transaction **T<sub>_i_</sub>** is executed on the state **S<sub>_i-1_</sub>**, then the new state of the blockchain is always **S<sub>_i_</sub>**. The Aptos blockchain uses the [Move language](/build/smart-contracts/book) to implement the deterministic execution function **Apply()**.
- **S<sub>_i_</sub>** : This is the _i_-the state of the blockchain. When the transaction **T<sub>_i_</sub>** is applied to the blockchain, it generates the new state **S<sub>_i_</sub>** (an outcome of applying **Apply(S<sub>_i-1_</sub>, T<sub>_i_</sub>)** to **S<sub>_i-1_</sub>** and **T<sub>_i_</sub>**). This causes Alice‚Äôs account balance to be reduced by 10 to 100 APT and Bob‚Äôs account balance to be increased by 10 to 62 APT. The new state **S<sub>_i_</sub>** shows these updated balances.

## Size limits

As part of the gas schedule, there are on-chain configurable limits for the sizes of [the transaction itself](https://github.com/aptos-labs/aptos-core/blob/8074588b5c9c4424fa247c2c9ec5572981ee31cd/aptos-move/aptos-gas-schedule/src/gas_schedule/transaction.rs#L71-L81) and [its outputs](https://github.com/aptos-labs/aptos-core/blob/8074588b5c9c4424fa247c2c9ec5572981ee31cd/aptos-move/aptos-gas-schedule/src/gas_schedule/transaction.rs#L152-L177).

| Limit Type             | Current Per Transaction Limit |
| ---------------------- | ----------------------------- |
| transaction            | 64KB                          |
| governance transaction | 1MB                           |
| a single write op      | 1MB                           |
| all write ops combined | 10MB                          |
| number of write ops    | 8192                          |
| a single event         | 1MB                           |
| all events combined    | 10MB                          |

# Validator Nodes Overview

> Learn about validator nodes on the Aptos blockchain, their components, and how they participate in consensus to process transactions and maintain network security.

import { Aside } from '@astrojs/starlight/components';

An Aptos node is an entity of the Aptos ecosystem that tracks the state of the Aptos blockchain. Clients interact with the blockchain via Aptos nodes. There are two types of nodes:

- Validator nodes
- [Fullnodes](/network/blockchain/fullnodes)

Each Aptos node comprises several logical components:

- [REST API service](/network/glossary#rest-api-service)
- [Mempool](#mempool)
- [Consensus (disabled in fullnodes)](#consensus)
- [Execution](#execution)
- [Virtual Machine](#virtual-machine-vm)
- [Storage](#storage)
- [State synchronizer](#state-synchronizer)

The [Aptos-core](/network/glossary#aptos-core) software can be configured to run as a validator node or as a fullnode.

## Overview

When a transaction is submitted to the Aptos blockchain, validator nodes run a distributed [consensus protocol](/network/glossary#consensus-protocol), execute the transaction, and store the transaction and the execution results on the blockchain. Validator nodes decide which transactions will be added to the blockchain and in which order.

The Aptos blockchain uses a Byzantine Fault Tolerance (BFT) consensus protocol for validator nodes to agree on the ledger of finalized transactions and their execution results. Validator nodes process these transactions and include them in their local copy of the blockchain database. This means that up-to-date validator nodes always maintain a copy of the current [state](/network/glossary#state) of the blockchain, locally.

Validator nodes communicate directly with other validator nodes over a private network. [Fullnodes](/network/blockchain/fullnodes) are an external validation and/or dissemination resource for the finalized transaction history. They receive transactions from peers and may re-execute them locally (the same way a validator executes transactions). Fullnodes store the results of re-executed transactions to local storage. In doing so, they can challenge any foul-play by validators and provide evidence if there is any attempt to re-write or modify the blockchain history. This helps to mitigate against validator corruption and/or collusion.

<Aside type="note">
  The AptosBFT consensus protocol provides fault tolerance of up to one-third of malicious validator nodes.
</Aside>

## Validator node components

![](~/images/validator.svg)

### Mempool

Mempool is a component within each node that holds an in-memory buffer of transactions that have been submitted to the blockchain, but not yet agreed upon or executed. This buffer is replicated between validator nodes and fullnodes.

The JSON-RPC service of a fullnode sends transactions to a validator node's mempool. Mempool performs various checks on the transactions to ensure transaction validity and protect against DOS attacks. When a new transaction passes initial verification and is added to mempool, it is then distributed to the mempools of other validator nodes in the network.

When a validator node temporarily becomes a leader in the consensus protocol, consensus pulls the transactions from mempool and proposes a new transaction block. This block is broadcast to other validators and contains a total ordering over all transactions in the block. Each validator then executes the block and submits votes on whether to accept the new block proposal.

### Consensus

Consensus is the component that is responsible for ordering blocks of transactions and agreeing on the results of execution by participating in the consensus protocol with other validator nodes in the network.

### Execution

Execution is the component that coordinates the execution of a block of transactions and maintains a transient state. Consensus votes on this transient state. Execution maintains an in-memory representation of the execution results until consensus commits the block to the distributed database. Execution uses the virtual machine to execute transactions. Execution acts as the glue layer between the inputs of the system (represented by transactions), storage (providing a persistency layer), and the virtual machine (for execution).

### Virtual machine (VM)

The virtual machine (VM) is used to run the Move program within each transaction and determine execution results. A node's mempool uses the VM to perform verification checks on transactions, while execution uses the VM to execute transactions.

### Storage

The storage component is used to persist agreed upon blocks of transactions and their execution results to the local database.

### State synchronizer

Nodes use their state synchronizer component to "catch up" to the latest state of the blockchain and stay up-to-date.

# Aptos Testnet Faucet ‚Äì Get Free APT for Development

> Generate free APT testnet tokens instantly with the Aptos Faucet. Ideal for testing smart contracts and building on the Aptos blockchain.

import { Faucet } from '~/components/react/Faucet';

The Aptos Testnet Faucet lets developers instantly request free APT tokens on the **Aptos testnet**.\
These tokens are for **testing purposes only** ‚Äî they hold no real-world value and cannot be exchanged for mainnet APT.

Use the faucet to:

- Deploy and test **Move smart contracts**
- Experiment with Aptos SDKs (TypeScript, Python, Rust, and more)
- Build and refine dApps before launching to mainnet

<Faucet />

## How to Use the Faucet

1. **Sign in** with your Google account.
2. **Enter your Aptos testnet wallet address**.
3. Click **Request APT** to instantly receive tokens.
4. Check your wallet balance ‚Äî tokens should appear within a few seconds.

> **Tip:** If you don‚Äôt have a testnet account, you can either [Create an Account with the Aptos TypeScript SDK](/build/sdks/ts-sdk/quickstart) (developer method) or [Install an Aptos Wallet and Switch to Testnet](https://aptosnetwork.com/ecosystem/directory/category/wallets) (UI method) to get started.

## Related Resources

- [Create an Account with the Aptos TypeScript SDK](/build/sdks/ts-sdk/quickstart)
- [Install an Aptos Wallet](https://aptosnetwork.com/ecosystem/directory/category/wallets)
- [Deploy a Smart Contract on Testnet](/build/guides/build-e2e-dapp/1-create-smart-contract)
- [Aptos CLI ‚Äì Create Test Accounts and Send Transactions](/build/cli/trying-things-on-chain/create-test-accounts)
- [Faucet API Reference](/build/apis/faucet-api)

# Aptos Glossary

> Comprehensive glossary of terms and concepts used throughout the Aptos ecosystem and documentation

## A

### Accumulator Root Hash

- An **accumulator root hash** is the root hash of
  a [Merkle accumulator](https://eprint.iacr.org/2009/625.pdf).

### Account

- An **account** in the Aptos blockchain is a container for an arbitrary number
  of [Move modules](#move-module) and [Move resources](#move-resources).
- The state of each account is composed of both code and data.
- The account is identified by [account address](#account-address).

See [Accounts](/network/blockchain/accounts) for more information.

### Account Address

- An **account address** is the address of an Aptos account.
- Account address refers to a specific destination on the Aptos network. The
  address dictates the destination and source of a specific amount of assets
  exchanged by two parties on the blockchain.
- Aptos addresses are 64-character hex string (32 bytes). Often times these
  strings are prefixed with `0x` and for first 16 addresses, the leading 0s are
  excluded (ex. `0x1`)

See [Accounts](/network/blockchain/accounts) for more information.

### API

- An **Application Programming Interface (API)** is a set of protocols and tools
  that allow users to interact with Aptos blockchain nodes and client networks
  via external applications. Aptos offers a REST API to communicate with our
  nodes.
- See [documentation](/build/apis) for more details.

### APT

**Aptos token (APT)** is the Aptos blockchain native token used for paying
network and transaction fees.

### Aptos

**Aptos** is a Layer 1 blockchain for everyone. It uses the Move programming
language and launched its mainnet on 2022-10-17 to redefine the web3 user
experience. The Aptos blockchain is dedicated to creating better user
experiences through increased speed, security, scalability, reliability and
usability with low transaction costs. The word "Aptos" means "The People" in the
Ohlone language. Learn more about the Aptos blockchain on
the [official Aptos website](https://aptosnetwork.com).

### AptosBFT

- **AptosBFT** is the Aptos protocol's BFT consensus algorithm.
- AptosBFT is based on Jolteon.

### Aptos Blockchain

- The **Aptos blockchain** is a ledger of immutable transactions agreed upon by
  the validators on the Aptos network (the network of validators).

### Aptos Name Service (ANS)

- The **Aptos Name Service (ANS)** is a decentralized naming address service for
  the Aptos blockchain. An Aptos name is a human-readable _.apt_ domain name
  that is used in place of a public key, for example _love.apt_.
- This service also allows users to register subdomain names in addition to the
  registered domain. Find out more
  at: [Aptosnames.com](https://www.aptosnames.com/)

### Aptos Core

**Aptos-core** is
the [open-source repository](https://github.com/aptos-labs/aptos-core/)
containing the code for Aptos Network software. Aptos-core contains software for

- the Aptos blockchain itself, which generates and stores the immutable ledger
  of confirmed transactions and
- the validation process, which implements the consensus algorithm to validate
  transactions and add them to the Aptos blockchain immutable ledger.

### Aptos Ecosystem

- **Aptos ecosystem** refers to various components of the Aptos blockchain
  network and their interactions. The Aptos ecosystem includes the
  community, [community-driven projects](https://aptosnetwork.com/ecosystem/directory),
  and [events](https://aptosnetwork.com/events).

### Aptos Explorer

- The **[Aptos Explorer](https://explorer.aptoslabs.com/)** is an interface that
  helps users examine details of the Aptos blockchain, including account
  information, validators, and transactions.
- The Aptos Explorer help users validate their work in Aptos wallets and other
  tools in the blockchain.

### Aptos Framework

The **Aptos Framework** defines the public API for blockchain updates and the
structure of on-chain data. It defines the business logic and access control for
the three key pillars of Aptos functionality: payments, treasury, and on-chain
governance. It is implemented as a set of modules written in the Move
programming language and stored on-chain as Move bytecode.

### Aptos Node

An **Aptos node** is a peer entity of the Aptos network that tracks the state of
the Aptos blockchain. There are two types of Aptos
nodes, [validators](#validator) and [fullnodes](#fullnodes).

### Aptos Protocol

- **Aptos protocol** is the specification of how transactions are submitted,
  ordered, executed, and recorded within the Aptos network.

### AptosAccount

- A **`AptosAccount`** is a Move resource that holds all the administrative data
  associated with an account, such as sequence number, balance, and
  authentication key.
- A **`AptosAccount`** is the only resource that every account is guaranteed to
  contain.

### AptosAccount module

- **The AptosAccount module** is a Move module that contains the code for
  manipulating the administrative data held in a particular `AptosAccount.T`
  resource.
- Code for checking or incrementing sequence numbers, withdrawing or depositing
  currency, and extracting gas deposits is included in the AptosAccount module.

### Aptos Devnet

- See [devnet](#devnet).

## B

### Blocks

- On Aptos, blocks are a batch of [transactions](#transaction) committed at the
  same time.
- Block number is analogous to "block height" in blockchain literature.
- Transactions are referenced by ledger version rather than by block.

### BlockSTM

- **BlockSTM** is the state-of-the-art dynamic parallelism execution engine developed by the Aptos Labs team.
- Dynamic parallelism allows developers to flexibly write applications without facing design constraints of statically declaring write sets of transactions.
- It has been adopted across the industry by multiple blockchains.
- More details can be found in [the blog post](https://medium.com/aptoslabs/block-stm-how-we-execute-over-160k-transactions-per-second-on-the-aptos-blockchain-3b003657e4ba) and [presentation at a16z crypto](https://www.youtube.com/watch?v=2SE5tqPzhyw)

### Byzantine (Validator)

- A **validator** that does not follow the specification of the consensus
  protocol, and wishes to compromise the correct execution of the protocol.
- BFT algorithms traditionally support up to one-third of the algorithm's voting
  power being held by Byzantine validators.

### Byzantine Fault Tolerance (BFT)

- **Byzantine Fault Tolerance** (BFT) is the ability of a distributed system to
  provide safety and liveness guarantees in the presence of faulty,
  or "[Byzantine](https://en.wikipedia.org/wiki/Byzantine_fault)," validators below a certain threshold.
- The Aptos blockchain uses AptosBFT, a consensus protocol based
  on [Jolteon](#jolteon).
- BFT algorithms typically operate with a number of entities, collectively
  holding $N$ votes (which are called "validators" in the Aptos network‚Äôs
  application of the system).
- $N$ is chosen to withstand some number of validators holding $f$ votes, which
  might be malicious.
- In this configuration, $N$ is typically set to $3f + 1$. Validators holding up to $f$
  votes will be allowed to be faulty ‚Äî offline, malicious, slow, etc. As
  long as $2f + 1$ votes are held by [honest](#honest-validator) validators, they
  will be able to reach consensus on consistent decisions.
- This implies that BFT consensus protocols can function correctly, even if up
  to one-third of the voting power is held by validators that are compromised or
  fail.

## C

### CLI

- **Command line interface** refers to the Aptos CLI used for developing on the
  Aptos blockchain, operating nodes, and debugging issues. Find out more
  at [the Aptos CLI page](/build/cli).

### Client

- **Client** is software that receives information from the blockchain and
  manages transactions. Clients interact with the blockchain through the Aptos
  nodes.

### Code Labs

- **Code labs and tutorials** depict various workflows - such as the use of the
  Aptos CLI in minting non-fungible tokens (NFTs) - in order for users to
  understand how the process works and employ related functions in their code.
  If users have the necessary funds in their accounts, they can follow the same
  code lab and tutorial steps used in devnet, testnet and mainnet networks.

### Consensus

- **Consensus** is a component of a validator.
- The consensus component is responsible for coordination and agreement amongst
  all validators on the block of transactions to be executed, their order, and
  the execution results.
- The Aptos blockchain is formed with these agreed-upon transactions and their
  corresponding execution results.
- The consensus component is accountable for achieving security, trust, and
  agreement among all validators on the Aptos blockchain.

### Consensus Protocol

- A **consensus protocol** is collectively executed by n validators to accept or
  reject a transaction and to agree on the ordering of transactions and
  execution results.
- See [BFT](#byzantine-fault-tolerance-bft).

## D

### Dapps

- **Decentralized applications (dapps)** are programs or digital applications
  that run on the Aptos blockchain autonomously. Smart contracts are commonly
  used to achieve this function.

### Devnet

- The **Aptos devnet** is a publicly deployed instance of the Aptos network that
  runs using a set of validator test nodes.
- The devnet is a demonstration of the Aptos network that is built for
  experimenting with new ideas
- The devnet simulates a digital payment system and the coins on the devnet have
  _no real world value_.
- The devnet is the network by which developers are given the opportunity to
  test given protocols. It is similar to testnet as it operates independently of
  the mainnet yet is reset weekly.

## E

### Ed25519

- **Ed25519** is our supported digital signature scheme.
- More specifically, the Aptos network uses the PureEdDSA scheme over the
  Ed25519 curve, as defined in RFC 8032.

### Epoch

- An **epoch** is the period of time between reconfigurations of the validator
  set and other administrative actions by the blockchain. On Aptos mainnet
  currently, it is every 2 hours.

### Event

- An **event** is the user-facing representation of the effects of executing a
  transaction.
- A transaction may be designed to emit any number of events as a list. For
  example, a `Coin<AptosCoin>` transfer emits a `WithdrawEvent` for the sender
  account and a `DepositEvent` for the recipient account.
- In the Aptos protocol, events provide evidence that the successful execution
  of a transaction resulted in a specific effect. The `DepositEvent` (in the
  above example) allows the recipient to confirm that a payment was received
  into their account.
- Events are persisted on the blockchain and are used to answer queries
  by [clients](#client).

### Execution

- **Execution** in the Aptos blockchain is an Aptos node component that manages
  the block of transactions. The execution component stores successful
  transactions.

### Expiration Time

A transaction ceases to be valid after its **expiration time**. If it is assumed
that:

- $Time\_C$ is the current time that is agreed upon between validators ($Time\_C$ is
  not the local time of the client);
- $Time\_E$ is the expiration time of a transaction $T\_N$; and
- $Time\_C > Time\_E$ and transaction $T\_N$ has not been included in the blockchain,
  then there is a guarantee that $T\_N$ will never be included in the blockchain.

## F

### Faucet

- The **faucet** is a service that mints APT on devnet. For testnet see the [mint page](/network/faucet).
- APT on devnet and testnet has no real world value, it is only for development purposes.
- To use a faucet, see [Faucet API](/build/apis/faucet-api).

### Fullnodes

- **Fullnodes** are clients that ensure data are stored up-to-date on the
  network. They replicate blockchain state and transactions from other fullnodes
  and validator nodes.

### Fungible Asset

- A **fungible asset** is an asset, such as a currency, share, in-game resource,
  etc., that is interchangeable with another identical asset without any loss in
  its value. For example, APT is a fungible asset because you can exchange one
  APT for another.
- Follow the [Asset Standards](/build/smart-contracts/aptos-standards#asset-standards) to create
  fungible assets on the Aptos blockchain.
- Next generation of the Coin standard that addresses shortcomings
  of `aptos_framework::coin` such as lack of guaranteed enforcement of freeze
  and burn and advanced functionalities such as programmable transfers, e.g.,
  approve in ERC-20.

### Fungible Token

- For the legacy Aptos Token Standard (aptos\_token::token), a **fungible token**
  is a token that is interchangeable with other identical tokens (i.e., tokens
  that share the same `TokenId`). This means the tokens have the
  same `creator address`, `collection name`, `token name`,
  and `property version`.
- For the Aptos Digital Asset Standard (aptos\_token\_objects::token), a \*
  _fungible token_\* is a fungible asset with metadata object that includes a
  Digital Asset resource.

### Fungible Unit

- A **fungible unit** is an individual unit of a fungible asset. These units are
  identical and interchangeable without any loss in value. For example, each
  [Octa](#octa) (the smallest unit of APT) is a fungible unit.

## G

### Gas

- **Gas** is a way to pay for computation and storage on a blockchain network.
  All transactions on the Aptos network cost a certain amount of gas.
- The gas required for a transaction depends on the size of the transaction, the
  computational cost of executing the transaction, and the amount of additional
  global state created by the transaction (e.g., if new accounts are created).
- The purpose of gas is regulating demand for the limited computational and
  storage resources of the validators, including preventing denial of service (
  DoS) attacks.

See [Gas and Storage Fees](/network/blockchain/gas-txn-fee) for more information.

### Gas Unit Price

- Each transaction specifies the **gas unit price** the sender is willing to pay
  per unit of gas.
- The price of gas required for a transaction depends on the current demand for
  usage of the network.
- Gas price is expressed in [Octas](#octa).

See [Gas and Storage Fees](/network/blockchain/gas-txn-fee) for more information.

## H

### Honest (Validator)

- **Honesty** means a validator that faithfully executes the consensus protocol
  and is not Byzantine.

## I

### Indexer

- **[Indexer](/build/indexer)** is the component of Aptos that
  retrieves, processes, and efficiently stores raw data in the database to
  provide speedy access to the Aptos blockchain state.
- At a high level, indexer gets data from a gRPC stream and runs processors to
  transform raw blockchain data and serve transformed data via GraphQL endpoint.

## J

### Jolteon

- **Jolteon** is a recent proposal for a [BFT](#byzantine-fault-tolerance-bft)
  consensus protocol.
- AptosBFT, the Aptos network's consensus algorithm, is based on Jolteon.
- It simplifies the reasoning about safety, and it addresses some performance
  limitations of previous consensus protocols. In particular, it reduces latency
  by 33% compared to HotStuff.

## L

### Leader

- A **leader** is a validator that proposes a block of transactions for the
  consensus protocol.
- In leader-based protocols, nodes must agree on a leader to make progress.
- Leaders are selected by a function that takes the
  current [round number](#round-number) as input.

## M

### Mainnet

- **Mainnet** refers to a working, fully-operational blockchain. A mainnet
  network has been fully deployed and performs the functionality of transferring
  digital currency from a sender to a recipient.

### Maximum Gas Amount

- The **Maximum Gas Amount** of a transaction is the maximum gas amount in gas
  units that the sender is ready to pay for the transaction.
- The transaction can be successfully executed only if the gas used does not
  exceed the maximum gas amount.
- The gas charged is equal to the gas price multiplied by units of gas required
  to process this transaction.
- If the transaction runs out of gas while it is being executed or the account
  runs out of balance during execution, then the sender will be charged for gas
  used and the transaction will fail.

See [Gas and Storage Fees](/network/blockchain/gas-txn-fee) for
more information.

### Mempool

- **Mempool** is one of the components of the validator. It holds an in-memory
  buffer of transactions that have been submitted but not yet agreed upon and
  executed. Mempool receives transactions from other [full nodes](#fullnodes).
- Transactions in the mempool of a validator are added from the JSON-RPC Service
  of the current node and from the mempool of other Aptos nodes.
- When the current validator is the leader, its consensus component pulls the
  transactions from its mempool and proposes the order of the transactions that
  form a block. The validator quorum then votes on the proposal.

### Merkle Trees

- **Merkle tree** is a type of authenticated data structure that allows for
  efficient verification of data integrity and updates.
- The Aptos network treats the entire blockchain as a single data structure that
  records the history of transactions and states over time.
- The [Merkle tree](https://en.wikipedia.org/wiki/Merkle_tree) implementation
  simplifies the work of apps accessing the blockchain. It allows apps to:
  - Read any data from any point in time.
  - Verify the integrity of the data using a unified framework.

### Merkle Accumulator

- The **[Merkle Accumulator](https://www.usenix.org/legacy/event/sec09/tech/full_papers/crosby.pdf)**
  is an _append-only_ Merkle tree that the Aptos blockchain uses to store the
  ledger.
- A Merkle accumulator can provide proofs that a transaction was included in the
  chain ("proof of inclusion").
- They are also called "history trees" in literature.

### Module

- A **module** in the Move programming language may either be a program or
  library that can create, transfer, or store assets.

### Move

- **Move** is a new programming language that implements all the transactions on
  the Aptos blockchain.
- It has two different kinds of code
  ‚Äî [Move scripts](#move-script)
  and [Move modules](#move-module).
- Move is a safe and secure programming language for web3 that emphasizes access
  control and scarcity. It is the programming language used to build the Aptos
  blockchain. You can read more about it
  in [Move on Aptos](/network/blockchain/move). { /* TODO add move-on-aptos landing page */}

### Move Bytecode

- Move programs are compiled into **Move bytecode**.
- Move bytecode is used to express Move scripts and Move modules.

### Move Module

- A **Move module** defines the rules for updating the global state of the Aptos
  blockchain.
- In the Aptos protocol, a Move module is a **smart contract**.
- Each user-submitted transaction includes a Move script. The Move script
  invokes procedures of one or more Move modules to update the global state of
  the blockchain according to the rules.

### Move Resources

- **Move resources** contain data that can be accessed according to the \*
  _procedures_\* declared in a Move **module.**
- Move resources can never be copied, reused, or lost. This protects Move
  programmers from accidentally or intentionally losing track of a resource.

### Move Script

- Each transaction submitted by a user includes a **Move script**.
- These transactions, also known as Move scripts, represent the operations a
  client submits to a validator.
- The operation could be a request to move coins from user A to user B, or it
  could involve interactions with published [Move modules](#move-module) (smart
  contracts).
- The Move script is an arbitrary program that interacts with resources
  published in the global storage of the Aptos blockchain by calling the
  procedures of a module. It encodes the logic for a transaction.
- A single Move script can send funds to multiple recipients and invoke
  procedures from several different modules.
- A Move script **is not** stored in the global state and cannot be invoked by
  other Move scripts. It is a single-use program.

To see example uses of Move scripts,
follow [Move scripts](/build/smart-contracts/scripts/script-tutorial).

### Move Virtual Machine (MVM)

- The **Move virtual machine** executes Move scripts written
  in [Move bytecode](#move-bytecode) to produce an execution result. This result
  is used to update the blockchain **state**.
- The virtual machine is part of a [validator](#validator).
- The Move virtual machine (MoveVM) processes each validator node that
  translates transactions along with the current blockchain ledger state to
  produce a changeset as input or storage delta as output.

## N

### Node

- A **node** is a peer entity of the Aptos network that tracks the state of the
  Aptos blockchain.
- An Aptos node consists of logical
  components. [Mempool](#mempool), [consensus](#consensus), and
  the [Move virtual machine](#move-virtual-machine-mvm) are examples of node
  components.

### Nonce

- **Nonce** is a number only used once, a random or semi-random number that is
  generated for a specific use for authentication protocols and cryptographic
  hash functions.

## O

### Octa

- An **Octa** is the smallest unit of [APT](#apt). 1 APT = 10<sup>8</sup> Octas.

### Open-Source Community

- **Open-source community** is a term used for a group of developers who work on
  open-source software. If you're reading this glossary, then you are part of
  the Aptos project's developer community.

## P

### Proof

- A **proof** is a way to verify the accuracy of data in the blockchain.
- Every operation in the Aptos blockchain can be verified cryptographically that
  it is indeed correct and that data has not been omitted.
- For example, if a user queries the information within a particular executed
  transaction, they will be provided with a cryptographic proof that the data
  returned to them is correct.

### Proof-of-Stake (PoS)

**Proof-of-Stake (PoS)** is a security mechanism that serves in confirming the
uniqueness and legitimacy of blockchain transactions. The PoS consensus
mechanism is leveraged by the Aptos blockchain powered by a network of
validators, which in turn update the system and process transactions.

## Q

### Quorum Store

- **Quorum Store** is the component that disseminates transactions (in batches) within the validator set.
- It significantly improves consensus throughput by removing the leader bottleneck.
- It decouples data dissemination from metadata ordering, allowing validators to disseminate data asynchronously in parallel.
- More details can be found in the [blog post](https://medium.com/aptoslabs/quorum-store-how-consensus-horizontally-scales-on-the-aptos-blockchain-988866f6d5b0)

## R

### Randapp

- A [dapp](#dapps) that uses randomness for its functionality.

### Resource Account

- A **resource account** is used to manage resources independent of an account
  managed by a user. For example, a developer may use a resource account to
  manage an account for module publishing, say managing a contract.

- The contract itself does not require a signer post initialization. A resource
  account gives you the means for the module to provide a signer to other
  modules and sign transactions on behalf of the module.

See [Resource accounts](/build/smart-contracts/resource-accounts) for
instructions on use.

### REST API Service

- The **REST API Service** component is the external interface of an Aptos node. Any
  incoming client request, such as submitted transactions or queries, must first
  go through the REST Service. A client needs to go through the REST Service
  component to access storage or any other component in the system. This filters
  requests and protects the system.
- Whenever a client submits a new transaction, the REST Service passes it
  to [mempool](#mempool).

### Round

- A **round** consists of achieving consensus on a block of transactions and
  their execution results.

### Round Number

- A **round number** is a shared counter used to select leaders during
  an [epoch](#epoch) of the consensus protocol.

## S

### SDKs

- Aptos **software development kits (SDKs)** are sets of tools that enable a
  developer to quickly create a custom app on the Aptos platform. Find out more
  at [Use the Aptos SDKs](/build/sdks).

### Sequence Number

- The **sequence number** for an account indicates the number of transactions
  that have been submitted and committed on chain from that account. It is
  incremented every time a transaction sent from that account is executed or
  aborted and stored in the blockchain.
- A transaction is executed only if it matches the current sequence number for
  the sender account. This helps sequence multiple transactions from the same
  sender and prevents replay attacks.
- If the current sequence number of an account A is X, then a transaction T on
  account A will only be executed if T's sequence number is X.
- These transactions will be held in mempool until they are the next sequence
  number for that account (or until they expire).
- When the transaction is applied, the sequence number of the account will
  become X+1. The account has a strictly increasing sequence number.

### Sender

- _Alternate name_: Sender address.
- **Sender** is the address that originates the transaction. A transaction must
  be signed by the sender but can have more than one signer.

### Shoal

- Method for decreasing latency for BFT protocols.
  See the [Shoal paper](https://arxiv.org/pdf/2306.03058.pdf)

### Smart Contract

- **Smart contract** refers to a computer program that automatically and
  directly carries out the contract's terms.
- See [Move Module](#move-module) for related details.

### State

- A **state** in the Aptos protocol is a snapshot of the distributed database.
- A transaction modifies the database and produces a new and updated state.

### State Root Hash

- **State root hash** is
  a [Merkle hash](https://en.wikipedia.org/wiki/Merkle_tree) over all keys and
  values the state of the Aptos blockchain at a given version.

## T

### Table

- A [**table**](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-stdlib/doc/table.md)
  implements the Table type and in Aptos is used to store information as
  key-value data within an account at large scale.

See [`table.move`](https://github.com/aptos-labs/aptos-core/blob/main/aptos-move/framework/aptos-stdlib/sources/table.move)
for the associated Aptos source file.

### Testnet

- **Testnet** describes the Aptos network that is not fully functional yet more
  stable than devnet; it is an alternative network to mainnet to be used for
  testing.

### Tokens

- **Tokens** are digital units of value issued on a blockchain. They can be
  redeemed for assets or value held. Tokens can be of the types: Fungible
  Token (FT), Non-Fungible Token (NFT), and Semi-Fungible Token (SFT).

### Transaction

- A raw **transaction** contains the following fields:
  - [Sender (account address)](#account-address)
  - [Move script](#move-script)
  - [Gas price](#gas-unit-price)
  - [Maximum gas amount](#maximum-gas-amount)
  - [Sequence number](#sequence-number)
  - [Expiration time](#expiration-time)
- A signed transaction is a raw transaction with the digital signature.
- An executed transaction changes the state of the Aptos blockchain.

### Transaction Script

- See [Move script](#move-script)

## V

### Validator

- _Alternate name_: Validators.
- A **validator** is an entity of the Aptos ecosystem that validates on the
  Aptos blockchain. It receives requests from clients and runs consensus,
  execution, and storage.
- A validator maintains the history of all the transactions on the blockchain.
- Internally, a validator needs to keep the current state, to execute
  transactions, and to calculate the next state.
- Aptos validators are in charge of verifying transactions.

### Validator Nodes

- **Validator nodes** are a unique class of fullnodes that take part in
  consensus, specifically a Byzantine Fault Tolerance (BFT) consensus protocol
  in Aptos. Validators agree upon transactions to be added to the Aptos
  blockchain as well as the order in which they are added.

### Version

- A **version** is a sequentially increasing number that increments for
  every [transaction](#transaction).
- On aptos, transactions are globally ordered and every transaction has a
  version (often called "height" in blockchain literature.)
- Transaction version 0 is the first transaction (genesis transaction), and a
  transaction version 100 is the 101st transaction in the blockchain.

## W

### Well-Formed Transaction

An Aptos transaction is **well-formed** if each of the following conditions are
true for the transaction:

- The transaction has a valid signature.
- An account exists at the sender address.
- It includes a public key, and the hash of the public key matches the sender
  account's authentication key.
- The sequence number of the transaction matches the sender account's sequence
  number.
- The sender account's balance is greater than
  the [maximum gas amount](#maximum-gas-amount).
- The expiration time of the transaction has not passed.

# Aptos Network Nodes

> Learn about validator nodes, validator fullnodes, and public fullnodes that power the Aptos network

import { CardGrid, LinkCard } from '@astrojs/starlight/components';

The Aptos network consists of three node types: validator nodes, validator fullnodes (VFNs), and public fullnodes (PFNs). To
participate in consensus, you are required to run a validator node and stake the minimum amount of utility coins. VFNs and PFNs
are not required to participate in consensus, but they are necessary to distribute blockchain data and enable ecosystem services,
e.g., indexing, querying, and RESTful API services (see [Aptos APIs](/build/apis)). VFNs can only be run by validator operators,
while PFNs can be run by anyone. You can learn more about the different types of nodes in the [Blockchain Deep Dive](/network/blockchain) section.

This section provides detailed, step-by-step instructions on how to deploy and operate Aptos nodes in different
environments. It also describes everything you need to stake and participate in consensus and governance.

## Quick Links

### Validation on Aptos

Everything you need to know about how validation, staking and governance works on Aptos.

<CardGrid>
  <LinkCard href="/network/blockchain/staking#validation-on-the-aptos-blockchain" title="How validation works" description="Validator-leader proposes and earns rewards on success." />

  <LinkCard href="/network/blockchain/staking#validator-state-and-stake-state" title="Validator states" description="Learn how a validator gets into a validator set." />
</CardGrid>

### Staking

<CardGrid>
  <LinkCard href="/network/blockchain/staking" title="Staking on Aptos" description="A comprehensive guide to how staking works on Aptos." />

  <LinkCard href="/network/blockchain/governance" title="Governance" description="Who can propose, who can vote, and how an AIP is resolved." />

  <LinkCard href="/network/nodes/validator-node/connect-nodes/staking-pool-operations" title="Owner" description="Describes the owner operations performed for staking." />

  <LinkCard href="/network/nodes/validator-node/connect-nodes/staking-pool-voter" title="Voter" description="Describes the voter operations performed for staking." />
</CardGrid>

### Validators and VFNs

A comprehensive guide to deploying nodes, staking operations and participate in consensus.

<CardGrid>
  <LinkCard href="/network/nodes/validator-node/node-requirements" title="Node requirements" description="Details the compute and storage resources you need. Read this first before anything." />

  <LinkCard href="/network/nodes/validator-node/deploy-nodes" title="Running validator node" description="In the cloud or on-premises, Docker or source, you will read step-by-step instructions here." />

  <LinkCard href="/network/nodes/validator-node/verify-nodes/node-liveness-criteria" title="Node health" description="You can verify your node health using several options." />

  <LinkCard href="/network/nodes/validator-node/connect-nodes/connect-to-aptos-network" title="Connecting to Aptos network" description="Steps to connect your nodes to an Aptos network." />

  <LinkCard href="/network/nodes/validator-node/connect-nodes/staking-pool-operations" title="Staking pool operations" description="Step-by-step guide for how to perform staking pool operations." />

  <LinkCard href="/network/nodes/validator-node/modify-nodes/shutting-down-nodes" title="Shutting down nodes" description="Leave the validator set first, and then shut down your node." />
</CardGrid>

### Public Fullnodes (PFNs)

A section with detailed, step-by-step instructions on everything related to Aptos PFNs.

<CardGrid>
  <LinkCard href="/network/nodes/full-node/deployments" title="Deploy a PFN" description="Follow this section to deploy a PFN." />

  <LinkCard href="/build/indexer/legacy/indexer-fullnode" title="Indexer PFN" description="Describes how to run an indexer PFN on the Aptos network." />
</CardGrid>

### Common Operations

<CardGrid>
  <LinkCard href="/network/nodes/localnet/local-development-network" title="Develop with localnet" description="Run a localnet for development (including validator nodes)." />

  <LinkCard href="/network/nodes/full-node/modify/update-fullnode-with-new-releases" title="Upgrade your PFN" description="Upgrade your node with new releases." />

  <LinkCard href="/network/nodes/bootstrap-fullnode/bootstrap-fullnode" title="Bootstrap from a snapshot" description="Use a snapshot to bootstrap a new node." />

  <LinkCard href="/network/nodes/bootstrap-fullnode/aptos-db-restore" title="Bootstrap from a backup" description="Use data restore to bootstrap a new node." />
</CardGrid>

# Bootstrap a Node

> Options for bootstrapping new Aptos nodes including state sync fast mode, snapshot restoration, and backup recovery for accessing ledger history.

Bootstrapping a new node usually only depends on [state sync](/network/nodes/configure/state-sync) in its fast sync mode, which synchronizes to a recent state with help from its peers and start syncing recent ledger history from there. However, if longer ledger history is needed for any reason, we have these choices:

- ### [Bootstrap from a Snapshot](/network/nodes/bootstrap-fullnode/bootstrap-fullnode)
- ### [Bootstrap from a Backup](/network/nodes/bootstrap-fullnode/aptos-db-restore)

# Bootstrap from a Backup

> Bootstrap Aptos nodes using cryptographically-proven backup files to quickly restore databases or recover historical blockchain data.

import { Aside } from '@astrojs/starlight/components';

This document describes how to bootstrap an Aptos node using a backup. This can be done on all node types, including
validators, VFNs and PFNs. Bootstrapping using a backup helps node operators achieve two goals:

1. Quickly bootstrap a database to start a new or failed node.
2. Efficiently recover data from any specific period in the blockchain's history (e.g., from genesis to a target version).

To achieve these goals, the Aptos database restore tool lets you use existing [public backup files](#public-backup-files) to restore
the database of a node. This includes the transaction history containing events, write sets, and key-value pairs. Using
the tool, you can restore transactions from any historical range, or restore the database to the latest version in the
backup. The public backup files are backed by cryptographic proofs and stored on both AWS and Google Cloud for easy
access.

## Public backup files

Aptos Labs maintains a few publicly accessible database backups by continuously querying a PFN and storing the backup
data in remote storage, such as Amazon S3 or Google Cloud Storage. The links to this backup data can be seen below:

|         | AWS Backup Data                                                                                                                                                                | Google Cloud Backup Data                                                                                                                                           |
| ------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Testnet | Discontinued                                                                                                                                                                   | [https://github.com/aptos-labs/aptos-networks/blob/main/testnet/backups/gcs.yaml](https://github.com/aptos-labs/aptos-networks/blob/main/testnet/backups/gcs.yaml) |
| Mainnet | [https://github.com/aptos-labs/aptos-networks/blob/main/mainnet/backups/s3-public.yaml](https://github.com/aptos-labs/aptos-networks/blob/main/mainnet/backups/s3-public.yaml) | [https://github.com/aptos-labs/aptos-networks/blob/main/mainnet/backups/gcs.yaml](https://github.com/aptos-labs/aptos-networks/blob/main/mainnet/backups/gcs.yaml) |

<Aside type="note">
  Backups are only created for `testnet` and `mainnet`. Given that `devnet` is wiped frequently, it is not useful to maintain backups for it.
</Aside>

The backup files consist of three types of data that can be used to reconstruct the blockchain DB:

- `epoch_ending` ‚Äì This contains the ledger\_info at the ending block of each epoch since the genesis. This data can be used to prove the epoch's provenance from the genesis and validator set of each epoch.
- `state_snapshot` ‚Äì This contains a snapshot of the blockchain's state Merkle tree (SMT) and key values at a certain version.
- `transaction` ‚Äì This contains the raw transaction metadata, payload, the executed outputs of the transaction after VM, and the cryptographic proofs of the transaction in the ledger history.

Each type of data in the backup storage is organized as follows:

- The metadata file in the metadata folder contains the range of each backup and the relative path to the backup folder.
- The backup contains a manifest file and all the actual chunked data files.

See the diagram below for a visual representation of the backup data structure:

![aptos-db-restore.png](~/images/aptos-db-restore.png)

## Restore an Aptos DB

The [Aptos CLI](/build/cli) supports two kinds of restore operations for Aptos nodes:

1. Recreating a database with a minimal transaction history at a user-specified transaction version (or the latest version offered by the backup).
2. Restoring the database over a specific period. In addition to the above, this option ensures that the
   recreated database carries the ledger history of the user-designated version range.

<Aside type="note">
  Aptos CLI 1.0.14 or newer is needed to perform these operations. Additionally, depending on whether you use AWS or
  Google Cloud, install [AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html) or
  [gsutil](https://cloud.google.com/storage/docs/gsutil_install).
</Aside>

The sections below provide examples of how to use the Aptos CLI to restore a database from a backup.

### Bootstrap to the latest version

The `aptos node bootstrap-db` command can quickly restore a database from the latest snapshot back to a target version,
but it does not restore the transaction history prior to the target version.

Use the following options to run the command:

- `target-version` ‚Äì The sync will begin from this period onwards in the transaction history (towards the latest version).
- `command-adapter-config` ‚Äì The path to one of the [YAML configuration files](#public-backup-files) that
  specifies the location of the public backup files and commands used by our backup and restore tool to interact with the remote storage.
- `target-db-dir` ‚Äì The target DB path to write the restored database.

Example command:

```shellscript filename="Terminal"
aptos node bootstrap-db \
    --target-version 500000000 \
    --command-adapter-config /path/to/s3-public.yaml \
    --target-db-dir /path/to/local/db
```

### Restore over a specific time period

The `aptos node bootstrap-db` command can restore the transaction history within a specified period, along with the state Merkle tree at the target version.

Use the following options to run the command:

- `ledger-history-start-version` ‚Äì The sync will begin from this period onwards in the transaction history (towards the target version).
- `target-version` ‚Äì The sync will end at this period in the transaction history.
- `command-adapter-config` ‚Äì The path to one of the [YAML configuration files](#public-backup-files) that specifies the location of the public backup files and commands used by our backup and restore tool to interact with the remote storage.
- `target-db-dir` ‚Äì The target DB path to write the restored database.

Example command:

```shellscript filename="Terminal"
aptos node bootstrap-db \
    --ledger-history-start-version 150000000 \
    --target-version 155000000
    --command-adapter-config /path/to/s3-public.yaml \
    --target-db-dir /path/to/local/db
```

### Restore a full history from genesis

To restore an Aptos node with the full history from genesis, set `ledger-history-start-version` to 0 and
disable the pruner by following the instructions in the [disabling the ledger pruner](/network/nodes/configure/data-pruning) section before
starting the node. Note: performing a full history restore requires a significant amount of resources and time.
See the resource requirements below.

- **Open File Limit**: Set the open file limit >= 999999, e.g., using `ulimit -n 1048576`.

If you are restoring a node, you will need the following resources:

|         | Disk   | RAM   |
| ------- | ------ | ----- |
| Testnet | 1.5 TB | 32 GB |
| Mainnet | 1 TB   | 32 GB |

Example command:

```shellscript filename="Terminal"
aptos node bootstrap-db \
  --ledger-history-start-version 0 \
  --target-version use_the_largest_version_in_backup \
  --command-adapter-config /path/to/s3-public.yaml \
  --target-db-dir /path/to/local/db
```

<Aside type="note">
  If you don't specify the target\_version (via `--target-version`), the tool will use the latest version in the backup as the target version.
</Aside>

# Bootstrap from a Snapshot

> Quickly bootstrap Aptos validator, VFN, or PFN nodes using community-provided snapshots to avoid slow state sync processes.

import { Aside } from '@astrojs/starlight/components';

This document describes how to bootstrap an Aptos node quickly using a snapshot. This can be done on all node types,
including validators, VFNs and PFNs.

<Aside type="caution">
  **Indexer snapshots**<br />
  The snapshots provided by the community do not provide indexer support. If you are bootstrapping an indexer node,
  you will need to do so by using a [backup](/network/nodes/bootstrap-fullnode/aptos-db-restore).
</Aside>

Although you can bootstrap a new node using [state sync](/network/nodes/configure/state-sync), this might not be the fastest approach after the network
has been running for a while; it can either take too much time, or it won't be able to fetch all the required data since
other nodes may have already pruned their ledger history. To avoid this, you can bootstrap your node using an
existing snapshot, which is simply a copy of the storage data of an existing node.

<Aside type="caution">
  **Mainnet snapshots**<br />
  It is not recommended to use snapshots for bootstrapping nodes in **mainnet**. This is because snapshots
  are not verified by the Aptos software. As a result, the snapshot may be invalid or contain incorrect data. To prevent
  security concerns, we recommend using snapshots only in test environments, e.g., **devnet** and **testnet**.

  If you must bootstrap a node using a **mainnet** snapshot, you should either generate the snapshot yourself
  or obtain it from a trusted source. You should also verify the snapshot's integrity and authenticity before using it
  (e.g., via cryptographic signatures and checksums).
</Aside>

## Find an existing snapshot

There are a number of snapshots that can be downloaded from different Aptos community members. These include:

- BWareLabs (Testnet and Mainnet): [BWareLabs Aptos Node Snapshots](https://bwarelabs.com/snapshots/aptos)

<Aside type="note">
  **Questions about snapshot data** <br />
  Depending on how the snapshot is constructed and compressed, the snapshot files may be different sizes. If you have any
  questions about the snapshot data, or run into any issues, please reach out to the Aptos community members directly
  via the [#node-support](https://discord.com/channels/945856774056083548/953421979136962560) channel in [Aptos Discord](https://discord.gg/aptosnetwork).
</Aside>

## Use a snapshot

To use a snapshot, simply download and copy the files to the location of the storage database for your node.
This location can be found and updated in the fullnode `yaml` configuration file under `data_dir`.
See the example tutorial ([Run a PFN](/network/nodes/full-node/deployments)) for how to configure the data directory.

# Building Aptos From Source

> Complete guide to building Aptos Core from source code including environment setup, dependencies installation, and build instructions for Linux, macOS, and Windows.

import { Aside, TabItem, Tabs } from '@astrojs/starlight/components';

[CLI Binary releases are available](/build/cli), but if you
want to build from source for an Aptos node or CLI, this is how.

## Supported operating systems

Aptos can be built on various operating systems, including Linux, macOS. and
Windows. Aptos is tested extensively on Linux and macOS, and less so on Windows.
Here are the versions we use:

- Linux - Ubuntu version 20.04 and 22.04
- macOS - macOS Monterey and later
- Microsoft Windows - Windows 10, 11 and Windows Server 2022+

## Clone the Aptos-core repo

1. Install [Git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git).
   Git is required to clone the aptos-core repo, and will need to be installed
   prior to continuing. You can install it with the instructions on the official
   [Git website](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git).

2. Clone the Aptos repository. To clone the Aptos repository (repo), you first
   need to open a command line prompt (Terminal on macOS / Linux, PowerShell on
   Windows). Then run the following command to clone the Git repository from GitHub.

   ```shellscript filename="Terminal"
   git clone https://github.com/aptos-labs/aptos-core.git
   ```

3. Now let's go into the newly created directory `aptos-core` by _changing directory_ or `cd`ing into it:
   ```shellscript filename="Terminal"
   cd aptos-core
   ```

### (Optional) Check out release branch

Optionally, check out a release branch to install an Aptos node.
We suggest you check out `devnet` for your first development.
See [Choose a network](/network/nodes/networks) for an
explanation of their differences.

<details>
  <summary>Release Branches</summary>

  <Tabs>
    <TabItem label="Devnet">
      ```shellscript filename="Terminal"
      git checkout --track origin/devnet
      ```
    </TabItem>

    <TabItem label="Testnet">
      ```shellscript filename="Terminal"
      git checkout --track origin/testnet
      ```
    </TabItem>

    <TabItem label="Mainnet">
      ```shellscript filename="Terminal"
      git checkout --track origin/mainnet
      ```
    </TabItem>
  </Tabs>
</details>

## Set up build dependencies

Prepare your developer environment by installing the dependencies needed to build, test and inspect Aptos Core.
No matter your selected mechanism for installing these dependencies, **it is imperative you keep your entire toolchain up-to-date**.
If you encounter issues later, update all packages and try again.

<details>
  <summary>macOS</summary>

  **> Using the automated script**

  1. Ensure you have `brew` package manager installed: [https://brew.sh/](https://brew.sh/)
  2. Run the dev setup script to prepare your environment:

  ```shellscript filename="Terminal"
  ./scripts/dev_setup.sh
  ```

  3. Update your current shell environment:

  ```shellscript filename="Terminal"
  source ~/.cargo/env
  ```

  <Aside type="note">
    You can see the available options for the script by running

    ```shellscript filename="Terminal"
    ./scripts/dev_setup.sh --help
    ```
  </Aside>

  **> Manual installation of dependencies**

  If the script above doesn't work for you, you can install these manually, but it's **not recommended**.

  1. [Rust](https://www.rust-lang.org/tools/install)
  2. [CMake](https://cmake.org/download/)
  3. [LLVM](https://releases.llvm.org/)
  4. [LLD](https://lld.llvm.org/)
</details>

<details>
  <summary>Linux</summary>

  **> Using the automated script**

  1. Run the dev setup script to prepare your environment:

  ```shellscript filename="Terminal"
  ./scripts/dev_setup.sh
  ```

  2. Update your current shell environment:

  ```shellscript filename="Terminal"
  source ~/.cargo/env
  ```

  <Aside type="note">
    You can see the available options for the script by running

    ```shellscript filename="Terminal"
    ./scripts/dev_setup.sh --help
    ```
  </Aside>

  **> Manual installation of dependencies**

  If the script above does not work for you, you can install these manually, but it is **not recommended**:

  1. [Rust](https://www.rust-lang.org/tools/install).
  2. [CMake](https://cmake.org/download/).
  3. [LLVM](https://releases.llvm.org/).
  4. [libssl-dev](https://packages.ubuntu.com/jammy/libssl-dev) and [libclang-dev](https://packages.ubuntu.com/jammy/libclang-dev)
</details>

<details>
  <summary>Windows</summary>

  **> Using the automated script**

  1. Open a PowerShell terminal as an administrator.
  2. Run the dev setup script to prepare your environment:

  ```powershell filename="Terminal"
  PowerShell -ExecutionPolicy Bypass -File ./scripts/windows_dev_setup.ps1
  ```

  3. Open a new PowerShell terminal after installing all dependencies

  **> Manual installation of dependencies**

  1. Install [Rust](https://www.rust-lang.org/tools/install).
  2. Install [LLVM](https://releases.llvm.org/). Visit their GitHub repository for the [latest prebuilt release](https://github.com/llvm/llvm-project/releases/tag/llvmorg-15.0.7).
  3. Install [Microsoft Visual Studio Build Tools for Windows](https://visualstudio.microsoft.com/downloads/#build-tools-for-visual-studio-2022). During setup, select "Desktop development with C++" and three additional options: MSVC C++ build tools, Windows 10/11 SDK, and C++ CMake tools for Windows.
  4. If on Windows ARM, install [Visual Studio](https://visualstudio.microsoft.com/vs).
  5. If not already installed during Visual Studio/Build Tools installation, install [CMake](https://cmake.org/download/).
  6. Open a new PowerShell terminal after installing all dependencies
</details>

### Additional Tools

If you used `scripts/dev_setup.sh` for macOS or Linux setup, additional tools are optionally available.

## Building Aptos

The simplest check that you have a working environment is to build everything and run the tests.

```shellscript filename="Terminal"
cargo build
cargo test -- --skip prover
```

If you have already installed the Move Prover Tools above then you don't need to
skip the prover tests.  To install the prover (optional), follow the [Prover guide](/build/smart-contracts/prover)

Other documentation of specific tools has recommended patterns for `cargo build` and `cargo run`

### Other resources

- [Run a Local Development Network](/network/nodes/localnet/local-development-network)
- [Indexer](/build/indexer)
- [Node Health Checker](/network/nodes/measure/node-health-checker)

# Configure a Node

> Understanding and configuring Aptos node internals including consensus observer, state sync, data pruning, telemetry, and node files.

This section contains tutorials for understanding and configuring Aptos node internals. These include:

- ### [Consensus Observer](/network/nodes/configure/consensus-observer)
- ### [State Synchronization](/network/nodes/configure/state-sync)
- ### [Data Pruning](/network/nodes/configure/data-pruning)
- ### [Telemetry](/network/nodes/configure/telemetry)
- ### [Locating Node Files](/network/nodes/configure/node-files-all-networks)

# Consensus Observer

> Configure consensus observer to reduce block synchronization time and transaction latencies for public fullnodes (PFNs) by 10-50%.

import { Aside } from '@astrojs/starlight/components';

Consensus observer is a new data dissemination technique that reduces block synchronization time, and
transaction latencies for Aptos fullnodes (i.e., VFNs and PFNs). It has been shown to reduce end-to-end
transaction latencies in Mainnet by 10% to 50%, depending on the load (i.e., transactions per second).

More information on consensus observer can be found in the AIP: [AIP-93: Consensus Observer](https://github.com/aptos-foundation/AIPs/blob/main/aips/aip-93.md).

<Aside type="tip">
  **Public Fullnodes (PFNs)**<br />
  The configuration settings described in this document are for public fullnodes (PFNs) only.
  Consensus observer has already been enabled (by default) for validators and validator fullnodes (VFNs).
  It is not recommended to change the consensus observer configurations for validators and VFNs.
</Aside>

## Configure consensus observer

<Aside type="caution" emoji="‚ùó">
  **Minimum Hardware Requirements**<br />
  Consensus observer is not enabled on PFNs (by default) because it requires nodes to meet the
  [minimum hardware requirements](/network/nodes/full-node/pfn-requirements#hardware-requirements).
  If your node is under-provisioned and does not meet these requirements, enabling consensus observer
  will result in degraded performance because it requires more CPU than traditional state sync. Only
  enable consensus observer if your node meets the minimum hardware requirements.
</Aside>

### Enable consensus observer

To enable consensus observer on your PFN, add the following to your node configuration file:

```yaml filename="fullnode.yaml"
consensus:
  enable_pre_commit: false

consensus_observer:
  observer_enabled: true
  publisher_enabled: true
```

### Disable consensus observer

To disable consensus observer on your PFN, add the following to your node configuration file:

```yaml filename="fullnode.yaml"
consensus:
  enable_pre_commit: true

consensus_observer:
  observer_enabled: false
  publisher_enabled: false
```

# Data Pruning

> Configure blockchain data pruning on Aptos nodes to manage storage space by controlling ledger history retention with customizable pruning windows.

import { Aside } from '@astrojs/starlight/components';

All Aptos nodes (e.g., validators, VFNs and PFNs) process transactions and commit new data to the blockchain.
As the blockchain grows (indefinitely), nodes can manage the amount of storage disk space required by pruning old
blockchain data. To achieve this, Aptos nodes prune the blockchain **ledger history** in their database, which
contains the history of all transactions. The ledger history may be **complete** (e.g., if you're operating an archival
node), or **pruned** to a certain window of transactions (to reduce storage requirements).

By default, ledger pruning is enabled on all nodes, and the pruning window can be configured. This document
describes how you can configure the behavior of the ledger pruner.

<Aside type="tip">
  **Default pruning window**<br />
  The default configuration of the ledger pruner is to keep only the most recent 150 million transactions.
  Almost all Aptos nodes in Mainnet and Testnet use the default configuration. If you wish to run an archival
  node, follow the instructions [here](/network/nodes/configure/state-sync#archival-pfns).
</Aside>

## Disable the ledger pruner

If you wish to disable the ledger pruner entirely, you can do so by adding the following to your node
configuration file.

```yaml filename="fullnode.yaml"
storage:
  storage_pruner_config:
    ledger_pruner_config:
      enable: false
```

<Aside type="danger">
  **Unbounded storage growth**<br />
  Be warned that disabling the ledger pruner will result in unbounded storage growth. This can
  lead to the storage disk filling up very quickly. Disabling the ledger pruner is not recommended.
</Aside>

## Configure the ledger pruner

You can configure the size of the ledger pruning window (i.e., the number of most recent transactions
to retain in storage). To do this, add the following to your node configuration file.

```yaml filename="fullnode.yaml"
storage:
  storage_pruner_config:
    ledger_pruner_config:
      prune_window: 100000000 # 100 million transactions
```

<Aside type="caution">
  **Minimum pruning window**<br />
  Setting the pruning window smaller than 100 million transactions can lead to runtime errors and damage the
  health of the node.
</Aside>

# Locating Node Files

> Find and download required configuration files, genesis blobs, and waypoints for deploying Aptos nodes on mainnet, testnet, and devnet networks.

This section contains pages for locating and downloading the files required to deploy an Aptos node
on different networks. These include:

- ### [Files For Mainnet](/network/nodes/configure/node-files-all-networks/node-files-mainnet)
- ### [Files For Testnet](/network/nodes/configure/node-files-all-networks/node-files-testnet)
- ### [Files For Devnet](/network/nodes/configure/node-files-all-networks/node-files-devnet)

# Files For Devnet

> Download required configuration files, genesis blob, waypoint, and Docker compose files for deploying Aptos nodes on devnet.

import { Aside } from '@astrojs/starlight/components';

When deploying an Aptos node in **devnet**, you may need to download the files listed on this page. The files are
organized by node type.

<Aside type="note">
  **File access**<br />
  Depending on the type of node you are deploying, and the deployment method, you may need to download some
  or all of the files listed below.
</Aside>

## Validator Files

All the files listed below are for validator nodes.

### docker-compose.yaml

- **Git repo:** `aptos-core`
- **Git branch:** `devnet` on [https://github.com/aptos-labs/aptos-core](https://github.com/aptos-labs/aptos-core)
- **Command to download:**
  ```shellscript filename="Terminal"
  wget -O docker-compose.yaml https://raw.githubusercontent.com/aptos-labs/aptos-core/devnet/docker/compose/aptos-node/docker-compose.yaml
  ```

### validator.yaml

- **Git repo:** `aptos-core`
- **Git branch:** `devnet` on [https://github.com/aptos-labs/aptos-core](https://github.com/aptos-labs/aptos-core)
- **Command to download:**
  ```shellscript filename="Terminal"
  wget -O validator.yaml https://raw.githubusercontent.com/aptos-labs/aptos-core/devnet/docker/compose/aptos-node/validator.yaml
  ```

### genesis.blob

- **Git repo:** `aptos-networks`
- **Git branch:** `main` on [https://github.com/aptos-labs/aptos-networks](https://github.com/aptos-labs/aptos-networks)
- **Command to download:**
  ```shellscript filename="Terminal"
  wget -O genesis.blob https://raw.githubusercontent.com/aptos-labs/aptos-networks/main/devnet/genesis.blob
  ```

### waypoint.txt

- **Git repo:** `aptos-networks`
- **Git branch:** `main` on [https://github.com/aptos-labs/aptos-networks](https://github.com/aptos-labs/aptos-networks)
- **Command to download:**
  ```shellscript filename="Terminal"
  wget -O waypoint.txt https://raw.githubusercontent.com/aptos-labs/aptos-networks/main/devnet/waypoint.txt
  ```

### docker-compose-src.yaml

- **Git repo:** `aptos-core`
- **Git branch:** `devnet` on [https://github.com/aptos-labs/aptos-core](https://github.com/aptos-labs/aptos-core)
- **Command to download:**
  ```shellscript filename="Terminal"
  wget -O docker-compose-src.yaml https://raw.githubusercontent.com/aptos-labs/aptos-core/devnet/docker/compose/aptos-node/docker-compose-src.yaml
  ```

### haproxy.cfg

- **Git repo:** `aptos-core`
- **Git branch:** `devnet` on [https://github.com/aptos-labs/aptos-core](https://github.com/aptos-labs/aptos-core)
- **Command to download:**
  ```shellscript filename="Terminal"
  wget -O haproxy.cfg https://raw.githubusercontent.com/aptos-labs/aptos-core/devnet/docker/compose/aptos-node/haproxy.cfg
  ```

### blocked.ips

- **Git repo:** `aptos-core`
- **Git branch:** `devnet` on [https://github.com/aptos-labs/aptos-core](https://github.com/aptos-labs/aptos-core)
- **Command to download:**
  ```shellscript filename="Terminal"
  wget -O blocked.ips https://raw.githubusercontent.com/aptos-labs/aptos-core/devnet/docker/compose/aptos-node/blocked.ips
  ```

## VFN or PFN files

The files listed below are for VFNs or PFNs.

### docker-compose-fullnode.yaml

- **Git repo:** `aptos-core`
- **Git branch:** `devnet` on [https://github.com/aptos-labs/aptos-core](https://github.com/aptos-labs/aptos-core)
- **Command to download:**
  ```shellscript filename="Terminal"
  wget -O docker-compose-fullnode.yaml https://raw.githubusercontent.com/aptos-labs/aptos-core/devnet/docker/compose/aptos-node/docker-compose-fullnode.yaml
  ```

### fullnode.yaml

- **Git repo:** `aptos-core`
- **Git branch:** `devnet` on [https://github.com/aptos-labs/aptos-core](https://github.com/aptos-labs/aptos-core)
- **Command to download:**
  ```shellscript filename="Terminal"
  wget -O fullnode.yaml https://raw.githubusercontent.com/aptos-labs/aptos-core/devnet/docker/compose/aptos-node/fullnode.yaml
  ```

### haproxy-fullnode.cfg

- **Git repo:** `aptos-core`
- **Git branch:** `devnet` on [https://github.com/aptos-labs/aptos-core](https://github.com/aptos-labs/aptos-core)
- **Command to download:**
  ```shellscript filename="Terminal"
  wget -O haproxy-fullnode.cfg https://raw.githubusercontent.com/aptos-labs/aptos-core/devnet/docker/compose/aptos-node/haproxy-fullnode.cfg
  ```

# Files For Mainnet

> Download required configuration files, genesis blob, waypoint, and Docker compose files for deploying Aptos nodes on mainnet.

import { Aside } from '@astrojs/starlight/components';

When deploying an Aptos node in **mainnet**, you may need to download the files listed on this page. The files are
organized by node type.

<Aside type="note">
  **File access**<br />
  Depending on the type of node you are deploying, and the deployment method, you may need to download some
  or all of the files listed below.
</Aside>

## Validator Files

All the files listed below are for validator nodes.

### docker-compose.yaml

- **Git repo:** `aptos-core`
- **Git branch:** `mainnet` on [https://github.com/aptos-labs/aptos-core](https://github.com/aptos-labs/aptos-core)
- **Command to download:**
  ```shellscript filename="Terminal"
  wget -O docker-compose.yaml https://raw.githubusercontent.com/aptos-labs/aptos-core/mainnet/docker/compose/aptos-node/docker-compose.yaml
  ```

### validator.yaml

- **Git repo:** `aptos-core`
- **Git branch:** `mainnet` on [https://github.com/aptos-labs/aptos-core](https://github.com/aptos-labs/aptos-core)
- **Command to download:**
  ```shellscript filename="Terminal"
  wget -O validator.yaml https://raw.githubusercontent.com/aptos-labs/aptos-core/mainnet/docker/compose/aptos-node/validator.yaml
  ```

### genesis.blob

- **Git repo:** `aptos-networks`
- **Git branch:** `main` on [https://github.com/aptos-labs/aptos-networks](https://github.com/aptos-labs/aptos-networks)
- **Command to download:**
  ```shellscript filename="Terminal"
  wget -O genesis.blob https://raw.githubusercontent.com/aptos-labs/aptos-networks/main/mainnet/genesis.blob
  ```

### waypoint.txt

- **Git repo:** `aptos-networks`
- **Git branch:** `main` on [https://github.com/aptos-labs/aptos-networks](https://github.com/aptos-labs/aptos-networks)
- **Command to download:**
  ```shellscript filename="Terminal"
  wget -O waypoint.txt https://raw.githubusercontent.com/aptos-labs/aptos-networks/main/mainnet/waypoint.txt
  ```

### docker-compose-src.yaml

- **Git repo:** `aptos-core`
- **Git branch:** `mainnet` on [https://github.com/aptos-labs/aptos-core](https://github.com/aptos-labs/aptos-core)
- **Command to download:**
  ```shellscript filename="Terminal"
  wget -O docker-compose-src.yaml https://raw.githubusercontent.com/aptos-labs/aptos-core/mainnet/docker/compose/aptos-node/docker-compose-src.yaml
  ```

### haproxy.cfg

- **Git repo:** `aptos-core`
- **Git branch:** `mainnet` on [https://github.com/aptos-labs/aptos-core](https://github.com/aptos-labs/aptos-core)
- **Command to download:**
  ```shellscript filename="Terminal"
  wget -O haproxy.cfg https://raw.githubusercontent.com/aptos-labs/aptos-core/mainnet/docker/compose/aptos-node/haproxy.cfg
  ```

### blocked.ips

- **Git repo:** `aptos-core`
- **Git branch:** `mainnet` on [https://github.com/aptos-labs/aptos-core](https://github.com/aptos-labs/aptos-core)
- **Command to download:**
  ```shellscript filename="Terminal"
  wget -O blocked.ips https://raw.githubusercontent.com/aptos-labs/aptos-core/mainnet/docker/compose/aptos-node/blocked.ips
  ```

***

## VFN or PFN files

The files listed below are for VFNs or PFNs.

### docker-compose-fullnode.yaml

- **Git repo:** `aptos-core`
- **Git branch:** `mainnet` on [https://github.com/aptos-labs/aptos-core](https://github.com/aptos-labs/aptos-core)
- **Command to download:**
  ```shellscript filename="Terminal"
  wget -O docker-compose-fullnode.yaml https://raw.githubusercontent.com/aptos-labs/aptos-core/mainnet/docker/compose/aptos-node/docker-compose-fullnode.yaml
  ```

### fullnode.yaml

- **Git repo:** `aptos-core`
- **Git branch:** `mainnet` on [https://github.com/aptos-labs/aptos-core](https://github.com/aptos-labs/aptos-core)
- **Command to download:**
  ```shellscript filename="Terminal"
  wget -O fullnode.yaml https://raw.githubusercontent.com/aptos-labs/aptos-core/mainnet/docker/compose/aptos-node/fullnode.yaml
  ```

### haproxy-fullnode.cfg

- **Git repo:** `aptos-core`
- **Git branch:** `mainnet` on [https://github.com/aptos-labs/aptos-core](https://github.com/aptos-labs/aptos-core)
- **Command to download:**
  ```shellscript filename="Terminal"
  wget -O haproxy-fullnode.cfg https://raw.githubusercontent.com/aptos-labs/aptos-core/mainnet/docker/compose/aptos-node/haproxy-fullnode.cfg
  ```

# Files For Testnet

> Download required configuration files, genesis blob, waypoint, and Docker compose files for deploying Aptos nodes on testnet.

import { Aside } from '@astrojs/starlight/components';

When deploying an Aptos node in **testnet**, you may need to download the files listed on this page. The files are
organized by node type.

<Aside type="note">
  **File access**
  Depending on the type of node you are deploying, and the deployment method, you may need to download some
  or all of the files listed below.
</Aside>

## Validator Files

All the files listed below are for validator nodes.

### docker-compose.yaml

- **Git repo:** `aptos-core`
- **Git branch:** `testnet` on [https://github.com/aptos-labs/aptos-core](https://github.com/aptos-labs/aptos-core)
- **Command to download:**
  ```shellscript filename="Terminal"
  wget -O docker-compose.yaml https://raw.githubusercontent.com/aptos-labs/aptos-core/testnet/docker/compose/aptos-node/docker-compose.yaml
  ```

### validator.yaml

- **Git repo:** `aptos-core`
- **Git branch:** `testnet` on [https://github.com/aptos-labs/aptos-core](https://github.com/aptos-labs/aptos-core)
- **Command to download:**
  ```shellscript filename="Terminal"
  wget -O validator.yaml https://raw.githubusercontent.com/aptos-labs/aptos-core/testnet/docker/compose/aptos-node/validator.yaml
  ```

### genesis.blob

- **Git repo:** `aptos-networks`
- **Git branch:** `main` on [https://github.com/aptos-labs/aptos-networks](https://github.com/aptos-labs/aptos-networks)
- **Command to download:**
  ```shellscript filename="Terminal"
  wget -O genesis.blob https://raw.githubusercontent.com/aptos-labs/aptos-networks/main/testnet/genesis.blob
  ```

### waypoint.txt

- **Git repo:** `aptos-networks`
- **Git branch:** `main` on [https://github.com/aptos-labs/aptos-networks](https://github.com/aptos-labs/aptos-networks)
- **Command to download:**
  ```shellscript filename="Terminal"
  wget -O waypoint.txt https://raw.githubusercontent.com/aptos-labs/aptos-networks/main/testnet/waypoint.txt
  ```

### docker-compose-src.yaml

- **Git repo:** `aptos-core`
- **Git branch:** `testnet` on [https://github.com/aptos-labs/aptos-core](https://github.com/aptos-labs/aptos-core)
- **Command to download:**
  ```shellscript filename="Terminal"
  wget -O docker-compose-src.yaml https://raw.githubusercontent.com/aptos-labs/aptos-core/testnet/docker/compose/aptos-node/docker-compose-src.yaml
  ```

### haproxy.cfg

- **Git repo:** `aptos-core`
- **Git branch:** `testnet` on [https://github.com/aptos-labs/aptos-core](https://github.com/aptos-labs/aptos-core)
- **Command to download:**
  ```shellscript filename="Terminal"
  wget -O haproxy.cfg https://raw.githubusercontent.com/aptos-labs/aptos-core/testnet/docker/compose/aptos-node/haproxy.cfg
  ```

### blocked.ips

- **Git repo:** `aptos-core`
- **Git branch:** `testnet` on [https://github.com/aptos-labs/aptos-core](https://github.com/aptos-labs/aptos-core)
- **Command to download:**
  ```shellscript filename="Terminal"
  wget -O blocked.ips https://raw.githubusercontent.com/aptos-labs/aptos-core/testnet/docker/compose/aptos-node/blocked.ips
  ```

## VFN or PFN files

The files listed below are for VFNs or PFNs.

## docker-compose-fullnode.yaml

- **Git repo:** `aptos-core`
- **Git branch:** `testnet` on [https://github.com/aptos-labs/aptos-core](https://github.com/aptos-labs/aptos-core)
- **Command to download:**
  ```shellscript filename="Terminal"
  wget -O docker-compose-fullnode.yaml https://raw.githubusercontent.com/aptos-labs/aptos-core/testnet/docker/compose/aptos-node/docker-compose-fullnode.yaml
  ```

## fullnode.yaml

- **Git repo:** `aptos-core`
- **Git branch:** `testnet` on [https://github.com/aptos-labs/aptos-core](https://github.com/aptos-labs/aptos-core)
- **Command to download:**
  ```shellscript filename="Terminal"
  wget -O fullnode.yaml https://raw.githubusercontent.com/aptos-labs/aptos-core/testnet/docker/compose/aptos-node/fullnode.yaml
  ```

## haproxy-fullnode.cfg

- **Git repo:** `aptos-core`
- **Git branch:** `testnet` on [https://github.com/aptos-labs/aptos-core](https://github.com/aptos-labs/aptos-core)
- **Command to download:**
  ```shellscript filename="Terminal"
  wget -O haproxy-fullnode.cfg https://raw.githubusercontent.com/aptos-labs/aptos-core/testnet/docker/compose/aptos-node/haproxy-fullnode.cfg
  ```

# State Synchronization

> Learn how state synchronization keeps Aptos nodes updated with the latest blockchain state including configuration options and syncing modes.

import { Aside } from '@astrojs/starlight/components';

Nodes in an Aptos network (e.g., validators, VFNs and PFNs) must always be synchronized to the latest blockchain state.
The [state synchronization](https://medium.com/aptoslabs/the-evolution-of-state-sync-the-path-to-100k-transactions-per-second-with-sub-second-latency-at-52e25a2c6f10) (state sync) component that runs on each node is responsible for this. State sync
identifies and fetches new blockchain data from peers, validates the data and persists it to local storage. This
document explains how to configure state sync on your node.

## State sync

At a high-level, state sync operates in two phases. First, nodes bootstrap on startup (in the **bootstrapping phase**).
This allows the node to catch up to the latest state in the Aptos blockchain. Then, the node will stay up-to-date with the blockchain
by continuously syncing (in the **continuous syncing phase**).

<Aside type="tip">
  **Need to start a node quickly? Here's what we recommend:**<br />

  - **Mainnet**: To sync the entire blockchain history, restore from a [backup](/network/nodes/bootstrap-fullnode/aptos-db-restore). Otherwise, use [fast sync](/network/nodes/configure/state-sync#fast-syncing).
  - **Testnet**: To sync the entire blockchain history, restore from a [backup](/network/nodes/bootstrap-fullnode/aptos-db-restore). Otherwise, use [fast sync](/network/nodes/configure/state-sync#fast-syncing).
  - **Devnet**: To sync the entire blockchain history, use [intelligent syncing](/network/nodes/configure/state-sync#intelligent-syncing). Otherwise, use [fast sync](/network/nodes/configure/state-sync#fast-syncing).
</Aside>

### Bootstrapping modes

When the node starts, state sync will perform bootstrapping using the configured bootstrapping mode.

<Aside type="tip">
  **Default bootstrapping modes?** <br />

  - **Mainnet and Testnet**: The default bootstrapping mode is **fast syncing**, because these networks are long-lived
    and have a large amount of historical data.
  - **Devnet**: The default bootstrapping mode is **intelligent syncing from genesis**, because this network is
    short-lived and typically has a small amount of historical data.
</Aside>

There are several bootstrapping modes:

- **Execute transactions from genesis**. This mode will fetch all transactions since genesis (i.e., the
  start of the blockchain's history), and re-execute each transaction. This mode is the slowest bootstrapping mode.
- **Apply transaction outputs from genesis**. This mode will fetch all transactions since genesis (i.e., the start of
  the blockchain's history), but it will skip transaction re-execution and instead apply the outputs of the
  transactions as originally produced by validator execution.
- **Intelligent syncing from genesis**. This mode is a hybrid of the previous two modes. It will fetch all transactions
  since genesis (i.e., the start of the blockchain's history), and will either execute the transactions, or apply the
  transaction outputs, depending on whichever is faster, per data chunk. This allows the node to adapt to CPU and network
  resource constraints more efficiently.
- **Fast syncing**. This mode will fetch the latest blockchain state directly, skipping all historical transactions.
  As a result, the node will not have historical transaction data, but it will be able to catch up much more quickly.

<Aside type="caution">
  **Syncing from genesis?** <br />
  Most nodes in Mainnet and Testnet do not keep all transaction data since genesis. If you wish to sync all
  data since genesis, you need to manually add seed peers to node's configuration file, so
  that your node can connect to peers with the data. See [Connecting to Seed Peers](/network/nodes/full-node/modify/fullnode-network-connections#connecting-to-seed-peers).
</Aside>

### Continuous syncing modes

After the node has bootstrapped, state sync will move into the continuous syncing phase to stay up-to-date with the
blockchain.

<Aside type="tip">
  **Default continuous syncing modes?**<br />
  The default continuous syncing mode is always intelligent syncing, because this mode is the most performant.
</Aside>

There are several continuous syncing modes:

- **Executing transactions**. This mode will keep the node up-to-date by executing transactions as they are
  committed to the blockchain.
- **Applying transaction outputs**. This mode will keep the node up-to-date by skipping the transaction execution
  and only applying the outputs of the transactions as previously produced by validator execution.
- **Intelligent syncing**. This mode will keep the node up-to-date by either executing the transactions, or applying
  the transaction outputs, depending on whichever is faster, per data chunk. This allows the node to adapt to CPU and
  network resource constraints more efficiently.

## Configuring state sync

The snippets below provide instructions for configuring state sync on your nodes for different use cases.
These configurations can be added to your node's configuration file, e.g., `fullnode.yaml` or `validator.yaml`.

<Aside type="danger">
  **Do you need to configure state sync?**<br />
  Most users should not need to configure state sync manually. State sync will automatically select the
  best configuration for your node and network. You should only configure state sync if you have a use case
  that requires it. Selecting the wrong configuration will lead to slower syncing times and degraded performance.
</Aside>

### Executing transactions from genesis

To execute all transactions from genesis and continue to execute new
transactions as they are committed, add the following to your node
configuration file:

```yaml filename="fullnode.yaml"
state_sync:
  state_sync_driver:
    bootstrapping_mode: ExecuteTransactionsFromGenesis
    continuous_syncing_mode: ExecuteTransactions
```

### Applying transaction outputs from genesis

To apply all transaction outputs from genesis and continue to apply new
transaction outputs as transactions are committed, add the following to your
node configuration file:

```yaml filename="fullnode.yaml"
state_sync:
  state_sync_driver:
    bootstrapping_mode: ApplyTransactionOutputsFromGenesis
    continuous_syncing_mode: ApplyTransactionOutputs
```

### Intelligent syncing from genesis

To execute or apply all transactions and outputs since genesis (and continue to
do the same as new transactions are committed), add the following to your node
configuration file:

```yaml filename="fullnode.yaml"
state_sync:
  state_sync_driver:
    bootstrapping_mode: ExecuteOrApplyFromGenesis
    continuous_syncing_mode: ExecuteTransactionsOrApplyOutputs
```

### Fast syncing

To download the latest blockchain state and continue to process new
transactions as they are committed, add the following to your
node configuration file:

```yaml filename="fullnode.yaml"
state_sync:
  state_sync_driver:
    bootstrapping_mode: DownloadLatestStates
    continuous_syncing_mode: ExecuteTransactionsOrApplyOutputs
```

## Verifying Syncing Progress

To verify that your node is syncing correctly, you can monitor the relevant state sync metrics exposed by the
[Node Inspection Service](/network/nodes/measure/node-inspection-service).

If your node is bootstrapping in **fast syncing** mode, you should monitor the following metric:

- `aptos_state_sync_version{type="synced_states"}`: This metric indicates the highest blockchain state that has been
  processed. This metric will increase as your node fast syncs. Once all states have been downloaded, this metric will
  stop increasing and your node will begin processing transactions as usual.

During normal node operation, you should monitor the following metric:

- `aptos_state_sync_version{type="synced"}`: This metric indicates the highest transaction version that has been
  fully processed by your node. This metric will increase as long as your node is syncing correctly.

<Aside type="tip">
  **Fast syncing times**<br />
  The speed of fast syncing depends on several factors, including your network bandwidth and disk performance.
  On most well-provisioned nodes, fast syncing usually completes within a few hours.
</Aside>

## Archival PFNs

<Aside type="danger">
  **Archival nodes are deprecated**<br />
  Running archival nodes is expensive and slow, as the amount of data being stored
  on the node will grow indefinitely. As a result, archival nodes have officially been deprecated.
  If you wish to store and maintain the entire blockchain history, we recommend using an [Indexer](/build/indexer).
</Aside>

To operate an archival PFN (which is a PFN that contains all blockchain data
since the start of the network, i.e., genesis), you can:

1. Make sure that your PFN is **not** using fast syncing as the bootstrapping mode.
   Fast syncing will skip the transaction history. Instead, using a mode that syncs from genesis,
   e.g., intelligent syncing from genesis.
2. Disable the ledger pruner, as described in the [Data Pruning document](/network/nodes/configure/data-pruning#disable-the-ledger-pruner).
   This will ensure that no data is deleted and the PFN contains all blockchain data.

Following these two steps together will ensure that your PFN fetches all data since
genesis, and continues to synchronize without pruning any data.

<Aside type="caution">
  **Syncing from genesis?** <br />
  As mentioned above, if you wish to sync all data since genesis, you need to manually add seed peers to
  your node's configuration file. See [Connecting to Seed Peers](/network/nodes/full-node/modify/fullnode-network-connections#connecting-to-seed-peers).
</Aside>

## Security implications and data integrity

All state syncing modes perform data integrity verifications to ensure that data is correct and appropriately signed
by the validators. However, there are some differences in the security guarantees provided by each mode:

1. **Executing transactions from genesis**: Executing transactions from genesis is the most secure syncing mode.
   It will verify that all transactions since the beginning of time were correctly agreed upon by consensus and
   that all transactions were appropriately executed by the validators.
2. **Applying transaction outputs from genesis**: Applying transaction outputs from genesis requires that the
   syncing node trust the validators to have executed the transactions correctly. However, all other
   blockchain state is still manually re-verified, e.g., consensus messages, the transaction history and state hashes.
3. **Intelligent syncing**: Intelligent syncing will either execute transactions or apply transaction outputs
   depending on whichever is faster, per data chunk. The security implications of using this mode
   are identical to above, depending on which method is used for each data chunk.
4. **Fast syncing**: Fast syncing skips the transaction history and downloads the latest blockchain state before
   continuously syncing. To do this, it requires that the syncing node trust the validators to have correctly
   agreed upon all transactions in the transaction history as well as the results of executing those transactions.
   However, all other blockchain data is still manually re-verified, e.g., epoch changes and the resulting blockchain states.

All the syncing modes get their root of trust from the validator set
and cryptographic signatures from those validators over the blockchain data.
For more information about how this works, see the [state synchronization blog post](https://medium.com/aptoslabs/the-evolution-of-state-sync-the-path-to-100k-transactions-per-second-with-sub-second-latency-at-52e25a2c6f10).

# Telemetry

> Understanding and configuring telemetry data collection from Aptos nodes including what information is sent and how to disable it if needed.

import { Aside } from '@astrojs/starlight/components';

When you run a node on an Aptos network, your node will send telemetry data to Aptos Labs. All node types
(e.g., validators, VFNs and PFNs) send telemetry data. This also occurs for other binaries (e.g., the Aptos CLI).
If you would prefer not to send telemetry, you can disable telemetry using the instructions below.

<Aside type="tip">
  **No personal information is collected**<br />
  Aptos telemetry does **not** collect personal information, such as usernames or email addresses.
  It only collects relevant software telemetry, such as software version, node metrics, operating system information
  and the IP address of your node. This data is used to enhance network decentralization and performance.
</Aside>

## Node telemetry

The categories of information collected by Aptos node telemetry, for the `aptos-node` binary, are listed below:

- **Core metrics:** Core metrics are those emitted by the core components of the `aptos-node` binary. These include,
  state sync, consensus, mempool and storage. You can see the full list of core metrics,
  [here](https://github.com/aptos-labs/aptos-core/blob/main/crates/aptos-telemetry/src/core_metrics.rs#L14-L29).

- **Build information**: Rust build information, including the versions of Rust, cargo, the target architecture and
  the build tag are also collected. You can see the full list of build information, [here](https://github.com/aptos-labs/aptos-core/blob/main/crates/aptos-build-info/src/lib.rs#L8-L20).

- **System information**: System information is also collected by node telemetry. This includes resource information
  (e.g., CPU, RAM, disk and network specifications) as well as operating system information. You can see the full list of
  system information, [here](https://github.com/aptos-labs/aptos-core/blob/main/crates/aptos-telemetry/src/system_information.rs#L14-L32).

- **Network metrics:**: Network metrics are also collected by node telemetry. These include network information such as
  the number of connected peers, the number of inbound and outbound messages, and the size of messages sent and received.
  You can see the full list of network metrics, [here](https://github.com/aptos-labs/aptos-core/blob/main/crates/aptos-telemetry/src/network_metrics.rs#L12-L17).

- **Prometheus metrics**: Prometheus metrics are also collected by node telemetry. These include runtime metrics
  for all the components of the `aptos-node` binary. You can see the full list of Prometheus metrics by visiting the
  metrics endpoint on your node using the [node inspection service](/network/nodes/measure/node-inspection-service).

- **Node logs**: Logs of warn-level and higher are also collected by node telemetry. These are used to monitor the
  health of the network. You can identify these logs by filtering the logs for the `aptos-node` binary, locally.

## CLI telemetry

The categories of information collected by Aptos CLI telemetry, for the `aptos` CLI, are listed below:

- **Command metrics**: Command metrics are those emitted by the CLI when a command is executed. These
  include the command itself, the latency of the command, and the success or failure of the command. You can see
  the full list of CLI metrics,
  [here](https://github.com/aptos-labs/aptos-core/blob/main/crates/aptos-telemetry/src/cli_metrics.rs#L12-L15).

- **Build information**: Rust build information, including the versions of Rust, cargo, the target architecture and
  the build tag are also collected for the CLI. You can see the full list of build information, [here](https://github.com/aptos-labs/aptos-core/blob/main/crates/aptos-build-info/src/lib.rs#L8-L20).

## Disabling telemetry

<Aside type="danger">
  **Disabling telemetry?**<br />
  Disabling telemetry is not recommended, as it helps the Aptos Labs team improve the performance and reliability
  of Aptos software. If you choose to disable telemetry, it will be much more difficult for the team to identify and
  debug any issues that you may be facing.

  If there are specific privacy or compliance requirements that prevent you from sending telemetry, or if you have
  concerns with certain types of information being sent, please reach out to the Aptos Labs team to see how they
  can help.
</Aside>

On macOS and Linux, you can set the `APTOS_DISABLE_TELEMETRY` environment variable to disable the metrics sent by
both the Aptos node and the Aptos CLI tool. To disable all telemetry, set `APTOS_DISABLE_TELEMETRY` environment to `true`:

```shellscript filename="Terminal"
export APTOS_DISABLE_TELEMETRY=true
```

The above command only disables telemetry for a single session in the current terminal where you run the command.
To disable it permanently across all terminals and Aptos binary invocations, include it in your startup profile.
For example:

```shellscript filename="Terminal"
echo "export APTOS_DISABLE_TELEMETRY=true" >> ~/.profile
source ~/.profile
```

## Configuring telemetry

<Aside type="tip">
  **Configuring telemetry?**<br />
  If you find that you need to disable specific telemetry metrics or collections, consider reaching out to the
  Aptos Labs team first, to let them know. Aptos Labs actively considers making changes to telemetry based
  on user feedback.
</Aside>

You can also configure telemetry to disable specific telemetry metrics and collections. The environment variable
list below shows the variables you can set to configure telemetry for Aptos nodes and the CLI:

- `APTOS_DISABLE_TELEMETRY`: This disables all telemetry emission, including sending telemetry to the Google Analytics service (GA4).
- `APTOS_FORCE_ENABLE_TELEMETRY`: This overrides the chain ID check and forces the Aptos node to send telemetry regardless of whether the remote service accepts it or not.
- `APTOS_DISABLE_TELEMETRY_PUSH_METRICS`: This disables sending [Prometheus](https://prometheus.io/) metrics.
- `APTOS_DISABLE_TELEMETRY_PUSH_LOGS`: This disables sending logs.
- `APTOS_DISABLE_TELEMETRY_PUSH_EVENTS`: This disables sending custom events.
- `APTOS_DISABLE_LOG_ENV_POLLING`: This disables the dynamic ability to send verbose logs.
- `APTOS_DISABLE_PROMETHEUS_NODE_METRICS`: This disables sending the Aptos node resource metrics such as system CPU, memory, etc.

# Run a Public Fullnode

> Deploy and operate your own public fullnode (PFN) to synchronize with the Aptos blockchain and stay up-to-date with the latest state.

import { Aside } from '@astrojs/starlight/components';

You can run your own public fullnode (PFN) to synchronize the state of the Aptos blockchain and stay
up-to-date. PFNs replicate the entire state of the blockchain by syncing from other Aptos VFNs and PFNs. PFNs
can be run by anyone. This section explains how to deploy a PFN and connect to an Aptos network. You can learn
more about the different types of nodes in the [Blockchain Deep Dive](/network/blockchain) section.

<Aside type="note">
  **Default connection to mainnet**<br />
  If you follow the default setup in this document, then your PFN will be connected to the Aptos mainnet. To connect
  to a different Aptos network, such as devnet or testnet, make sure you have the correct docker image tag, or source
  code branch if you build the binary directly.

  You can find the genesis and waypoint files for all the networks, here ‚ûú [https://github.com/aptos-labs/aptos-networks](https://github.com/aptos-labs/aptos-networks).
</Aside>

# Deploy a PFN

> Step-by-step guides for deploying a public fullnode (PFN) on Aptos networks using various deployment methods including source code, Docker, and cloud platforms.

import { Aside } from '@astrojs/starlight/components';

The following guides provide step-by-step instructions for deploying a PFN on the Aptos networks.

<Aside type="note">
  **Do I have to run a PFN?**<br />
  If you do not wish to run a PFN, but still want to interact with the Aptos blockchain, you can use the REST API
  provided by the Aptos Labs' PFNs (see [Aptos APIs](/build/apis)). Note, however, that Aptos Labs-provided PFNs have rate
  limits, which can impede your development. You can get higher rate limits by creating an [Geomi](https://geomi.dev/) account and attaching a payment method. You can also deploy your own PFN
  and synchronize with the Aptos blockchain directly, or use a different node infrastructure provider.
</Aside>

Select the guide for the deployment method you prefer:

<Aside type="caution">
  **Choose a network**<br />
  These guides default to deploying a PFN in the Aptos mainnet network, but they can easily be used to do
  the same in other networks (e.g., devnet or testnet network). To do so, check out the desired network branch
  and use the `genesis.blob` and `waypoint.txt` node files for the respective branches:
  [mainnet](/network/nodes/configure/node-files-all-networks/node-files-mainnet),
  [devnet](/network/nodes/configure/node-files-all-networks/node-files-devnet), and
  [testnet](/network/nodes/configure/node-files-all-networks/node-files-testnet).
</Aside>

- ### [Using Source Code](/network/nodes/full-node/deployments/using-source-code)
- ### [Using Docker](/network/nodes/full-node/deployments/using-docker)
- ### [Using GCP](/network/nodes/full-node/deployments/using-gcp)

# Using Docker

> Deploy a public fullnode (PFN) using Docker containers with automated configuration download and container setup for x86-64 systems.

import { Aside } from '@astrojs/starlight/components';

This section describes how to configure and run your PFN using Docker.

<Aside type="caution">
  **Supported only on x86-64 CPUs**<br />
  Running aptos-core via Docker is currently only supported on x86-64 CPUs. If you have an Apple M1/M2 (ARM64) Mac, use
  the aptos-core source code approach (above). If M1/M2 support is important to you, comment on this
  issue: [https://github.com/aptos-labs/aptos-core/issues/1412](https://github.com/aptos-labs/aptos-core/issues/1412)
</Aside>

1. First, install [Docker](https://docs.docker.com/get-docker/).
2. Next, run the following script to prepare your local configuration and data directory for mainnet. This will
   download the `fullnode.yaml` configuration file, the `genesis.blob` and `waypoint.txt` files for your PFN, and
   create a `data` directory to store the blockchain database:

```shellscript filename="Terminal"
mkdir mainnet && cd mainnet
mkdir data && \
curl -O https://raw.githubusercontent.com/aptos-labs/aptos-core/mainnet/docker/compose/aptos-node/fullnode.yaml && \
curl -O https://raw.githubusercontent.com/aptos-labs/aptos-networks/main/mainnet/waypoint.txt && \
curl -O https://raw.githubusercontent.com/aptos-labs/aptos-networks/main/mainnet/genesis.blob
```

<Aside type="caution">
  **Don't want to connect to mainnet?**<br />
  To connect to other networks (e.g., `devnet` and `testnet`), you can find the genesis and waypoint here ‚ûú [https://github.com/aptos-labs/aptos-networks](https://github.com/aptos-labs/aptos-networks).
  Be sure to download the `genesis.blob` and `waypoint.txt` for those networks, instead of using the genesis
  and waypoint pointed to by the `curl` commands above.
</Aside>

3. Next, make sure that the `fullnode.yaml` configuration file that you downloaded above contains only the following content.
   This will ensure that this configuration is for a PFN and not for another node type (e.g., validator or VFN):

```yaml filename="fullnode.yaml"
base:
  role: "full_node"
  data_dir: "/opt/aptos/data"
  waypoint:
    from_file: "/opt/aptos/etc/waypoint.txt"

execution:
  genesis_file_location: "/opt/aptos/etc/genesis.blob"

full_node_networks:
  - network_id: "public"
    discovery_method: "onchain"
    listen_address: "/ip4/0.0.0.0/tcp/6182"

api:
  enabled: true
  address: "0.0.0.0:8080"
```

<Aside type="caution">
  **Don't want to allow inbound connections?** <br />
  Override the following if you do not want other PFNs connecting to yours: `listen_address: "/ip4/127.0.0.1/tcp/6182"`.
</Aside>

4. Next, run the following `docker` command:

```shellscript filename="Terminal"
docker run --pull=always \
  --rm -p 8080:8080 \
  -p 9101:9101 -p 6180:6180 \
  -v $(pwd):/opt/aptos/etc -v $(pwd)/data:/opt/aptos/data \
  --workdir /opt/aptos/etc \
  --name=aptos-fullnode aptoslabs/validator:mainnet aptos-node \
  -f /opt/aptos/etc/fullnode.yaml
```

<Aside type="caution">
  **Sudo access**<br />
  Note: you may need to prefix the docker command with `sudo` depending on your configuration.
</Aside>

<Aside type="note">
  **Docker tags**<br />
  The `mainnet` tag always refers to the latest official Docker image tag. You can find the latest hash for comparison at:
  [https://github.com/aptos-labs/aptos-networks/tree/main/mainnet](https://github.com/aptos-labs/aptos-networks/tree/main/mainnet)
</Aside>

You have now successfully configured and started running a PFN in the Aptos mainnet.

<Aside type="note">
  **Verify your PFN**
  If you want to verify that your PFN is running correctly, you can follow the instructions in the [Verify a PFN](/network/nodes/full-node/verify-pfn) guide.
</Aside>

# Using GCP

> Deploy a public fullnode (PFN) on Google Cloud Platform using Terraform and Kubernetes with comprehensive setup, validation, and monitoring instructions.

import { Aside } from '@astrojs/starlight/components';

This tutorial explains how to configure and deploy a PFN using Google Cloud (GCP). Running a PFN in the cloud
usually provides better stability and availability compared to running it on your laptop.

<Aside type="caution">
  **Don't want to connect to devnet?**<br />
  This tutorial defaults to deploying a PFN in the Aptos `devnet` network. To connect to other networks
  (e.g., `mainnet` and `testnet`), replace all instances of `devnet` with the appropriate network name.
</Aside>

## Prerequisites

You can run the commands in this guide to deploy your PFN on Google Kubernetes Engine from any machine you want, e.g.
a [VM on GCP](https://cloud.google.com/compute), [Google Cloud Shell](https://cloud.google.com/shell), or your personal computer.

The following packages are pre-installed with Cloud Shell. **Make sure to review** the
[documentation around ephemeral mode](https://cloud.google.com/shell/docs/using-cloud-shell/#choose_ephemeral_mode) if
you choose to use Cloud Shell. However, if you are running the installation from your laptop or another machine,
you need to install:

- Terraform 1.3.6: [https://www.terraform.io/downloads.html](https://www.terraform.io/downloads.html)
- Kubernetes CLI: [https://kubernetes.io/docs/tasks/tools/](https://kubernetes.io/docs/tasks/tools/)
- Google Cloud CLI: [https://cloud.google.com/sdk/docs/install-sdk](https://cloud.google.com/sdk/docs/install-sdk)

After you have installed the gcloud CLI, [log into GCP using gcloud](https://cloud.google.com/sdk/gcloud/reference/auth/login):

```shellscript filename="Terminal"
gcloud auth login --update-adc
```

<Aside type="note">
  **Already have a GCP account set up?**<br />
  If you already have a GCP account setup, skip to [Getting Started](#getting-started). If you do not have a GCP account, then follow
  the below sections to create and configure your GCP account.
</Aside>

### GCP setup

#### Sign up for the 90-day free trial

Google Cloud offers a [90 day, $300 free trial for every new user](https://cloud.google.com/free/docs/gcp-free-tier/#free-trial). The $300 are given as credits to your
account and you can use them to get a sense of Google Cloud products. Some GCP feature such as GPUs and Windows
servers are not available in the free trial. Sign up for the credits, [here](https://cloud.google.com/free).

#### Create a new GCP project

- Create a new project on the GCP Console or using the gcloud command from the Google Cloud CLI. Be sure to
  familiarize yourself with the [resource hierarchy on GCP](https://cloud.google.com/resource-manager/docs/cloud-platform-resource-hierarchy).
- [Follow these instructions to setup a new project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#creating_a_project).

#### Enable billing, upgrade your account

You will still be able to use the free trial credits, but enabling billing allows you to have full access to all the
features of GCP and not experience any interruption to your nodes. [Upgrade your account by following the steps outlined here.](https://cloud.google.com/free/docs/gcp-free-tier#how-to-upgrade)

#### Additional GCP resources

This should be enough to get your GCP setup ready to start deploying your PFN. But if you are new to GCP, you may want
to check out some of their [guides](https://cloud.google.com/docs/get-started/quickstarts) and [Google Cloud Skills Boost](https://www.cloudskillsboost.google/catalog).

## Getting started

<Aside type="note">
  **Before you proceed**<br />
  From here on, this guide assumes that you have already set up your GCP account, and have created a new project for
  deploying an Aptos PFN.
</Aside>

You can deploy a PFN on GCP by using the Aptos Terraform module.

1. Create a working directory for your configuration.

   - Choose a workspace name e.g. `devnet`. **Note**: This defines the Terraform workspace name, which in turn is used
     to form resource names. Feel free to choose a different name if you are connecting to a different network.

   ```shellscript filename="Terminal"
   export WORKSPACE=devnet
   ```

   - Create a directory for the workspace

   ```shellscript filename="Terminal"
   mkdir -p ~/$WORKSPACE
   ```

2. Create a storage bucket for storing the Terraform state on Google Cloud Storage. Use the console or this gcs command
   to create the bucket. The name of the bucket must be unique. See the Google Cloud Storage documentation,
   [here](https://cloud.google.com/storage/docs/creating-buckets#prereq-cli).

```shellscript filename="Terminal"
gsutil mb gs://BUCKET_NAME
# for example
gsutil mb gs://<project-name>-aptos-terraform-dev
```

3. Create Terraform file called `main.tf` in your working directory:

```shellscript filename="Terminal"
cd ~/$WORKSPACE
touch main.tf
```

4. Modify the `main.tf` file to configure Terraform and create a PFN from the Terraform module.

**Note:** If you are using a different version of Terraform, you will need to use the `tfenv` command to change the required version.

You can find the Docker image tag for `devnet` on the [Aptos Docker Hub](https://hub.docker.com/r/aptoslabs/validator/tags?page=1\&ordering=last_updated\&name=devnet).

<Aside type="caution">
  **Want to connect to a different network?**<br />
  If you wish to connect to a different network than `devnet`, you will need to find the appropriate Docker image
  tag for that network and replace all references to it.
</Aside>

Example content for `main.tf`:

```terraform filename="main.tf"
terraform {
  required_version = "~> 1.3.6"
  backend "gcs" {
    bucket = "BUCKET_NAME" # bucket name created in step 2
    prefix = "state/fullnode"
  }
}

module "fullnode" {
  # download Terraform module from aptos-labs/aptos-core repo
  source        = "github.com/aptos-labs/aptos-core.git//terraform/fullnode/gcp?ref=main"
  region        = "us-central1"  # Specify the region
  zone          = "c"            # Specify the zone suffix
  project       = "gcp-fullnode" # Specify your GCP project ID
  fullnode_name = "BUCKET_NAME" #bucket name created in step 2
  era           = 1              # bump era number to wipe the chain
  image_tag     = "devnet" # Specify the docker image tag
}
```

5. Initialize Terraform in the same directory of your `main.tf` file:

```shellscript filename="Terminal"
terraform init
```

This will download all the Terraform dependencies into the `.terraform` folder.

6. Create a new Terraform workspace to isolate your environments:

```shellscript filename="Terminal"
terraform workspace new $WORKSPACE
# This command will list all workspaces
terraform workspace list
```

7. Apply the configuration:

```shellscript filename="Terminal"
terraform apply
```

This might take a while to finish (10 - 20 minutes), Terraform will create all the resources on your cloud account.

## Validation

Once Terraform apply finishes, you can follow this section to validate your deployment.

1. Configure your Kubernetes client to access the cluster you just deployed:

```shellscript filename="Terminal"
gcloud container clusters get-credentials aptos-$WORKSPACE --zone <region_zone_name> --project <project_name>
# for example:
gcloud container clusters get-credentials aptos-devnet --zone us-central1-a --project aptos-fullnode
```

2. Check that your PFN pods are now running (this may take a few minutes):

```shellscript filename="Terminal"
kubectl get pods -n aptos
```

You should see this:

```shellscript filename="Terminal"
NAME                       READY   STATUS    RESTARTS   AGE
devnet0-aptos-fullnode-0   1/1     Running   0          56s
```

3. Get your PFN IP:

```shellscript filename="Terminal"
kubectl get svc -o custom-columns=IP:status.loadBalancer.ingress -n aptos
```

You should see something like this:

```
[map[ip:104.198.36.142]]
```

4. Check the REST API, make sure that the ledger version is increasing:

```shellscript filename="Terminal"
curl http://<IP>/v1
# Example command syntax: curl http://104.198.36.142/v1
```

You should see this something like this:

```json filename="Terminal"
{
  "chain_id": 25,
  "epoch": "22",
  "ledger_version": "9019844",
  "oldest_ledger_version": "0",
  "ledger_timestamp": "1661620200131348",
  "node_role": "full_node",
  "oldest_block_height": "0",
  "block_height": "1825467"
}
```

5. To verify the correctness of your PFN, you will need to:

   - Set up a port-forwarding mechanism directly to the Aptos pod in one ssh terminal, and
   - Test it in another ssh terminal.

   Follow the below steps:

   - Set up the port-forwarding to the aptos-fullnode pod. Use `kubectl get pods -n aptos` to get the name of the pod:

     ```shellscript filename="Terminal"
     kubectl port-forward -n aptos <pod-name> 9101:9101
     # for example:
     kubectl port-forward -n aptos devnet0-aptos-fullnode-0 9101:9101
     ```

   - Open a new ssh terminal. Execute the following curl calls to verify the correctness:

     ```shellscript filename="Terminal"
     curl -v http://0:9101/metrics 2> /dev/null | grep "aptos_state_sync_version{type=\"synced\"}"

     curl -v http://0:9101/metrics 2> /dev/null | grep "aptos_connections{direction=\"outbound\""
     ```

   - Exit port-forwarding when you are done by entering control-c in the terminal.

## PFN identity and seed peers

### Static identity

If you want to configure your node with a static identity, first see the [Generate a PFN Identity](/network/nodes/full-node/modify/network-identity-fullnode) tutorial
to generate a static identity, and then follow the below instructions to configure your Terraform file.

1. Generate a static identity for your PFN by following the guide: [Creating a static identity for a PFN](/network/nodes/full-node/modify/network-identity-fullnode#generate-a-static-identity).

2. Modify the `main.tf` to add `fullnode_identity` entries in `fullnode_helm_values`. This will configure the identity
   for the PFN. Insert the correct values for your PFN's identity attributes. For example:

```terraform filename="main.tf"
module "fullnode" {
  # download Terraform module from aptos-labs/aptos-core repo
  source        = "github.com/aptos-labs/aptos-core.git//terraform/fullnode/gcp?ref=main"
  region        = "us-central1"  # Specify the region
  zone          = "c"            # Specify the zone suffix
  project       = "gcp-fullnode" # Specify your GCP project name
  era           = 1              # bump era number to wipe the chain
  image_tag     = "devnet"       # Specify the docker image tag to use

  fullnode_helm_values = {
    chain = {
      name = "devnet"
    }
    # create fullnode from this identity config, so it will always have same peer id and address
    fullnode_identity = {
      type = "from_config"
      key = "B8BD811A91D8E6E0C6DAC991009F189337378760B55F3AD05580235325615C74"
      peer_id = "ca3579457555c80fc7bb39964eb298c414fd60f81a2f8eedb0244ec07a26e575"
    }
  }
}
```

3. Apply Terraform changes:

```shellscript filename="Terminal"
terraform apply
```

### Seed peers

You can add seed peers to allow your PFN to connect to specific nodes. See the guide
[Customize PFN Networks](/network/nodes/full-node/modify/fullnode-network-connections) for more information.

1. Obtain the seed peer information.

2. Modify the `main.tf` to add the seed peers in `fullnode_helm_values`. This will configure the seeds for the PFN. For example:

```terraform filename="main.tf"
module "fullnode" {
  # download Terraform module from aptos-labs/aptos-core repo
  source        = "github.com/aptos-labs/aptos-core.git//terraform/fullnode/gcp?ref=main"
  region        = "us-central1"  # Specify the region
  zone          = "c"            # Specify the zone suffix
  project       = "gcp-fullnode" # Specify your GCP project name
  era           = 1              # bump era number to wipe the chain
  image_tag     = "dev_5b525691" # Specify the docker image tag to use

  fullnode_helm_values = {
    # add a list of peers as upstream
    aptos_chains = {
      devnet = {
        seeds = {
          "bb14af025d226288a3488b4433cf5cb54d6a710365a2d95ac6ffbd9b9198a86a" = {
          addresses = ["/dns4/pfn0.node.devnet.aptoslabs.com/tcp/6182/noise-ik/bb14af025d226288a3488b4433cf5cb54d6a710365a2d95ac6ffbd9b9198a86a/handshake/0"]
          role = "Upstream"
          },
          "7fe8523388084607cdf78ff40e3e717652173b436ae1809df4a5fcfc67f8fc61" = {
          addresses = ["/dns4/pfn1.node.devnet.aptoslabs.com/tcp/6182/noise-ik/7fe8523388084607cdf78ff40e3e717652173b436ae1809df4a5fcfc67f8fc61/handshake/0"]
          role = "Upstream"
          },
          "f6b135a59591677afc98168791551a0a476222516fdc55869d2b649c614d965b" = {
          addresses = ["/dns4/pfn2.node.devnet.aptoslabs.com/tcp/6182/noise-ik/f6b135a59591677afc98168791551a0a476222516fdc55869d2b649c614d965b/handshake/0"]
          role = "Upstream"
          }
        }
      }
    }
  }
}
```

3. Apply Terraform changes:

```shellscript filename="Terminal"
terraform apply
```

## Check logging

To check the logs of the pod, use the following commands:

```shellscript filename="Terminal"
# Get a list of the pods
kubectl get pods -n aptos

# Get logs of the pod
kubectl logs <pod-name> -n aptos
# for example:
kubectl logs devnet0-aptos-fullnode-0 -n aptos
```

When using GKE, the logs of the cluster and pod will automatically show up in the Google Cloud console. From the console menu, choose `Kubernetes Engine`. From the side menu, choose `Workloads`. You will see all the pods from the cluster listed.

![GKE Workloads screenshot](~/images/tutorial-gcp-logging1.png "GKE Workloads screenshot")

The `devnet0-aptos-fullnode` is the pod that is running the aptos fullnode container. Click on the pod to view details. You will see some metrics and other details about the pod.

![GKE Workloads Pod screenshot](~/images/tutorial-gcp-logging2.png "GKE Workloads Pod screenshot")

Click the `LOGS` tab to view the logs directly from the pod. If there are errors in the pod, you will see them here.

![GKE Workloads Pod Logs screenshot](~/images/tutorial-gcp-logging3.png "GKE Workloads Pod Logs screenshot")

Click the `open in new window` icon to view the logs in the Log Explorer. This screen allows advanced searching in the logs.

![GKE Workloads Pod Logs Explorer screenshot](~/images/tutorial-gcp-logging4.png "GKE Workloads Pod Logs Explorer screenshot")

Other logging insights are available in the Logs Dashboard

![GKE Workloads Pod Logs Dashboard screenshot](~/images/tutorial-gcp-logging5.png "GKE Workloads Pod Logs Dashboard screenshot")

Additional [features](https://cloud.google.com/logging/docs) are available through [Cloud Logging](https://cloud.google.com/logging), including creating log-based metrics, logging sinks and log buckets.

## Check monitoring

Google cloud captures many metrics from the cluster and makes them easily viewable in the console. From the console menu, choose `Kubernetes Engine`. Click on the cluster that aptos is deployed to. Click on the `Operations` link at the top right. Click on the `Metrics` sub-tab to view specific cluster metrics.

![GKE Monitoring metrics screenshot](~/images/tutorial-gcp-mon1.png "GKE Monitoring metrics screenshot")

Click the `View in Cloud Monitoring` link at the top to view the built-in GKE [dashboard](https://cloud.google.com/stackdriver/docs/solutions/gke/observing) for the cluster.

![GKE Monitoring dashboard screenshot](~/images/tutorial-gcp-mon2.png "GKE Monitoring dashboard screenshot")

Google Cloud [Monitoring](https://cloud.google.com/monitoring) has many other features to easily monitor the cluster and pods. You can configure [uptime checks](https://cloud.google.com/monitoring/uptime-checks/introduction) for the services and configure [alerts](https://cloud.google.com/monitoring/alerts/using-alerting-ui) for when the metrics reach a certain [threshold](https://cloud.google.com/stackdriver/docs/solutions/slo-monitoring/sli-metrics/overview).

<Aside type="note">
  **Verify your PFN**<br />
  If you want to verify that your PFN is running correctly, you can follow the instructions in the [Verify a PFN](/network/nodes/full-node/verify-pfn) guide.
</Aside>

# Using Source Code

> Deploy a public fullnode (PFN) by building from aptos-core source code with complete configuration and setup instructions.

import { Aside } from '@astrojs/starlight/components';

To deploy a PFN using the `aptos-core` source code, first, see [Building Aptos From Source](/network/nodes/building-from-source) for instructions
on how to download the `aptos-core` repository and build the binary. Then, follow the steps below:

1. Make sure your current working directory is `aptos-core`.

2. Check out the `mainnet` branch using `git checkout --track origin/mainnet`; remember, you may instead use `devnet` or `testnet`
   if you wish to run your PFN in a different network.

3. Next, download the `genesis.blob` and `waypoint.txt` files for the network your PFN will connect to:

   - Run this command to download the genesis blob (for mainnet):

     ```shellscript filename="Terminal"
     curl -O https://raw.githubusercontent.com/aptos-labs/aptos-networks/main/mainnet/genesis.blob
     ```

   - Run this command to download the waypoint file (for mainnet):
     ```shellscript filename="Terminal"
     curl -O https://raw.githubusercontent.com/aptos-labs/aptos-networks/main/mainnet/waypoint.txt
     ```

   <Aside type="caution">
     **Don't want to connect to mainnet?**<br />
     To connect to other networks (e.g., `devnet` and `testnet`), you can find the genesis and waypoint here ‚ûú [https://github.com/aptos-labs/aptos-networks](https://github.com/aptos-labs/aptos-networks).
     Be sure to download the `genesis.blob` and `waypoint.txt` for those networks, instead of using the genesis
     and waypoint pointed to by the `curl` commands above.
   </Aside>

4. Next, run the command below to create a copy of the PFN configuration YAML template:
   ```shellscript filename="Terminal"
   cp config/src/config/test_data/public_full_node.yaml fullnode.yaml
   ```

5. Finally, edit the `fullnode.yaml` configuration file to ensure that your PFN: (i) contains the genesis blob
   and waypoint file you just downloaded; and (ii) saves the synchronized blockchain data to the location of your
   choice (on your local machine). To do this:

   1. Specify the correct path to the `genesis.blob` file you just downloaded by editing `execution.genesis_file_location` in the `fullnode.yaml` configuration. By default, it points to `genesis.blob` in the current working directory.
      ```yaml filename="fullnode.yaml"
      execution:
        genesis_file_location: "./genesis.blob"
      ```
   2. Specify the correct path to the `waypoint.txt` file you just downloaded by editing `base.waypoint.from_file` in the `fullnode.yaml` configuration. By default, it points to `waypoint.txt` in the current working directory. For example:
      ```yaml filename="fullnode.yaml"
      base:
        waypoint:
          from_file: "./waypoint.txt"
      ```
   3. Specify the directory on your local machine that you want to store the blockchain database by editing the `base.data_dir` in the `fullnode.yaml` configuration. For example, you can create a directory `my-full-node/data` in your home directory and specify it as:
      ```yaml filename="fullnode.yaml"
      base:
        data_dir: "</path/to/my/homedir/my-full-node/data>"
      ```

6. Start your local public fullnode by running the below command:

```shellscript filename="Terminal"
cargo run -p aptos-node --release -- -f ./fullnode.yaml
```

<Aside type="note">
  **Debugging?**<br />
  The command above will build a release binary for `aptos-node` at: `aptos-core/target/release/aptos-node`. The release
  binaries tend to be substantially faster than debug binaries but lack debugging information useful for development.
  To build a debug binary, omit the `--release` flag from the command above.
</Aside>

You have now successfully configured and started running a PFN in the Aptos mainnet.

<Aside type="note">
  **Verify your PFN**<br />
  If you want to verify that your PFN is running correctly, you can follow the instructions in the [Verify a PFN](/network/nodes/full-node/verify-pfn) guide.
</Aside>

# Modify a PFN

> Common operations and modifications for public fullnodes (PFN) including upgrades, identity generation, and network customization.

This section contains tutorials for performing common operations and modifications to a PFN. These include:

- ### [Upgrade your PFN](/network/nodes/full-node/modify/update-fullnode-with-new-releases)
- ### [Generate a PFN Identity](/network/nodes/full-node/modify/network-identity-fullnode)
- ### [Customize PFN Networks](/network/nodes/full-node/modify/fullnode-network-connections)

# Customize PFN Networks

> Advanced network configuration options for public fullnodes (PFN) including seed peers, static identities, and private network setups.

import { Aside } from '@astrojs/starlight/components';

<Aside type="caution">
  **Advanced customization**<br />
  Most PFN operators will not need to customize their PFN's network connections. This is only required
  for advanced use cases, such as connecting to specific peers, or configuring a private PFN. If you do
  not have a relevant use case, you should avoid making changes to your PFN's network connections.
</Aside>

When running a PFN, you can configure your node's network connections for a few different purposes.
For example, you can add a seed peer to your node's configuration to connect your node to a specific
peer of your choosing. Or you can leverage a static network identity for your PFN to allow other nodes
to connect to you, as described in [Generate a PFN Identity](/network/nodes/full-node/modify/network-identity-fullnode).

This document outlines how to configure the network of your PFN for different use cases, including:

- Allowing nodes to connect to your PFN.
- Connecting your PFN to seed peers.
- Configuring priority access for other PFNs.
- Configuring your PFN as a private PFN.

## Allowing PFN connections

<Aside type="note">
  **Generate a static identity**<br />
  Before allowing other nodes to connect to your PFN, you will need to create a static identity. See [Generate a PFN Identity](/network/nodes/full-node/modify/network-identity-fullnode).
</Aside>

Once you start your PFN with a static identity you can allow others to connect to your PFN:

<Aside type="note">
  **Default port settings**<br />
  In the steps below, the port numbers used are for illustration only. You can use your choice of port numbers.
  See [PFN Requirements](/network/nodes/full-node/pfn-requirements) for more information on port settings.
</Aside>

- Make sure you open the TCP port of the network you wish to allow external connections on (e.g., `6180` or `6182`).
  This is required to allow other nodes to connect to your PFN.
- If you are using Docker, simply add `- "6180:6180"` or `- "6182:6182"` under ports in your `docker-compose.yaml` file.
- Share your PFN static network identity with others. They can then use it in the `seeds` key of their node's
  configuration file to connect to your PFN. See the section below.
- Make sure the port number you put in the `addresses` matches the one you have in the PFN configuration file
  (for example, `6180` or `6182`).

<Aside type="note">
  You can share your PFN's network identity in our Discord to advertise your node for others to connect to. Note:
  this is optional (and not required!).
</Aside>

The snippets below show the configuration file entries and format for allowing other nodes to connect to your PFN.
The format of each seed peer entry should have a unique `peer_id`, list of `addresses`, and a `role`:

```yaml filename="docker-compose.yaml"
<Peer_ID>:
  addresses:
  # with DNS
  - "/dns4/<DNS_Name>/tcp/<Port_Number>/noise-ik/<Public_Key>/handshake/0"
  role: Upstream
<Peer_ID>:
  addresses:
  # with IP
  - "/ip4/<IP_Address>/tcp/<Port_Number>/noise-ik/<Public_Key>/handshake/0"
  role: Upstream
```

For example:

```yaml filename="docker-compose.yaml"
B881EA2C174D8211C123E5A91D86227DB116A44BB345A6E66874F83D8993F813:
  addresses:
  - "/dns4/pfn0.node.devnet.aptoslabs.com/tcp/6182/noise-ik/B881EA2C174D8211C123E5A91D86227DB116A44BB345A6E66874F83D8993F813/handshake/0"
  role: "Upstream"
B881EA2C174D8211C123E5A91D86227DB116A44BB345A6E66874F83D8993F813:
  addresses:
  - "/ip4/100.20.221.187/tcp/6182/noise-ik/B881EA2C174D8211C123E5A91D86227DB116A44BB345A6E66874F83D8993F813/handshake/0"
  role: "Upstream"
```

## Connecting to seed peers

<Aside type="caution">
  **Seeds are not required**<br />
  Seed peers are not usually required for your PFN to connect to any Aptos network. All Aptos networks are automatically
  discoverable. Adding seed peers should only be done if you wish to connect to a specific peer or set of peers (e.g.,
  if you wish to sync historical data that is not available through regular peers).
</Aside>

To add seed peers to your PFN, the seed peers' addresses should be added to your PFN configuration file, under
the `seeds` key in the public network configuration. Each seed peer entry should have a unique `peer_id`, list of
`addresses`, and a `role` (e.g., `Upstream`). The snippet below shows an example
of a configuration file with seed peers manually added:

```yaml
full_node_networks:
  - discovery_method: "onchain"
    listen_address: ...
    seeds: # All seeds are declared below
      bb14af025d226288a3488b4433cf5cb54d6a710365a2d95ac6ffbd9b9198a86a:
        addresses:
          - "/dns4/pfn0.node.devnet.aptoslabs.com/tcp/6182/noise-ik/bb14af025d226288a3488b4433cf5cb54d6a710365a2d95ac6ffbd9b9198a86a/handshake/0"
        role: "Upstream"
      7fe8523388084607cdf78ff40e3e717652173b436ae1809df4a5fcfc67f8fc61:
        addresses:
          - "/dns4/pfn1.node.devnet.aptoslabs.com/tcp/6182/noise-ik/7fe8523388084607cdf78ff40e3e717652173b436ae1809df4a5fcfc67f8fc61/handshake/0"
        role: "Upstream"
      f6b135a59591677afc98168791551a0a476222516fdc55869d2b649c614d965b:
        addresses:
          - "/dns4/pfn2.node.devnet.aptoslabs.com/tcp/6182/noise-ik/f6b135a59591677afc98168791551a0a476222516fdc55869d2b649c614d965b/handshake/0"
        role: "Upstream"
```

## Configuring priority access

To configure your PFN to allow other nodes to connect to it even when your PFN has hit the maximum number
of available network connections, follow this method:

In the configuration file for your PFN add the other node as a seed peer with the `Downstream` role.
This will allow the other node to connect directly to you with priority access. For example:

```yaml
seeds:
  <other node's peer id>
    addresses:
    - <address of the other node>
    role: Downstream # Allows the node to connect to us
```

Similarly, to make the other node dial out to your PFN, add the following to the other node's configuration file:

```yaml
seeds:
  <your node's peer id>
    addresses:
    - <address of your npde>
    role: PreferredUpstream # Allows the node to connect to the seed peer
```

## Configuring private PFNs

You can also configure your PFN as a private PFN should you wish. What this means is that your PFN will
not allow unauthenticated connections, specifically, any node that is not a validator, VFN or seed peer
will be unable to connect to your PFN.

To configure your PFN as a private PFN, add the following to your PFN configuration file. Note, you
should add this to the public network entry in the `full_node_networks` configuration:

```yaml
...
full_node_networks:
  - discovery_method: "onchain"
    listen_address: ...
    max_inbound_connections: 0  # Prevents any unauthenticated inbound connections
    mutual_authentication: true  # Requires authenticated connections
    ...
...
```

# Generate a PFN Identity

> Learn about ephemeral vs. static identities for public fullnodes (PFN) and how to generate unique network identities for monitoring and persistence.

import { Aside } from '@astrojs/starlight/components';

<Aside type="danger">
  Validators and VFNs have their identities initialized when first created and their identities are long-lived (immutable).
  PFN identities are more ephemeral and can be regenerated. As such, generating an identity using this
  guide **should only be done for PFNs**, and not for validators or VFNs.
</Aside>

## Ephemeral vs. Static Identities

Public fullnodes (PFNs) will automatically start up with a randomly generated (ephemeral) network identity unless a static identity is provided. This works well for
regular PFNs. However, there are cases where you may want to generate and assign a static network identity to your PFN (e.g., for monitoring purposes).

<Aside type="caution">
  PFN identities should be unique across the network. If you are running multiple PFNs, make sure to generate a
  unique identity for each PFN. Attempting to share the same identity across multiple PFNs will result in degraded
  node performance.
</Aside>

### Ephemeral Identity

- Automatically generated on node startup. The same ephemeral identity is used across restarts if the identity key file already exists.
- By default, the identity file is stored at `/opt/aptos/data/db/ephemeral_identity_key`.

### Static Identity

This is useful when:

- You wish to advertise your PFN as a seed (i.e., for other Aptos PFNs to connect to).
- You wish to add your PFN to an allowlist of known identities on an upstream PFN or VFN.
- You wish to fix the identity of your PFN across restarts and releases so that telemetry and other monitoring tools can track your PFN over time.

## Generate a static identity

To create a static identity for your PFN, you will first need to generate a private and public key pair. You will then
need to derive the `peer_id` from the public key, and use the `peer_id` in your configuration file
(e.g., `fullnode.yaml`) to configure the static network identity for your PFN.

The steps below will guide you through the process of generating a static identity for your PFN. The exact steps depend
on whether you are using the `aptos-core` source code to run your PFN, or Docker.

### Using the aptos-core source code

If you use the `aptos-core` source code to run your PFN, follow these steps:

1. **Generate the private key**

First, use the [Aptos CLI](/build/cli) (`aptos`) to produce a hex encoded static
x25519 private key. This will be the private key for your network identity. Run the following `aptos` CLI command:

```shellscript filename="Terminal"
aptos key generate --key-type x25519 --output-file /path/to/private-key.txt
```

This command will create a file `private-key.txt` with the private key in it, and a corresponding
`private-key.txt.pub` file with the public key in it. An example `private-key.txt` file and
`private-key.txt.pub` file are shown below:

```shellscript filename="Terminal"
cat ~/private-key.txt
C83110913CBE4583F820FABEB7514293624E46862FAE1FD339B923F0CACC647D%

cat ~/private-key.txt.pub
B881EA2C174D8211C123E5A91D86227DB116A44BB345A6E66874F83D8993F813%
```

2. **Retrieve the peer identity**

Next, retrieve the peer identity from the public key using the `aptos` CLI. The `--host` flag in
the command will provide the host information to output a network address for your PFN. Run the following command
(be sure to update the `--host` flag with your actual host information):

```shellscript filename="Terminal"
aptos key extract-peer --host example.com:6180 \
    --public-network-key-file private-key.txt.pub \
    --output-file peer-info.yaml
```

This command will output the public identity information for your PFN to a file `peer-info.yaml`. For example:

```json
{
  "Result": {
    "B881EA2C174D8211C123E5A91D86227DB116A44BB345A6E66874F83D8993F813": {
      "addresses": [
        "/dns/example.com/tcp/6180/noise-ik/0xB881EA2C174D8211C123E5A91D86227DB116A44BB345A6E66874F83D8993F813/handshake/0"
      ],
      "keys": [
        "0xB881EA2C174D8211C123E5A91D86227DB116A44BB345A6E66874F83D8993F813"
      ],
      "role": "Upstream"
    }
  }
}
```

In this example, `B881EA2C174D8211C123E5A91D86227DB116A44BB345A6E66874F83D8993F813` is the `peer_id`.

3. **Start a PFN with the identity**

After extracting the peer identity from the public key, you can start your PFN with the identity using the
public key in the `peer_id` field of the configuration file (e.g., `fullnode.yaml`). For example:

```yaml filename="fullnode.yaml"
full_node_networks:
  - network_id: "public"
discovery_method: "onchain"
identity:
  type: "from_config"
  key: "<PRIVATE_KEY>"
  peer_id: "<PEER_ID>"
```

In our example (from above), the configuration file (`fullnode.yaml`) should now have the following information:

```yaml filename="fullnode.yaml"
full_node_networks:
  - network_id: "public"
    discovery_method: "onchain"
    identity:
      type: "from_config"
      key: "C83110913CBE4583F820FABEB7514293624E46862FAE1FD339B923F0CACC647D"
      peer_id: "B881EA2C174D8211C123E5A91D86227DB116A44BB345A6E66874F83D8993F813"
```

Starting your PFN with this configuration will assign your PFN with the static network identity you generated.

### Using Docker

If you use Docker to run your PFN, follow these steps:

1. **Prepare your tools**

First, `cd` into the directory for your local PFN and start a Docker container with the latest tools, for example:

```shellscript filename="Terminal"
cd ~/my-full-node
docker run -it aptoslabs/tools:devnet /bin/bash
```

2. **Generate the private key**

Next, follow the remaining steps from inside the `aptoslabs/tools` Docker container.

Open a new terminal and `cd` into the directory where you started the Docker container for your PFN. Making
sure to provide the **full path** to where you want the private key file to be stored, run the command:

```shellscript filename="Terminal"
aptos key generate \
    --key-type x25519 \
    --output-file /path/to/private-key.txt
```

3. **Retrieve the peer identity**

Next, retrieve the peer identity from the public key using the `aptos` CLI. The `--host` flag in
the command will provide the host information to output a network address for your PFN. Run the following command
(be sure to update the `--host` flag with your actual host information):

```shellscript filename="Terminal"
aptos key extract-peer --host example.com:6180 \
    --public-network-key-file private-key.txt.pub \
    --output-file peer-info.yaml
```

This command will output the public identity information for your PFN to a file `peer-info.yaml`. For example:

```json
{
  "Result": {
    "B881EA2C174D8211C123E5A91D86227DB116A44BB345A6E66874F83D8993F813": {
      "addresses": [
        "/dns/example.com/tcp/6180/noise-ik/0xB881EA2C174D8211C123E5A91D86227DB116A44BB345A6E66874F83D8993F813/handshake/0"
      ],
      "keys": [
        "0xB881EA2C174D8211C123E5A91D86227DB116A44BB345A6E66874F83D8993F813"
      ],
      "role": "Upstream"
    }
  }
}
```

In this example, `B881EA2C174D8211C123E5A91D86227DB116A44BB345A6E66874F83D8993F813` is the `peer_id`.

4. **Start a PFN with the identity**

After extracting the peer identity from the public key, you can start your PFN with the identity using the
public key in the `peer_id` field of the configuration file (e.g., `fullnode.yaml`). For example:

```yaml
full_node_networks:
  - network_id: "public"
discovery_method: "onchain"
identity:
  type: "from_config"
  key: "<PRIVATE_KEY>"
  peer_id: "<PEER_ID>"
```

In our example (from above), the configuration file (`fullnode.yaml`) should now have the following information:

```yaml
full_node_networks:
  - network_id: "public"
    discovery_method: "onchain"
    identity:
      type: "from_config"
      key: "C83110913CBE4583F820FABEB7514293624E46862FAE1FD339B923F0CACC647D"
      peer_id: "B881EA2C174D8211C123E5A91D86227DB116A44BB345A6E66874F83D8993F813"
```

Starting your PFN with this configuration will assign your PFN with the static network identity you generated.

## Check your node identity

If you want to check the identity of your node at runtime, there are several ways to do so. Two of the simplest
methods are:

- **Using the REST API**: You can query the `/v1/info` endpoint of your node's [REST API](/build/apis/fullnode-rest-api)
  to retrieve the identity information.
- **Using the Node Inspection Service**: You can query the `/identity_information` endpoint on your node's inspection service
  to retrieve the identity information of your node. You can read more [here](/network/nodes/measure/node-inspection-service#examine-identity-information).

<Aside type="note">
  Nodes with multiple network connection types (e.g., `VFN` and `public` networks) will have identities for each connection type.
  For public fullnodes (PFNs), there is only one network connection type (`public`), so there will be only one identity.
</Aside>

# Upgrade your PFN

> Step-by-step guide to update your public fullnode (PFN) with new Aptos releases including source code, Docker, and Terraform deployment methods.

import { Aside } from '@astrojs/starlight/components';

This document outlines the process for updating your PFN with new Aptos releases. All PFNs will need to be updated
when new releases are available. For PFNs running in `devnet`, an additional data wipe step is required as `devnet`
is wiped on every new release.

## Source code deployment

If you run your PFN from the [aptos-core][aptos-labs/aptos-core] source code, you can update your PFN by
following these steps:

1. Stop your PFN by running the command below (or killing the `aptos-node` process manually):

   ```shellscript filename="Terminal"
   cargo stop aptos-node
   ```

2. Fetch the latest release appropriate for your network, e.g., `devnet`, `testnet`, or `mainnet`. Be sure to replace
   `[network_branch]` with the appropriate branch name below:

   ```shellscript filename="Terminal"
   git checkout [network_branch] && git pull
   ```

3. Rebuild the binary as you did during the initial setup.

4. If your PFN is running in `devnet`, follow the additional steps in the [Data Wipe and Reset](#upgrade-with-data-wipe-devnet-only) section below.

5. Restart your PFN by running the same deployment command as before. For example:

   ```shellscript filename="Terminal"
   cargo run -p aptos-node --release -- -f ./fullnode.yaml
   ```

### (Devnet) Data Wipe and Reset

<Aside type="caution">
  **Devnet only wipe**<br />
  Only follow these additional steps if your PFN is running in `devnet`. Other networks (e.g., `testnet` and `mainnet`)
  don't require this step (as data is never wiped)!
</Aside>

If your PFN is running in `devnet`, follow these additional steps after stopping your PFN (and before restarting it!):

1. Delete the data folder (the directory path is what you specified in the configuration file, e.g., `fullnode.yaml`).

   - The default data folder is `/opt/aptos/data`.

2. Delete the `genesis.blob` file and `waypoint.txt` file (depending on how you configured it, you might not have this file and may instead have a `waypoint` directly in your configuration file).

3. Download the new [genesis.blob](/network/nodes/configure/node-files-all-networks/node-files-devnet#genesisblob) file and the new [waypoint](/network/nodes/configure/node-files-all-networks/node-files-devnet#waypointtxt).

4. Update the configuration file (e.g., `fullnode.yaml`) with the new genesis.blob and waypoint files.

5. Restart your PFN by running the same deployment command as before.

## Docker deployment

If you run your PFN from a Docker image, you can update your PFN by:

1. Stop your PFN by running the command below:
   ```shellscript filename="Terminal"
   docker compose down --volumes
   ```
2. (Devnet only!) If your PFN is running in `devnet`, delete the entire directory which holds your PFN config and data directory.
3. Re-install and configure those files as during the original setup.
4. Restart your PFN by running the same deployment command as before. For example:
   ```shellscript filename="Terminal"
   docker compose up -d
   ```

## GCP deployment

If you run your PFN in GCP, follow the steps below to update your PFN. Note: if your PFN is
running in `devnet`, an additional data wipe step is required.

### Upgrade with data wipe (devnet only)

<Aside type="caution">
  **Devnet only wipe**<br />
  Only follow these steps if your PFN is running in `devnet`. Other networks don't require this step (as data is never wiped)
  and we recommend not wiping your data in these networks.
</Aside>

If you are running a `devnet` PFN, follow these steps to update:

1. Increase the `era` number in `main.tf` to trigger a new data volume creation, which will start the PFN on a new DB.

2. Update the `image_tag` in `main.tf` to contain the new release version.

3. Update the Terraform module for the PFN (run this in the same directory of your `main.tf` file):

```shellscript filename="Terminal"
terraform get -update
```

4. Apply the Terraform changes:

```shellscript filename="Terminal"
terraform apply
```

### Upgrade without data wipe

If you are not running a `devnet` PFN, follow these steps to update:

1. Update the `image_tag` in `main.tf`.

2. Update the Terraform module for the PFN (run this in the same directory of your `main.tf` file):

```shellscript filename="Terminal"
terraform get -update
```

3. Apply the Terraform changes:

```shellscript filename="Terminal"
terraform apply

# If you didn't update the image tag, terraform will show nothing to change, in this case, force a helm update
terraform apply -var force_helm_update=true
```

[rest_spec]: https://github.com/aptos-labs/aptos-core/tree/main/api

[devnet_genesis]: https://devnet.aptoslabs.com/genesis.blob

[devnet_waypoint]: https://devnet.aptoslabs.com/waypoint.txt

[aptos-labs/aptos-core]: https://github.com/aptos-labs/aptos-core.git

[status dashboard]: https://status.devnet.aptos.dev

# PFN Requirements

> Hardware, network, storage, and port requirements for running a production-grade public fullnode (PFN) on the Aptos blockchain.

import { Aside } from '@astrojs/starlight/components';

To ensure that your public fullnode (PFN) operates smoothly, it should meet the requirements specified in this document.

## Hardware requirements

<Aside type="caution">
  **Minimum hardware requirements**<br />
  Failing to meet the minimum hardware requirements mean that your PFN will experience degradation under
  load and general instability in production environments. It is not recommended to run a PFN without
  meeting the minimum hardware requirements.
</Aside>

For running a production-grade PFN, we recommend that your hardware meet the same requirements as a
validator or VFN. You can see the hardware requirements for these, here: [validator and VFN hardware requirements](/network/nodes/validator-node/node-requirements#hardware-requirements).

<Aside type="note">
  **Testing PFNs**<br />
  If you wish to run a PFN for development or testing only, lower hardware specs can be used.
  But, it should not be used in production.
</Aside>

## Network requirements and ports

When you are running a PFN, you are required to open network ports on your nodes to allow other nodes (i.e., peers)
to connect to you. There are different Aptos network types, and each network type uses a different port. However,
the only network type that a PFN uses is the public network, where PFNs to connect to other PFNs and VFNs.

Your PFN can be configured so that the public network operates using a specific port on your node. You can configure
the port settings using the node configuration YAML file. Here is an [example
configuration file](https://github.com/aptos-labs/aptos-core/blob/main/config/src/config/test_data/public_full_node.yaml#L16) for a PFN
that configures the public network to use port `6180`.

### Port settings

The recommendations described below assume the default port settings used by PFNs. If you have
changed the default port settings in your configuration file, then you should adjust the recommendations accordingly.

<Aside type="caution">
  **Exposing ports**<br />
  Unless explicitly required, we recommend that you do not expose any other ports while operating a PFN. This is because
  exposing additional ports can increase the attack surface of your node and make it more vulnerable to adversaries.
</Aside>

#### Running a PFN:

Assuming default ports are used, the following should be configured for PFNs:

- Open the following TCP ports:
  - `6182` ‚Äì **Public network**: Open this port publicly to enable other PFNs to connect to your PFN.
- Close the following TCP ports:
  - `9101` ‚Äì **Inspection service**: Close this port to prevent unauthorized metric inspection.
  - `9102` ‚Äì **Admin service**: Close this port to prevent unauthorized admin service interaction.
  - `80/8080` - **REST API**: Close this port to prevent unauthorized REST API access.

<Aside type="caution">
  **Exposing services**<br />
  The inspection service port (`9101`), admin service port (`9102`) and the REST API port (`80` or `8080`)
  are likely useful for your internal network, e.g., application development and debugging. However, the inspection service
  port and the admin service port should never be exposed publicly as they can be easily abused. Similarly, if you choose
  to expose the REST API endpoint publicly, you should deploy an additional authentication or rate-limiting mechanism to
  prevent abuse.
</Aside>

## Storage requirements

The amount of data stored by Aptos PFNs depends on the ledger history (length) of the blockchain and the number of
on-chain states (e.g., accounts and resources). Both the ledger history and the number of
on-chain states depend on several additional factors, including the age of the blockchain, the average transaction
rate over time, and the configuration of the ledger database pruner. At the time of writing, we estimate
that testnet and mainnet PFNs require several 100's of GB of storage.

Note that because archival nodes store the entire history of the blockchain, the database size on archival nodes
will continue to grow unbounded. As a result, we cannot provide a recommendation for archival node storage sizes.

<Aside type="note">
  **Devnet blockchain storage**<br />
  The Aptos devnet is currently reset on a weekly basis. If you are deploying a devnet PFN, this means that the storage
  will be reset (i.e., wiped) every week. See the `#devnet-release` channel on the [Aptos Discord](https://discord.gg/aptosnetwork).
</Aside>

# Verify a PFN

> Monitor and verify your public fullnode (PFN) operation by checking synchronization status, network connections, and storage metrics.

import { Aside } from '@astrojs/starlight/components';

After deploying your PFN, you can verify that it is operating correctly by checking several of the PFN's metrics.
This document describes the common types of checks that you might wish to perform.

<Aside type="note">
  You can learn more about Aptos metrics in the [Node Inspection Service](/network/nodes/measure/node-inspection-service) documents.
</Aside>

### Verify synchronization

During the initial synchronization of your PFN, there may be a lot of data to transfer (read more about how state
sync works in the [state sync](/network/nodes/configure/state-sync) guide). You can monitor state sync progress
by querying the metrics port to see what version your node is currently synced to. Run the following example
command to see the currently synced version of your node:

```shellscript filename="Terminal"
curl 127.0.0.1:9101/metrics 2> /dev/null | grep "aptos_state_sync_version{.*\"synced\"}" | awk '{print $2}'
```

The command will output the current synced version of your node. For example:

```shellscript filename="Terminal"
71000
```

Compare the synced version returned by this command (e.g., `71000`) with the highest version shown on the
[Aptos explorer page](https://explorer.aptoslabs.com/?network=mainnet). If your node is catching up to the highest
version, it is synchronizing correctly. It is fine if the explorer page differs by a few versions, as the explorer
nodes may sync with some variance.

<Aside type="caution">
  **Using fast sync?**<br />
  If your node is fast syncing, the command may show `0` until it has finally caught up. To verify that the node is
  fast syncing, run the following command:

  ```shellscript filename="Terminal"
  curl 127.0.0.1:9101/metrics 2> /dev/null | grep "aptos_state_sync_version{.*\"synced_states\"}" | awk '{print $2}'
  ```

  This should show an increasing number of synced states. It may take several hours for your node to fast sync to the
  latest version. Eventually, once fast syncing is complete, the `aptos_state_sync_version{.*"synced"}` command will
  return the current synced version of your node.

  You can read more about fast syncing here: [State sync bootstrapping](/network/nodes/configure/state-sync#bootstrapping-phase).
</Aside>

### (Optional) Verify outbound network connections

If you wish, you can also check the outbound network connections for your PFN. The number of outbound network
connections should be more than `0` for healthy PFNs. Run the following command:

```shellscript filename="Terminal"
curl 127.0.0.1:9101/metrics 2> /dev/null | grep "aptos_connections{direction=\"outbound\""
```

The above command will output the number of outbound network connections for your node. For example:

```shellscript filename="Terminal"
curl 127.0.0.1:9101/metrics 2> /dev/null | grep "aptos_connections{direction=\"outbound\""
aptos_connections{direction="outbound",network_id="Public",peer_id="aabd651f",role_type="full_node"} 3
```

If the number of outbound connections returned is `0`, then it means your node cannot connect to the Aptos blockchain. If this happens to you, follow these steps to resolve the issue:

1. Update your node to the latest release by following the [Update your Node](/network/nodes/full-node/modify/update-fullnode-with-new-releases).
2. Remove any `seed` peers you may have added to your configuration file. The seeds may be preventing you from
   connecting to the network. Seed peers are discussed in the [Connecting your PFN to seed peers](/network/nodes/full-node/modify/fullnode-network-connections#connecting-to-seed-peers) section.
3. Ensure that you have used the correct `genesis.blob` and `waypoint.txt` files for your network. This is a common error.

### (Optional) Examine Docker ledger size

If you are running your PFN using Docker, you can monitor the size of the blockchain ledger by entering the Docker
container and checking the size. This will allow you to see how much storage the blockchain ledger is currently consuming.

- First, run `docker container ls` on your terminal and copy the NAME field output. This will be a string similar to `public_full_node_fullnode_1`.
- Next, run these commands to check the storage size consumed by the ledger, using the NAME field you copied over in place of `public_full_node_fullnode_1`:

```shellscript filename="Terminal"
# Obtain the container ID:
id=$(docker container ls | grep public_full_node_fullnode_1 | grep -oE "^[0-9a-zA-Z]+")

# Enter the container:
docker exec -it $id /bin/bash

# Observe the volume (ledger) size:
du -cs -BM /opt/aptos/data
```

[rest_spec]: https://github.com/aptos-labs/aptos-core/tree/main/api

[devnet_genesis]: https://devnet.aptoslabs.com/genesis.blob

[devnet_waypoint]: https://devnet.aptoslabs.com/waypoint.txt

[aptos-labs/aptos-core]: https://github.com/aptos-labs/aptos-core.git

[status dashboard]: https://status.devnet.aptos.dev

# Develop with Localnet

> Run a local Aptos blockchain network for development and testing applications, including CLI-based and source code deployment options.

If you want to develop and test your applications on the Aptos blockchain, you can run a
local network (**localnet**). This network will run on your local machine, and will not be
connected to any other Aptos network. Running a localnet is the easiest way to test and
develop Aptos applications, and make changes to the Aptos node software.

## Recommended Steps

Most developers should use the Aptos CLI to run a local development network. This is the simplest
and easiest way to get started. It provides a local deployment that works just like a production network,
including the [Node API](/build/apis), [Transaction Stream](/build/indexer/txn-stream), [Indexer API](/build/indexer) and [Faucet](/build/apis/faucet-api).

To get started, follow this guide: [Localnet using the Aptos CLI](/network/nodes/localnet/local-development-network)

## Specialized Steps

If you're developing the core Aptos node software, or have more complex testing needs, consider the
guides below. The first guide provides a way to run a localnet with a single validator node, and the
second guide provides a way to run a localnet with multiple validator nodes, and validator
fullnodes (VFNs).

To run a localnet with a single validator node, directly from the `aptos-core` source code, follow this guide:

- [Localnet from source code](/network/nodes/localnet/run-a-localnet)

To run a localnet with multiple validator nodes and validator fullnodes (VFNs), follow this guide:

- [Multi-node Localnet](/network/nodes/localnet/run-a-multinode-localnet)

# Localnet using the Aptos CLI

> Complete guide to running a local Aptos development network using the CLI with Node API, Indexer API, transaction stream, and faucet services.

import { Aside, Steps } from '@astrojs/starlight/components';

Local networks can be helpful when testing your code. They are not connected to any production Aptos networks like mainnet, but they are useful for three main reasons:

1. **No rate limits:** You can interact with hosted services like the Node API, Indexer API, and faucet with no rate-limits to speed up testing.
2. **Reproducibility:** You can set up specific on-chain scenarios and restart the network from scratch at any point to return to a clean slate.
3. **High availability**: The Aptos devnet and testnet networks are periodically upgraded, during which time they can be unavailable. Local development networks are also always available even if you have no internet access.

<br />

# Starting A Local Network

<Steps>
  1. Ensure you have the [Aptos CLI](/build/cli) installed.

     You can verify if the Aptos CLI is installed by running `aptos --version`.

  2. Ensure you have Docker installed.

     You can check whether Docker is installed by running `docker --version`.

     1. This is exclusively needed for making a production-like environment by running the Indexer API. Many downstream tools such as the Aptos SDK depend on the Indexer API.
     2. Docker recommends that you install via [Docker Desktop](https://www.docker.com/products/docker-desktop/) to get automatic updates.

  3. Start Docker.

  4. Run the following command in a new terminal to start the private network:

     ```shellscript filename="Terminal"
     aptos node run-local-testnet --with-indexer-api
     ```

     <Aside type="caution">
       Note: Despite using the name `local-testnet` above, this has nothing to do with the official Aptos testnet. This command will run a network entirely local to your machine.
     </Aside>

     You should expect to see an output similar to this:

     ```shellscript filename="Terminal"
     Readiness endpoint: http://0.0.0.0:8070/

     Indexer API is starting, please wait...
     Node API is starting, please wait...
     Transaction stream is starting, please wait...
     Postgres is starting, please wait...
     Faucet is starting, please wait...

     Completed generating configuration:
             Log file: "/Users/dport/.aptos/testnet/validator.log"
             Test dir: "/Users/dport/.aptos/testnet"
             Aptos root key path: "/Users/dport/.aptos/testnet/mint.key"
             Waypoint: 0:397412c0f96b10fa3daa24bfda962671c3c3ae484e2d67ed60534750e2311f3d
             ChainId: 4
             REST API endpoint: http://0.0.0.0:8080
             Metrics endpoint: http://0.0.0.0:9101/metrics
             Aptosnet fullnode network endpoint: /ip4/0.0.0.0/tcp/6181
             Indexer gRPC node stream endpoint: 0.0.0.0:50051

     Aptos is running, press ctrl-c to exit

     Node API is ready. Endpoint: http://0.0.0.0:8080/
     Postgres is ready. Endpoint: postgres://postgres@127.0.0.1:5433/local_testnet
     Transaction stream is ready. Endpoint: http://0.0.0.0:50051/
     Indexer API is ready. Endpoint: http://127.0.0.1:8090
     Faucet is ready. Endpoint: http://127.0.0.1:8081/

     Applying post startup steps...

     Setup is complete, you can now use the local testnet!
     ```

  5. Wait for the network to start

     Once the terminal says `Setup is complete, you can now use the local testnet!` the local network will be running.

     <Aside type="caution">
       If you ran into an error, look at the common errors below to debug.
     </Aside>

     <details>
       <summary>Common Errors On Network Startup</summary>

       ### Address Already In Use

       ```shellscript filename="Terminal"
       panicked at 'error binding to 0.0.0.0:8080: error creating server listener: Address already in use (os error 48)'
       ```

       This means one of the ports needed by the local network is already in use by another process.

       To fix this on Unix systems, you can:

       1. Identify the name and PID of the process by running `lsof -i :8080`.
       2. Run `kill <pid>` once you know the PID to free up that port.

       ### Too many open files error

       ```shellscript filename="Terminal"
       panicked at crates/aptos/src/node/local_testnet/logging.rs:64:10:
       called \`Result::unwrap()\` on an \`Err\` value: Os { code: 24, kind: Uncategorized, message: \"Too many open files\" }
       ```

       This means there were too many open files on your system. On many Unix systems you can increase the maximum number of open files by adding something like this to your `.zshrc`:

       ```shellscript filename="Terminal"
       ulimit -n 1048576
       ```

       ### Docker is not available

       ```shellscript filename="Terminal"
       Unexpected error: Failed to apply pre-run steps for Postgres: Docker is not available, confirm it is installed and running. On Linux you may need to use sudo
       ```

       To debug this, try the below fixes:

       1. Make sure you have docker installed by running `docker --version`.
       2. Ensure the Docker daemon is running by running `docker info` (if this errors saying `Cannot connect to the Docker daemon` Docker is NOT running)
       3. Make sure the socket for connecting to Docker is present on your machine in the default location. For example, on Unix systems `/var/run/docker.sock` should exist.
          1. If that file does not exist, open Docker Desktop and enable `Settings -> Advanced -> Allow the default Docker socket to be used.`
          2. Or, you can find where the Docker socket is by running `docker context inspect | grep Host`, then symlink that location to the default location by running `sudo ln -s /Users/dport/.docker/run/docker.sock /var/run/docker.sock`
     </details>

     As you can see from the example output in step 4, once the local network is running, you have access to the following services:

     {/* TODO: replace API spec link */}

     - [Node API](/rest-api): This is a REST API that runs directly on the node. It enables core write functionality such as transaction submission and a limited set of read functionality, such as reading account resources or Move module information.
     - [Indexer API](/build/indexer/indexer-api): This is a [GraphQL](https://graphql.org/) API that provides rich read access to indexed blockchain data. If you click on the URL for the Indexer API above, by default [http://127.0.0.1:8090](http://127.0.0.1:8090), it will open the Hasura Console, a web UI that will help you query the Indexer GraphQL API.
     - [Transaction Stream Service](/build/indexer/txn-stream): This is a gRPC stream of transactions used by the Indexer API. This is only relevant to you if you are developing an [Indexer SDK](/build/indexer/indexer-sdk) custom processor.
     - [Postgres](https://www.postgresql.org/): This is the database that the Indexer processors write to. The Indexer API reads from this database.
     - [Faucet](/build/apis/faucet-api): You can use this to fund accounts on your local network.

     If you do not want to run any of these sub-components of a network, there are flags to disable them.

     If you are writing a script and would like to wait for the local network to come up with all services, you can make a GET request to `http://127.0.0.1:8070`. At first this will return http code [503](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/503). When it returns [200](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/200) it means all the services are ready.

     For more information on different flags you can pass when starting your local network, or configuration settings such as changing which port certain services run on, run the help command:

     ```shellscript filename="Terminal"
     aptos node run-local-testnet --help
     ```
</Steps>

## Using The Local Network

Now that the network is running, you can use it like you would any other network.

So, you can create a local profile like this:

```shellscript filename="Terminal"
aptos init --profile <your-profile-name> --network local
```

You can then use that profile for any commands you want to use going forward. For example, if you wanted to publish a Move module like the [`hello_blockchain`](https://github.com/aptos-labs/aptos-core/tree/main/aptos-move/move-examples/hello_blockchain) package to your local network you could run:

```shellscript filename="Terminal"
aptos move publish --profile <your-profile-name> --package-dir /opt/git/aptos-core/aptos-move/move-examples/hello_blockchain --named-addresses HelloBlockchain=local
```

### Configuring the TypeScript SDK

If you want to use the local network with the TypeScript SDK, you can use local network URLs when initializing the client object (`Aptos`):

```tsx
import { Aptos, AptosConfig, Network } from "@aptos-labs/ts-sdk";

const network = Network.LOCAL;
const config = new AptosConfig({ network });
const client = new Aptos(config);
```

### Resetting the local network

Sometimes while developing it is helpful to reset the local network back to its initial state, for example:

- You made backwards incompatible changes to a Move module, and you'd like to redeploy it without renaming it or using a new account.
- You are building a [custom indexer processor](/build/indexer) and would like to index using a fresh network.
- You want to clear all on chain state, e.g. accounts, objects, etc.

To start with a brand new local network, use the `--force-restart` flag:

```shellscript filename="Terminal"
aptos node run-local-testnet --force-restart
```

It will then prompt you if you really want to restart the chain, to ensure that you do not delete your work by accident.

```shellscript filename="Terminal"
Are you sure you want to delete the existing chain? [yes/no]
> yes
```

If you do not want to be prompted, include `--assume-yes` as well:

```shellscript filename="Terminal"
aptos node run-local-testnet --force-restart --assume-yes
```

## Running in a container

If you want to run the localnet using a Docker container, you can do it like this:

```shellscript
docker run \
   --platform linux/amd64 \
   -v /var/run/docker.sock:/var/run/docker.sock \
   --network host \
   -v /tmp/testnet:/testnet \
   aptoslabs/tools:nightly \
   aptos node run-local-testnet \
   --test-dir /testnet \
   --with-indexer-api
```

Instead of `nightly` you can use any tag from [here](https://hub.docker.com/r/aptoslabs/tools/tags).

Note: `-v /var/run/docker.sock:/var/run/docker.sock` allows the CLI to run other containers using the host Docker daemon, for example Postgres and Hasura for the indexer API. You don't have to do this if you are not setting `--with-indexer-api`.

Note: If this fails because `/var/run/docker.sock` doesn't exist, see the [Docker is not available](#docker-is-not-available) section above.

# Localnet from source code

> Run a local Aptos network from aptos-core source code for testing modifications to the codebase or Aptos Framework with single validator setup.

import { Aside } from '@astrojs/starlight/components';

You can run a localnet using the [aptos-core](https://github.com/aptos-labs/aptos-core) source code. This approach is useful for testing modifications to the aptos-core codebase or to the Aptos Framework.

<Aside type="note">
  It is easier to run a localnet using the [Aptos CLI](/network/nodes/localnet/local-development-network) than it is to run it from source code. The CLI also provides a more user-friendly experience and additional features.
  Learn how by following this guide: [Localnet using the Aptos CLI](/network/nodes/localnet/local-development-network).
</Aside>

The rest of this document describes:

- How to start your localnet with a single validator node.
- How to start a Faucet service and attach it to your localnet.

## Using the Aptos-core source code

1. Follow steps in [Building Aptos From Source](/network/nodes/building-from-source)

2. With your development environment ready, you can start your localnet.

   <Aside type="note">
     - When you run the below command to start the localnet, your terminal will enter into an interactive mode, with a message `Aptos is running, press ctrl-c to exit`. Hence, you will need to open another shell terminal for the subsequent steps described in this section.
     - After the below command runs, copy the `Test dir` information from the terminal output for the next step.
   </Aside>

   To start your localnet, run the following command:

   ```shellscript filename="Terminal"
   CARGO_NET_GIT_FETCH_WITH_CLI=true cargo run -p aptos-node -- --test
   ```

   See below for an example of the partial output. Make a note of the `Test dir` from the output.

   ```shellscript filename="Terminal"
   ...
   ...
   ...

   Completed generating configuration:
       Log file: "/private/var/folders/gn/m74t8ylx55z935q8wx035qn80000gn/T/b3adc18c144bfcc78a1541953893bc1c/validator.log"
       Test dir: "/private/var/folders/gn/m74t8ylx55z935q8wx035qn80000gn/T/b3adc18c144bfcc78a1541953893bc1c/0/node.yaml"
       Aptos root key path: "/private/var/folders/gn/m74t8ylx55z935q8wx035qn80000gn/T/b3adc18c144bfcc78a1541953893bc1c/mint.key"
       Waypoint: 0:47e676b5fe38ebe2aec6053db7b3daa0b805693d6422e3475e46e89499464ecf
       ChainId: TESTING
       REST API endpoint: 0.0.0.0:8080
       Fullnode network: /ip4/0.0.0.0/tcp/7180
   Aptos is running, press ctrl-c to exit
   ```

<Aside type="tip">
  The above command starts a localnet with a single validator node. The command runs `aptos-node` from a genesis-only ledger state. If you want to reuse the ledger state produced by a previous run of `aptos-node`, then use:

  ```shellscript filename="Terminal"
  cargo run -p aptos-node -- --test --config <config-path>
  ```
</Aside>

### Attaching a Faucet to your localnet

Faucets are stateless services that can be run in parallel with the localnet. A Faucet is a way to create Aptos test coins with no real-world value. You can use the Faucet by sending a request to create coins and transfer them into a given account on your behalf.

1. Make sure that you started your localnet as described in Step 5 above.
2. Open a new shell terminal.
3. Copy the _Aptos root key path_ from your terminal where you started the localnet, and use it to replace the `mint-key-file-path` in the below command.
4. Run the following command to start a Faucet:

```shellscript filename="Terminal"
cargo run --package aptos-faucet-service -- run-simple --key-file-path "/tmp/694173aa3bbe019499bbd5cf3fe0e2fc/mint.key" --node-url http://127.0.0.1:8080 --chain-id TESTING
```

This will start a Faucet running locally without any restrictions to tokens that can be claimed and minted. This Faucet service will be as accessible as the localnet you started above.

## Interacting with the localnet

After starting your localnet, you will see the following:

```shellscript filename="Terminal"
Entering test mode, this should never be used in production!
Completed generating configuration:
        Log file: "/tmp/694173aa3bbe019499bbd5cf3fe0e2fc/validator.log"
        Test dir: "/tmp/694173aa3bbe019499bbd5cf3fe0e2fc/0/node.yaml"
        Aptos root key path: "/tmp/694173aa3bbe019499bbd5cf3fe0e2fc/mint.key"
        Waypoint: 0:197bc8b76761622c2d2054d8bf93c1802fa0eb4bc55f0f3d4442878fdecc297f
        ChainId: TESTING
        REST API endpoint: 0.0.0.0:8080
        Fullnode network: /ip4/0.0.0.0/tcp/7180

Aptos is running, press ctrl-c to exit
```

Use the [Aptos CLI tool](/build/cli) to interact with your localnet. The above output contains information you will use for starting the [Aptos CLI tool](/build/cli):

- `Aptos root key path`: The root key (also known as the mint or faucet key) controls the account that can mint tokens. Available in the docker compose folder under `aptos_root_key`.
- `Waypoint`: A verifiable checkpoint of the blockchain (available in the docker compose folder under waypoint.txt)
- `REST endpoint`: The endpoint for the REST service, e.g., `http://127.0.0.1:8080`.
- `ChainId`: The chain ID uniquely distinguishes this network from other blockchain networks.

## Next steps

At this point, you will have a special root account at `0x1` that can perform the mint operation. Follow up with some tutorials such as on [Aptos Learn workshops](https://learn.aptoslabs.com/en/workshops)

# Multi-node Localnet

> Deploy a local network with multiple validator nodes and validator fullnodes using Aptos Forge for advanced testing and development scenarios.

import { Aside } from '@astrojs/starlight/components';

This guide describes how to run a local network with multiple validator nodes and validator fullnodes. You will use [Aptos Forge](https://github.com/aptos-labs/aptos-core/tree/main/testsuite/forge-cli/src) in the [aptos-core](https://github.com/aptos-labs/aptos-core) source code for this.

<Aside type="note">
  The steps described in this guide should only be used for test networks of multi-node local networks. Do not use this guide for deploying networks in production environments.
  This guide also assumes that you have completed the steps in [Building Aptos From Source](/network/nodes/building-from-source).
</Aside>

## Localnet with multiple validators

To deploy a localnet with multiple local validators, run this command from the root directory of the [aptos-core](https://github.com/aptos-labs/aptos-core) source code:

```sh
cargo run -p aptos-forge-cli \
        -- \
        --suite "run_forever" \
        --num-validators 4 test local-swarm
```

This will start a local network of 4 validators, each running in their own process. The network will run forever unless you manually terminate it.

The terminal output will display the locations of the validator files (for example, the genesis files, logs, node configurations, etc.) and the commands that were run to start each node. The process id (PID) of each node and server addresses (e.g., REST APIs) are also displayed when it starts. For example, if you run the above command you should see:

```text
...
2022-09-01T15:41:27.228289Z [main] INFO crates/aptos-genesis/src/builder.rs:462 Building genesis with 4 validators. Directory of output: "/private/var/folders/dx/c0l2rrkn0656gfx6v5_dy_p80000gn/T/.tmpq9uPMJ"
...
2022-09-01T15:41:28.090606Z [main] INFO testsuite/forge/src/backend/local/swarm.rs:207 The root (or mint) key for the swarm is: 0xf9f...
...
2022-09-01T15:41:28.094800Z [main] INFO testsuite/forge/src/backend/local/node.rs:129 Started node 0 (PID: 78939) with command: ".../aptos-core/target/debug/aptos-node" "-f" "/private/var/folders/dx/c0l2rrkn0656gfx6v5_dy_p80000gn/T/.tmpq9uPMJ/0/node.yaml"
2022-09-01T15:41:28.094825Z [main] INFO testsuite/forge/src/backend/local/node.rs:137 Node 0: REST API is listening at: http://127.0.0.1:64566
2022-09-01T15:41:28.094838Z [main] INFO testsuite/forge/src/backend/local/node.rs:142 Node 0: Inspection service is listening at http://127.0.0.1:64568
...
```

Using the information from this output, you can stop a single node and restart
it. For example, to stop and restart the node `0`, execute the below commands:

```sh
kill -9 <Node 0 PID>
cargo run -p aptos-node \
        -- \
        -f <Location to the node 0 configuration file displayed above>
```

## Faucet and minting

In order to mint coins in this test network you need to run a faucet. You can do that with this command:

```sh
cargo run -p aptos-faucet-service -- run-simple --key <key> --node-url <node_url>
```

You can get the values above like this:

- `key`: When you started the swarm, there was output like this: `The root (or mint) key for the swarm is: 0xf9f...`. This is the `key`.
- `node_url`: When you started the swarm, there was output like this: `REST API is listening at: http://127.0.0.1:64566`. This is the `node_url`.

The above command will run a faucet locally, listening on port `8081`. Using this faucet, you can then mint tokens to your test accounts, for example:

```sh
curl -X POST http://127.0.0.1:8081/mint?amount=<amount to mint>&pub_key=<public key to mint tokens to>
```

As an alternative to using the faucet service, you may use the faucet CLI directly:

```sh
cargo run -p aptos-faucet-cli -- --amount 10 --accounts <account_address> --key <private_key>
```

<Aside type="tip">
  See more on how the faucet works in the [README](https://github.com/aptos-labs/aptos-core/tree/main/crates/aptos-faucet).
  Also see how to use the [Aptos CLI](/build/cli) with an existing faucet.
</Aside>

## Validator fullnodes

To also run validator fullnodes inside the network, use the `--num-validator-fullnodes` flag. For example:

```sh
cargo run -p aptos-forge-cli \
        -- \
        --suite "run_forever" \
        --num-validators 3 \
        --num-validator-fullnodes 1 test local-swarm
```

## Additional usage

To see all tool usage options, run:

```sh
cargo run -p aptos-forge-cli --help
```

# Monitor your Nodes

> Comprehensive node monitoring and inspection tools including metrics collection, health checking, and performance analysis for Aptos nodes.

You have several options for monitoring and inspecting the health and performance of your nodes:

- ### [Node Inspection Service](/network/nodes/measure/node-inspection-service)
- ### [Important Node Metrics](/network/nodes/measure/important-metrics)
- ### [Node Health Checker](/network/nodes/measure/node-health-checker)

# Important Node Metrics

> Key metrics and counters for monitoring Aptos node health including consensus, state sync, networking, and storage performance indicators.

import { Aside } from '@astrojs/starlight/components';

When you visit the metrics endpoint (see [Node Inspection Service](/network/nodes/measure/node-inspection-service)), you will notice that
there are a large number of metrics and counters being produced by your node. Most of these metrics and counters are
useful only for blockchain development and diagnosing hard-to-find issues. As a result, we recommend that node
operators ignore most metrics and pay attention to only the key metrics presented below:

<Aside type="note">
  **Metric instability**<br />
  As Aptos continues to grow and develop the blockchain software, many metrics will come and go.
  As a result, we recommend relying on the presence of only the metrics explicitly mentioned below.
  All other metrics should be considered unstable and may be changed/removed without warning.
</Aside>

### Consensus

If you are running a validator node, the following
[consensus](/network/blockchain/blockchain-deep-dive#consensus) metrics are important:

1. `aptos_consensus_proposals_count`: Counts the number of times the node sent a block
   proposal to the network. The count will increase only when the validator is chosen to be a proposer,
   which depends on the node's stake and leader election reputation. You should expect this metric to
   increase at least once per hour.
2. `aptos_consensus_last_committed_round`: Counts the last committed round of the node.
   During consensus, we expect this value to increase once per consensus round, which should be multiple
   times per second. If this does not happen, it is likely the node is not participating in consensus.
3. `aptos_consensus_timeout_count`: Counts the number of times the node locally timed out while trying
   to participate in consensus. If this counter increases, it is likely the node is not participating
   in consensus and may be having issues, e.g., network difficulties.
4. `aptos_state_sync_executing_component_counters{label="consensus"`: This counter increases
   a few times per second as long as the node is participating in consensus. When this counter stops
   increasing, it means the node is not participating in consensus, and has likely fallen back to state
   synchronization (e.g., because it fell behind the rest of the validators and needs to catch up).

### State sync

If you are running a fullnode (or a validator that still needs to synchronize to the latest blockchain
state), the following [state sync](/network/nodes/configure/state-sync) metrics are important:

1. `aptos_state_sync_version{type="synced"}`: This metric displays the current synced version of the node,
   i.e., the number of transactions the node has processed. If this metric stops increasing, it means the
   node is not syncing. Likewise, if this metric doesn't increase faster than the rate at which new transactions
   are committed to the blockchain, it means the node is unlikely to get and stay up-to-date with the rest of
   the network. Note: if you've selected to use [fast sync](/network/nodes/configure/state-sync#fast-syncing),
   this metric won't increase until all states have been downloaded, which may take some time. See (3) below.
2. `aptos_data_client_highest_advertised_data{data_type="transactions"}`: This metric displays the highest
   version synced and advertised by the peers that your node is connected to. As a result, when this metric is
   higher than `aptos_state_sync_version{type="synced"}` (above) it means your node can see new blockchain data and
   will sync the data from its peers.
3. `aptos_state_sync_version{type="synced_states"}`: This metric counts the number of states that have been
   downloaded while a node is [fast syncing](/network/nodes/configure/state-sync#fast-syncing). If this metric doesn't increase,
   and `aptos_state_sync_version{type="synced"}` doesn't increase (from above), it means the node is not syncing
   at all and an issue has likely occurred.
4. `aptos_state_sync_bootstrapper_errors` and `aptos_state_sync_continuous_syncer_errors`: If your node is
   facing issues syncing (or is seeing transient failures), these metrics will increase each time an error occurs.
   The `error_label` inside these metrics will display the error type.

<Aside type="note">
  Compare the synced version shown by `aptos_state_sync_version{type="synced"}` with the highest version shown on the [Aptos Explorer](https://explorer.aptoslabs.com/?network=mainnet) to see how far behind the latest blockchain version your node is. Remember to select the correct network that your node is syncing to (e.g., `mainnet`).
</Aside>

### Networking

The following network metrics are important, for both validators and fullnodes:

1. `aptos_connections{direction="inbound"` and `aptos_connections{direction="outbound"`: These metrics count
   the number of peers your node is connected to, as well as the direction of the network connection. An `inbound`
   connection means that a peer (e.g., another fullnode) has connected to you. An `outbound` connection means that
   your node has connected to another node (e.g., connected to a validator fullnode).
   1. If your node is a validator, the sum of both `inbound` and `outbound` connections should be equal to the
      number of other validators in the network. Note that only the sum of these connections matter. If all connections
      are `inbound`, or all are `outbound`, this doesn't matter.
   2. If your node is a fullnode, the number of `outbound` connections should be `> 0`. This will ensure your node is
      able to synchronize. Note that the number of `inbound` connections matters only if you want to act as a seed in
      the network and allow other nodes to connect to you as discussed
      [Fullnode Network Connections](/network/nodes/full-node/modify/fullnode-network-connections#allowing-pfn-connections).

### Mempool

The following [mempool](/network/blockchain/blockchain-deep-dive#mempool) metrics are important:

1. `core_mempool_index_size{index="system_ttl"`: This metric displays the number of transactions currently sitting in
   the mempool of the node and waiting to be committed to the blockchain:
   1. If your node is a fullnode, it's highly unlikely that this metric will be `> 0`, unless transactions are actively
      being sent to your node via the REST API and/or other fullnodes that have connected to you. Most fullnode operators
      should ignore this metric.
   2. If your node is a validator, you can use this metric to see if transactions from your node's mempool are being
      included in the blockchain (e.g., if the count decreases). Likewise, if this metric only increases, it means
      that either: (i) your node is unable to forward transactions to other validators to be included in the blockchain; or
      (ii) that the entire blockchain is under heavy load and may soon become congested.

### REST API

The following [REST API](/build/apis) metrics are important: {/* TODO Maybe replace with API spec */}

1. `aptos_api_requests_count{method="GET"` and `aptos_api_requests_count{method="POST"`: These metrics count
   the number of REST API `GET` and `POST` requests that have been received via the node's REST API. This
   allows you to monitor and track the amount of REST API traffic on your node. You can also further use the
   `operation_id` in the metric to monitor the types of operations the requests are performing.

2. `aptos_api_response_status_count`: This metric counts the number of response types that were sent for
   the REST API. For example, `aptos_api_response_status_count{status="200"}` counts the number of requests
   that were successfully handled with a `200` response code. You can use this metric to track the success and
   failure rate of the REST API traffic.

# Node Health Checker

> Use the Aptos Node Health Checker (NHC) service to evaluate and monitor the health of your fullnodes by comparing against baseline configurations.

import { Aside, Steps } from '@astrojs/starlight/components';

The Aptos Node Health Checker (NHC) service can be used to check the health of any Aptos fullnodes (VFNs or PFNs).
If you are a node operator, use the NHC service to check if your node is running correctly. The NHC service evaluates
your node's health by comparing against a baseline node configuration, and outputs the evaluation results.

This document describes how to run NHC locally when you are operating a node.

<Aside type="note">
  If you don't want to run the NHC service yourself, you can use the
  [publicly available NHC service](https://nodetools.aptosfoundation.org/#/node_checker) run by the Aptos Foundation.
</Aside>

## Quickstart

Before you get into the details of how NHC works, you can run the below steps to start the NHC service and send it a request. This tutorial uses a baseline configuration for a devnet fullnode, i.e., it will evaluate your node against a devnet fullnode that is configured with the baseline configuration YAML.

**Important**: If your local node is not a devnet fullnode, you must use a different baseline config. See [the configuration examples in aptos-core](https://github.com/aptos-labs/aptos-core/tree/main/ecosystem/node-checker/configuration_examples) for other such example configs.

<Steps>
  1. Download the baseline configuration YAML

     Download a baseline configuration YAML file for a devnet fullnode. The below command will download the `devnet_fullnode.yaml` configuration file:

     ```shellscript filename="Terminal"
     mkdir /tmp/nhc
     cd /tmp/nhc
     wget https://raw.githubusercontent.com/aptos-labs/aptos-core/main/ecosystem/node-checker/configuration_examples/devnet_fullnode.yaml
     ```

  2. Start the NHC service

     Start the NHC service by providing the above-downloaded `devnet_fullnode.yaml` baseline configuration YAML file:

     ```shellscript filename="Terminal"
     docker run -v /tmp/nhc:/nhc -p 20121:20121 -t aptoslabs/node-checker:nightly /usr/local/bin/aptos-node-checker server run --baseline-config-paths /nhc/devnet_fullnode.yaml
     ```

  3. Send a request to NHC service

     Finally, send a request to the NHC service you started above. The following command runs health checks of your node that is at `node_url=http://mynode.mysite.com` and compares these results with the node configured in the baseline configuration `devnet_fullnode`:

     ```shellscript filename="Terminal"
     curl 'http://localhost:20121/check?node_url=http://mynode.mysite.com&api_port=80&baseline_configuration_id=devnet_fullnode'
     ```

     You will see output similar to this:

     ```json filename="Terminal"
     {
       "check_results": [
         {
           "headline": "Chain ID reported by baseline and target match",
           "score": 100,
           "explanation": "The node under investigation reported the same Chain ID 18 as is reported by the baseline node",
           "checker_name": "node_identity",
           "links": []
         },
         {
           "headline": "Role Type reported by baseline and target match",
           "score": 100,
           "explanation": "The node under investigation reported the same Role Type full_node as is reported by the baseline node",
           "checker_name": "node_identity",
           "links": []
         },
         {
           "headline": "Target node produced valid recent transaction",
           "score": 100,
           "explanation": "We were able to pull the same transaction (version: 3238616) from both your node and the baseline node. Great! This implies that your node is keeping up with other nodes in the network.",
           "checker_name": "transaction_availability",
           "links": []
         }
       ],
       "summary_score": 100,
       "summary_explanation": "100: Awesome!"
     }
     ```
</Steps>

## How NHC works

The NHC runs as a service. When you want to run a health check of your node, you send the HTTP requests to this service.

A single NHC instance can be configured to check the health of multiple node configurations, each of different type, for example:

- A public fullnode connected to the Aptos mainnet.
- A validator node connected to the Aptos testnet.
- A node running in a single node testnet.

### Baseline configuration

In all the above cases, a baseline node is used to compare your node's health. For example, for a public fullnode connected to the Aptos devnet, the baseline node might be a node run by the Aptos team and this node demonstrates optimal performance and participation characteristics.

You will download the baseline configuration YAML before running the NHC service for your node. The baseline node's configuration YAML describes where to find this baseline node (URL + port), what evaluators (e.g., metrics checks, TPS tests, API validations, etc.) the NHC service should run, what parameters the NHC should use for those evaluators, what name the configuration has, and so on. See these [example baseline configuration YAML files](https://github.com/aptos-labs/aptos-core/tree/main/ecosystem/node-checker/configuration_examples).

When you send requests to the NHC service, you must include a baseline configuration. For example, a request to NHC to use `devnet_fullnode` as the baseline configuration will look like this:

```shellscript filename="Terminal"
curl 'http://nhc.aptoslabs.com/check?node_url=http://myfullnode.mysite.com&baseline_configuration_id=devnet_fullnode'
```

### Getting baseline configurations ready

In order to run the NHC service, you must have a baseline configuration that the service can use. You have two options here:

#### Configure a pre-existing YAML

You can find a few [example baseline configuration YAML files](https://github.com/aptos-labs/aptos-core/tree/main/ecosystem/node-checker/configuration_examples) that work for each of the above use cases and more.

Next, download these configuration YAML files into the `/etc/nhc` folder in your host system. For example:

```shellscript filename="Terminal"
mkdir /tmp/nhc
cd /tmp/nhc
configs=(devnet_fullnode testnet_fullnode mainnet_fullnode); for c in ${configs[@]}; do wget https://raw.githubusercontent.com/aptos-labs/aptos-core/main/ecosystem/node-checker/configuration_examples/$c.yaml; done
```

These configurations are not quite ready to be used as they are. You will need to modify certain fields, such as the baseline node address or evaluator set (`evaluators` and `evaluator_args` in the YAML) used. The best way to iterate on this is to run the NHC with a downloaded baseline configuration and see what it says on startup.

### Required files

For some NHC configurations, you will need accompanying files, e.g., `mint.key` to use for running a TPS test against a validator. You should make sure these files are also available to NHC, either on disk or mounted into your container. NHC expects them on startup at a path specified in the baseline configuration YAML.

## Running NHC: Docker

<Aside type="note">
  While the Aptos team hosts our own instances of this service, we encourage node operators to run their own instances.
</Aside>

When you are ready with baseline configuration YAML and the required files, you can run the NHC server with a command like this, for example, with Docker:

```shellscript filename="Terminal"
docker run -v /etc/nhc:/etc/nhc -p 20121:20121 -t aptoslabs/node-checker:nightly /usr/local/bin/aptos-node-checker server run --baseline-config-paths /tmp/nhc/devnet_fullnode.yaml /tmp/nhc/testnet_fullnode.yaml /tmp/nhc/mainnet/fullnode.yaml
```

<Aside type="note">
  You may want to include other environment variables such as `RUST_LOG=info`. As you can see, by default NHC runs on port 20121. Make sure to publish it from the container, as shown in the above command, and ensure the port is open on your host. You may change the port NHC runs on with `--listen-port`.
</Aside>

## Running NHC: Source

First, check out the source:

```shellscript filename="Terminal"
git clone git@github.com:aptos-labs/aptos-core.git
cd aptos-core
```

Depending on your setup, you may want to check out a particular branch, to ensure NHC is compatible with your node, e.g., `git checkout --track devnet`.

Run NHC:

```shellscript filename="Terminal"
cargo run -p aptos-node-checker --release -- server run --baseline-config-paths /tmp/nhc/devnet_fullnode.yaml
```

## Generating the OpenAPI specs

To generate the OpenAPI specs, run the following commands from `ecosystem/node-checker`:

```shellscript filename="Terminal"
cargo run -- server generate-openapi -f yaml > doc/spec.yaml
cargo run -- server generate-openapi -f json > doc/spec.json
```

You can also hit the `/spec.yaml` and `/spec.json` endpoints of the running service.

# Node Health Checker FAQ

> Frequently asked questions about the Aptos Node Health Checker including troubleshooting evaluation failures and understanding latency tests.

The Aptos Node Health Checker (NHC) service can be used to check the health of your node(s). See [Node Health Checker](/network/nodes/measure/node-health-checker) for full documentation on the NHC.

The purpose of this FAQ is to help you understand why your node did not pass a particular health check when you ran NHC for it. If you didn't find the information you wanted in this FAQ, [open an issue](https://github.com/aptos-labs/aptos-core/issues/new/choose), or [open a PR](https://github.com/aptos-labs/aptos-core/pulls) and add the information yourself.

## How does the latency evaluator work?

You are likely here because you were given an NHC evaluation result like this:

```shellscript filename="Terminal"
Average latency too high: The average latency was 1216ms, which is higher than the maximum allowed latency of 1000ms.
```

While the NHC reports 1216ms above, when you `ping` you might see a latency like 600ms. This difference is because when you `ping` an IP, the result you see is a single round trip (where the latency is the round trip time (RTT)). On the other hand, the NHC latency test will a request to the API running on your node. In effect, this means that the NHC will time 2 round trips, because it does the following:

1. SYN
2. SYNACK
3. ACK + Send HTTP request
4. Receive HTTP response

i.e., the NHC must do a TCP handshake (one round trip) and then make an HTTP request (second round trip).

The reason the NHC uses the latency evaluator is to ensure that we can maintain good network performance. In particular, if the latency to your node is too high, it will result in a low TPS and high time to finality, both of which are very important to running a highly performant L1 blockchain. **If you receive this error, you will need to try and improve the latency to your node. We have set high thresholds on this value with the understanding that nodes will be running all over the world**.

# Node Inspection Service

> Access runtime metrics and system information from Aptos nodes through the inspection service for monitoring health and performance.

import { Aside } from '@astrojs/starlight/components';

Aptos nodes collect metrics and system information while running. These metrics provide a way to track,
monitor and inspect the health and performance of the node dynamically, at runtime. Node metrics and system
information can be queried or exported via an inspection service that runs on each node.
To see the list of important metrics and counters, see the [Important Node Metrics](/network/nodes/measure/important-metrics) document.

<Aside type="caution">
  We do not recommend making the inspection service publicly accessible, as it may expose potentially sensitive
  information about your node, such as file paths and directories.
</Aside>

## Inspection service features

If you'd like to examine all the endpoints provided by the inspection service, visit the following URL
once you have started your node:

```sh
http://localhost:9101/
```

This will display a directory of all the endpoints and features offered by the service, for example:

```
Welcome to the Aptos Inspection Service!
The following endpoints are available:
	- /configuration
	- /consensus_health_check
	- /forge_metrics
	- /identity_information
	- /json_metrics
	- /metrics
	- /peer_information
	- /system_information
```

## Examine node metrics

If you'd like to examine the metrics of your node at runtime, visit the following URL:

```sh
http://localhost:9101/metrics
```

This will display the values of all the metrics and counters of your node at the time you queried it.
To see updates to these values, simply refresh the page.

Likewise, if you wish to view the metrics in `json` format, visit the following URL:

```sh
http://localhost:9101/json_metrics
```

## Configure the inspection service

You can configure various aspects of the node inspection service, for example, you can change the port it listens on,
enable or disable certain endpoints, and more. The inspection service is enabled by default, so you do not need to do
anything special once you start your node.

The inspection service should run by default at port `9101`. To change the port the inspection service listens on
(e.g., to `1000`), add the following to your node configuration file:

```yaml filename="fullnode.yaml"
inspection_service:
  port: 1000
```

## Examine node configuration

The inspection service also provides a way to examine the configuration file of your node
at runtime (i.e., the node configuration file that your node started with).

<Aside type="caution">
  By default, the configuration endpoint is disabled as it may expose potentially sensitive
  information about your node, e.g., file paths and directories. We recommend enabling this
  endpoint only if the inspection service is not publicly accessible.
</Aside>

To enable this feature, add the following to your node configuration file:

```yaml filename="fullnode.yaml"
inspection_service:
  expose_configuration: true
```

And visit the configuration URL:

```sh
http://localhost:9101/configuration
```

## Examine system information

Likewise, the inspection service also provides a way to examine the system information of your node
at runtime (i.e., build and hardware information). Simply visit the following URL:

```sh
http://localhost:9101/system_information
```

If you'd like to disable this endpoint, add the following to your node configuration file:

```yaml filename="fullnode.yaml"
inspection_service:
  expose_system_information: false
```

<Aside type="note">
  The system information displayed here is not guaranteed to be 100% accurate due to limitations
  in the way this information is collected.
</Aside>

## Examine identity information

The inspection service also provides an easy way to examine the identity of your node
(i.e., the peer ID for each network) at runtime. Simply visit the following URL:

```sh
http://localhost:9101/identity_information
```

If you'd like to disable this endpoint, add the following to your node configuration file:

```yaml filename="fullnode.yaml"
inspection_service:
  expose_identity_information: false
```

# Aptos Networks

> Overview of Aptos blockchain networks including Localnet, Devnet, Testnet, and Mainnet with their properties, URLs, and configuration details.

## Network Overview

1. [Localnet](http://127.0.0.1:8080) -- our standalone tool for local development against a known version of the codebase with no external network.
2. [Devnet](https://api.devnet.aptoslabs.com/v1/spec#/) -- a shared resource for the community, data resets weekly, weekly update from aptos-core main branch.
3. [Testnet](https://api.testnet.aptoslabs.com/v1/spec#/) -- a shared resource for the community, data will be preserved, network configuration will mimic Mainnet.
4. [Mainnet](https://api.mainnet.aptoslabs.com/v1/spec#/) -- a production network with real assets.

{/* TODO Make this fit better on the screen */}

### Network properties

| Network Name | Chain ID                                                                                              | Genesis & Waypoint                                                           | Faucet                                                                | Epoch Duration | Network Provider                                    | Release Cadence | Wipe Cadence |
| ------------ | ----------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------- | --------------------------------------------------------------------- | -------------- | --------------------------------------------------- | --------------- | ------------ |
| Mainnet      | 1                                                                                                     | [Files Here](https://github.com/aptos-labs/aptos-networks/tree/main/mainnet) | N/A                                                                   | 2 hours        | Fully Decentralized                                 | Monthly, varies | Never        |
| Testnet      | 2                                                                                                     | [Files Here](https://github.com/aptos-labs/aptos-networks/tree/main/testnet) | No programmatic access, you must use the [mint page](/network/faucet) | 2 hours        | Managed by Aptos Labs on behalf of Aptos Foundation | Monthly, varies | Never        |
| Devnet       | [On Aptos Explorer **select Devnet from top right**](https://explorer.aptoslabs.com/?network=Devnet). | [Files Here](https://github.com/aptos-labs/aptos-networks/tree/main/devnet)  | Accessible programmatically via the API                               | 2 hours        | Managed by Aptos Labs on behalf of Aptos Foundation | Weekly          | On update    |

### Network URLs

The below URLs are provided by Aptos Labs.

| Network Name | REST API                                         | REST API Spec                                                | Indexer GraphQL API                                         | Indexer GraphQL API Spec                                                                                          | Indexer GRPC                               | Faucet                                         | Current Token Supply API                                |
| ------------ | ------------------------------------------------ | ------------------------------------------------------------ | ----------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------- | ------------------------------------------ | ---------------------------------------------- | ------------------------------------------------------- |
| Mainnet      | [REST API](https://api.mainnet.aptoslabs.com/v1) | [REST API Spec](https://api.mainnet.aptoslabs.com/v1/spec#/) | [Indexer API](https://api.mainnet.aptoslabs.com/v1/graphql) | [Indexer API Spec](https://cloud.hasura.io/public/graphiql?endpoint=https://api.mainnet.aptoslabs.com/v1/graphql) | [GRPC](https://grpc.mainnet.aptoslabs.com) | N/A                                            | [API](https://aptos-supply.dev.gcp.aptosdev.com/supply) |
| Testnet      | [REST API](https://api.testnet.aptoslabs.com/v1) | [REST API Spec](https://api.testnet.aptoslabs.com/v1/spec#/) | [Indexer API](https://api.testnet.aptoslabs.com/v1/graphql) | [Indexer API Spec](https://cloud.hasura.io/public/graphiql?endpoint=https://api.testnet.aptoslabs.com/v1/graphql) | [GRPC](https://grpc.testnet.aptoslabs.com) | [Mint](/network/faucet)                        | N/A                                                     |
| Devnet       | [REST API](https://api.devnet.aptoslabs.com/v1)  | [REST API Spec](https://api.devnet.aptoslabs.com/v1/spec#/)  | [Indexer API](https://api.devnet.aptoslabs.com/v1/graphql)  | [Indexer API Spec](https://cloud.hasura.io/public/graphiql?endpoint=https://api.devnet.aptoslabs.com/v1/graphql)  | [GRPC](https://grpc.devnet.aptoslabs.com)  | [Faucet](https://faucet.devnet.aptoslabs.com/) | N/A                                                     |

<details>
  <summary>Token Supply API Update</summary>
  On December 12, 2024, the Aptos Foundation updated its current token supply API. This updated version of the API more accurately reflects the current circulating supply of mainnet by updating the circulating supply number as of the beginning of the current monthly period. The previous version of the API reported the circulating supply as of the prior monthly period. There have been no changes to the network‚Äôs circulating supply schedule and the network‚Äôs circulating supply remains consistent with the original tokenomics as published [here](https://aptosnetwork.com/currents/aptos-tokenomics-overview).
</details>

# Run a Validator and VFN

> Learn how to participate in the Aptos consensus protocol by deploying and running a validator node and validator fullnode (VFN) with step-by-step guidance.

import { Aside, Steps } from '@astrojs/starlight/components';

To participate in the Aptos consensus protocol, you must deploy and run a validator node and (optionally) a validator
fullnode (VFN). This document provides a high-level overview of the important steps required for deploying both node types.

<Aside type="note">
  While VFNs are not required to participate in consensus, it is highly recommended for every validator operator to run a VFN.
  This is because VFNs are the sole ingress and egress points of blockchain data for the ecosystem. Having many VFNs
  in the network helps to improve reliability, increase data availability, and provide high-quality blockchain access to the public.
</Aside>

Before initializing a staking pool or delegation pool, read about [Staking](/network/blockchain/staking) and
[Delegated Staking](/network/blockchain/delegated-staking) to learn the
differences between the stake pool types. Note that once a stake pool has been created, it cannot be changed to a delegation pool
or vice versa.

Use the documents within this section to run an Aptos validator and a VFN. At a high-level, the process is as follows:

<Steps>
  1. Understand the requirements and deployment types.

     Read the node requirements and select a deployment method (e.g., on-premises or cloud services).
     Start by reading the node requirements to get to know the compute, memory, networking and storage resources you need.
     Also, select a method to deploy your nodes, i.e., use cloud managed Kubernetes, Docker, or source code.

  2. Generate identities for your nodes.

     Create your public/private keypairs and account addresses for the validator and VFN.
     Remember to keep your private keys confidential!

  3. Configure your validator and VFN.

     Configure your nodes to use the generated keys and identities.
     Using YAML files, configure your nodes with the keys and identities generated in the previous step.
     This is required to allow your nodes to connect to other nodes (i.e., peers) securely.

  4. Download genesis and a waypoint for your nodes.

     Bootstrap the nodes with a genesis and waypoint, and prepare them for startup.
     With the nodes configured correctly, install the binaries and download the genesis blob and waypoint files.
     These will give your nodes the information they need to start syncing with other peers.

  5. Join the validator set and start participating.

     Initialize the staking pool, join the validator set and start validating to earn rewards.
     Before other peers will accept connections from your nodes, you will need to join the validator set.
     To do this, you must initialize a staking pool and delegate to operators and voters.
     Once your staking pool has been set up, you can join the validator set.
     At this point your nodes will begin to sync with the network and your validator will be able to start participating in consensus.
     This is when you can start earning rewards.
</Steps>

# Connect to the Network

> Connect your deployed validator and validator fullnode (VFN) to the Aptos network by initializing staking pools and joining the validator set.

import { Aside } from '@astrojs/starlight/components';

<Aside type="caution">
  **Node deployment** <br />
  Before you can connect your nodes to the Aptos network, you will need to deploy them. Make sure to have
  deployed your nodes using one of the [deployment methods](/network/nodes/validator-node/deploy-nodes) before proceeding.
</Aside>

Once you have deployed your validator and validator fullnode (VFN), you will need to
connect them to the Aptos network. This requires initializing your staking pool, joining the validator set,
updating your identity files, and bootstrapping your nodes. If you do not complete these steps, your nodes
will not be able to connect to other nodes in the network.

Follow the [Connect to a Network](/network/nodes/validator-node/connect-nodes/connect-to-aptos-network) guide to get started.

# Connect to a Network

> Step-by-step guide to connect your validator and VFN to an Aptos network including stake pool initialization, identity updates, and validator set joining.

import { Aside, Steps } from '@astrojs/starlight/components';

This document describes how to connect your validator and validator fullnode (VFN) to an Aptos network.

<Aside type="caution">
  **MINIMUM STAKING REQUIREMENTS**<br />
  You should only follow these instructions if your validator is able to meet the minimum
  [staking requirements](/network/blockchain/staking#minimum-and-maximum-stake) for the
  network. The current required minimum staking requirement is 1 Million APT tokens.
</Aside>

At a high-level, there are four steps required to connect your nodes to an Aptos network:

<Steps>
  1. Initialize stake pool

     First, you will need to initialize the stake pool.

  2. Update identities

     Second, you will need to update your node identity configurations to match the pool address.

  3. Join validator set

     Third, you will need to join the validator set.

  4. Bootstrap your nodes

     Finally, you will need to bootstrap your nodes, so they can connect to the network and start syncing.
</Steps>

We will go through each of these steps in detail below.

## Initialize the stake pool

To begin, you will need to initialize the staking pool for your nodes. There are two types of pools you
can initialize, a staking pool or a delegation pool. You can read more about the differences between these
pools in the [Staking](/network/blockchain/staking) and [Delegated Staking](/network/blockchain/delegated-staking) sections.

To initialize a staking pool, follow the instructions in
[staking pool operations](/network/nodes/validator-node/connect-nodes/staking-pool-operations#initialize-a-staking-pool). Otherwise,
to initialize a delegation pool, follow the instructions in
[delegation pool operations](/network/nodes/validator-node/connect-nodes/delegation-pool-operations#initialize-a-delegation-pool).

## Update identities

Before joining the validator set, you will need to update your node identity configuration files to match the pool address.
This is required to ensure that your nodes are able to connect to other peers in the network.

<Aside type="caution">
  **UPDATING THE POOL ADDRESS**<br />
  It is a common error to forget to update the pool address in the node identity configurations. If you do not
  update the pool address for **both your validator and VFN identity files**, your nodes will not be able to connect to
  other peers in the network.
</Aside>

Follow the steps below to update your node identity configurations, depending on the deployment method you used.

### Using Source Code

If you used the source code to deploy your nodes, follow these steps:

1. Stop your validator and VFN and remove the data directory from both nodes. Make sure to remove the
   `secure-data.json` file on the validator, too. You can see the location of the `secure-data.json` file in your
   validator's configuration file.
2. Update your `account_address` in the `validator-identity.yaml` and `validator-fullnode-identity.yaml` files to your **pool address**. Do not change anything else.
3. Restart the validator and VFN.

### Using Docker

If you used Docker to deploy your nodes, follow these steps:

1. Stop your node and remove the data volumes: `docker compose down --volumes`. Make sure to remove the
   `secure-data.json` file on the validator, too. You can see the location of the `secure-data.json` file in your
   validator's configuration file.
2. Update your `account_address` in the `validator-identity.yaml` and `validator-fullnode-identity.yaml` files to your **pool address**.
   Do not change anything else.
3. Restart the nodes with: `docker compose up`

### Using Terraform

If you used Terraform to deploy your nodes (e.g., for AWS, Azure or GCP), follow these steps:

1. Increase the `era` number in your Terraform configuration. When this configuration is applied, it will wipe the data.

2. Set the `enable_monitoring` variable in your terraform module. For example:

   ```terraform filename="config.tf"
   module "aptos-node" {
     ...
     enable_monitoring           = true
     utility_instance_num        = 3  # this will add one more utility instance to run monitoring component
   }
   ```

3. Apply the changes with: `terraform apply` You will see a new pod getting created. Run `kubectl get pods` to check.

4. Find the IP/DNS for the monitoring load balancer, using:

   ```shellscript filename="Terminal"
   kubectl get svc ${WORKSPACE}-mon-aptos-monitoring --output jsonpath='{.status.loadBalancer.ingress[0]}'
   ```

   You will be able to access the Terraform dashboard on `http://<ip/DNS>`.

5. Pull the latest of the terraform module `terraform get -update`, and then apply the Terraform: `terraform apply`.

6. Download the `genesis.blob` and `waypoint.txt` files for your network. See [Node Files](/network/nodes/configure/node-files-all-networks) for locations and commands to download these files.

7. Update your `account_address` in the `validator-identity.yaml` and `validator-fullnode-identity.yaml` files to your **pool address**. Do not change anything else.

8. Recreate the secrets. Make sure the secret name matches your `era` number, e.g. if you have `era = 3`, then you should replace the secret name to be:

```shellscript filename="Terminal"
${WORKSPACE}-aptos-node-0-genesis-e3
```

```shellscript filename="Terminal"
export WORKSPACE=<your workspace name>

kubectl create secret generic ${WORKSPACE}-aptos-node-0-genesis-e2 \
    --from-file=genesis.blob=genesis.blob \
    --from-file=waypoint.txt=waypoint.txt \
    --from-file=validator-identity.yaml=keys/validator-identity.yaml \
    --from-file=validator-full-node-identity.yaml=keys/validator-full-node-identity.yaml
```

## Join the validator set

Next, you will need to join the validator set. Follow the steps below:

<Aside type="caution">
  **MAINNET VS TESTNET**<br />
  The commands shown below are for the Aptos mainnet. If you are connecting to a different
  network, you will need to change the `--network` value in the commands accordingly. You can view the
  values in [Aptos Blockchain Networks](/network/nodes/networks) to see how profiles can be configured based on the network.
</Aside>

### 1. Initialize the Aptos CLI

First, initialize the Aptos CLI with your operator account private key. This can be found in your `private-keys.yaml` file
under the entry `account_private_key`.

Replace `<operator_account_private_key>` with the value from the file in the command below:

```shellscript filename="Terminal"
aptos init --profile mainnet-operator \
   --network mainnet \
   --private-key <operator_account_private_key> \
   --skip-faucet
```

### 2. Check your account balance

Next, make sure you have enough funds to pay for transaction gas on the network. You can check this using the CLI, by
running the command below:

```shellscript filename="Terminal"
aptos account list --profile mainnet-operator
```

This will show you the coin balance you have in the validator account. You will see an output like below:

```json filename="Terminal"
"coin": {
   "value": "5000"
}
```

### 3. Update on-chain network addresses

Next, you will need to update the network addresses for your validator and VFN. This is required to ensure that your nodes
are able to connect to other peers in the network. First, fetch the pool address for your nodes, by running the command below.
Note: the owner address is the address of the account that owns the stake pool, and was used to initialize the stake pool.

```shellscript filename="Terminal"
aptos node get-stake-pool --owner-address <owner_address>
```

Using the pool address from the command above, you will need to update the network addresses for your nodes. You can
do this by running the command below. Note that it requires the `operator.yaml` file, which was created when you first
deployed your nodes.

```shellscript filename="Terminal"
aptos node update-validator-network-addresses  \
   --pool-address <pool-address> \
   --operator-config-file ~/$WORKSPACE/$USERNAME/operator.yaml \
   --profile mainnet-operator
```

<Aside type="note">
  **UPDATING THE NETWORK ADDRESSES**<br />
  Updating your network addresses on-chain requires waiting for the next epoch to begin. This is because the network
  addresses are updated at the end of the current epoch. Before the next epoch, your nodes will not be able to connect
  to other peers in the network.
</Aside>

### 4. Update on-chain consensus key

Next, you will need to update the consensus key for your nodes. This is required to ensure that your nodes are able to
participate in consensus. You can do this by running the command below. Note that it requires the pool address and
the `operator.yaml` file (similar to above).

```shellscript filename="Terminal"
aptos node update-consensus-key  \
   --pool-address <pool-address> \
   --operator-config-file ~/$WORKSPACE/$USERNAME/operator.yaml \
   --profile mainnet-operator
```

<Aside type="note">
  **UPDATING THE CONSENSUS KEY**<br />
  Updating your consensus key on-chain requires waiting for the next epoch to begin. This is because the consensus key
  is updated at the end of the current epoch. Before the next epoch, your nodes will not be able to participate in consensus.
</Aside>

### 5. Join the validator set

Finally, you will need to join the validator set. You can do this by running the command below:

```shellscript filename="Terminal"
aptos node join-validator-set \
   --pool-address <pool-address> \
   --profile mainnet-operator
```

The validator set is updated at the end of every epoch. You will need to wait for the next epoch to begin before your
validator node is able to join the validator set.

<Aside type="note">
  **IDENTIFYING THE NEXT EPOCH**<br />
  You can identify the next epoch by checking the [Aptos Explorer](https://explorer.aptoslabs.com/validators/all?network=mainnet) or by running the command `aptos node get-stake-pool`.
</Aside>

### 6. Check the validator set

When you execute the command to join the validator set, your validator will be in a "Pending Active" state until the
next epoch occurs. You can run the command below to look for your validator in the `pending_active` list.

```shellscript filename="Terminal"
aptos node show-validator-set --profile mainnet-operator | jq -r '.Result.pending_active' | grep <pool_address>
```

When the next epoch occurs, the node will be moved into `active_validators` list. Run the command
below to see your validator in the "active\_validators" list:

```shellscript filename="Terminal"
aptos node show-validator-set --profile mainnet-operator | jq -r '.Result.active_validators' | grep <pool_address>
```

## Bootstrap your nodes

After joining the validator set and updating your node identity configurations to match the pool address,
you will need to bootstrap your nodes to connect to the network. To do this, follow the steps below:

1. Start the VFN. The VFN will connect to the network and start syncing. See [State Synchronization](/network/nodes/configure/state-sync) for more information.
2. Once the VFN is synced, restart the validator. It will sync from the VFN and then connect to other validators
   in the network and start participating in consensus.

Once both of these steps are complete, your nodes will be connected to the network and participating in consensus.

## Next steps

Congratulations! You have successfully connected your nodes to the Aptos network. To verify that your nodes are running
correctly, visit the [Node Health](/network/nodes/validator-node/verify-nodes/node-liveness-criteria) document. This document describes how you can verify and
monitor the health of your validator and VFN, including an initial node verification section.

# Delegation Pool Operations

> Comprehensive guide to delegation pool operations for delegated staking including initialization, delegation, commission management, and allowlisting features.

> Beta: This documentation is in experimental, beta mode. Supply feedback by opening a [GitHub issue](https://github.com/aptos-labs/developer-docs/issues/new/choose).
> See also the related [Staking Pool Operations](/network/nodes/validator-node/connect-nodes/staking-pool-operations) instructions.

Validator operators should follow these instructions to carry out delegation pool operations for [delegated staking](/network/blockchain/delegated-staking). You may delegate as little as 10 APT plus a small add stake fee that will be mostly refunded as rewards at the end of the current epoch. You might notice that some UIs might use 11 APT as the minimum for a round number. Note that your validator will become part of the _Active Validator Set_ only when the delegation pool satisfies the minimum cumulative [staking requirement of 1 million APT](/network/nodes/validator-node/connect-nodes/staking-pool-operations).

The delegation pool owner should set an operator for the pool via the `set_operator` function described in the [Perform pool owner operations](#perform-pool-owner-operations) section. The operator should then start their own Aptos node, as it is a best practice to have a different account for owner and operator. Once the delegation pool attains 1 million APT, the operator can join the validator set.

The operator address will receive the pool commission that was set at the initialization of the delegation pool, which is automatically distributed as stake in the delegation pool at the end of each epoch. The operator will act as a normal Delegation Pool account that is able to do all the operations described in [Perform delegation pool operations](#perform-delegation-pool-operations).

## Prerequisites

1. [Install and configure](/build/cli) the Aptos CLI. If you are looking to develop on the Aptos blockchain, debug apps, or perform node operations, the Aptos tool offers a command line interface for these purposes.
2. [Initialize local configuration and create an account](/build/cli/setup-cli) on the Aptos blockchain.

## Initialize a delegation pool

Before initializing a delegation pool, you need to know the delegation pool address. You can use the following CLI commands to obtain the delegation pool address depending on where you are in the process:

- Before you create the delegation pool:
  ```shellscript filename="Terminal"
  aptos account derive-resource-account-address --address <owner_address> --seed "aptos_framework::delegation_pool<SEED>" --seed-encoding utf8
  ```
  - The `<SEED>` is a number chosen by you to create the resource account address to host the delegation pool resource. Once you choose a seed, you should use the same value for all following usages.
- After you create the delegation pool:
  ```shellscript filename="Terminal"
  aptos account derive-resource-account-address
  ```

1. Run the command below, substitute in the profile you previously configured during initialization:

   ```shellscript filename="Terminal"
   aptos move run --profile <your-profile> \
      --function-id 0x1::delegation_pool::initialize_delegation_pool \
      --args u64:1000 string:00
   ```

   Where `--args`:

   - `u64:1000` represents `operator_commission_percentage` - 1000 is equivalent to 10% and 10000 is 100%.
   - `string:00` represents `delegation_pool_creation_seed` - a number chosen by you to create a resource account associated with your owner address; this account is used to host the delegation pool resource. You should use the same number here as the `--seed` you used in the previous step to create the delegation pool.

2. Once this command is executed without error an account for resources is established using the `owner` signer and a provided `delegation_pool_creation_seed` to hold the `delegation pool resource` and possess the underlying stake pool.

3. The `owner` is granted authority over assigning the `operator` and `voter` roles, which are initially held by the `owner`.

4. The delegation pool can now accept a minimum amount of 10 APT from any user who wishes to delegate to it.

5. The delegation pool can now [connect to the Aptos Network](/network/nodes/validator-node/connect-nodes/connect-to-aptos-network).

## Perform delegation pool operations

This section describes the available operations that can be performed on this recently created pool. Once the delegation pool has been established, use the Aptos CLI to operate the pool. The available actions that can be performed on it include:

- Add `amount` of coins to the delegation pool `pool_address` using the public entry method `add_stake(delegator: &signer, pool_address: address, amount u64)` and substituting your values into the command below before running it:

  ```shellscript filename="Terminal"
  aptos move run --profile delegator \
    --function-id 0x1::delegation_pool::add_stake \
    --args address:<pool_address> u64:<amount>
  ```

- Undelegate (unlock) the amount of funds from the delegator's active and pending active stake up to the limit of the active stake in the stake pool using public entry method `unlock(delegator: &signer, pool_address: address, amount: u64)` and substituting your values into the command below before running it:

  ```shellscript filename="Terminal"
  aptos move run --profile delegator \
    --function-id 0x1::delegation_pool::unlock \
    --args address:<pool_address> u64:<amount>
  ```

- Cancel undelegate (reactivate stake) `amount` of coins from `pending_inactive` state to `active state` using public entry method `reactivate_stake(delegator: &signer, pool_address: address, amount: u64)` with the command and your values:

  ```shellscript filename="Terminal"
  aptos move run --profile delegator \
    --function-id 0x1::delegation_pool::reactivate_stake \
    --args address:<pool_address> u64:<amount>
  ```

- Withdraw `amount` of owned inactive stake from the delegation pool at `pool_address` using the public entry method ` withdraw(delegator: &signer, pool_address: address, amount: u64)` and the command:

  ```shellscript filename="Terminal"
  aptos move run --profile delegator \
    --function-id 0x1::delegation_pool::withdraw \
    --args address:<pool_address> u64:<amount>
  ```

## Perform pool owner operations

Delegation pool owners have access to specific methods designed for modifying the `operator` and `voter` roles of the delegation pool. Use the following Aptos CLI commands and include the relevant addresses:

- Set the operator address for the delegation pool:

  ```shellscript filename="Terminal"
  aptos move run --profile delegation_pool_owner \
    --function-id 0x1::delegation_pool::set_operator \
    --args address:<new_operator_address>
  ```

Delegation pool owners can update the commission percentage for the delegation pool. The commission rate change can be requested at least 7.5 days before the current lockup cycle ends. The new commission percentage takes effect upon any `synchronize_delegation_pool` call after the end of the current lockup cycle. Owners are required to call `synchronize_delegation_pool` as soon as the lockup cycle ends to ensure that the new commission percentage takes effect. Otherwise, the old commission rate will continue to be used until the next `synchronize_delegation_pool` call.

- Update the commission percentage for the delegation pool; `<new_commission_percentage>` has two decimal points precision (e.g., 13.25% is represented as 1325):

  ```shellscript filename="Terminal"
  aptos move run --profile delegation_pool_owner \
    --function-id 0x1::delegation_pool::update_commission_percentage \
    --args u64:<new_commission_percentage>
  ```

## Set beneficiary addresses for operators

Delegation pool operators can set beneficiary addresses to receive the operator commission earned by the delegation pool.

- The beneficiary addresses can be set by the operator using the following command:

  ```shellscript filename="Terminal"
  aptos move run --profile delegation_pool_operator \
    --function-id 0x1::delegation_pool::set_beneficiary_for_operator \
    --args address:<new_beneficiary_address>
  ```

- To view the beneficiary address set for the operator, use the following command:
  ```shellscript filename="Terminal"
  aptos move view --url <REST API for the network> \
    --function-id 0x1::delegation_pool::beneficiary_for_operator \
    --args address:<operator_address>
  ```

Any existing unpaid commission rewards will be paid to the new beneficiary. To ensures payment to the current beneficiary, one should first call `synchronize_delegation_pool` before switching the beneficiary. In case an operator operates multiple delegation pools, the operator can only set one beneficiary for all the delegation pools, not a separate one for each pool.

Once the beneficiary address is set, the operator commission earned by the delegation pool will be distributed to the beneficiary address. The beneficiary account can perform the operations such as `unlock` and `withdraw` for the commission earned.

## Check delegation pool information

Until the delegation pool has received 1 million APT and the validator has been added to the set of active validators, there will be no rewards to track during each cycle. In order to obtain information about a delegation pool, use the Aptos [View function](/build/apis/fullnode-rest-api#reading-state-with-the-view-function)

- `get_owned_pool_address(owner: address): address` - Returns the address of the delegation pool belonging to the owner, or produces an error if there is no delegation pool associated with the owner.

- `delegation_pool_exists(addr: address): bool` - Returns true if a delegation pool exists at the provided address `addr`.

- `operator_commission_percentage(pool_address: address): u64` - Returns the operator commission percentage set on the delegation pool at initialization.

- `get_stake(pool_address: address, delegator_address: address): (u64, u64, u64)` - Returns total stake owned by `delegator_address` within delegation pool `pool_address` in each of its individual states: (`active`,`inactive`,`pending_inactive`).

- `get_delegation_pool_stake(pool_address: address): (u64, u64, u64, u64)` - Returns the stake amounts on `pool_address` in the different states: (`active`,`inactive`,`pending_active`,`pending_inactive`).

- `shareholders_count_active_pool(pool_address: address): u64` - Returns the number of delegators owning an active stake within `pool_address`.

- `get_pending_withdrawal(pool_address: address, delegator_address: address): (bool, u64)` - Returns if the specified delegator possesses any withdrawable stake. However, if the delegator has recently initiated a request to release some of their stake and the stake pool's lockup cycle has not ended yet, then their funds may not yet be available for withdrawal.

- `can_withdraw_pending_inactive(pool_address: address): bool` - Returns whether `pending_inactive` stake can be directly withdrawn from the delegation pool, implicitly its stake pool, in the special case the validator had gone inactive before its lockup expired.

In the [Aptos TypeScript SDK](/build/sdks/ts-sdk), a View function request would resemble:

```typescript filename="view_function.ts"
import { Aptos, AptosConfig } from "@aptos-labs/ts-sdk";

const NODE_URL = "https://aptos-testnet.public.blastapi.io";

(async () => {
  const aptosConfig = new AptosConfig({ fullnode: NODE_URL });
  const aptos = new Aptos(aptosConfig);
  const payload: InputViewRequestData = {
    function: "0x1::delagation_pool::get_stake",
    functionArguments: ["pool_address", "delegator_address"],
  };
  console.log(await aptos.view({ payload }));
})();
```

Alternatively, you can use Aptos CLI to call View functions.

```shellscript filename="Terminal"
aptos move view [OPTIONS] --function-id <FUNCTION_ID>
```

To discover the available options and the process for making an `aptos move view` call, access the help information with `aptos move view --help`. This will display the required arguments for invoking the view functions.

## Compute delegation pool rewards earned

Use this formula to calculate _rewards earned_ for `active` and `pending_inactive` staking. This formula assumes that different stake operations such as `unlock` and `reactivate` take out the _principals_ first and then _rewards_. Therefore, _rewards earned_ may vary based upon how the formula you use is constructed:

1. Get the amount of `active` and `pending_inactive` staking from the [`get_stake`](https://github.com/aptos-labs/aptos-core/blob/ed63ab756cda61439287304ed89bbb156fcbeaed/aptos-move/framework/aptos-framework/sources/delegation_pool.move#L321) view function.

2. Calculate principal:

   - "active principal" = **AddStakeEvent** - **UnlockStakeEvent** + **ReactivateStakeEvent**. If at any point during the iteration, "active principal" \< 0, reset to 0. Negative principal could happen when the amount users `unlock` include rewards earned from staking.
   - "pending inactive principal" = **UnlockStakeEvent** - **ReactivateStakeEvent**. If at any point during the iteration, "pending inactive principal" \< 0, reset to 0. Negative principal could happen when the amount users `reactivate` include rewards earned from staking.

3. Compute rewards earned:
   - active rewards = `active` - active principal.
   - pending\_inactive\_rewards = `pending_inactive` - "pending inactive principal".

## Allowlisting for delegation pools

Delegation pool owners can set an allowlist for their delegation pool. They can add or remove addresses from the allowlist and evict delegators who are not on the allowlist. Here is the flow:

1. By default, a delegation pool is permissionless and does not have an allowlist. The pool owner can set an allowlist, transitioning the pool to a permissioned state.
2. When an allowlist is first established in a delegation pool, it starts empty. This initial empty allowlist does not impact existing stakes in the pool. However, the pool will not accept any new stakes or reactivation of pending-inactive stakes from any stakers because no one is on the allowlist initially.
3. The pool owner may add stakers' wallet addresses to the allowlist. Once an address is added, the staker can add new stakes or reactivate existing stakes in the pool. Note that this feature does not facilitate a mechanism for stakers to request to be added to the allowlist; such requests must be managed off-chain (e.g., through private communication between the operator and staker, or UI-based solutions).
4. If a delegator is removed from the allowlist, they are no longer able to add or reactivate stakes. However, they retain the ability to unlock and withdraw their existing stakes.
5. The pool owner can evict a delegator who is not included on the allowlist. This action will unlock the delegator's entire stake, transitioning all of their active stakes to a pending inactive state. As the evicted delegator is not on the allowlist, they cannot reactive their stake. Note that these tokens will remain locked up until the end of the lockup period, and the existing stake will also continue to earn rewards until then. When the lockup period ends, the funds will be unstaked (inactive), but will remain in the pool until the delegator initiates a withdrawal.
6. If a delegator's stake enters the pending inactive state due to eviction, the pool owner can subsequently add the delegator back to the allowlist. However, this action will not automatically reactivate the stake. Automatic reactivation is not provided to prevent potential misuse by a malicious pool owner who might repeatedly evict and re-allowlist a delegator to prevent them from leaving the pool. Once a delegator is back on the allowlist, the delegator must manually call the reactivate\_stake function to reactivate their stake.
7. Delegation pools that have enabled allowlisting can disable it. When disabled, the delegation pool becomes permissionless, allowing any staker to stake to the pool.

- The delegation pool owner can enable allow listing and create an empty allowlist using the following command:

  ```shellscript filename="Terminal"
  aptos move run --profile delegation_pool_owner \
    --function-id 0x1::delegation_pool::enable_delegators_allowlisting
  ```

- The delegation pool owner can disable allow listing and delete the existing allowlist using the following command:

  ```shellscript filename="Terminal"
  aptos move run --profile delegation_pool_owner \
    --function-id 0x1::delegation_pool::disable_delegators_allowlisting
  ```

- The delegation pool owner can add an address to the allowlist using the following command:

  ```shellscript filename="Terminal"
  aptos move run --profile delegation_pool_owner \
    --function-id 0x1::delegation_pool::allowlist_delegator \
    --args address:<delegator_address>
  ```

- The delegation pool owner can remove an address from the allowlist using the following command:

  ```shellscript filename="Terminal"
  aptos move run --profile delegation_pool_owner \
    --function-id 0x1::delegation_pool::remove_delegator_from_allowlist \
    --args address:<delegator_address>
  ```

- The delegation pool owner can evict a delegator from the pool by unlocking their entire stake using the following command:

  ```shellscript filename="Terminal"
  aptos move run --profile delegation_pool_owner \
    --function-id 0x1::delegation_pool::evict_delegator \
    --args address:<delegator_address>
  ```

There are also view functions available to check the allowlist status and the addresses on the allowlist:

- The following view function returns whether `pool` has allow listing enabled:

  ```shellscript filename="Terminal"
  aptos move view --url <REST API for the network> \
    --function-id 0x1::delegation_pool::allowlisting_enabled \
    --args address:<pool>
  ```

- The following view function returns whether `delegator` is on the allowlist of `pool`:

  ```shellscript filename="Terminal"
  aptos move view --url <REST API for the network> \
    --function-id 0x1::delegation_pool::delegator_allowlisted \
    --args address:<pool> address:<delegator>
  ```

- The following view function returns the allowlist defined on pool:

  ```shellscript filename="Terminal"
  aptos move view --url <REST API for the network> \
    --function-id 0x1::delegation_pool::get_delegators_allowlist \
    --args address:<pool>
  ```

# Staking Pool Operations

> Complete guide to staking pool operations including initialization, owner operations, commission management, and performance monitoring with minimum 1M APT requirement.

import { Aside } from '@astrojs/starlight/components';

This document describes how to perform [staking](/network/blockchain/staking) pool operations. Note that a staking pool can only accept stake
from the stake pool owner. You can stake only when you meet the minimum staking requirement.

<Aside type="note">
  **MINIMUM STAKING REQUIREMENT**<br />
  The current minimum staking requirement is 1 million APT.
</Aside>

See also the related
[Delegation Pool Operations](/network/nodes/validator-node/connect-nodes/delegation-pool-operations) instructions to accept stake from multiple delegators in order to reach the minimum
staking requirement.

<Aside type="caution">
  **POOL TYPES ARE STATIC**<br />
  There is no upgrade mechanism for the staking contract to move from a staking pool to a delegation pool. A new
  delegation pool must be created.
</Aside>

## Initialize a staking pool

<Aside type="note">
  **TESTNET VS MAINNET**<br />
  The Aptos CLI commands below target mainnet. Change the `--network` value for testnet and devnet.
  View the values in [Aptos Blockchain Networks](/network/nodes/networks) to see how profiles can be configured based on the network.
</Aside>

Before initializing a staking pool, ensure that there is an existing owner account with 1 Million APT.

1. Initialize the [Aptos CLI](/build/cli) with a private key from an existing account, such as a wallet, or create a new account.

```shellscript filename="Terminal"
aptos init --profile mainnet-owner \
  --network mainnet
```

You can either enter the private key from an existing wallet, or create new wallet address.

2. Run the following command to initialize the staking pool:

```shellscript filename="Terminal"
aptos stake create-staking-contract \
  --operator <operator-address> \
  --voter <voter-address> \
  --amount 100000000000000 \
  --commission-percentage 10 \
  --profile mainnet-owner
```

3. Once the staking pool has been initialized, you can proceed to [connect to the Aptos Network](/network/nodes/validator-node/connect-nodes/connect-to-aptos-network).

## Perform pool owner operations

### Transfer coin between accounts

```shellscript filename="Terminal"
aptos account transfer \
  --account <operator-address> \
  --amount <amount> \
  --profile mainnet-owner
```

### Switch operator

```shellscript filename="Terminal"
aptos stake set-operator \
  --operator-address <new-operator-address> \
  --profile mainnet-owner
```

### Switch voter

```shellscript filename="Terminal"
aptos stake set-delegated-voter \
  --voter-address <new-voter-address> \
  --profile mainnet-owner
```

### Add stake

```shellscript filename="Terminal"
aptos stake add-stake \
  --amount <amount> \
  --profile mainnet-owner
```

### Increase stake lockup

```shellscript filename="Terminal"
aptos stake increase-lockup --profile mainnet-owner
```

### Unlock stake

```shellscript filename="Terminal"
aptos stake unlock-stake \
  --amount <amount> \
  --profile mainnet-owner
```

### Withdraw stake

```shellscript filename="Terminal"
aptos stake withdraw-stake \
  --amount <amount> \
  --profile mainnet-owner
```

### Update commission

```shellscript filename="Terminal"
aptos move run --function-id 0x1::staking_contract::update_commission \
  --args address:<operator_address> u64:<commission_percentage> \
  --profile mainnet-owner
```

## Set beneficiary addresses for operators

Staking pool operators can set beneficiary addresses to receive the operator commission earned by the staking pool.

- The beneficiary addresses can be set by the operator using the following command:

  ```shellscript filename="Terminal"
  aptos move run --profile mainnet_operator \
    --function-id 0x1::staking_contract::set_beneficiary_for_operator \
    --args address:<new_beneficiary_address>
  ```

- To view the beneficiary address set for the operator, use the following command:
  ```shellscript filename="Terminal"
  aptos move view --url <REST API for the network> \
    --function-id 0x1::staking_contract::beneficiary_for_operator \
    --args address:<operator_address>
  ```

Any existing unpaid commission rewards will be paid to the new beneficiary. To ensures payment to the current beneficiary, one should first call `distribute` before switching the beneficiary. In case an operator operates multiple staking pools, the operator can set one beneficiary for all the staking pools, not a separate one for each pool.

Once the beneficiary address is set, either the operator or the beneficiary can request the operator commission by `request_commission`.

## Checking your stake pool information

<Aside type="note">
  Before you proceed, see [Validation on the Aptos blockchain](/network/blockchain/staking#validation-on-the-aptos-blockchain) for a brief overview.
</Aside>

To check the details of your stake pool, run the below CLI command with the `get-stake-pool` option by providing the `--owner-address` and `--url` fields.

The below command is for an example owner address `e7be097a90c18f6bdd53efe0e74bf34393cac2f0ae941523ea196a47b6859edb`.

<Aside type="note">
  For testnet or devnet `--url` field values, see [Aptos Blockchain Networks](/network/nodes/networks).
</Aside>

```shellscript filename="Terminal"
aptos node get-stake-pool \
  --owner-address e7be097a90c18f6bdd53efe0e74bf34393cac2f0ae941523ea196a47b6859edb \
  --profile mainnet-operator
```

Example output:

```json
{
  "Result": [
    {
      "state": "Active",
      "pool_address": "25c3482850a188d8aa6edc5751846e1226a27863643f5ebc52be4f7d822264e3",
      "operator_address": "3bec5a529b023449dfc86e9a6b5b51bf75cec4a62bf21c15bbbef08a75f7038f",
      "voter_address": "3bec5a529b023449dfc86e9a6b5b51bf75cec4a62bf21c15bbbef08a75f7038f",
      "pool_type": "StakingContract",
      "total_stake": 100525929489123,
      "commission_percentage": 10,
      "commission_not_yet_unlocked": 15949746439,
      "lockup_expiration_utc_time": "2022-10-07T07:12:55Z",
      "consensus_public_key": "0xb3a7ac1491b0165f08f136c2b02739846b6610084984d5298c2983c4f8e5553284bffca2e3fe2b99167da82717501732",
      "validator_network_addresses": [
        "/ip4/35.91.145.164/tcp/6180/noise-ik/0xeddf05470520af91b847f353dd804a04399e1213d130a4260e813527f2c49262/handshake/0"
      ],
      "fullnode_network_addresses": [],
      "epoch_info": {
        "epoch": 594,
        "epoch_interval_secs": 3600,
        "current_epoch_start_time": {
          "unix_time": 1665087178789891,
          "utc_time": "2022-10-06T20:12:58.789891Z"
        },
        "next_epoch_start_time": {
          "unix_time": 1665090778789891,
          "utc_time": "2022-10-06T21:12:58.789891Z"
        }
      }
    }
  ]
}
```

### Description of output fields

**state**

- "Active": Validator is already in the validator set and proposing.
- "Pending\_active": Validator will be added to the validator set in the next epoch. \*\*Do not try to join the validator set again before the arrival of next epoch, or else you will receive an error. \*\*

**pool\_address**

- Use this "pool\_address" (not the operator address) in you `validator.yaml` file. If you mistakenly used the operator address, you will receive the message: "Validator not in validator set".

**commission\_percentage**

- This can be set only by the stake pool owner. Operator receives the "commission\_percentage" of the generated staking rewards. If you request the commission (you can do so by running the command `aptos stake request-commission`), then at the end of the `lockup_expiration_utc_time` the commission part of the rewards will go to the operator address while the rest will stay in the stake pool and belong to the owner. Here "the commission part of the rewards" means the value of **commission\_not\_yet\_unlocked**.

  For example, in a scenario with a lock-up of one month, you call `aptos stake request-commission` every month. This will pay out the commission that was accrued during the previous month but only when unlocked at the end of the previous month. Regardless of how often you run `aptos stake request-commission` during the month, the commission is only paid out upon the completion of `lockup_expiration_utc_time`.

  <Aside type="note">
    **COMPOUNDING**<br />
    Note that if you do not request commission for multiple months, your commission will accrue more due to compounding of the **commission\_percentage** during these months.
  </Aside>

**commission\_not\_yet\_unlocked**

- The amount of commission (amount of APT) that is not yet unlocked. It will be unlocked at the `lockup_expiration_utc_time`. This is the total commission amount available to the operator, i.e., the staking rewards **only** to the operator. This does not include the staking rewards to the owner.

**lockup\_expiration\_utc\_time**

- The date when the commission will unlock. However, this unlocked commission will not be auto-disbursed. It will only disburse when the command `aptos stake request-commission` is called again.

**epoch\_info**

- Use [Epoch Converter](https://www.epochconverter.com/) or a similar tool to convert the `unix_time` into human-readable time.

## Requesting commission

Either an owner, an operator or the beneficiary of the operator can request commission. You must request commission **twice**, once before the end of the lockup period and a second time after the lockup period ends, i.e., at the end of **lockup\_expiration\_utc\_time**, by running the `aptos stake request-commission` command. Make sure to provide the operator and the owner addresses. See an example command below:

```shellscript filename="Terminal"
aptos stake request-commission \
  --operator-address 0x3bec5a529b023449dfc86e9a6b5b51bf75cec4a62bf21c15bbbef08a75f7038f \
  --owner-address 0xe7be097a90c18f6bdd53efe0e74bf34393cac2f0ae941523ea196a47b6859edb \
  --profile mainnet-operator
```

When you run the `aptos stake request-commission` command before the end of the lockup expiration, the command will initiate unlock for any locked commission earned up until that moment in time. The commission will remain in `pending_inactive` until the end of the lockup period, will continue to earn rewards until the lockup period expires. The commission will not be withdrawable until after the end of the lockup period, when `aptos stake request-commission` is called a second time.

See example below:

Month 1 Day 29, you call the command, it would initiate unlock for 29 days worth of commission.

Month 2, Day 29, if you call the command again, it would disburse the fully unlocked commission from previous month (29 days worth), and initiate commission unlock for Month 1 Day 30 + Month 2 Day 1-29 (30 days worth).

Month 3, Day 29, if you call the commission again, 30 days of commission would be disbursed, and a new batch of commission would initiate unlock.

You can call the command multiple times, and the amount you receive depends on the day when you requested commission unlock previously.

Commission is unlocked when `request-commission` is called, the staker unlocks stake, or the staker switches operator.

## Checking your validator performance

To see your validator performance in the current and past epochs and the rewards earned, run the below command. The output will show the validator's performance in block proposals, and in governance voting and governance proposals. Default values are used in the below command. Type `aptos node get-performance --help` to see default values used.

```shellscript filename="Terminal"
aptos node get-performance \
  --pool-address <pool address> \
  --profile mainnet-operator
```

Example output:

```json
{
  "Result": {
    "current_epoch_successful_proposals": 56,
    "current_epoch_failed_proposals": 0,
    "previous_epoch_rewards": [
      "12312716242",
      "12272043711",
      "12312912674",
      "12313011054",
      "12313109435",
      "12180092056",
      "12313305136",
      "12313403519",
      "12313501903",
      "12313600288"
    ],
    "epoch_info": {
      "epoch": 68,
      "epoch_interval": 3600000000,
      "last_epoch_start_time": {
        "unix_time": 1665074662417326,
        "utc_time": "2022-10-06T16:44:22.417326Z",
        "local_time": "Thu Oct  6 16:44:22 2022"
      },
      "next_epoch_start_time": {
        "unix_time": 1665078262417326,
        "utc_time": "2022-10-06T17:44:22.417326Z",
        "local_time": "Thu Oct  6 17:44:22 2022"
      }
    }
  }
}
```

#### Description of fields

**current\_epoch\_successful\_proposals**

- Successful leader-validator proposals during the current epoch. Also see [Validation on the Aptos blockchain](/network/blockchain/staking#validation-on-the-aptos-blockchain) for the distinction between leader-validator and the voter-validator.

**previous\_epoch\_rewards**

- An ordered list of rewards earned (APT amounts) for the previous 10 epochs, starting with the 10 epoch in the past. In the above example, a reward of 12312716242 APT was earned 10 epochs past and a reward of 12313600288 APT was earned in the most recent epoch. If a reward is 0 for any epoch, then:
  - Either the validator was not part of the validator set in that epoch (could have been in either inactive or pending\_active validator state), or
  - The validator missed all the leader proposals.

### Checking the performance for all epochs

To check the performance of all the epochs since the genesis, run the below command. You can filter the results for your pool address with `grep`, as shown below:

```shellscript filename="Terminal"
aptos node analyze-validator-performance \
  --analyze-mode detailed-epoch-table \
  --profile mainnet-operator \
  --start-epoch 0 | grep <pool address>
```

## Tracking rewards

`DistributeEvent` is emitted when there is a transfer from staking\_contract to
the operator or staker (owner). Rewards can be tracked either by listening to
`DistributeEvent` or by using the [View function](/build/apis/fullnode-rest-api#reading-state-with-the-view-function)
to call `staking_contract_amounts`. This will return `accumulated_rewards` and `commission_amount`.

# Voting for a Staking Pool

> Guide for staking pool voters to participate in Aptos governance using both the Governance UI and Aptos CLI for proposal voting and delegation.

If you are a [staking pool](/network/blockchain/staking) voter, then we recommend strongly that you do not store your Aptos voter keys with a
custodian before the custodian supports this function. Until then, we suggest you store your voter keys in an Aptos
wallet like [Petra](https://petra.app/).

This document describes how to perform staking voter operations while in the Aptos mainnet using an Aptos wallet.

### Using Governance UI

To participate as a voter in the Aptos governance, follow these steps:

1. Go to the [Proposals section](https://governance.aptosfoundation.org/) of the Aptos Governance page.
2. Connect your wallet by clicking on **CONNECT WALLET** (top-right).
3. Make sure that wallet is set to connect to Mainnet.
4. View the proposals. When you are ready to vote on a proposal, click on the proposal and vote.
5. You will see a green bar indicating that the voting transaction is successful.

### Using the Aptos CLI

1. Get your stake pool info using: `aptos node get-stake-pool --owner-address <owner-address> --url <REST API for the network>`.
2. To see the list of proposals, execute: `aptos governance list-proposals --url https://api.mainnet.aptoslabs.com`.
3. To set up your voter profile, run: `aptos init`.
4. To vote on a proposal, execute: `aptos governance vote --proposal-id <PROPOSAL_ID> --pool-address <POOL_ADDRESS> --url <URL> --profile <profile>`.

## Delegation Pool Voter

If you staked to a [delegation pool](/network/blockchain/delegated-staking), you can vote proportional to your stake amount in the delegation pool or delegate your votes to another voter address.

### Using Governance UI

To participate as a voter, follow these steps:

1. Go to the [Proposals section](https://govscan.live/aptos-proposals) on Govscan.
2. Connect your wallet by clicking on **CONNECT WALLET**
3. Make sure that wallet is set to connect to Mainnet.
4. View the proposals. When you are ready to vote on a proposal, click on the proposal and vote.
5. You will see a green bar indicating that the voting transaction is successful.

### Using the Aptos CLI

1. Get your delegation pool address from the [Aptos Explorer page](https://explorer.aptoslabs.com/validators/delegation?network=mainnet).
2. To see the list of proposals, execute: `aptos governance list-proposals --url https://api.mainnet.aptoslabs.com`.
3. To set up your voter profile, run: `aptos init`.
4. To vote on a proposal, execute: `aptos move run --function-id 0x1::delegation_pool::vote --args address:<pool-address> u64:<proposal-id> u64:<voting-power> bool:<true or false>`.

To delegate your voting power, follow these steps:

1. Get your delegation pool address from the [Aptos Explorer page](https://explorer.aptoslabs.com/validators/delegation?network=mainnet).
2. To set up your voter profile, run: `aptos init`.
3. To delegate voting power, run: `aptos move run --function-id 0x1::delegation_pool::delegate_voting_power --args address:<pool-address> address:<delegated-voter-address>`.
4. The new delegated voter will take effect in the next lockup cycle after the current lockup cycle ends. To view delegated voter, run `aptos move view --profile delegator --function-id 0x1::delegation_pool::calculate_and_update_delegator_voter --args address:<pool-address> address:<delegator-address>`.

# Deploy Validator and VFN Nodes

> Choose from multiple deployment methods to set up your validator and validator fullnode (VFN) across various platforms and cloud providers.

import { Aside } from '@astrojs/starlight/components';

Before you can run a validator and validator fullnode (VFN) in an Aptos network, you will need to select a deployment
method for your nodes. The guides below provide step-by-step instructions for deploying a validator node and VFN
on various platforms, and across different Aptos networks.

Once your nodes are deployed, you can connect them to an Aptos network by initializing your staking pool and joining
the validator set. See [Connect Nodes](/network/nodes/validator-node/connect-nodes) for more information.

<Aside type="caution">
  Before selecting a deployment method, make sure to read and understand the [Node Requirements](/network/nodes/validator-node/node-requirements) first.
</Aside>

# Deployment methods

Select a deployment method for your nodes:

- ### [Using Source Code](/network/nodes/validator-node/deploy-nodes/using-source-code)
- ### [Using Docker](/network/nodes/validator-node/deploy-nodes/using-docker)
- ### [Using AWS](/network/nodes/validator-node/deploy-nodes/using-aws)
- ### [Using Azure](/network/nodes/validator-node/deploy-nodes/using-azure)
- ### [Using GCP](/network/nodes/validator-node/deploy-nodes/using-gcp)

# Using AWS

> Deploy Aptos validator and validator fullnode (VFN) on Amazon Web Services using Terraform and EKS with comprehensive setup instructions.

import { Aside } from '@astrojs/starlight/components';

This is a step-by-step guide to deploy an Aptos validator and validator fullnode (VFN) using Amazon Web Services (AWS). Using this guide,
the validator and VFN will be deployed on separate machines.

<Aside type="caution">
  **Prerequisites**<br />
  Before you begin, make sure to read and understand the [Node Requirements](/network/nodes/validator-node/node-requirements). Similarly, make sure you have
  installed the [Aptos CLI](/build/cli),
  [Terraform](https://www.terraform.io/downloads.html),
  [Kubernetes CLI](https://kubernetes.io/docs/tasks/tools/),
  and [AWS CLI](https://aws.amazon.com/cli/). This guide assumes that you already have an AWS account setup.
</Aside>

## Deployment steps

<Aside type="note">
  **Default connection to mainnet**<br />
  If you follow the default setup in this document, then your validator and VFN will be connected to the Aptos mainnet.
  To connect to a different Aptos network, such as testnet, make sure you download the correct genesis and waypoint
  files for the network you want to connect to. Similarly, you will need to modify the Terraform files to use the
  correct configurations (e.g., `source`, `image_tag` and `chain_id`).
</Aside>

1. Create a working directory for your Aptos nodes, and pick a username for your nodes, e.g.,

   ```shellscript filename="Terminal"
   export WORKSPACE=mainnet
   export USERNAME=alice
   mkdir ~/$WORKSPACE
   cd ~/$WORKSPACE
   ```

2. Create an S3 storage bucket for storing the Terraform state on AWS. You can do this on the AWS UI or using the
   command below:

   ```shellscript filename="Terminal"
   aws s3 mb s3://<bucket name> --region <region name>
   ```

3. Create a Terraform file called `main.tf` in your working directory:

   ```shellscript filename="Terminal"
   cd ~/$WORKSPACE
   vi main.tf
   ```

4. Modify the `main.tf` file to configure Terraform and create the Terraform module. See the example below:

   ```terraform filename="main.tf"
   terraform {
     required_version = "~> 1.3.6"
     backend "s3" {
       bucket = "terraform.aptos-node"
       key    = "state/aptos-node"
       region = <aws region>
     }
   }

   provider "aws" {
     region = <aws region>
   }

   module "aptos-node" {
     # Download the Terraform module from the aptos-core repository.
     source        = "github.com/aptos-labs/aptos-core.git//terraform/aptos-node/aws"
     region        = <aws region>  # Specify the AWS region
     # zone_id     = "<Route53 zone id>"  # Use Route53 if you want to use DNS
     era           = 1  # Bump the era number to wipe the chain data
     chain_id      = 1  # Use 1 for mainnet, or different values for other networks.
     image_tag     = "mainnet" # Specify the image tag to use based on the network
     validator_name = "<Name of your validator>" # Specify the name of your validator
   }
   ```

   For all customization options, see:

   - The Terraform variables: [https://github.com/aptos-labs/aptos-core/blob/main/terraform/aptos-node/aws/variables.tf](https://github.com/aptos-labs/aptos-core/blob/main/terraform/aptos-node/aws/variables.tf)
   - The Helm values: [https://github.com/aptos-labs/aptos-core/blob/main/terraform/helm/aptos-node/values.yaml](https://github.com/aptos-labs/aptos-core/blob/main/terraform/helm/aptos-node/values.yaml).

5. Initialize Terraform in the `$WORKSPACE` directory where you created the `main.tf` file.

   ```shellscript filename="Terminal"
   terraform init
   ```

   This will download all the Terraform dependencies into the `.terraform` folder in your current working directory.

6. Create a new Terraform workspace to isolate your environments, and see the list of workspaces.

   ```shellscript filename="Terminal"
   terraform workspace new $WORKSPACE

   # This command will list all workspaces
   terraform workspace list
   ```

7. Apply the Terraform configuration.

   ```shellscript filename="Terminal"
   terraform apply
   ```

   This may take a while to finish (e.g., >20 minutes). Terraform will create all the resources on your cloud account.

8. After `terraform apply` finishes, you can check if the resources have been created correctly, by running the following commands:

   - `aws eks update-kubeconfig --name aptos-$WORKSPACE`: This command will configure access for your k8s cluster.
   - `kubectl get pods`: This command will output all pods in the cluster. You should see haproxy, the
     validator and the VFN (with the validator and VFN pod `pending` due to further action in later steps).
   - `kubectl get svc`: This command will output all services in the cluster. You should see the
     `validator-lb` and `fullnode-lb`, with an external IP for network connectivity.

9. Next, we need to inject your node's IP information into your environment. You can do this by running the following commands:

   ```shellscript filename="Terminal"
   export VALIDATOR_ADDRESS="$(kubectl get svc ${WORKSPACE}-aptos-node-0-validator-lb --output jsonpath='{.status.loadBalancer.ingress[0].hostname}')"

   export FULLNODE_ADDRESS="$(kubectl get svc ${WORKSPACE}-aptos-node-0-fullnode-lb --output jsonpath='{.status.loadBalancer.ingress[0].hostname}')"
   ```

10. Now, generate the key pairs for your nodes in your working directory. You can do this by running
    the following command with the Aptos CLI:

    ```shellscript filename="Terminal"
    aptos genesis generate-keys --output-dir ~/$WORKSPACE/keys
    ```

    This will create 4 key files under `~/$WORKSPACE/keys` directory:

    - `public-keys.yaml`: This file contains all public keys for your validator and VFN, as well as your account address.
    - `private-keys.yaml`: This file contains all private keys for your validator and VFN.
    - `validator-identity.yaml`: This file contains the public and private keys for your validator, as well as your account address.
    - `validator-full-node-identity.yaml`: This file contains the public and private keys for your VFN, as well as your account address.

    <Aside type="caution">
      **Backup your private keys**<br />
      Your private keys are important for you to establish ownership of your nodes. Never share your **private** keys with anyone,
      and make sure to **backup** `private-keys.yaml` somewhere safe.
    </Aside>

11. Next, you will need to set your validator configuration. This includes setting the validator and VFN host names,
    which may be IP addresses or DNS addresses. This can be done by running the following command:

    ```shellscript filename="Terminal"
    aptos genesis set-validator-configuration \
      --local-repository-dir ~/$WORKSPACE \
      --username $USERNAME \
      --owner-public-identity-file ~/$WORKSPACE/keys/public-keys.yaml \
      --validator-host $VALIDATOR_ADDRESS:6180 \
      --full-node-host $FULLNODE_ADDRESS:6182 \
      --stake-amount 100000000000000
    ```

    Configuring the validator will create two YAML files in the `~/$WORKSPACE/$USERNAME` directory: `owner.yaml` and
    `operator.yaml`. These will be useful for connecting your nodes to the Aptos network (later).

12. Download the following files by following the instructions on the [Node Files](/network/nodes/configure/node-files-all-networks) pages.
    You will need to select the appropriate network (e.g., `mainnet`, `testnet`, `devnet`) and download the following files:

    - `genesis.blob`
    - `waypoint.txt`

13. To recap, in your working directory (`~/$WORKSPACE`), you should have a list of files:

    - `main.tf`: The Terraform files to install the `aptos-node` module.
    - `keys` folder containing:
      - `public-keys.yaml`: Public keys for both nodes.
      - `private-keys.yaml`: Private keys for both nodes.
      - `validator-identity.yaml`: Key and account information for the validator.
      - `validator-full-node-identity.yaml`: Key and account information for the VFN.
    - `$username` folder containing:
      - `owner.yaml`: The owner, operator and voter mappings.
      - `operator.yaml`: Validator and VFN operator information.
    - `waypoint.txt`: The waypoint for the genesis transaction on the network you are connecting to.
    - `genesis.blob` The genesis blob for the network you are connecting to.

14. Finally, insert the `genesis.blob`, `waypoint.txt` and the identity files as secrets into the k8s cluster,
    by running the following command:

    ```shellscript filename="Terminal"
    kubectl create secret generic ${WORKSPACE}-aptos-node-0-genesis-e1 \
        --from-file=genesis.blob=genesis.blob \
        --from-file=waypoint.txt=waypoint.txt \
        --from-file=validator-identity.yaml=keys/validator-identity.yaml \
        --from-file=validator-full-node-identity.yaml=keys/validator-full-node-identity.yaml
    ```

    <Aside type="caution">
      **Era numbers and dangling volumes**<br />
      The `-e1` suffix in the command above refers to the era number. If you changed the `era` number, make sure it matches
      when creating the secrets.

      The `era` is a concept relevant only to Kubernetes deployments of an Aptos node.
      Changing the `era` provides an easy way to wipe your deployment's state (e.g., blockchain data). However, this may
      lead to dangling persistent volumes. Confirm the existence of any dangling volumes with `kubectl get pvc`
      and delete any dangling volumes manually to minimize costs.
    </Aside>

15. Now, we should be able to see that all pods are running, including the validator and VFN. You can check this by
    executing the following command:

    ```shellscript filename="Terminal"
    kubectl get pods

    # Example output
    NAME                                        READY   STATUS    RESTARTS   AGE
    node1-aptos-node-0-fullnode-e9-0              1/1     Running   0          4h31m
    node1-aptos-node-0-haproxy-7cc4c5f74c-l4l6n   1/1     Running   0          4h40m
    node1-aptos-node-0-validator-0                1/1     Running   0          4h30m
    ```

<Aside type="caution">
  **Next steps**<br />
  You have now completed setting up your validator and VFN using AWS. However, your nodes will not be able to connect
  to the Aptos network just yet.
</Aside>

## Connecting to the Aptos Network

You have now completed setting up your validator and VFN using AWS. Proceed to [Connect Nodes](/network/nodes/validator-node/connect-nodes) for the next steps.

# Using Azure

> Deploy Aptos validator and validator fullnode (VFN) on Microsoft Azure using Terraform and Kubernetes with detailed setup guide.

import { Aside } from '@astrojs/starlight/components';

This is a step-by-step guide to deploy an Aptos validator and validator fullnode (VFN) using Microsoft Azure. Using this guide,
the validator and VFN will be deployed on separate machines.

<Aside type="caution">
  **Prerequisites** <br />
  Before you begin, make sure to read and understand the [Node Requirements](/network/nodes/validator-node/node-requirements). Similarly, make sure you have
  installed the [Aptos CLI](/build/cli),
  [Terraform](https://www.terraform.io/downloads.html),
  [Kubernetes CLI](https://kubernetes.io/docs/tasks/tools/),
  and [Azure CLI](https://docs.microsoft.com/en-us/cli/azure/install-azure-cli). This guide assumes that you already have
  an Azure account setup.
</Aside>

## Deployment steps

<Aside type="note">
  **Default connection to mainnet**<br />
  If you follow the default setup in this document, then your validator and VFN will be connected to the Aptos mainnet.
  To connect to a different Aptos network, such as testnet, make sure you download the correct genesis and waypoint
  files for the network you want to connect to. Similarly, you will need to modify the Terraform files to use the
  correct configurations (e.g., `source`, `image_tag` and `chain_id`).
</Aside>

1. Create a working directory for your Aptos nodes, and pick a username for your nodes, e.g.,

   ```shellscript filename="Terminal"
   export WORKSPACE=mainnet
   export USERNAME=alice
   mkdir ~/$WORKSPACE
   cd ~/$WORKSPACE
   ```

2. Create a blob storage container for storing the Terraform state on Azure, you can do this on the Azure UI
   or using the commands below:

   ```shellscript filename="Terminal"
   az group create -l <azure region> -n aptos-$WORKSPACE
   az storage account create -n <storage account name> -g aptos-$WORKSPACE -l <azure region> --sku Standard_LRS
   az storage container create -n <container name> --account-name <storage account name> --resource-group aptos-$WORKSPACE
   ```

3. Create a Terraform file called `main.tf` in your working directory:

   ```shellscript filename="Terminal"
   cd ~/$WORKSPACE
   vi main.tf
   ```

4. Modify the `main.tf` file to configure Terraform and create the Terraform module. See the example below:

   ```terraform filename="main.tf"
   terraform {
     required_version = "~> 1.3.6"
     backend "azurerm" {
       resource_group_name  = <resource group name>
       storage_account_name = <storage account name>
       container_name       = <container name>
       key                  = "state/validator"
     }
   }

   module "aptos-node" {
     # Download the Terraform module from the aptos-core repository.
     source        = "github.com/aptos-labs/aptos-core.git//terraform/aptos-node/azure"
     region        = <azure region>  # Specify the Azure region
     era           = 1  # Bump the era number to wipe the chain data
     chain_id      = 1  # Use 1 for mainnet, or different values for other networks.
     image_tag     = "mainnet" # Specify the image tag to use based on the network
     validator_name = "<Name of your validator>" # Specify the name of your validator
   }
   ```

   For all customization options, see:

   - The Terraform variables [https://github.com/aptos-labs/aptos-core/blob/main/terraform/aptos-node/azure/variables.tf](https://github.com/aptos-labs/aptos-core/blob/main/terraform/aptos-node/azure/variables.tf)
   - The Helm values: [https://github.com/aptos-labs/aptos-core/blob/main/terraform/helm/aptos-node/values.yaml](https://github.com/aptos-labs/aptos-core/blob/main/terraform/helm/aptos-node/values.yaml).

5. Initialize Terraform in the `$WORKSPACE` directory where you created the `main.tf` file.

   ```shellscript filename="Terminal"
   terraform init
   ```

   This will download all the Terraform dependencies into the `.terraform` folder in your current working directory.

6. Create a new Terraform workspace to isolate your environments, and see the list of workspaces.

   ```shellscript filename="Terminal"
   terraform workspace new $WORKSPACE

   # This command will list all workspaces
   terraform workspace list
   ```

7. Apply the Terraform configuration.

   ```shellscript filename="Terminal"
   terraform apply
   ```

   This may take a while to finish (e.g., >20 minutes). Terraform will create all the resources on your cloud account.

8. After `terraform apply` finishes, you can check if the resources have been created correctly, by running the following commands:

   - `az aks get-credentials --resource-group aptos-$WORKSPACE --name aptos-$WORKSPACE`: This command will configure access for your k8s cluster.
   - `kubectl get pods`: This command will output all pods in the cluster. You should see haproxy, the
     validator and the VFN (with the validator and VFN pod `pending` due to further action in later steps).
   - `kubectl get svc`: This command will output all services in the cluster. You should see the
     `validator-lb` and `fullnode-lb`, with an external IP for network connectivity.

9. Next, we need to inject your node's IP information into your environment. You can do this by running the following commands:

   ```shellscript filename="Terminal"
   export VALIDATOR_ADDRESS="$(kubectl get svc ${WORKSPACE}-aptos-node-0-validator-lb --output jsonpath='{.status.loadBalancer.ingress[0].hostname}')"

   export FULLNODE_ADDRESS="$(kubectl get svc ${WORKSPACE}-aptos-node-0-fullnode-lb --output jsonpath='{.status.loadBalancer.ingress[0].hostname}')"
   ```

10. Now, generate the key pairs for your nodes in your working directory. You can do this by running
    the following command with the Aptos CLI:

    ```shellscript filename="Terminal"
    aptos genesis generate-keys --output-dir ~/$WORKSPACE/keys
    ```

    This will create 4 key files under `~/$WORKSPACE/keys` directory:

    - `public-keys.yaml`: This file contains all public keys for your validator and VFN, as well as your account address.
    - `private-keys.yaml`: This file contains all private keys for your validator and VFN.
    - `validator-identity.yaml`: This file contains the public and private keys for your validator, as well as your account address.
    - `validator-full-node-identity.yaml`: This file contains the public and private keys for your VFN, as well as your account address.

    <Aside type="caution">
      **Backup your private keys** <br />
      Your private keys are important for you to establish ownership of your nodes. Never share your **private** keys with anyone,
      and make sure to **backup** `private-keys.yaml` somewhere safe.
    </Aside>

11. Next, you will need to set your validator configuration. This includes setting the validator and VFN host names,
    which may be IP addresses or DNS addresses. This can be done by running the following command:

    ```shellscript filename="Terminal"
    aptos genesis set-validator-configuration \
      --local-repository-dir ~/$WORKSPACE \
      --username $USERNAME \
      --owner-public-identity-file ~/$WORKSPACE/keys/public-keys.yaml \
      --validator-host $VALIDATOR_ADDRESS:6180 \
      --full-node-host $FULLNODE_ADDRESS:6182 \
      --stake-amount 100000000000000

    ```

    Configuring the validator will create two YAML files in the `~/$WORKSPACE/$USERNAME` directory: `owner.yaml` and
    `operator.yaml`. These will be useful for connecting your nodes to the Aptos network (later).

12. Download the following files by following the instructions on the [Node Files](/network/nodes/configure/node-files-all-networks) pages.
    You will need to select the appropriate network (e.g., `mainnet`, `testnet`, `devnet`) and download the following files:

    - `genesis.blob`
    - `waypoint.txt`

13. To recap, in your working directory (`~/$WORKSPACE`), you should have a list of files:

    - `main.tf`: The Terraform files to install the `aptos-node` module.
    - `keys` folder containing:
      - `public-keys.yaml`: Public keys for both nodes.
      - `private-keys.yaml`: Private keys for both nodes.
      - `validator-identity.yaml`: Key and account information for the validator.
      - `validator-full-node-identity.yaml`: Key and account information for the VFN.
    - `$username` folder containing:
      - `owner.yaml`: The owner, operator and voter mappings.
      - `operator.yaml`: Validator and VFN operator information.
    - `waypoint.txt`: The waypoint for the genesis transaction on the network you are connecting to.
    - `genesis.blob` The genesis blob for the network you are connecting to.

14. Finally, insert the `genesis.blob`, `waypoint.txt` and the identity files as secrets into the k8s cluster,
    by running the following command:

    ```shellscript filename="Terminal"
    kubectl create secret generic ${WORKSPACE}-aptos-node-0-genesis-e1 \
      --from-file=genesis.blob=genesis.blob \
      --from-file=waypoint.txt=waypoint.txt \
      --from-file=validator-identity.yaml=keys/validator-identity.yaml \
      --from-file=validator-full-node-identity.yaml=keys/validator-full-node-identity.yaml
    ```

    <Aside type="caution">
      **Era numbers and dangling volumes**<br />
      The `-e1` suffix in the command above refers to the era number. If you changed the `era` number, make sure it matches
      when creating the secrets.

      The `era` is a concept relevant only to Kubernetes deployments of an Aptos node.
      Changing the `era` provides an easy way to wipe your deployment's state (e.g., blockchain data). However, this may
      lead to dangling persistent volumes. Confirm the existence of any dangling volumes with `kubectl get pvc`
      and delete any dangling volumes manually to minimize costs.
    </Aside>

15. Now, we should be able to see that all pods are running, including the validator and VFN. You can check this by
    executing the following command:

    ```shellscript filename="Terminal"
    kubectl get pods

    # Example output
    NAME                                        READY   STATUS    RESTARTS   AGE
    node1-aptos-node-0-fullnode-e9-0              1/1     Running   0          4h31m
    node1-aptos-node-0-haproxy-7cc4c5f74c-l4l6n   1/1     Running   0          4h40m
    node1-aptos-node-0-validator-0                1/1     Running   0          4h30m
    ```

<Aside type="caution">
  **Next steps** <br />
  You have now completed setting up your validator and VFN using Azure. However, your nodes will not be able to connect
  to the Aptos network just yet.
</Aside>

## Connecting to the Aptos Network

You have now completed setting up your validator and VFN using Azure. Proceed to [Connect Nodes](/network/nodes/validator-node/connect-nodes) for the next steps.

# Using Docker

> Step-by-step guide to deploy Aptos validator and validator fullnode (VFN) using Docker containers on separate machines.

import { Aside } from '@astrojs/starlight/components';

<Aside type="caution">
  **Apple M1+ Users** <br />
  Docker deployment has only been tested on Linux, Windows, and Intel macOS. If you are on M1+ macOS, you will
  need to deploy using [source code](/network/nodes/full-node/deployments/using-source-code).
</Aside>

This is a step-by-step guide to deploy an Aptos validator and validator fullnode (VFN) using Docker. Using this guide, the validator
and VFN will be deployed on separate machines.

<Aside type="caution">
  **Prerequisites** <br />
  Before you begin, make sure to read and understand the [Node Requirements](/network/nodes/validator-node/node-requirements). Similarly, make sure you have
  installed the [Aptos CLI](/build/cli), and [Docker with Docker Compose](https://docs.docker.com/engine/install/).
</Aside>

## Deployment steps

<Aside type="note">
  **Default connection to mainnet**<br />
  If you follow the default setup in this document, then your validator and VFN will be connected to the Aptos mainnet.
  To connect to a different Aptos network, such as testnet, make sure you download the correct genesis and waypoint
  files for the network you want to connect to. Similarly, you will need to modify the docker compose files to use the
  correct docker images by network name.
</Aside>

1. Create a working directory for your Aptos nodes, and pick a username for your nodes, e.g.,

   ```shellscript filename="Terminal"
   export WORKSPACE=mainnet
   export USERNAME=alice
   mkdir ~/$WORKSPACE
   cd ~/$WORKSPACE
   ```

2. Generate the key pairs for your nodes in your working directory. You can do this by running
   the following command with the Aptos CLI:

   ```shellscript filename="Terminal"
   aptos genesis generate-keys --output-dir ~/$WORKSPACE/keys
   ```

   This will create 4 key files under `~/$WORKSPACE/keys` directory:

   - `public-keys.yaml`: This file contains all public keys for your validator and VFN, as well as your account address.
   - `private-keys.yaml`: This file contains all private keys for your validator and VFN.
   - `validator-identity.yaml`: This file contains the public and private keys for your validator, as well as your account address.
   - `validator-full-node-identity.yaml`: This file contains the public and private keys for your VFN, as well as your account address.

   <Aside type="caution">
     **Backup your private keys** <br />
     Your private keys are important for you to establish ownership of your nodes. Never share your **private** keys with anyone,
     and make sure to **backup** `private-keys.yaml` somewhere safe.
   </Aside>

3. Next, you will need to set your validator configuration. This includes setting the validator and VFN host names,
   which may be IP addresses or DNS addresses.

   <Aside type="caution">
     **DNS addresses**<br />
     Using DNS is recommended over IP addresses, as it enables more efficient node migrations and is more resilient
     to host changes.
   </Aside>

   You can set your validator configuration by running the following command with the Aptos CLI:

   ```shellscript filename="Terminal"

   # Replace <validator node IP / DNS address> and <Full Node IP / DNS address> below,
   # with the appropriate IP or DNS address for your nodes.

   cd ~/$WORKSPACE
   aptos genesis set-validator-configuration \
       --local-repository-dir ~/$WORKSPACE \
       --username $USERNAME \
       --owner-public-identity-file ~/$WORKSPACE/keys/public-keys.yaml \
       --validator-host <validator node IP / DNS address>:<Port> \
       --full-node-host <Full Node IP / DNS address>:<Port> \
       --stake-amount 100000000000000

   # For example, if you are using IP addresses:

   aptos genesis set-validator-configuration \
       --local-repository-dir ~/$WORKSPACE \
       --username $USERNAME \
       --owner-public-identity-file ~/$WORKSPACE/keys/public-keys.yaml \
       --validator-host 35.232.235.205:6180 \
       --full-node-host 34.135.169.144:6182 \
       --stake-amount 100000000000000

   # Otherwise, if you are using DNS addresses:

   aptos genesis set-validator-configuration \
       --local-repository-dir ~/$WORKSPACE \
       --username $USERNAME \
       --owner-public-identity-file ~/$WORKSPACE/keys/public-keys.yaml \
       --validator-host bot.aptosdev.com:6180 \
       --full-node-host fn.bot.aptosdev.com:6182 \
       --stake-amount 100000000000000
   ```

   Configuring the validator will create two YAML files in the `~/$WORKSPACE/$USERNAME` directory: `owner.yaml` and
   `operator.yaml`. These will be useful for connecting your nodes to the Aptos network (later).

4. Download the following files by following the instructions on the [Node Files](/network/nodes/configure/node-files-all-networks) pages.
   You will need to select the appropriate network (e.g., `mainnet`, `testnet`, `devnet`) and download the following files:

   - `validator.yaml`
   - `fullnode.yaml`
   - `docker-compose.yaml`
   - `docker-compose-fullnode.yaml`
   - `haproxy.cfg`
   - `haproxy-fullnode.cfg`
   - `blocked.ips`
   - `genesis.blob`
   - `waypoint.txt`

5. To recap, in your working directory (`~/$WORKSPACE`), you should have a list of files:

   - `docker-compose.yaml`: The docker compose file to run the validator.
   - `docker-compose-fullnode.yaml`: The docker compose file to run the VFN.
   - `keys` folder containing:
     - `public-keys.yaml`: Public keys for both nodes.
     - `private-keys.yaml`: Private keys for both nodes.
     - `validator-identity.yaml`: Key and account information for the validator.
     - `validator-full-node-identity.yaml`: Key and account information for the VFN.
   - `$username` folder containing:
     - `owner.yaml`: The owner, operator and voter mappings.
     - `operator.yaml`: Validator and VFN operator information.
   - `waypoint.txt`: The waypoint for the genesis transaction on the network you are connecting to.
   - `genesis.blob` The genesis blob for the network you are connecting to.

6. To start the validator node, run the following command in your working directory:

   ```shellscript filename="Terminal"
   docker-compose up (or `docker compose up` depends on your version)
   ```

   This will start the validator node using the docker compose file and the images specified in the
   `docker-compose.yaml` file. If you wish to change the network you are connecting to, you will need to modify
   the file to use the correct docker images by network name.

7. Before you can start the VFN, you will need to modify the `fullnode.yaml` file to update the host address for the
   validator node. For example, if you are using IP addresses, you will need to update the `full_node_networks`
   `addresses` for the `vfn` network as follows:

   ```yaml filename="fullnode.yaml"
   ---
   addresses:
     - "/ip4/100.100.100.100/tcp/6181/noise-ik/..." # Set the IP Address of the validator
   ```

   Otherwise, if you are using DNS addresses, you will need to update the `addresses` field as follows:

   ```yaml filename="fullnode.yaml"
   ---
   addresses:
     - "/dns/example.com/tcp/6181/noise-ik/..." # Set the DNS Address of the validator
   ```

8. To start your VFN, run the following commands on a separate, dedicated VFN machine. You will need to copy across
   the keys, configuration and docker compose files from the validator machine.

   <Aside type="caution">
     **VFN identity**<br />
     You should copy the keys and configuration
     files across to the VFN machine from the working location where they were generated. Do not attempt to generate
     another set of keys or files for the VFN, as these will not be recognized by the network.
   </Aside>

   To start the VFN, run the following command in your working directory:

   ```shellscript filename="Terminal"
   docker-compose -f docker-compose-fullnode.yaml up
   ```

   This will start the VFN using the docker compose file and the images specified in the
   `docker-compose-fullnode.yaml` file. If you wish to change the network you are connecting to, you will need to modify
   the file to use the correct docker images by network name.

   <Aside type="caution">
     **Next steps**<br />
     You have now completed setting up your validator and VFN using Docker. However, your nodes will not be able to connect
     to the Aptos network just yet.
   </Aside>

## Connecting to the Aptos Network

You have now completed setting up your validator and VFN using Docker. Proceed to [Connect Nodes](/network/nodes/validator-node/connect-nodes) for the next steps.

# Using GCP

> Deploy Aptos validator and validator fullnode (VFN) on Google Cloud Platform using Terraform and Kubernetes with step-by-step instructions.

import { Aside } from '@astrojs/starlight/components';

This is a step-by-step guide to deploy an Aptos validator and validator fullnode (VFN) using Google Cloud Platform Services (GCP).
Using this guide, the validator and VFN will be deployed on separate machines.

<Aside type="caution">
  **Prerequisites** <br />
  Before you begin, make sure to read and understand the [Node Requirements](/network/nodes/validator-node/node-requirements). Similarly, make sure you have
  installed the [Aptos CLI](/build/cli),
  [Terraform](https://www.terraform.io/downloads.html),
  [Kubernetes CLI](https://kubernetes.io/docs/tasks/tools/),
  and [Google Cloud CLI](https://cloud.google.com/sdk/docs/install-sdk). This guide assumes that you already have a GCP
  account setup, and have created a new project for deploying your nodes.
</Aside>

## Deployment steps

1. Create a working directory for your Aptos nodes, and pick a username for your nodes, e.g.,

   ```shellscript filename="Terminal"
   export WORKSPACE=mainnet
   export USERNAME=alice
   mkdir ~/$WORKSPACE
   cd ~/$WORKSPACE
   ```

2. Create a storage bucket for storing the Terraform state on Google Cloud Storage.

   <Aside type="caution">
     **Storage bucket name**<br />
     The name of the Google Cloud storage bucket must be unique.
     See the Google Cloud Storage documentation, [here](https://cloud.google.com/storage/docs/creating-buckets#prereq-cli).
   </Aside>

   Use the GCP UI or Google Cloud Storage command to create the bucket:

   ```shellscript filename="Terminal"
   gsutil mb gs://BUCKET_NAME

   # Here's an example of creating a bucket
   gsutil mb gs://<project-name>-aptos-terraform-dev
   ```

3. Create a Terraform file called `main.tf` in your working directory:

   ```shellscript filename="Terminal"
   cd ~/$WORKSPACE
   vi main.tf
   ```

4. Modify the `main.tf` file to configure Terraform and create the Terraform module. See the example below:

   ```terraform filename="main.tf"
   terraform {
     required_version = "~> 1.3.6"
     backend "gcs" {
       bucket = "BUCKET_NAME" # The bucket name created above
       prefix = "state/aptos-node"
     }
   }

   module "aptos-node" {
     # Download the Terraform module from the aptos-core repository.
     source        = "github.com/aptos-labs/aptos-core.git//terraform/aptos-node/gcp"
     region        = "us-central1"  # Specify the GCP region
     zone          = "c"            # Specify the zone suffix
     project       = "<GCP Project ID>" # Specify your GCP project ID
     era           = 1  # Bump the era number to wipe the chain data
     chain_id      = 1  # Use 1 for mainnet, or different values for other networks.
     image_tag     = "mainnet" # Specify the image tag to use based on the network
     validator_name = "<Name of your validator>" # Specify the name of your validator
   }
   ```

   For all customization options, see:

   - The Terraform variables: [https://github.com/aptos-labs/aptos-core/blob/main/terraform/aptos-node/gcp/variables.tf](https://github.com/aptos-labs/aptos-core/blob/main/terraform/aptos-node/gcp/variables.tf)
   - The Helm values: [https://github.com/aptos-labs/aptos-core/blob/main/terraform/helm/aptos-node/values.yaml](https://github.com/aptos-labs/aptos-core/blob/main/terraform/helm/aptos-node/values.yaml).

5. Initialize Terraform in the `$WORKSPACE` directory where you created the `main.tf` file.

   ```shellscript filename="Terminal"
   terraform init
   ```

   This will download all the Terraform dependencies into the `.terraform` folder in your current working directory.

6. Create a new Terraform workspace to isolate your environments, and see the list of workspaces.

   ```shellscript filename="Terminal"
   terraform workspace new $WORKSPACE

   # This command will list all workspaces
   terraform workspace list
   ```

7. Apply the Terraform configuration.

   ```shellscript filename="Terminal"
   terraform apply
   ```

   This may take a while to finish (e.g., >20 minutes). Terraform will create all the resources on your cloud account.

8. After `terraform apply` finishes, you can check if the resources have been created correctly, by running the following commands:

   - `gcloud container clusters get-credentials aptos-$WORKSPACE --zone <region/zone> --project <project>`: This command will configure access for your k8s cluster.
   - `kubectl get pods`: This command will output all pods in the cluster. You should see haproxy, the
     validator and the VFN (with the validator and VFN pod `pending` due to further action in later steps).
   - `kubectl get svc`: This command will output all services in the cluster. You should see the
     `validator-lb` and `fullnode-lb`, with an external IP for network connectivity.

9. Next, we need to inject your node's IP information into your environment. You can do this by running the following commands:

   ```shellscript filename="Terminal"
   export VALIDATOR_ADDRESS="$(kubectl get svc ${WORKSPACE}-aptos-node-0-validator-lb --output jsonpath='{.status.loadBalancer.ingress[0].hostname}')"

   export FULLNODE_ADDRESS="$(kubectl get svc ${WORKSPACE}-aptos-node-0-fullnode-lb --output jsonpath='{.status.loadBalancer.ingress[0].hostname}')"
   ```

10. Now, generate the key pairs for your nodes in your working directory. You can do this by running
    the following command with the Aptos CLI:

    ```shellscript filename="Terminal"
    aptos genesis generate-keys --output-dir ~/$WORKSPACE/keys
    ```

    This will create 4 key files under `~/$WORKSPACE/keys` directory:

    - `public-keys.yaml`: This file contains all public keys for your validator and VFN, as well as your account address.
    - `private-keys.yaml`: This file contains all private keys for your validator and VFN.
    - `validator-identity.yaml`: This file contains the public and private keys for your validator, as well as your account address.
    - `validator-full-node-identity.yaml`: This file contains the public and private keys for your VFN, as well as your account address.

    <Aside type="caution">
      **Backup your private keys**<br />
      Your private keys are important for you to establish ownership of your nodes. Never share your **private** keys with anyone,
      and make sure to **backup** `private-keys.yaml` somewhere safe.
    </Aside>

11. Next, you will need to set your validator configuration. This includes setting the validator and VFN host names,
    which may be IP addresses or DNS addresses. This can be done by running the following command:

    ```shellscript filename="Terminal"
    aptos genesis set-validator-configuration \
      --local-repository-dir ~/$WORKSPACE \
      --username $USERNAME \
      --owner-public-identity-file ~/$WORKSPACE/keys/public-keys.yaml \
      --validator-host $VALIDATOR_ADDRESS:6180 \
      --full-node-host $FULLNODE_ADDRESS:6182 \
      --stake-amount 100000000000000

    ```

    Configuring the validator will create two YAML files in the `~/$WORKSPACE/$USERNAME` directory: `owner.yaml` and
    `operator.yaml`. These will be useful for connecting your nodes to the Aptos network (later).

12. Download the following files by following the instructions on the [Node Files](/network/nodes/configure/node-files-all-networks) pages.
    You will need to select the appropriate network (e.g., `mainnet`, `testnet`, `devnet`) and download the following files:

    - `genesis.blob`
    - `waypoint.txt`

13. To recap, in your working directory (`~/$WORKSPACE`), you should have a list of files:

    - `main.tf`: The Terraform files to install the `aptos-node` module.
    - `keys` folder containing:
      - `public-keys.yaml`: Public keys for both nodes.
      - `private-keys.yaml`: Private keys for both nodes.
      - `validator-identity.yaml`: Key and account information for the validator.
      - `validator-full-node-identity.yaml`: Key and account information for the VFN.
    - `$username` folder containing:
      - `owner.yaml`: The owner, operator and voter mappings.
      - `operator.yaml`: Validator and VFN operator information.
    - `waypoint.txt`: The waypoint for the genesis transaction on the network you are connecting to.
    - `genesis.blob` The genesis blob for the network you are connecting to.

14. Finally, insert the `genesis.blob`, `waypoint.txt` and the identity files as secrets into the k8s cluster,
    by running the following command:

    ```shellscript filename="Terminal"
    kubectl create secret generic ${WORKSPACE}-aptos-node-0-genesis-e1 \
        --from-file=genesis.blob=genesis.blob \
        --from-file=waypoint.txt=waypoint.txt \
        --from-file=validator-identity.yaml=keys/validator-identity.yaml \
        --from-file=validator-full-node-identity.yaml=keys/validator-full-node-identity.yaml
    ```

    <Aside type="caution">
      **Era numbers and dangling volumes** <br />
      The `-e1` suffix in the command above refers to the era number. If you changed the `era` number, make sure it matches
      when creating the secrets.

      The `era` is a concept relevant only to Kubernetes deployments of an Aptos node.
      Changing the `era` provides an easy way to wipe your deployment's state (e.g., blockchain data). However, this may
      lead to dangling persistent volumes. Confirm the existence of any dangling volumes with `kubectl get pvc`
      and delete any dangling volumes manually to minimize costs.
    </Aside>

15. Now, we should be able to see that all pods are running, including the validator and VFN. You can check this by
    executing the following command:

    ```shellscript filename="Terminal"
    kubectl get pods

    # Example output
    NAME                                        READY   STATUS    RESTARTS   AGE
    node1-aptos-node-0-fullnode-e9-0              1/1     Running   0          4h31m
    node1-aptos-node-0-haproxy-7cc4c5f74c-l4l6n   1/1     Running   0          4h40m
    node1-aptos-node-0-validator-0                1/1     Running   0          4h30m
    ```

<Aside type="caution">
  **Next steps** <br />
  You have now completed setting up your validator and VFN using GCP. However, your nodes will not be able to connect
  to the Aptos network just yet.
</Aside>

## Connecting to the Aptos Network

You have now completed setting up your validator and VFN using GCP. Proceed to [Connect Nodes](/network/nodes/validator-node/connect-nodes) for the next steps.

# Using Source Code

> Build and deploy Aptos validator and validator fullnode (VFN) directly from source code with comprehensive setup instructions.

import { Aside } from '@astrojs/starlight/components';

This is a step-by-step guide to deploy an Aptos validator and validator fullnode (VFN) using source code. Using this guide, the validator
and VFN will be deployed on separate machines.

<Aside type="caution">
  **Prerequisites**<br />
  Before you begin, make sure to read and understand the [Node Requirements](/network/nodes/validator-node/node-requirements). Similarly, make sure you have
  installed the [Aptos CLI](/build/cli), as you will need it to setup your nodes.
</Aside>

## Deployment Steps

<Aside type="note">
  **Default connection to mainnet**<br />
  If you follow the default setup in this document, then your validator and VFN will be connected to the Aptos mainnet.
  To connect to a different Aptos network, such as testnet, make sure you select the appropriate source code branch
  when you build the binary, and download the correct genesis and waypoint files for the network you want to connect to.
</Aside>

1. Follow the steps in [Building Aptos From Source](/network/nodes/building-from-source) to download the `aptos-core` repository and source code.

2. Checkout the `mainnet` branch using `git checkout --track origin/mainnet`. Note: if you want to deploy a validator
   and VFN on another network, use the appropriate branch name (e.g., `testnet`).

3. Create a working directory for your Aptos nodes, and pick a username for your nodes, e.g.,

   ```shellscript filename="Terminal"
   export WORKSPACE=mainnet
   export USERNAME=alice
   mkdir ~/$WORKSPACE
   ```

4. Generate the key pairs for your nodes in your working directory. You can do this by running
   the following command with the Aptos CLI:

   ```shellscript filename="Terminal"
   aptos genesis generate-keys --output-dir ~/$WORKSPACE/keys
   ```

   This will create 4 key files under `~/$WORKSPACE/keys` directory:

   - `public-keys.yaml`: This file contains all public keys for your validator and VFN, as well as your account address.
   - `private-keys.yaml`: This file contains all private keys for your validator and VFN.
   - `validator-identity.yaml`: This file contains the public and private keys for your validator, as well as your account address.
   - `validator-full-node-identity.yaml`: This file contains the public and private keys for your VFN, as well as your account address.

   <Aside type="caution">
     **Backup your private keys** <br />
     Your private keys are important for you to establish ownership of your nodes. Never share your **private** keys with anyone,
     and make sure to **backup** `private-keys.yaml` somewhere safe.
   </Aside>

5. Next, you will need to set your validator configuration. This includes setting the validator and VFN host names,
   which may be IP addresses or DNS addresses.

   <Aside type="note">
     **DNS addresses** <br />
     Using DNS is recommended over IP addresses, as it enables more efficient node migrations and is more resilient
     to host changes.
   </Aside>

   You can set your validator configuration by running the following command with the Aptos CLI:

   ```shellscript filename="Terminal"

   # Replace <validator node IP / DNS address> and <Full Node IP / DNS address> below,
   # with the appropriate IP or DNS address for your nodes.

   cd ~/$WORKSPACE
   aptos genesis set-validator-configuration \
       --local-repository-dir ~/$WORKSPACE \
       --username $USERNAME \
       --owner-public-identity-file ~/$WORKSPACE/keys/public-keys.yaml \
       --validator-host <validator node IP / DNS address>:<Port> \
       --full-node-host <Full Node IP / DNS address>:<Port> \
       --stake-amount 100000000000000

   # For example, if you are using IP addresses:

   aptos genesis set-validator-configuration \
       --local-repository-dir ~/$WORKSPACE \
       --username $USERNAME \
       --owner-public-identity-file ~/$WORKSPACE/keys/public-keys.yaml \
       --validator-host 35.232.235.205:6180 \
       --full-node-host 34.135.169.144:6182 \
       --stake-amount 100000000000000

   # Otherwise, if you are using DNS addresses:

   aptos genesis set-validator-configuration \
       --local-repository-dir ~/$WORKSPACE \
       --username $USERNAME \
       --owner-public-identity-file ~/$WORKSPACE/keys/public-keys.yaml \
       --validator-host bot.aptosdev.com:6180 \
       --full-node-host fn.bot.aptosdev.com:6182 \
       --stake-amount 100000000000000
   ```

   Configuring the validator will create two YAML files in the `~/$WORKSPACE/$USERNAME` directory: `owner.yaml` and
   `operator.yaml`. These will be useful for connecting your nodes to the Aptos network (later).

6. Download the following files by following the instructions on the [Node Files](/network/nodes/configure/node-files-all-networks) pages.
   You will need to select the appropriate network (e.g., `mainnet`, `testnet`, `devnet`) and download the following files:

   - `validator.yaml`
   - `fullnode.yaml`
   - `genesis.blob`
   - `waypoint.txt`

7. Next, copy the `validator.yaml` and `fullnode.yaml` template files (that were just downloaded) into the
   `~/$WORKSPACE/config/` directory. This can be done by running the following commands:

   ```shellscript filename="Terminal"
   mkdir ~/$WORKSPACE/config
   cp validator.yaml ~/$WORKSPACE/config/validator.yaml
   cp fullnode.yaml ~/$WORKSPACE/config/fullnode.yaml
   ```

   These will be the primary configuration files for your validator and VFN, respectively.

8. Now, modify the `validator.yaml` and `fullnode.yaml` template files to contain the appropriate information
   and working directories for your validator and VFN.

   For the `validator.yaml` file, you will need to modify the following fields:

   - `base.data_dir`: The directory where the blockchain data will be stored.
   - `base.waypoint`: The waypoint for the genesis transaction on the network you are connecting to.
   - `consensus.initial_safety_rules_config`: The waypoint for the genesis transaction on the network you are connecting to,
     as well as the `validator-identity.yaml` file location.
   - `execution.genesis_file_location`: The genesis blob for the network you are connecting to.
   - `storage.rocksdb_configs.enable_storage_sharding`: Set to `true`.
   - `validator_network.identity`: The `validator-identity.yaml` file location.

   For the `fullnode.yaml` file, you will need to modify the following fields:

   - `base.data_dir`: The directory where the blockchain data will be stored.
   - `base.waypoint`: The waypoint for the genesis transaction on the network you are connecting to.
   - `execution.genesis_file_location`: The genesis blob for the network you are connecting to.
   - `storage.rocksdb_configs.enable_storage_sharding`: Set to `true`.
   - `full_node_networks`: - The `public` network will need to be updated with the `validator-full-node-identity.yaml`
     file location. - The `vfn` network will need to be updated with the correct IP address or DNS address of the validator.
     For example, if you are using IP addresses, you will need to update the `addresses` field as follows:

     ```yaml filename="fullnode.yaml"
     ---
     addresses:
       - "/ip4/100.100.100.100/tcp/6181/noise-ik/..." # Set the IP Address of the validator
     ```

     Otherwise, if you are using DNS addresses, you will need to update the `addresses` field as follows:

     ```yaml filename="fullnode.yaml"
     ---
     addresses:
       - "/dns/example.com/tcp/6181/noise-ik/..." # Set the DNS Address of the validator
     ```

9. To recap, in your working directory (`~/$WORKSPACE`), you should have a list of files:

   - `config` folder containing:
     - `validator.yaml`: The validator config file.
     - `fullnode.yaml`: The VFN config file.
   - `keys` folder containing:
     - `public-keys.yaml`: Public keys for both nodes.
     - `private-keys.yaml`: Private keys for both nodes.
     - `validator-identity.yaml`: Key and account information for the validator.
     - `validator-full-node-identity.yaml`: Key and account information for the VFN.
   - `$username` folder containing:
     - `owner.yaml`: The owner, operator and voter mappings.
     - `operator.yaml`: Validator and VFN operator information.
   - `waypoint.txt`: The waypoint for the genesis transaction on the network you are connecting to.
   - `genesis.blob` The genesis blob for the network you are connecting to.

10. Now that you have set up your configuration files, you can start your validator and VFN.
    To start your validator, run the following commands, with the paths assuming you are in the root of the `aptos-core` directory:

    ```shellscript filename="Terminal"
    cargo clean
    cargo build -p aptos-node --release
    sudo mv target/release/aptos-node /usr/local/bin
    aptos-node -f ~/$WORKSPACE/config/validator.yaml
    ```

    To start your VFN, run the following commands on a separate, dedicated VFN machine. You will need to download the
    `aptos-core` source code and build the binary on the VFN machine. Likewise, you will need to copy across
    the keys and configuration files from the validator machine.

    <Aside type="caution">
      **VFN identity** <br />
      You should copy the keys and configuration
      files across to the VFN machine from the working location where they were generated. Do not attempt to generate
      another set of keys or files for the VFN, as these will not be recognized by the network.
    </Aside>

    Start your VFN by running the following commands, with the paths assuming you are in the root of the `aptos-core` directory:

    ```shellscript filename="Terminal"
    cargo clean
    cargo build -p aptos-node --release
    sudo mv target/release/aptos-node /usr/local/bin
    aptos-node -f ~/$WORKSPACE/config/fullnode.yaml
    ```

    <Aside type="caution">
      **Next steps** <br />
      You have now completed setting up your validator and VFN using source code. However, your nodes will not be able to connect
      to the Aptos network just yet.
    </Aside>

### (Optional) Running as a Service

If you want to run `aptos-node` as a service, you can set it up to run as a service controlled by `systemctl`.
This is optional, and can be done using the service template below. You will need to modify the template
to match your environment and configuration.

```shellscript filename="/etc/systemd/system/aptos-node.service"
[Unit]
Description=Aptos Node Service

[Service]
User=nodeuser
Group=nodeuser

LimitNOFILE=500000

#Environment="RUST_LOG=error"
WorkingDirectory=/home/nodeuser/aptos-core
ExecStart=/usr/local/bin/aptos-node -f /home/nodeuser/aptos-mainnet/config/validator.yaml

Restart=on-failure
RestartSec=3s

StandardOutput=journal
StandardError=journal
SyslogIdentifier=aptos-node

[Install]
WantedBy=multi-user.target
```

## Connecting to the Aptos Network

You have now completed setting up your validator and VFN using source code. Proceed to [Connect Nodes](/network/nodes/validator-node/connect-nodes)
for the next steps.

# How to Modify Nodes

> Learn how to perform common maintenance operations on your validator and validator fullnode (VFN) including upgrades, shutdowns, and key rotation.

This section contains tutorials for performing common operations and modifications to your validator and
validator fullnode (VFN). These include:

- ### [Upgrade Nodes](/network/nodes/validator-node/modify-nodes/update-validator-node)
- ### [Shutdown Nodes](/network/nodes/validator-node/modify-nodes/shutting-down-nodes)
- ### [Rotate Consensus Key](/network/nodes/validator-node/modify-nodes/rotate-consensus-key)

# Rotate Consensus Key

> Step-by-step guide to rotate your validator's consensus key for enhanced security including key generation, on-chain updates, and cleanup procedures.

import { Aside } from '@astrojs/starlight/components';

Consensus key rotation is an action taken by a node operator to change the identity of a validator they control.
It happens typically when the corresponding private key is (potentially) lost/leaked,
or every few months as a common security practice.

Below is the step-by-step guide of performing a consensus key rotation with detailed examples.

## New key generation

Using the following [Aptos CLI](/build/cli) command to generate a new consensus identity.
In this example, identity files are saved to directory `/new/key/root`.

```shellscript filename="Terminal"
aptos genesis generate-keys --output-dir /new/key/root
```

## Add new private key to node

Edit the node config yaml as described below.

```yaml
# ...
consensus:
    # ...
    safety_rules:
        # ...
        initial_safety_rules_config:
            from_file:
                # ...
                identity_blob_path: /old/key/root/validator-identity.yaml
                overriding_identity_paths:              # new!
                - /new/key/root/validator-identity.yaml # new!
```

<Aside type="note">
  - Field `identity_blob_path` is required.
  - Field `overriding_identity_paths` is optional, and allows multiple identities to be specified for rotation purposes.
  - The node will choose the identity that matches the on-chain state.
</Aside>

Now restart the node.
It should load the new key but continue using the old key for consensus.

## Add new public key on chain

Aptos CLI is needed again, and your operator account is assumed to have been set up as a CLI profile `profile1`.

Find your pool address (denoted by `$POOL_ADDR`).

In `/new/key/root/public-keys.yaml`,

- find the public key of your new consensus identity  (denoted by `$NEW_PUBLIC_KEY`);
- find the proof of possession of your new consensus identity (denoted by `$PROOF_OF_POSSESSION`).

Run a transaction with aptos CLI to update the on-chain consensus public key for the next epoch.

```shellscript
aptos move run \
    --profile profile1 \
    --function-id 0x1::stake::rotate_consensus_key \
    --args \
        address:$POOL_ADDR \
        hex:$NEW_PUBLIC_KEY \
        hex:$PROOF_OF_POSSESSION
```

Here is a complete example.

```shellscript
aptos move run \
    --profile profile1 \
    --function-id 0x1::stake::rotate_consensus_key \
    --args \
        address:0x1eb42885d7d5232269229e56bb80d0959584e14485097ebf9ab619cf4fda5c02 \
        hex:0xacb7859468ca85cf9935e64ebb2b9b3fa8187de42d541acebaf732365a0131eaa994098f9d0d7e6b8ddea8ef11e16c55 \
        hex:0x8e27fd9300433191b1123217928a6f5190a6ec344ea8623555712a850029b34f5c4bab68df7568b48bcced408cde5174064284407ee760df5dbf12d1c6090589ea1a692997018aca740e91d2182e5715c7745565fe99361e279ccfcfa10ae1f7
```

## Wait for the next epoch

The new key should become effective after the next epoch change (which happens every 2 hours).

## (Advanced) Old key clean-up

In the secure storage (typically a file named `secure_storage.json`),
consensus identities are organized as follows.

- Field `consensus` contains the default consensus identity.
  - Typically created when you start the node for the first time.
  - Must exist.
- Field `consensus_X` contains additional consensus identities with `X` as its public key.
  - Created because you once added it to `overriding_identity_paths` in node config yaml.

**Currently, identities won't be deleted automatically from secure storage**,
even if you delete the corresponding identity from the node config yaml.

If you need to ensure the old key is completely gone, manually clean-up is needed.

Here is an example of `secure_storage.json`.

```js
{
    // ...
    "consensus": {
        "data": "GetResponse",
        "last_update": 1731372563,
        "value": "0x221f6fbfefa0a40b84c88fbb546a0884977dcc56719a96ed4e5d69b6a4ff58c8"
    },
    "consensus_acb7859468ca85cf9935e64ebb2b9b3fa8187de42d541acebaf732365a0131eaa994098f9d0d7e6b8ddea8ef11e16c55": {
        "data": "GetResponse",
        "last_update": 1731383387,
        "value": "0x18d5098b3819d5fb0fc208b8bb0946b263f961f60716fc4d10d4b010fdb89a55"
    },
    // ...
}
```

To delete private key `0x18d5...`, simply delete the entire field with key `consensus_acb7...`.

To delete private key `0x221f...`, update the value `0x221f...` to something else (e.g. another private key).

# Shutdown Nodes

> Safely shutdown your validator and validator fullnode (VFN) by leaving the validator set and cleaning up resources across different deployment methods.

import { Aside } from '@astrojs/starlight/components';

If you want to shut down your validator and validator fullnode (VFN), follow the instructions below to leave the
validator set and clean up the resources used by the nodes.

<Aside type="caution">
  **LEAVE THE VALIDATOR SET FIRST**<br />
  It is important to leave the validator set before shutting down your nodes. Otherwise, you will reduce stake
  participation in the network and risk degrading network health.
</Aside>

## Leave the validator set

Before shutting down your nodes, you must leave the validator set. This will ensure that your node is no longer
responsible for participating in consensus. Validator nodes can leave the validator set at any time. This also
happens automatically when there is insufficient stake in the validator account.

When you leave the validator set, your node will be marked as "inactive" in the next epoch. To leave the validator set,
run the following command using the Aptos CLI. You will need to set the `profile` and `owner-address` flags.

```shellscript filename="Terminal"
aptos node leave-validator-set --profile <operator-profile> --pool-address <owner-address>
```

<Aside type="caution">
  **WAITING FOR EPOCH CHANGES**<br />
  If you leave the validator set, it will only take effect at the beginning of the next epoch. You will
  need to wait for the next epoch to start before shutting down your nodes. Similarly, if you leave
  the validator set and then rejoin in the same epoch, the rejoin will fail. You should wait for the
  next epoch to start before rejoining the validator set.
</Aside>

## Shutdown methods

Once you have successfully left the validator set, you can shut down your nodes. The method for shutting down your
nodes depends on how you deployed them. Choose the appropriate section below to shut down your nodes.

## Using Source Code

1. Stop your node by killing the `aptos-node` process. This is sufficient to shut down your node.
2. (Optional) If you wish to free up space, remove the data directory, e.g., `rm -r <your-data-directory>`.
3. (Optional) If you wish to reuse your node identity, you should keep the configuration files:
   - `public-keys.yaml`
   - `private-keys.yaml`
   - `validator-identity.yaml`
   - `validator-full-node-identity.yaml`

## Using Docker

1. Stop your node and remove the data volumes by running the command: `docker compose down --volumes`.
   This is sufficient to shut down your node.
2. (Optional) If you wish to reuse your node identity, you should keep the configuration files:
   - `public-keys.yaml`
   - `private-keys.yaml`
   - `validator-identity.yaml`
   - `validator-full-node-identity.yaml`

## Using Terraform

<Aside type="note">
  Terraform is commonly used to setup nodes on cloud providers like AWS, Azure, and GCP.
</Aside>

1. Stop your node and delete all the resources by running the command: `terraform destroy`. This
   is sufficient to shut down your node.
2. (Optional) If you wish to reuse your node identity, you should keep the configuration files:
   - `public-keys.yaml`
   - `private-keys.yaml`
   - `validator-identity.yaml`
   - `validator-full-node-identity.yaml`

# Upgrade Nodes

> Keep your validator and VFN up-to-date with simple upgrades and VFN failover techniques to minimize downtime during software updates.

import { Aside } from '@astrojs/starlight/components';

This section contains tutorials for upgrading your validator and validator fullnode (VFN). Upgrades are a
common operation for maintaining your nodes. Aptos Labs frequently releases new versions of the
Aptos node software, and you should keep your nodes up to date to ensure they are secure and reliable.

<Aside type="caution">
  Running old node versions and failing to update your nodes can lead to security vulnerabilities, performance
  degradation, and network instability. It is important to keep your nodes up to date.
</Aside>

There are two primary ways to upgrade your nodes. The first is a **simple** **upgrade** of the node software, and the
second is a more **complex** **failover** process between your validator and VFN. The failover process is useful for
minimizing validator downtime when you need to upgrade.

## Simple Upgrade

To perform a simple node upgrade, you can upgrade the validator and VFN individually, one at a time.
This process is straightforward and can be repeated for each node. The steps are as follows:

1. First, stop the node manually (e.g., the validator or VFN). To stop the node, it will depend on your deployment method.
2. Next, update the node software to the latest version. This may require downloading the latest binary or Docker image,
   or recompiling the source code. Depending on your deployment method, you can perform this step in the background while the node is still running.
   This should help minimize downtime.
3. Finally, once you have updated the node software, restart the node using the latest software version and the original
   commands you used to start the node.

   <Aside type="note">
     **REPEAT FOR EACH NODE**<br />
     You will need to perform the simple upgrade process for each node individually. This means you will need to upgrade
     the validator and VFN separately.
   </Aside>

<br />

## Upgrade via VFN Failover

To minimize validator downtime, you can perform a failover process between your validator and VFN. This process involves
upgrading the VFN to the latest version and converting it to the validator. Once the VFN has been converted to the new
validator, you can then upgrade the original validator and convert it into the new VFN.

The benefit of this approach is that it minimizes validator downtime by allowing you to prepare the new
validator while the original validator is still running.

<Aside type="caution">
  **Node differences**<br />
  Before you begin the failover process, it is important to understand that the data maintained by the two nodes
  (i.e., validator and VFN) is not identical. The VFN is missing the `consensus_db` and the `secure-data.json`
  file, and both nodes use different configuration files (including identities).

  If you are not comfortable with the failover process, you should consider performing a simple upgrade instead.
</Aside>

To perform a VFN failover upgrade, you should follow these steps:

1. Update your DNS to swap the [network addresses](/network/nodes/validator-node/connect-nodes/connect-to-aptos-network#3-update-on-chain-network-addresses) between the validator and VFN.

2. Stop the VFN and update the node software to the latest version. This may require downloading the latest binary or Docker image,
   or recompiling the source code. In addition, you will need to copy the `consensus_db` and `secure-data.json` file from the validator to the VFN,
   as well as the validator configuration file (including validator identities).

3. Once the VFN is primed to become the new validator, you can stop the old validator, and start the new validator
   immediately. This will minimize validator downtime.

   <Aside type="caution">
     **ONLY ONE VALIDATOR AT A TIME** <br />
     It is important to ensure that only a single validator is running at any given time. If you fail to stop
     the original validator before starting the new validator, you will have two validators running at the same time,
     and this will lead to consensus failures and performance issues on your nodes.
   </Aside>

4. Now, you will have a validator running the new code version. Observe that before DNS changes take effect your new
   validator will only have outbound connections.

5. Next, prepare the original validator to become the new VFN. This will involve updating the node software to the latest
   version, and copying the VFN configuration file (including VFN identities) across.

6. Once the original validator is ready to become the new VFN, you can start the new VFN.

<Aside type="note">
  Once you have completed the failover process, you should monitor the new validator and VFN to ensure they are running
  correctly, and that your validator is still participating in consensus.
</Aside>

# Node Requirements

> Hardware, networking, and software requirements for running Aptos validator and validator fullnode (VFN) to ensure optimal performance and stability.

import { Aside } from '@astrojs/starlight/components';

To ensure that your validator and validator fullnode (VFN) operate smoothly, both nodes should meet the
requirements specified in this document.

<Aside type="caution">
  **Failure to meet requirements**<br />
  Failure to meet the requirements outlined in this document will result in your nodes experiencing degradation under load,
  consensus failures, reward losses, and general instability.
</Aside>

## Resource isolation

When running an Aptos validator and VFN, we strongly recommend that the nodes run on two separate and
independent machines. These machines should be well-provisioned, meet the requirements outlined below and
be isolated from each other. Maintaining resource isolation between the validator and the VFN is important
for security and to ensure that the nodes do not encounter performance degradation, instability or failures when
under load.

<Aside type="note">
  For deploying the validator and VFN in the cloud, we provide Terraform support on two cloud providers: **GCP** and **AWS**.
  See [**Running Validator Node**](/network/nodes/validator-node/deploy-nodes).
</Aside>

## Hardware requirements

For running an Aptos validator and VFN in mainnet, we recommend that your hardware be performant enough to maintain
\~30,000 transactions per second (TPS). There are two ways to evaluate if your hardware meets this requirement:

1. Use the reference specs provided below.
2. Run the performance benchmarking tool provided by Aptos.

Note that both the validator and VFN require sufficient hardware separately (i.e., two separate machines that
satisfy the requirements outlined below).

### Reference specs

**Specifications for Running an Aptos Validator and VFN on Mainnet**

| Component            | Specification                                                     |
| -------------------- | ----------------------------------------------------------------- |
| CPU                  | 32 cores, 2.8GHz or faster, AMD Milan EPYC or Intel Xeon Platinum |
| Memory               | 64GB RAM                                                          |
| Storage              | 3.0 TB SSD with at least 60K IOPS and 200MiB/s bandwidth          |
| Networking Bandwidth | 1Gbps                                                             |

**Example Machine Types on Various Clouds**

| Cloud Provider | Machine Type                      | Notes                |
| -------------- | --------------------------------- | -------------------- |
| AWS            | c6id.16xlarge                     | If using a local SSD |
| AWS            | c6i.16xlarge + io2 EBS volume     | With 60K IOPS        |
| GCP            | t2d-standard-60 + pd-ssd          | With 60K IOPS        |
| Azure          | Standard\_D64\_v5                 | With 64K IOPS        |
| Latitude.sh    | m4.large, rs4.large or rs4.xlarge | With 64K IOPS        |

### Performance benchmarking

If you'd prefer to evaluate your hardware for sufficient performance, you can use the performance benchmarking
tool. First, clone the `aptos-core` repository and install the required dependencies (see the
[**Cloning aptos-core**](/network/nodes/building-from-source#clone-the-aptos-core-repo) section).
Then, execute the following commands to run the benchmark:

```shellscript filename="Terminal"
TABULATE_INSTALL=lib-only pip install tabulate

./testsuite/performance_benchmark.sh --short
```

Once the benchmark finishes, it will print out a table, with a column `"t/s"`, which shows the TPS achieved by your
hardware. The evaluation criteria is encoded in the tool, and the tool will display a warning if your hardware does
not meet the requirements.

**Local SSD vs. network storage**

Cloud deployments require choosing between local storage or network storage, such as, AWS EBS and GCP PD.
Loosely speaking, a local SSD often provides lower latency and cost, especially relative to IOPS (input/output
operations per second), while network storage requires CPU support to scale IOPS. However, network
storage provides better support for backups and offers improved reliability for nodes that stop or fail, thus enabling
higher availability. The choice between local SSD and network storage depends on your specific requirements and
constraints.

### Motivating hardware requirements

Hardware requirements for Aptos nodes depend on: (i) the transaction workload being executed; and (ii) the size of the
database on each machine. The current hardware requirements have been set using an estimated transaction workload
(e.g., 30,000 TPS) and an estimated database growth rate for 2024. These may be subject to change. It is also worth
noting that transaction workloads can change frequently, and thus it is necessary to provision your hardware to meet the
requirements of the most demanding transaction workloads. This will ensure that your nodes can perform well under
load and remain stable.

Generally, the size of the database on each machine is a function of the ledger history (i.e., the number
of transactions in the blockchain history) and the number of on-chain states (e.g., accounts and resources).
Both the ledger history and the number of on-chain states depend on several additional factors, including the age
of the blockchain, the average transaction rate over time, and the configuration of the ledger database pruner.
At the time of writing, we estimate that testnet and mainnet require several 100's of GB of storage.

Note that because archival nodes store the entire history of the blockchain, the database size on archival nodes will
continue to grow unbounded. As a result, we cannot provide a recommendation for archival node storage sizes.

## Network requirements and ports

When you are running a validator and a VFN, you are required to open network ports on your nodes to allow other
nodes (i.e., peers) to connect to you. There are different Aptos network types, and each network type uses a different port (see below).

### Network types

There are three types of Aptos networks:

1. **Validator network:** Validators connect to each other over this network. Validator fullnodes (VFNs) and public fullnodes (PFNs) do not use this network.
2. **VFN network:** The validator fullnode (VFN) network allows a validator and VFN pair to connect to each other. This network is private between the validator and the VFN.
3. **Public network:** The public network allows VFNs and public fullnodes (PFNs) to connect to other VFNs and PFNs. This allows public node operators to access the blockchain.

Your node can be configured so that each of these networks can operate using a different port on your node. You can configure
the port settings using the node configuration YAML file. Here is an [example
configuration file](https://github.com/aptos-labs/aptos-core/blob/4ce85456853c7b19b0a751fb645abd2971cc4c0c/docker/compose/aptos-node/fullnode.yaml#L10) for a VFN node
that configures the VFN network to use port `6181` and the public network to use port `6182`.

### Port settings

The recommendations described below assume the default port settings used by validators, VFNs and PFNs. If you have
changed the default port settings in your configuration file, then you should adjust the recommendations accordingly.

<Aside type="caution">
  **Exposing ports**<br />
  Unless explicitly required, we recommend that you do not expose any other ports while operating a node. This is because
  exposing additional ports can increase the attack surface of your node and make it more vulnerable to adversaries.
</Aside>

#### Running a validator:

Assuming default ports are used, the following should be configured for validator nodes:

- Open the following TCP ports:
  - `6180` - **Validator network**: Open this port publicly to enable the validator to connect to other validators in the network.
  - `6181` ‚Äì **VFN network**: Open this port privately to only be accessible by your VFN.
- Close the following TCP ports:
  - `6182` ‚Äì **Public network**: Close this port to prevent PFN connections.
  - `9101` ‚Äì **Inspection service**: Close this port to prevent unauthorized metric inspection.
  - `9102` ‚Äì **Admin service**: Close this port to prevent unauthorized admin service interaction.
  - `80/8080` **REST API**: Close this port to prevent unauthorized REST API access.

#### Running a VFN:

Assuming default ports are used, the following should be configured for VFN nodes:

- Open the following TCP ports:
  - `6181` ‚Äì **VFN network**: Open this port privately to only be accessible by your validator.
  - `6182` ‚Äì **Public network**: Open this port publicly to enable PFNs to connect to your VFN.
- Close the following TCP ports:
  - `9101` ‚Äì **Inspection service**: Close this port to prevent unauthorized metric inspection.
  - `9102` ‚Äì **Admin service**: Close this port to prevent unauthorized admin service interaction.
  - `80/8080` **REST API**: Close this port to prevent unauthorized REST API access.

<Aside type="caution">
  **Exposing services**<br />
  The inspection service port (`9101`), admin service port (`9102`) and the REST API port (`80` or `8080`)
  are likely useful for your internal network, e.g., application development and debugging. However, the inspection service
  port and the admin service port should never be exposed publicly as they can be easily abused. Similarly, if you choose
  to expose the REST API endpoint publicly, you should deploy an additional authentication or rate-limiting mechanism to
  prevent abuse.
</Aside>

## Software Requirements

### Time Service

It is highly recommended to enable system clock synchronization using a Network Time Protocol (NTP) service.
Accurate timekeeping ensures that nodes participate in consensus promptly and remain synchronized with the rest of the network.
Failure to maintain consistent system time may cause nodes to lag behind and validators may even fail to propose blocks.

# Operator

> Complete operator guide for participating in the Aptos network including validator deployment, network connection, staking setup, and maintaining node liveness.

import { Aside, Steps } from '@astrojs/starlight/components';

If you are an operator participating in the Aptos network, then use this document to perform the operator tasks such as deploying a validator node and validator fullnode, registering the nodes on the Aptos community platform, and performing the validation.

<Aside type="note">
  **Both validator node and validator fullnode are required for mainnet** <br />
  For participating in the Aptos mainnet, you must deploy both a validator node and a validator fullnode.
</Aside>

## Deploy the nodes and register

<Steps>
  1. Read the

     Make sure that your hardware, storage and network resources satisfy the node requirements.

  2. Deploy the nodes

     Follow the detailed node installation steps provided in [**Running Validator Node**](/network/nodes/validator-node/deploy-nodes)
     and deploy a validator node and a validator fullnode.
</Steps>

Note that your nodes will not be running correctly (not syncing, not participating in consensus),
until they're added to the validator set via [staking pool operations](/network/nodes/validator-node/connect-nodes/staking-pool-operations) (below).

## Connect to Aptos network

After deploying your nodes, [connect to the Aptos Network](/network/nodes/validator-node/connect-nodes/connect-to-aptos-network).

## Set up staking and delegation pool operations

After connecting your nodes to the Aptos network, establish [staking pool operations](/network/nodes/validator-node/connect-nodes/staking-pool-operations) to add your node to the validator set.

Similarly, conduct [delegation pool operations](/network/nodes/validator-node/connect-nodes/delegation-pool-operations) for APT delegated to your validator. Your node will start syncing and participating in consensus.

## Ensure your nodes are live

After your nodes are deployed and configure, make sure they meet [node liveness criteria](/network/nodes/validator-node/verify-nodes/node-liveness-criteria).

# Monitor Nodes

> Monitor and verify the health, performance, and status of your validator and validator fullnode (VFN) with comprehensive verification guides.

This section contains tutorials for verifying the health and performance of your validator and validator fullnode (VFN). These include:

- ### [Node Health](/network/nodes/validator-node/verify-nodes/node-liveness-criteria)
- ### [Validator Leaderboard](/network/nodes/validator-node/verify-nodes/leaderboard-metrics)

# Validator Leaderboard

> Understand how validator rewards performance is calculated and displayed on the Aptos Validator Leaderboard including proposal success rates and epoch metrics.

import { Aside } from '@astrojs/starlight/components';

This document explains how the rewards performance for validator nodes are calculated and displayed on
the [Aptos Validator Leaderboard](https://explorer.aptoslabs.com/validators/all?network=mainnet).

## Calculating validator rewards

Validators are rewarded for participating in consensus. The rewards are calculated based on the number of successful
proposals made by the validator, and the rewards performance is the percentage of rewards earned by the validator out
of the maximum reward earning opportunity.

During an epoch, only the validators in the validator set can propose and vote. The duration of each epoch is set
by governance and validators are selected as leaders (in rounds) to make proposals. This occurs multiple
times in each epoch, meaning that validators can be selected as leaders multiple times in a single epoch.

On each successful proposal, the proposing validator earns rewards based on their stake and on the reward rate that is
configured on-chain. The reward rate is the same for every validator. If all the proposals in an epoch achieve
quorum consensus, a validator earns the maximum reward for the epoch. If all the proposals in an epoch fail, a
validator earns zero rewards for that epoch. The reward performance is calculated as a percentage of the
rewards earned by the validator out of the maximum reward earning opportunity.

Validators are only rewarded for proposing, and not for voting. Rewards are given only at the end of the epoch,
not on every block.

### Reward calculation example

The reward a leader receives is calculated by multiplying the maximum possible reward with the leader's proposal
success rate. For example:

- A leader with 8 successful and 2 failed proposals will receive 80% of maximum reward in the epoch.
- Similarly, another leader with 80 successful and 20 failed proposals will also receive 80% of maximum reward.
- Also, two leaders with no failures but one with 10 and another with 100 successful proposals will get the same % of the maximum reward.

<Aside type="note">
  **REWARDS RATE**<br />
  Note also that the rewards rate is the same for every validator. Hence, the maximum reward is directly proportional
  to the staking amount, i.e., the more a validator stakes, the more the validator can earn in absolute terms.
</Aside>

### Rewards performance

The **REWARDS** **PERFORMANCE** column on the
[Aptos Validator Leaderboard](https://explorer.aptoslabs.com/validators/all?network=mainnet) shows the rewards
performance of a validator. It is calculated as a percentage of the rewards earned by the validator out of the maximum
reward earning opportunity. This is a cumulative metric across all the epochs,
i.e., `(rewards earned across all epochs)/(maximum reward opportunity across all epochs)`

A validator can improve their rewards performance by improving their proposal success rate.

### Last epoch performance

The **LAST EPOCH PERFORMANCE** column on the
[Aptos Validator Leaderboard](https://explorer.aptoslabs.com/validators/all?network=mainnet) shows the rewards
performance of a validator in the last epoch. It is calculated as a percentage of the rewards earned by the validator
in the last epoch out of the maximum reward earning opportunity in the last epoch, i.e., `(rewards earned in the last
epoch)/(maximum reward opportunity in the last epoch)`.

This metric provides an early indicator to see if a validator is improving their reward performance.

# Node Health

> Verify and monitor the health of your validator and validator fullnode (VFN) using runtime metrics, local monitoring tools, and telemetry data.

import { Aside } from '@astrojs/starlight/components';

This document describes how you can verify and monitor the health of your validator and validator fullnode (VFN) in the
Aptos network. Many of the methods described here rely on the runtime metrics that your nodes collect and report. These
metrics are collected by the Aptos node binary and are exposed via a Prometheus metrics endpoint. For a detailed
description of the important metrics, see the [Node Inspection Service](/network/nodes/measure/node-inspection-service) and
[Important Node Metrics](/network/nodes/measure/important-metrics) documentation.

## Initial Node Verification

After deploying your nodes and connecting them to the Aptos network, you should verify that your nodes are running
correctly.

<Aside type="note">
  **FIRST TIME?**<br />
  In some environments, e.g., `mainnet` and `testnet`, your VFN will begin syncing first (before your validator is able to sync).
  This is normal behaviour. Once your VFN has finished syncing, your validator node will start syncing and eventually start participating in consensus.
</Aside>

You can verify the correctness of your nodes by inspecting several simple metrics. Follow these steps:

1. Check if your nodes are state syncing by running this command:

   ```shellscript filename="Terminal"
   curl 127.0.0.1:9101/metrics 2> /dev/null | grep "aptos_state_sync_version"
   ```

   You should expect to see the `synced` or `synced_states` versions increasing. The versions should start increasing
   for your VFN first, then eventually your validator node will start syncing.

   <Aside type="note">
     **CLOUD DEPLOYMENT?**<br />
     You may need to replace `127.0.0.1` with your validator or VFN IP/DNS if deployed on the cloud.
   </Aside>

2. Verify that your validator is connecting to other peers on the network.

   ```shellscript filename="Terminal"
   curl 127.0.0.1:9101/metrics 2> /dev/null | grep "aptos_connections{.*\"Validator\".*}"
   ```

   The command will output the number of inbound and outbound connections of your validator node. For example:

   ```shellscript filename="Terminal"
   aptos_connections{direction="inbound",network_id="Validator",peer_id="f326fd30",role_type="validator"} 5
   aptos_connections{direction="outbound",network_id="Validator",peer_id="f326fd30",role_type="validator"} 2
   ```

   As long as one of the metrics is greater than zero, your validator node is connected to at least one of the peers on the network. If your validator is not
   connected to any peers, make sure your VFN has completed syncing first. Once your VFN has finished syncing, your validator
   node will start syncing and eventually be able to connect to other peers.

3. After your node syncs to the latest version, you can also check if consensus is making progress, and your node is proposing.

   ```shellscript filename="Terminal"
   curl 127.0.0.1:9101/metrics 2> /dev/null | grep "aptos_consensus_current_round"

   curl 127.0.0.1:9101/metrics 2> /dev/null | grep "aptos_consensus_proposals_count"
   ```

   You should expect to see these numbers continue to increase.

## Local Monitoring

If you are a node operator, there are several tools available to you to verify the health of your node going forward:

- **Metrics:** You can monitor your local metrics endpoint by running a `curl` command against the
  [Node Inspection Service](/network/nodes/measure/node-inspection-service) and verify key metrics. For example, you can
  verify the synchronization status of your node by running the command outlined in the
  [Verify synchronization](/network/nodes/full-node/verify-pfn#verify-synchronization) section.

- **REST API:** You can also monitor your node's health by querying the REST API. For example, you can verify the
  current block height of your node by pinging the index page of your node's REST API. For more information, see the
  [Aptos API Specification](/build/apis/fullnode-rest-api).

- **Monitoring tools:** To improve observability, you can also install monitoring tools that scrape the local metrics endpoint:
  - For Kubernetes based deployments, install the monitoring Helm chart ([https://github.com/aptos-labs/aptos-core/tree/main/terraform/helm/monitoring](https://github.com/aptos-labs/aptos-core/tree/main/terraform/helm/monitoring)).
  - Locally, you may run Prometheus and Grafana directly. Dashboards that utilize the metrics can be found here: ([https://github.com/aptos-labs/aptos-core/tree/main/dashboards](https://github.com/aptos-labs/aptos-core/tree/main/dashboards)).

## Telemetry

The Aptos Labs team can also monitor your node remotely using [Node Telemetry](/network/nodes/configure/telemetry). When you enable telemetry on
your nodes, the Aptos node binary will send telemetry data in the background, which includes the node's metrics.
Telemetry data from your node is necessary to evaluate the performance, liveness and health of your nodes.

If your node is using the default config without explicitly disabling telemetry, and has `HTTPS` egress access to the
internet, then it will report various key metrics to Aptos Labs. Aptos Labs will also observe the on-chain events
such as proposals per hour on your node, as defined in the liveness criteria.

# Latest Aptos Releases

> Find the latest Aptos releases for mainnet, testnet, and devnet with their corresponding GitHub branches

Each Aptos release can be found on the GitHub site for [Aptos-core releases](https://github.com/aptos-labs/aptos-core/releases).
Each release is mirrored by the following git branches:

- [Latest Mainnet Release](https://github.com/aptos-labs/aptos-core/tree/mainnet)
- [Latest Testnet Release](https://github.com/aptos-labs/aptos-core/tree/testnet)
- [Latest Devnet Release](https://github.com/aptos-labs/aptos-core/tree/devnet)

Aptos typically conducts multiple devnet releases for each testnet and mainnet
release. Hence, devnet releases use commit hashes for tracking rather than
version numbers. Testnet and mainnet releases usually have a one-to-one
correlation, meaning each testnet release rolls into mainnet.

Hot fixes are exceptions that may occur in mainnet to address urgent issues in
production. See the [Aptos Release Process](https://github.com/aptos-labs/aptos-core/blob/main/RELEASE.md)
for more details.

## Update nodes

If you are a node operator, [update your nodes with the new release](/network/nodes/full-node/modify/update-fullnode-with-new-releases).

## Subscribe to Release Announcements

### Subscribe via GitHub

1. Go to the [aptos-labs/aptos-core](https://github.com/aptos-labs/aptos-core)
   repository.
2. Open the **Watch** menu and select **Custom**.
3. Select the **Releases** checkbox and click **Apply**.

### Subscribe via [Aptos Discord](https://discord.gg/aptosnetwork)

Join the Aptos Discord server to interact with us and our community. We also post upcoming releases in these channels.

- [#mainnet-release](https://discord.com/channels/945856774056083548/1042502400507916349)
- [#testnet-release](https://discord.com/channels/945856774056083548/1025614160555413545)
- [#devnet-release](https://discord.com/channels/945856774056083548/956692649430093904)

### Subscribe via [Aptos Twitter](https://x.com/AptosRelease)

Follow [@AptosRelease](https://x.com/AptosRelease) on Twitter to get the latest updates about our upcoming
mainnet releases and be notified when it is time to update your node. Every
couple of days, [@AptosRelease](https://x.com/AptosRelease) will tweet a countdown to remind you to update to
the latest version. _Note: We do not post about hotfixes here!_

## Aptos Release Process

To understand how we conduct releases, review the [Aptos Release Process](https://github.com/aptos-labs/aptos-core/blob/main/RELEASE.md).

# 404

> Page not found. Check the URL or try using the search bar.

import Move404 from '@components/Move404/index.astro';

<Move404 />